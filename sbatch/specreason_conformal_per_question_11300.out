
CondaError: Run 'conda init' before 'conda activate'

Mon Aug 25 17:24:58 2025       
+-----------------------------------------------------------------------------------------+
| NVIDIA-SMI 550.54.14              Driver Version: 550.54.14      CUDA Version: 12.4     |
|-----------------------------------------+------------------------+----------------------+
| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |
| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |
|                                         |                        |               MIG M. |
|=========================================+========================+======================|
|   0  NVIDIA A100 80GB PCIe          Off |   00000000:4F:00.0 Off |                    0 |
| N/A   50C    P0            297W /  300W |   66763MiB /  81920MiB |     99%      Default |
|                                         |                        |             Disabled |
+-----------------------------------------+------------------------+----------------------+
|   1  NVIDIA A100 80GB PCIe          Off |   00000000:52:00.0 Off |                    0 |
| N/A   28C    P0             43W /  300W |       0MiB /  81920MiB |      0%      Default |
|                                         |                        |             Disabled |
+-----------------------------------------+------------------------+----------------------+
|   2  NVIDIA A100 80GB PCIe          Off |   00000000:56:00.0 Off |                    0 |
| N/A   27C    P0             63W /  300W |   43627MiB /  81920MiB |      0%      Default |
|                                         |                        |             Disabled |
+-----------------------------------------+------------------------+----------------------+
|   3  NVIDIA A100 80GB PCIe          Off |   00000000:57:00.0 Off |                    0 |
| N/A   27C    P0             44W /  300W |       0MiB /  81920MiB |      0%      Default |
|                                         |                        |             Disabled |
+-----------------------------------------+------------------------+----------------------+
|   4  NVIDIA A100 80GB PCIe          Off |   00000000:D5:00.0 Off |                    0 |
| N/A   28C    P0             42W /  300W |       0MiB /  81920MiB |      0%      Default |
|                                         |                        |             Disabled |
+-----------------------------------------+------------------------+----------------------+
                                                                                         
+-----------------------------------------------------------------------------------------+
| Processes:                                                                              |
|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |
|        ID   ID                                                               Usage      |
|=========================================================================================|
|    0   N/A  N/A   2223691      C   python                                      66754MiB |
|    2   N/A  N/A   2258570      C   /home/shenhui/miniconda3/bin/python         43618MiB |
+-----------------------------------------------------------------------------------------+
====================================================================================
Starting a new run with:
  - Small Model:     deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B
  - Eval Model:      Qwen/QwQ-32B
  - Dataset:         aime25
  - PPL Array Path:  /home/xiongjing/qj/sglang-parallel-test-time-scaling/ppls_aime25_64_qwq_32_r1_1_500_per_question.npy
====================================================================================
Starting SGLang server for small model (deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B)...
Small model server started with PID: 2367434
Starting SGLang server for evaluation model (Qwen/QwQ-32B)...
Evaluation model server started with PID: 2367435
Waiting for SGLang servers to be ready...
wait-for-it.sh: waiting 300 seconds for 0.0.0.0:40001
wait-for-it.sh: 0.0.0.0:40001 is available after 64 seconds
Small model server is up.
wait-for-it.sh: waiting 300 seconds for 0.0.0.0:40000
wait-for-it.sh: 0.0.0.0:40000 is available after 49 seconds
Evaluation model server is up.
Starting evaluation script...
Starting evaluation on dataset: aime25
Saving results to: /home/xiongjing/qj/sglang-parallel-test-time-scaling/ppls_aime25_64_qwq_32_r1_1_500_per_question.npy
Processing problems (max 16 concurrent):   0%|          | 0/240 [00:00<?, ?it/s]Processing problems (max 16 concurrent):   0%|          | 1/240 [00:06<26:43,  6.71s/it]Processing problems (max 16 concurrent):   1%|          | 2/240 [00:06<11:36,  2.93s/it]Processing problems (max 16 concurrent):   8%|▊         | 18/240 [00:12<02:02,  1.82it/s]Processing problems (max 16 concurrent):   8%|▊         | 19/240 [00:13<01:56,  1.90it/s]Processing problems (max 16 concurrent):  15%|█▍        | 35/240 [00:19<01:29,  2.30it/s]Processing problems (max 16 concurrent):  15%|█▌        | 36/240 [00:19<01:27,  2.34it/s]Processing problems (max 16 concurrent):  22%|██▏       | 52/240 [00:25<01:15,  2.50it/s]Processing problems (max 16 concurrent):  23%|██▎       | 55/240 [00:26<01:10,  2.64it/s]Processing problems (max 16 concurrent):  30%|██▉       | 71/240 [00:31<00:58,  2.87it/s]Processing problems (max 16 concurrent):  30%|███       | 73/240 [00:32<00:57,  2.88it/s]Processing problems (max 16 concurrent):  35%|███▌      | 84/240 [00:32<00:35,  4.41it/s]Processing problems (max 16 concurrent):  37%|███▋      | 89/240 [00:37<00:55,  2.74it/s]Processing problems (max 16 concurrent):  38%|███▊      | 90/240 [00:38<01:00,  2.46it/s]Processing problems (max 16 concurrent):  42%|████▏     | 100/240 [00:38<00:33,  4.18it/s]Processing problems (max 16 concurrent):  44%|████▍     | 106/240 [00:42<00:46,  2.89it/s]Processing problems (max 16 concurrent):  46%|████▌     | 110/240 [00:43<00:45,  2.89it/s]Processing problems (max 16 concurrent):  51%|█████     | 122/240 [00:44<00:27,  4.35it/s]Processing problems (max 16 concurrent):  52%|█████▎    | 126/240 [00:46<00:31,  3.65it/s]Processing problems (max 16 concurrent):  54%|█████▍    | 129/240 [00:47<00:33,  3.34it/s]Processing problems (max 16 concurrent):  55%|█████▌    | 132/240 [00:48<00:32,  3.32it/s]Processing problems (max 16 concurrent):  59%|█████▉    | 142/240 [00:49<00:19,  4.93it/s]Processing problems (max 16 concurrent):  60%|██████    | 145/240 [00:50<00:19,  4.76it/s]Processing problems (max 16 concurrent):  62%|██████▏   | 148/240 [00:53<00:33,  2.74it/s]Processing problems (max 16 concurrent):  64%|██████▍   | 154/240 [00:54<00:25,  3.31it/s]Processing problems (max 16 concurrent):  68%|██████▊   | 164/240 [00:57<00:23,  3.28it/s]Processing problems (max 16 concurrent):  71%|███████   | 170/240 [00:58<00:18,  3.72it/s]Processing problems (max 16 concurrent):  75%|███████▌  | 180/240 [01:02<00:17,  3.37it/s]Processing problems (max 16 concurrent):  77%|███████▋  | 185/240 [01:03<00:15,  3.53it/s]Processing problems (max 16 concurrent):  82%|████████▏ | 196/240 [01:05<00:10,  4.25it/s]Processing problems (max 16 concurrent):  82%|████████▏ | 197/240 [01:06<00:12,  3.43it/s]Processing problems (max 16 concurrent):  84%|████████▍ | 201/240 [01:07<00:11,  3.42it/s]Processing problems (max 16 concurrent):  86%|████████▋ | 207/240 [01:08<00:06,  4.75it/s]Processing problems (max 16 concurrent):  89%|████████▉ | 213/240 [01:09<00:05,  4.77it/s]Processing problems (max 16 concurrent):  90%|█████████ | 217/240 [01:12<00:08,  2.85it/s]Processing problems (max 16 concurrent):  93%|█████████▎| 223/240 [01:13<00:04,  3.55it/s]Processing problems (max 16 concurrent):  97%|█████████▋| 233/240 [01:15<00:01,  3.91it/s]Processing problems (max 16 concurrent): 100%|██████████| 240/240 [01:15<00:00,  3.17it/s]
PPL统计信息:
原始问题 0: 16 个校准样本, PPL范围: [1.3010, 1.7121]
原始问题 1: 16 个校准样本, PPL范围: [1.5891, 2.1410]
原始问题 2: 16 个校准样本, PPL范围: [1.5952, 2.4472]
原始问题 3: 16 个校准样本, PPL范围: [1.3634, 2.0272]
原始问题 4: 16 个校准样本, PPL范围: [1.3047, 1.8526]
原始问题 5: 16 个校准样本, PPL范围: [1.4465, 1.8067]
原始问题 6: 16 个校准样本, PPL范围: [1.9774, 2.7547]
原始问题 7: 16 个校准样本, PPL范围: [1.3041, 1.7968]
原始问题 8: 16 个校准样本, PPL范围: [1.3390, 1.9731]
原始问题 9: 16 个校准样本, PPL范围: [1.9324, 2.8750]
原始问题 10: 16 个校准样本, PPL范围: [1.4793, 2.3645]
原始问题 11: 16 个校准样本, PPL范围: [1.4088, 2.1101]
原始问题 12: 16 个校准样本, PPL范围: [2.1547, 2.9163]
原始问题 13: 16 个校准样本, PPL范围: [1.6947, 2.1584]
原始问题 14: 16 个校准样本, PPL范围: [1.7577, 2.1881]
Elapsed time: 75.670779 seconds
Evaluation script for this run finished successfully.
Killing SGLang servers with PIDs: 2367434 and 2367435...
suite_conformal_per_question.sh: line 60: 2367434 Killed                  CUDA_VISIBLE_DEVICES=$SMALL_MODEL_DEVICE python3 -m sglang.launch_server --model-path "$SMALL_MODEL" --tp 1 --mem-fraction-static 0.9 --host "$SGLANG_HOST" --port "$SMALL_MODEL_PORT" > "$SMALL_MODEL_LOG" 2>&1
suite_conformal_per_question.sh: line 60: 2367435 Killed                  CUDA_VISIBLE_DEVICES=$EVAL_MODEL_DEVICES python3 -m sglang.launch_server --model-path "$EVAL_MODEL" --tp 2 --mem-fraction-static 0.9 --host "$SGLANG_HOST" --port "$EVAL_MODEL_PORT" > "$EVAL_MODEL_LOG" 2>&1
All evaluation runs have been completed.
