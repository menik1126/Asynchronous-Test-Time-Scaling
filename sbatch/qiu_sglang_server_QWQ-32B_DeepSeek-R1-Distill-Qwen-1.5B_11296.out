Mon Aug 25 14:47:35 2025       
+-----------------------------------------------------------------------------------------+
| NVIDIA-SMI 550.54.14              Driver Version: 550.54.14      CUDA Version: 12.4     |
|-----------------------------------------+------------------------+----------------------+
| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |
| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |
|                                         |                        |               MIG M. |
|=========================================+========================+======================|
|   0  NVIDIA A100 80GB PCIe          Off |   00000000:4F:00.0 Off |                    0 |
| N/A   46C    P0             89W /  300W |   66761MiB /  81920MiB |     81%      Default |
|                                         |                        |             Disabled |
+-----------------------------------------+------------------------+----------------------+
|   1  NVIDIA A100 80GB PCIe          Off |   00000000:52:00.0 Off |                    0 |
| N/A   26C    P0             43W /  300W |       0MiB /  81920MiB |      0%      Default |
|                                         |                        |             Disabled |
+-----------------------------------------+------------------------+----------------------+
|   2  NVIDIA A100 80GB PCIe          Off |   00000000:56:00.0 Off |                    0 |
| N/A   26C    P0             63W /  300W |   43627MiB /  81920MiB |      0%      Default |
|                                         |                        |             Disabled |
+-----------------------------------------+------------------------+----------------------+
|   3  NVIDIA A100 80GB PCIe          Off |   00000000:57:00.0 Off |                    0 |
| N/A   26C    P0             43W /  300W |       0MiB /  81920MiB |      0%      Default |
|                                         |                        |             Disabled |
+-----------------------------------------+------------------------+----------------------+
|   4  NVIDIA A100 80GB PCIe          Off |   00000000:D5:00.0 Off |                    0 |
| N/A   27C    P0             42W /  300W |       0MiB /  81920MiB |      0%      Default |
|                                         |                        |             Disabled |
+-----------------------------------------+------------------------+----------------------+
                                                                                         
+-----------------------------------------------------------------------------------------+
| Processes:                                                                              |
|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |
|        ID   ID                                                               Usage      |
|=========================================================================================|
|    0   N/A  N/A   2223691      C   python                                      66752MiB |
|    2   N/A  N/A   2258570      C   /home/shenhui/miniconda3/bin/python         43618MiB |
+-----------------------------------------------------------------------------------------+
/home/xiongjing
Waiting for server on port 40000 to start...
INFO 08-25 14:47:45 __init__.py:190] Automatically detected platform cuda.
INFO 08-25 14:47:45 __init__.py:190] Automatically detected platform cuda.
Waiting for server on port 40000 to start...
[2025-08-25 14:47:48] server_args=ServerArgs(model_path='Qwen/QwQ-32B', tokenizer_path='Qwen/QwQ-32B', tokenizer_mode='auto', skip_tokenizer_init=False, load_format='auto', trust_remote_code=False, dtype='auto', kv_cache_dtype='auto', quantization=None, quantization_param_path=None, context_length=None, device='cuda', served_model_name='Qwen/QwQ-32B', chat_template=None, is_embedding=False, revision=None, host='0.0.0.0', port=40000, mem_fraction_static=0.9, max_running_requests=None, max_total_tokens=None, chunked_prefill_size=8192, max_prefill_tokens=16384, schedule_policy='fcfs', schedule_conservativeness=1.0, cpu_offload_gb=0, tp_size=1, stream_interval=1, stream_output=False, random_seed=918132188, constrained_json_whitespace_pattern=None, watchdog_timeout=300, dist_timeout=None, download_dir=None, base_gpu_id=0, gpu_id_step=1, log_level='info', log_level_http=None, log_requests=False, log_requests_level=0, show_time_cost=False, enable_metrics=False, decode_log_interval=40, api_key=None, file_storage_path='sglang_storage', enable_cache_report=False, reasoning_parser=None, dp_size=1, load_balance_method='round_robin', ep_size=1, dist_init_addr=None, nnodes=1, node_rank=0, json_model_override_args='{}', lora_paths=None, max_loras_per_batch=8, lora_backend='triton', attention_backend='flashinfer', sampling_backend='flashinfer', grammar_backend='outlines', speculative_algorithm=None, speculative_draft_model_path=None, speculative_num_steps=5, speculative_eagle_topk=4, speculative_num_draft_tokens=8, speculative_accept_threshold_single=1.0, speculative_accept_threshold_acc=1.0, speculative_token_map=None, enable_double_sparsity=False, ds_channel_config_path=None, ds_heavy_channel_num=32, ds_heavy_token_num=256, ds_heavy_channel_type='qk', ds_sparse_decode_threshold=4096, disable_radix_cache=False, disable_cuda_graph=False, disable_cuda_graph_padding=False, enable_nccl_nvls=False, disable_outlines_disk_cache=False, disable_custom_all_reduce=False, disable_mla=False, disable_overlap_schedule=False, enable_mixed_chunk=False, enable_dp_attention=False, enable_ep_moe=False, enable_torch_compile=False, torch_compile_max_bs=32, cuda_graph_max_bs=160, cuda_graph_bs=None, torchao_config='', enable_nan_detection=False, enable_p2p_check=False, triton_attention_reduce_in_fp32=False, triton_attention_num_kv_splits=8, num_continuous_decode_steps=1, delete_ckpt_after_loading=False, enable_memory_saver=False, allow_auto_truncate=False, enable_custom_logit_processor=False, tool_call_parser=None, enable_hierarchical_cache=False, enable_flashinfer_mla=False, flashinfer_mla_disable_ragged=False, warmups=None, debug_tensor_dump_output_folder=None, debug_tensor_dump_input_file=None, debug_tensor_dump_inject=False)
[2025-08-25 14:47:48] server_args=ServerArgs(model_path='deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B', tokenizer_path='deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B', tokenizer_mode='auto', skip_tokenizer_init=False, load_format='auto', trust_remote_code=False, dtype='auto', kv_cache_dtype='auto', quantization=None, quantization_param_path=None, context_length=None, device='cuda', served_model_name='deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B', chat_template=None, is_embedding=False, revision=None, host='0.0.0.0', port=40001, mem_fraction_static=0.9, max_running_requests=None, max_total_tokens=None, chunked_prefill_size=8192, max_prefill_tokens=16384, schedule_policy='fcfs', schedule_conservativeness=1.0, cpu_offload_gb=0, tp_size=1, stream_interval=1, stream_output=False, random_seed=1059835114, constrained_json_whitespace_pattern=None, watchdog_timeout=300, dist_timeout=None, download_dir=None, base_gpu_id=0, gpu_id_step=1, log_level='info', log_level_http=None, log_requests=False, log_requests_level=0, show_time_cost=False, enable_metrics=False, decode_log_interval=40, api_key=None, file_storage_path='sglang_storage', enable_cache_report=False, reasoning_parser=None, dp_size=1, load_balance_method='round_robin', ep_size=1, dist_init_addr=None, nnodes=1, node_rank=0, json_model_override_args='{}', lora_paths=None, max_loras_per_batch=8, lora_backend='triton', attention_backend='flashinfer', sampling_backend='flashinfer', grammar_backend='outlines', speculative_algorithm=None, speculative_draft_model_path=None, speculative_num_steps=5, speculative_eagle_topk=4, speculative_num_draft_tokens=8, speculative_accept_threshold_single=1.0, speculative_accept_threshold_acc=1.0, speculative_token_map=None, enable_double_sparsity=False, ds_channel_config_path=None, ds_heavy_channel_num=32, ds_heavy_token_num=256, ds_heavy_channel_type='qk', ds_sparse_decode_threshold=4096, disable_radix_cache=False, disable_cuda_graph=False, disable_cuda_graph_padding=False, enable_nccl_nvls=False, disable_outlines_disk_cache=False, disable_custom_all_reduce=False, disable_mla=False, disable_overlap_schedule=False, enable_mixed_chunk=False, enable_dp_attention=False, enable_ep_moe=False, enable_torch_compile=False, torch_compile_max_bs=32, cuda_graph_max_bs=160, cuda_graph_bs=None, torchao_config='', enable_nan_detection=False, enable_p2p_check=False, triton_attention_reduce_in_fp32=False, triton_attention_num_kv_splits=8, num_continuous_decode_steps=1, delete_ckpt_after_loading=False, enable_memory_saver=False, allow_auto_truncate=False, enable_custom_logit_processor=False, tool_call_parser=None, enable_hierarchical_cache=False, enable_flashinfer_mla=False, flashinfer_mla_disable_ragged=False, warmups=None, debug_tensor_dump_output_folder=None, debug_tensor_dump_input_file=None, debug_tensor_dump_inject=False)
Waiting for server on port 40000 to start...
INFO 08-25 14:48:03 __init__.py:190] Automatically detected platform cuda.
INFO 08-25 14:48:03 __init__.py:190] Automatically detected platform cuda.
INFO 08-25 14:48:03 __init__.py:190] Automatically detected platform cuda.
INFO 08-25 14:48:03 __init__.py:190] Automatically detected platform cuda.
Waiting for server on port 40000 to start...
Waiting for server on port 40000 to start...
[2025-08-25 14:48:21 TP0] Init torch distributed begin.
[2025-08-25 14:48:21 TP0] Init torch distributed begin.
[2025-08-25 14:48:21 TP0] Init torch distributed ends. mem usage=0.00 GB
[2025-08-25 14:48:21 TP0] Load weight begin. avail mem=78.73 GB
[2025-08-25 14:48:21 TP0] Init torch distributed ends. mem usage=0.00 GB
[2025-08-25 14:48:21 TP0] Load weight begin. avail mem=78.73 GB
[2025-08-25 14:48:21 TP0] The following error message 'operation scheduled before its operands' can be ignored.
[2025-08-25 14:48:22 TP0] The following error message 'operation scheduled before its operands' can be ignored.
[2025-08-25 14:48:22 TP0] Using model weights format ['*.safetensors']
[2025-08-25 14:48:22 TP0] Using model weights format ['*.safetensors']
[2025-08-25 14:48:23 TP0] No model.safetensors.index.json found in remote.
Loading safetensors checkpoint shards:   0% Completed | 0/1 [00:00<?, ?it/s]
Loading safetensors checkpoint shards:   0% Completed | 0/14 [00:00<?, ?it/s]
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:00<00:00,  1.15it/s]
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:00<00:00,  1.15it/s]

[2025-08-25 14:48:24 TP0] Load weight end. type=Qwen2ForCausalLM, dtype=torch.bfloat16, avail mem=75.14 GB, mem usage=3.58 GB.
[2025-08-25 14:48:24 TP0] KV Cache is allocated. #tokens: 2519168, K size: 33.63 GB, V size: 33.63 GB
[2025-08-25 14:48:24 TP0] Memory pool end. avail mem=5.76 GB
Loading safetensors checkpoint shards:   7% Completed | 1/14 [00:01<00:14,  1.09s/it]
[2025-08-25 14:48:24 TP0] Capture cuda graph begin. This can take up to several minutes. avail mem=5.15 GB
  0%|          | 0/23 [00:00<?, ?it/s]Loading safetensors checkpoint shards:  14% Completed | 2/14 [00:02<00:14,  1.21s/it]
  4%|▍         | 1/23 [00:01<00:34,  1.56s/it]  9%|▊         | 2/23 [00:02<00:18,  1.11it/s]Loading safetensors checkpoint shards:  21% Completed | 3/14 [00:03<00:14,  1.28s/it]
 13%|█▎        | 3/23 [00:02<00:13,  1.44it/s] 17%|█▋        | 4/23 [00:02<00:11,  1.69it/s]Waiting for server on port 40000 to start...
 22%|██▏       | 5/23 [00:03<00:09,  1.85it/s] 26%|██▌       | 6/23 [00:03<00:08,  1.96it/s]Loading safetensors checkpoint shards:  29% Completed | 4/14 [00:05<00:13,  1.33s/it]
 30%|███       | 7/23 [00:04<00:07,  2.10it/s] 35%|███▍      | 8/23 [00:04<00:07,  2.14it/s] 39%|███▉      | 9/23 [00:05<00:06,  2.15it/s]Loading safetensors checkpoint shards:  36% Completed | 5/14 [00:06<00:12,  1.35s/it]
 43%|████▎     | 10/23 [00:05<00:05,  2.23it/s] 48%|████▊     | 11/23 [00:05<00:05,  2.23it/s] 52%|█████▏    | 12/23 [00:06<00:04,  2.22it/s]Loading safetensors checkpoint shards:  43% Completed | 6/14 [00:07<00:10,  1.36s/it]
 57%|█████▋    | 13/23 [00:06<00:04,  2.26it/s] 61%|██████    | 14/23 [00:07<00:03,  2.26it/s] 65%|██████▌   | 15/23 [00:07<00:03,  2.25it/s]Loading safetensors checkpoint shards:  50% Completed | 7/14 [00:09<00:09,  1.37s/it]
 70%|██████▉   | 16/23 [00:08<00:03,  2.25it/s] 74%|███████▍  | 17/23 [00:08<00:02,  2.26it/s] 78%|███████▊  | 18/23 [00:09<00:02,  2.23it/s]Loading safetensors checkpoint shards:  57% Completed | 8/14 [00:10<00:08,  1.38s/it]
 83%|████████▎ | 19/23 [00:09<00:01,  2.24it/s] 87%|████████▋ | 20/23 [00:09<00:01,  2.26it/s] 91%|█████████▏| 21/23 [00:10<00:00,  2.23it/s]Loading safetensors checkpoint shards:  64% Completed | 9/14 [00:12<00:06,  1.39s/it]
 96%|█████████▌| 22/23 [00:10<00:00,  2.23it/s]100%|██████████| 23/23 [00:11<00:00,  2.27it/s]100%|██████████| 23/23 [00:11<00:00,  2.04it/s]
[2025-08-25 14:48:36 TP0] Capture cuda graph end. Time elapsed: 11.29 s. avail mem=3.21 GB. mem usage=1.94 GB.
Loading safetensors checkpoint shards:  71% Completed | 10/14 [00:13<00:05,  1.36s/it]
[2025-08-25 14:48:36 TP0] max_total_num_tokens=2519168, chunked_prefill_size=8192, max_prefill_tokens=16384, max_running_requests=4097, context_len=131072
[2025-08-25 14:48:37] INFO:     Started server process [2310654]
[2025-08-25 14:48:37] INFO:     Waiting for application startup.
[2025-08-25 14:48:37] INFO:     Application startup complete.
[2025-08-25 14:48:37] INFO:     Uvicorn running on http://0.0.0.0:40001 (Press CTRL+C to quit)
Loading safetensors checkpoint shards:  79% Completed | 11/14 [00:14<00:03,  1.17s/it]
Waiting for server on port 40000 to start...
[2025-08-25 14:48:38] INFO:     127.0.0.1:20882 - "GET /get_model_info HTTP/1.1" 200 OK
[2025-08-25 14:48:38 TP0] Prefill batch. #new-seq: 1, #new-token: 7, #cached-token: 0, token usage: 0.00, #running-req: 0, #queue-req: 0, 
Loading safetensors checkpoint shards:  86% Completed | 12/14 [00:15<00:02,  1.17s/it]
[2025-08-25 14:48:39] INFO:     127.0.0.1:20892 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 14:48:39] The server is fired up and ready to roll!
Loading safetensors checkpoint shards:  93% Completed | 13/14 [00:16<00:01,  1.21s/it]
Loading safetensors checkpoint shards: 100% Completed | 14/14 [00:17<00:00,  1.24s/it]
Loading safetensors checkpoint shards: 100% Completed | 14/14 [00:17<00:00,  1.28s/it]

[2025-08-25 14:48:41 TP0] Load weight end. type=Qwen2ForCausalLM, dtype=torch.bfloat16, avail mem=17.60 GB, mem usage=61.12 GB.
[2025-08-25 14:48:41 TP0] KV Cache is allocated. #tokens: 39846, K size: 4.86 GB, V size: 4.86 GB
[2025-08-25 14:48:41 TP0] Memory pool end. avail mem=7.54 GB
[2025-08-25 14:48:41 TP0] Capture cuda graph begin. This can take up to several minutes. avail mem=6.90 GB
  0%|          | 0/23 [00:00<?, ?it/s]  4%|▍         | 1/23 [00:01<00:32,  1.49s/it]  9%|▊         | 2/23 [00:01<00:18,  1.12it/s] 13%|█▎        | 3/23 [00:02<00:13,  1.44it/s] 17%|█▋        | 4/23 [00:02<00:11,  1.64it/s] 22%|██▏       | 5/23 [00:03<00:10,  1.78it/s] 26%|██▌       | 6/23 [00:03<00:08,  1.89it/s] 30%|███       | 7/23 [00:04<00:08,  1.96it/s] 35%|███▍      | 8/23 [00:04<00:07,  1.97it/s] 39%|███▉      | 9/23 [00:05<00:06,  2.01it/s] 43%|████▎     | 10/23 [00:05<00:06,  2.02it/s]Waiting for server on port 40000 to start...
 48%|████▊     | 11/23 [00:06<00:06,  2.00it/s] 52%|█████▏    | 12/23 [00:06<00:05,  2.01it/s] 57%|█████▋    | 13/23 [00:07<00:05,  1.94it/s] 61%|██████    | 14/23 [00:07<00:04,  1.94it/s] 65%|██████▌   | 15/23 [00:08<00:04,  1.96it/s] 70%|██████▉   | 16/23 [00:08<00:03,  1.96it/s] 74%|███████▍  | 17/23 [00:09<00:03,  1.96it/s] 78%|███████▊  | 18/23 [00:09<00:02,  1.95it/s] 83%|████████▎ | 19/23 [00:10<00:02,  1.95it/s] 87%|████████▋ | 20/23 [00:10<00:01,  1.91it/s] 91%|█████████▏| 21/23 [00:11<00:01,  1.89it/s] 96%|█████████▌| 22/23 [00:12<00:00,  1.87it/s]100%|██████████| 23/23 [00:12<00:00,  1.86it/s]100%|██████████| 23/23 [00:12<00:00,  1.83it/s]
[2025-08-25 14:48:54 TP0] Capture cuda graph end. Time elapsed: 12.61 s. avail mem=4.93 GB. mem usage=1.97 GB.
[2025-08-25 14:48:55 TP0] max_total_num_tokens=39846, chunked_prefill_size=8192, max_prefill_tokens=16384, max_running_requests=2049, context_len=40960
[2025-08-25 14:48:55] INFO:     Started server process [2310653]
[2025-08-25 14:48:55] INFO:     Waiting for application startup.
[2025-08-25 14:48:55] INFO:     Application startup complete.
[2025-08-25 14:48:55] INFO:     Uvicorn running on http://0.0.0.0:40000 (Press CTRL+C to quit)
[2025-08-25 14:48:56] INFO:     127.0.0.1:30924 - "GET /get_model_info HTTP/1.1" 200 OK
[2025-08-25 14:48:56 TP0] Prefill batch. #new-seq: 1, #new-token: 6, #cached-token: 0, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-08-25 14:48:57] INFO:     127.0.0.1:30930 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 14:48:57] The server is fired up and ready to roll!
[2025-08-25 14:48:57] INFO:     127.0.0.1:30942 - "GET /get_model_info HTTP/1.1" 200 OK
Server on port 40000 is ready!
[2025-08-25 14:48:57] INFO:     127.0.0.1:1364 - "GET /get_model_info HTTP/1.1" 200 OK
Server on port 40001 is ready!
[2025-08-25 14:51:26 TP0] Prefill batch. #new-seq: 8, #new-token: 656, #cached-token: 8, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-08-25 14:51:26 TP0] Decode batch. #running-req: 8, #token: 347, token usage: 0.00, gen throughput (token/s): 1.55, largest-len: 0, #queue-req: 0, 
[2025-08-25 14:51:27 TP0] Decode batch. #running-req: 8, #token: 667, token usage: 0.00, gen throughput (token/s): 1726.84, largest-len: 0, #queue-req: 0, 
[2025-08-25 14:51:27 TP0] Decode batch. #running-req: 8, #token: 987, token usage: 0.00, gen throughput (token/s): 1696.11, largest-len: 0, #queue-req: 0, 
[2025-08-25 14:51:27 TP0] Decode batch. #running-req: 8, #token: 1307, token usage: 0.00, gen throughput (token/s): 1676.80, largest-len: 0, #queue-req: 0, 
[2025-08-25 14:51:27 TP0] Decode batch. #running-req: 8, #token: 1627, token usage: 0.00, gen throughput (token/s): 1704.89, largest-len: 0, #queue-req: 0, 
[2025-08-25 14:51:27 TP0] Decode batch. #running-req: 8, #token: 1947, token usage: 0.00, gen throughput (token/s): 1637.00, largest-len: 0, #queue-req: 0, 
[2025-08-25 14:51:28 TP0] Decode batch. #running-req: 8, #token: 2267, token usage: 0.00, gen throughput (token/s): 1602.61, largest-len: 0, #queue-req: 0, 
[2025-08-25 14:51:28 TP0] Decode batch. #running-req: 8, #token: 2587, token usage: 0.00, gen throughput (token/s): 1636.38, largest-len: 0, #queue-req: 0, 
[2025-08-25 14:51:28 TP0] Decode batch. #running-req: 8, #token: 2907, token usage: 0.00, gen throughput (token/s): 1671.38, largest-len: 0, #queue-req: 0, 
[2025-08-25 14:51:28 TP0] Decode batch. #running-req: 8, #token: 3227, token usage: 0.00, gen throughput (token/s): 1697.19, largest-len: 0, #queue-req: 0, 
[2025-08-25 14:51:28 TP0] Decode batch. #running-req: 8, #token: 3547, token usage: 0.00, gen throughput (token/s): 1701.95, largest-len: 0, #queue-req: 0, 
[2025-08-25 14:51:29 TP0] Decode batch. #running-req: 8, #token: 3867, token usage: 0.00, gen throughput (token/s): 1724.73, largest-len: 0, #queue-req: 0, 
[2025-08-25 14:51:29] INFO:     127.0.0.1:16732 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 14:51:29] INFO:     127.0.0.1:16734 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 14:51:29] INFO:     127.0.0.1:16748 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 14:51:29] INFO:     127.0.0.1:16754 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 14:51:29] INFO:     127.0.0.1:16758 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 14:51:29] INFO:     127.0.0.1:16774 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 14:51:29] INFO:     127.0.0.1:16786 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 14:51:29] INFO:     127.0.0.1:16802 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 14:51:29 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 82, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-08-25 14:51:29 TP0] Prefill batch. #new-seq: 7, #new-token: 7, #cached-token: 574, token usage: 0.00, #running-req: 1, #queue-req: 0, 
[2025-08-25 14:51:29 TP0] Decode batch. #running-req: 8, #token: 187, token usage: 0.00, gen throughput (token/s): 1061.07, largest-len: 0, #queue-req: 0, 
[2025-08-25 14:51:29 TP0] Decode batch. #running-req: 8, #token: 507, token usage: 0.00, gen throughput (token/s): 1814.61, largest-len: 0, #queue-req: 0, 
[2025-08-25 14:51:29 TP0] Decode batch. #running-req: 8, #token: 827, token usage: 0.00, gen throughput (token/s): 1718.86, largest-len: 0, #queue-req: 0, 
[2025-08-25 14:51:29 TP0] Decode batch. #running-req: 8, #token: 1147, token usage: 0.00, gen throughput (token/s): 1758.61, largest-len: 0, #queue-req: 0, 
[2025-08-25 14:51:30 TP0] Decode batch. #running-req: 8, #token: 1467, token usage: 0.00, gen throughput (token/s): 1776.77, largest-len: 0, #queue-req: 0, 
[2025-08-25 14:51:30 TP0] Decode batch. #running-req: 8, #token: 1787, token usage: 0.00, gen throughput (token/s): 1758.15, largest-len: 0, #queue-req: 0, 
[2025-08-25 14:51:30 TP0] Decode batch. #running-req: 8, #token: 2107, token usage: 0.00, gen throughput (token/s): 1732.52, largest-len: 0, #queue-req: 0, 
[2025-08-25 14:51:30 TP0] Decode batch. #running-req: 8, #token: 2427, token usage: 0.00, gen throughput (token/s): 1721.48, largest-len: 0, #queue-req: 0, 
[2025-08-25 14:51:30 TP0] Decode batch. #running-req: 8, #token: 2747, token usage: 0.00, gen throughput (token/s): 1725.68, largest-len: 0, #queue-req: 0, 
[2025-08-25 14:51:30 TP0] Decode batch. #running-req: 8, #token: 3067, token usage: 0.00, gen throughput (token/s): 1718.71, largest-len: 0, #queue-req: 0, 
[2025-08-25 14:51:31 TP0] Decode batch. #running-req: 8, #token: 3387, token usage: 0.00, gen throughput (token/s): 1724.60, largest-len: 0, #queue-req: 0, 
[2025-08-25 14:51:31 TP0] Decode batch. #running-req: 8, #token: 3707, token usage: 0.00, gen throughput (token/s): 1731.12, largest-len: 0, #queue-req: 0, 
[2025-08-25 14:51:31 TP0] Decode batch. #running-req: 8, #token: 4027, token usage: 0.00, gen throughput (token/s): 1748.47, largest-len: 0, #queue-req: 0, 
[2025-08-25 14:51:31] INFO:     127.0.0.1:16732 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 14:51:31] INFO:     127.0.0.1:16734 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 14:51:31] INFO:     127.0.0.1:16748 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 14:51:31] INFO:     127.0.0.1:16754 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 14:51:31] INFO:     127.0.0.1:16758 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 14:51:31] INFO:     127.0.0.1:16774 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 14:51:31] INFO:     127.0.0.1:16786 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 14:51:31] INFO:     127.0.0.1:16802 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 14:51:31 TP0] Prefill batch. #new-seq: 1, #new-token: 572, #cached-token: 0, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-08-25 14:51:31 TP0] Prefill batch. #new-seq: 7, #new-token: 4004, #cached-token: 0, token usage: 0.01, #running-req: 1, #queue-req: 0, 
[2025-08-25 14:51:33] INFO:     127.0.0.1:43436 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 14:51:33] INFO:     127.0.0.1:43444 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 14:51:33] INFO:     127.0.0.1:43452 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 14:51:33] INFO:     127.0.0.1:43458 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 14:51:33] INFO:     127.0.0.1:43466 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 14:51:33] INFO:     127.0.0.1:43482 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 14:51:33] INFO:     127.0.0.1:43484 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 14:51:33] INFO:     127.0.0.1:43486 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 14:51:33 TP0] Prefill batch. #new-seq: 1, #new-token: 500, #cached-token: 72, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-08-25 14:51:33 TP0] Prefill batch. #new-seq: 7, #new-token: 3500, #cached-token: 504, token usage: 0.00, #running-req: 1, #queue-req: 0, 
[2025-08-25 14:51:33] INFO:     127.0.0.1:43436 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 14:51:34] INFO:     127.0.0.1:43458 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 14:51:34] INFO:     127.0.0.1:43444 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 14:51:34] INFO:     127.0.0.1:43452 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 14:51:34] INFO:     127.0.0.1:43466 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 14:51:34] INFO:     127.0.0.1:43482 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 14:51:34] INFO:     127.0.0.1:43484 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 14:51:34] INFO:     127.0.0.1:43486 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 14:51:34 TP0] Prefill batch. #new-seq: 1, #new-token: 162, #cached-token: 50, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-08-25 14:51:34 TP0] Prefill batch. #new-seq: 7, #new-token: 1134, #cached-token: 350, token usage: 0.00, #running-req: 1, #queue-req: 0, 
[2025-08-25 14:51:35 TP0] Decode batch. #running-req: 8, #token: 476, token usage: 0.00, gen throughput (token/s): 91.24, largest-len: 0, #queue-req: 0, 
[2025-08-25 14:51:35 TP0] Decode batch. #running-req: 8, #token: 796, token usage: 0.00, gen throughput (token/s): 1548.90, largest-len: 0, #queue-req: 0, 
[2025-08-25 14:51:35 TP0] Decode batch. #running-req: 8, #token: 1116, token usage: 0.00, gen throughput (token/s): 1737.57, largest-len: 0, #queue-req: 0, 
[2025-08-25 14:51:35 TP0] Decode batch. #running-req: 8, #token: 1436, token usage: 0.00, gen throughput (token/s): 1713.55, largest-len: 0, #queue-req: 0, 
[2025-08-25 14:51:35 TP0] Decode batch. #running-req: 8, #token: 1756, token usage: 0.00, gen throughput (token/s): 1747.48, largest-len: 0, #queue-req: 0, 
[2025-08-25 14:51:35 TP0] Decode batch. #running-req: 8, #token: 2076, token usage: 0.00, gen throughput (token/s): 1789.22, largest-len: 0, #queue-req: 0, 
[2025-08-25 14:51:36 TP0] Decode batch. #running-req: 8, #token: 2396, token usage: 0.00, gen throughput (token/s): 1831.18, largest-len: 0, #queue-req: 0, 
[2025-08-25 14:51:36 TP0] Decode batch. #running-req: 8, #token: 2716, token usage: 0.00, gen throughput (token/s): 1839.47, largest-len: 0, #queue-req: 0, 
[2025-08-25 14:51:36 TP0] Decode batch. #running-req: 8, #token: 3036, token usage: 0.00, gen throughput (token/s): 1869.03, largest-len: 0, #queue-req: 0, 
[2025-08-25 14:51:36 TP0] Decode batch. #running-req: 8, #token: 3356, token usage: 0.00, gen throughput (token/s): 1836.41, largest-len: 0, #queue-req: 0, 
[2025-08-25 14:51:36 TP0] Decode batch. #running-req: 8, #token: 3676, token usage: 0.00, gen throughput (token/s): 1792.38, largest-len: 0, #queue-req: 0, 
[2025-08-25 14:51:37 TP0] Decode batch. #running-req: 8, #token: 3996, token usage: 0.00, gen throughput (token/s): 1763.89, largest-len: 0, #queue-req: 0, 
[2025-08-25 14:51:37] INFO:     127.0.0.1:16732 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 14:51:37] INFO:     127.0.0.1:16734 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 14:51:37] INFO:     127.0.0.1:16748 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 14:51:37] INFO:     127.0.0.1:16754 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 14:51:37] INFO:     127.0.0.1:16758 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 14:51:37] INFO:     127.0.0.1:16774 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 14:51:37] INFO:     127.0.0.1:16786 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 14:51:37] INFO:     127.0.0.1:16802 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 14:51:37 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 211, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-08-25 14:51:37 TP0] Prefill batch. #new-seq: 7, #new-token: 7, #cached-token: 1477, token usage: 0.00, #running-req: 1, #queue-req: 0, 
[2025-08-25 14:51:37 TP0] Decode batch. #running-req: 8, #token: 316, token usage: 0.00, gen throughput (token/s): 1034.39, largest-len: 0, #queue-req: 0, 
[2025-08-25 14:51:37 TP0] Decode batch. #running-req: 8, #token: 636, token usage: 0.00, gen throughput (token/s): 1659.07, largest-len: 0, #queue-req: 0, 
[2025-08-25 14:51:37 TP0] Decode batch. #running-req: 8, #token: 956, token usage: 0.00, gen throughput (token/s): 1728.60, largest-len: 0, #queue-req: 0, 
[2025-08-25 14:51:37 TP0] Decode batch. #running-req: 8, #token: 1276, token usage: 0.00, gen throughput (token/s): 1713.42, largest-len: 0, #queue-req: 0, 
[2025-08-25 14:51:38 TP0] Decode batch. #running-req: 8, #token: 1596, token usage: 0.00, gen throughput (token/s): 1711.18, largest-len: 0, #queue-req: 0, 
[2025-08-25 14:51:38 TP0] Decode batch. #running-req: 8, #token: 1916, token usage: 0.00, gen throughput (token/s): 1688.56, largest-len: 0, #queue-req: 0, 
[2025-08-25 14:51:38 TP0] Decode batch. #running-req: 8, #token: 2236, token usage: 0.00, gen throughput (token/s): 1718.08, largest-len: 0, #queue-req: 0, 
[2025-08-25 14:51:38 TP0] Decode batch. #running-req: 8, #token: 2556, token usage: 0.00, gen throughput (token/s): 1744.48, largest-len: 0, #queue-req: 0, 
[2025-08-25 14:51:38 TP0] Decode batch. #running-req: 8, #token: 2876, token usage: 0.00, gen throughput (token/s): 1771.33, largest-len: 0, #queue-req: 0, 
[2025-08-25 14:51:39 TP0] Decode batch. #running-req: 8, #token: 3196, token usage: 0.00, gen throughput (token/s): 1750.07, largest-len: 0, #queue-req: 0, 
[2025-08-25 14:51:39 TP0] Decode batch. #running-req: 8, #token: 3516, token usage: 0.00, gen throughput (token/s): 1679.26, largest-len: 0, #queue-req: 0, 
[2025-08-25 14:51:39 TP0] Decode batch. #running-req: 8, #token: 3836, token usage: 0.00, gen throughput (token/s): 1665.08, largest-len: 0, #queue-req: 0, 
[2025-08-25 14:51:39 TP0] Decode batch. #running-req: 8, #token: 4156, token usage: 0.00, gen throughput (token/s): 1710.72, largest-len: 0, #queue-req: 0, 
[2025-08-25 14:51:39] INFO:     127.0.0.1:16732 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 14:51:39] INFO:     127.0.0.1:16734 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 14:51:39] INFO:     127.0.0.1:16748 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 14:51:39] INFO:     127.0.0.1:16754 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 14:51:39] INFO:     127.0.0.1:16758 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 14:51:39] INFO:     127.0.0.1:16774 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 14:51:39] INFO:     127.0.0.1:16786 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 14:51:39] INFO:     127.0.0.1:16802 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 14:51:39 TP0] Prefill batch. #new-seq: 1, #new-token: 659, #cached-token: 42, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-08-25 14:51:39 TP0] Prefill batch. #new-seq: 5, #new-token: 3295, #cached-token: 210, token usage: 0.02, #running-req: 1, #queue-req: 0, 
[2025-08-25 14:51:40 TP0] Prefill batch. #new-seq: 2, #new-token: 1000, #cached-token: 402, token usage: 0.09, #running-req: 6, #queue-req: 0, 
[2025-08-25 14:51:40] INFO:     127.0.0.1:43444 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 14:51:40] INFO:     127.0.0.1:43452 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 14:51:40] INFO:     127.0.0.1:43458 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 14:51:40] INFO:     127.0.0.1:43466 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 14:51:40] INFO:     127.0.0.1:43482 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 14:51:41] INFO:     127.0.0.1:43484 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 14:51:41 TP0] Prefill batch. #new-seq: 6, #new-token: 3000, #cached-token: 1206, token usage: 0.01, #running-req: 2, #queue-req: 0, 
[2025-08-25 14:51:41] INFO:     127.0.0.1:43486 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 14:51:41] INFO:     127.0.0.1:43488 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 14:51:42 TP0] Prefill batch. #new-seq: 2, #new-token: 1000, #cached-token: 402, token usage: 0.08, #running-req: 8, #queue-req: 0, 
[2025-08-25 14:51:42] INFO:     127.0.0.1:43444 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 14:51:42] INFO:     127.0.0.1:43458 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 14:51:42] INFO:     127.0.0.1:43452 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 14:51:42] INFO:     127.0.0.1:43466 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 14:51:42] INFO:     127.0.0.1:43482 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 14:51:42] INFO:     127.0.0.1:43484 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 14:51:42 TP0] Prefill batch. #new-seq: 1, #new-token: 710, #cached-token: 0, token usage: 0.00, #running-req: 2, #queue-req: 0, 
[2025-08-25 14:51:42] INFO:     127.0.0.1:43488 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 14:51:42] INFO:     127.0.0.1:43486 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 14:51:44 TP0] Decode batch. #running-req: 1, #token: 738, token usage: 0.02, gen throughput (token/s): 0.32, largest-len: 0, #queue-req: 0, 
[2025-08-25 14:51:45 TP0] Decode batch. #running-req: 1, #token: 778, token usage: 0.02, gen throughput (token/s): 22.68, largest-len: 0, #queue-req: 0, 
[2025-08-25 14:51:47 TP0] Decode batch. #running-req: 1, #token: 818, token usage: 0.02, gen throughput (token/s): 22.75, largest-len: 0, #queue-req: 0, 
[2025-08-25 14:51:49 TP0] Decode batch. #running-req: 1, #token: 858, token usage: 0.02, gen throughput (token/s): 22.69, largest-len: 0, #queue-req: 0, 
[2025-08-25 14:51:49] INFO:     127.0.0.1:43444 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 14:51:49 TP0] Prefill batch. #new-seq: 8, #new-token: 936, #cached-token: 400, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-08-25 14:51:49 TP0] Decode batch. #running-req: 8, #token: 431, token usage: 0.00, gen throughput (token/s): 31.97, largest-len: 0, #queue-req: 0, 
[2025-08-25 14:51:49 TP0] Decode batch. #running-req: 8, #token: 751, token usage: 0.00, gen throughput (token/s): 1680.12, largest-len: 0, #queue-req: 0, 
[2025-08-25 14:51:49 TP0] Decode batch. #running-req: 8, #token: 1071, token usage: 0.00, gen throughput (token/s): 1637.59, largest-len: 0, #queue-req: 0, 
[2025-08-25 14:51:50 TP0] Decode batch. #running-req: 8, #token: 1391, token usage: 0.00, gen throughput (token/s): 1609.90, largest-len: 0, #queue-req: 0, 
[2025-08-25 14:51:50 TP0] Decode batch. #running-req: 8, #token: 1711, token usage: 0.00, gen throughput (token/s): 1747.23, largest-len: 0, #queue-req: 0, 
[2025-08-25 14:51:50 TP0] Decode batch. #running-req: 8, #token: 2031, token usage: 0.00, gen throughput (token/s): 1680.22, largest-len: 0, #queue-req: 0, 
[2025-08-25 14:51:50 TP0] Decode batch. #running-req: 8, #token: 2351, token usage: 0.00, gen throughput (token/s): 1687.41, largest-len: 0, #queue-req: 0, 
[2025-08-25 14:51:50 TP0] Decode batch. #running-req: 8, #token: 2671, token usage: 0.00, gen throughput (token/s): 1687.36, largest-len: 0, #queue-req: 0, 
[2025-08-25 14:51:51 TP0] Decode batch. #running-req: 8, #token: 2991, token usage: 0.00, gen throughput (token/s): 1659.97, largest-len: 0, #queue-req: 0, 
[2025-08-25 14:51:51 TP0] Decode batch. #running-req: 8, #token: 3311, token usage: 0.00, gen throughput (token/s): 1650.40, largest-len: 0, #queue-req: 0, 
[2025-08-25 14:51:51 TP0] Decode batch. #running-req: 8, #token: 3631, token usage: 0.00, gen throughput (token/s): 1704.94, largest-len: 0, #queue-req: 0, 
[2025-08-25 14:51:51 TP0] Decode batch. #running-req: 8, #token: 3951, token usage: 0.00, gen throughput (token/s): 1682.20, largest-len: 0, #queue-req: 0, 
[2025-08-25 14:51:51] INFO:     127.0.0.1:11562 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 14:51:51] INFO:     127.0.0.1:11570 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 14:51:51] INFO:     127.0.0.1:11586 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 14:51:51] INFO:     127.0.0.1:11596 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 14:51:51] INFO:     127.0.0.1:11598 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 14:51:51] INFO:     127.0.0.1:11600 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 14:51:51] INFO:     127.0.0.1:11610 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 14:51:51] INFO:     127.0.0.1:11612 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 14:51:51 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 166, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-08-25 14:51:51 TP0] Prefill batch. #new-seq: 7, #new-token: 7, #cached-token: 1162, token usage: 0.00, #running-req: 1, #queue-req: 0, 
[2025-08-25 14:51:51 TP0] Decode batch. #running-req: 8, #token: 271, token usage: 0.00, gen throughput (token/s): 1123.00, largest-len: 0, #queue-req: 0, 
[2025-08-25 14:51:52 TP0] Decode batch. #running-req: 8, #token: 591, token usage: 0.00, gen throughput (token/s): 1680.57, largest-len: 0, #queue-req: 0, 
[2025-08-25 14:51:52 TP0] Decode batch. #running-req: 8, #token: 911, token usage: 0.00, gen throughput (token/s): 1715.44, largest-len: 0, #queue-req: 0, 
[2025-08-25 14:51:52 TP0] Decode batch. #running-req: 8, #token: 1231, token usage: 0.00, gen throughput (token/s): 1709.88, largest-len: 0, #queue-req: 0, 
[2025-08-25 14:51:52 TP0] Decode batch. #running-req: 8, #token: 1551, token usage: 0.00, gen throughput (token/s): 1749.96, largest-len: 0, #queue-req: 0, 
[2025-08-25 14:51:52 TP0] Decode batch. #running-req: 8, #token: 1871, token usage: 0.00, gen throughput (token/s): 1674.01, largest-len: 0, #queue-req: 0, 
[2025-08-25 14:51:53 TP0] Decode batch. #running-req: 8, #token: 2191, token usage: 0.00, gen throughput (token/s): 1680.75, largest-len: 0, #queue-req: 0, 
[2025-08-25 14:51:53 TP0] Decode batch. #running-req: 8, #token: 2511, token usage: 0.00, gen throughput (token/s): 1744.31, largest-len: 0, #queue-req: 0, 
[2025-08-25 14:51:53 TP0] Decode batch. #running-req: 8, #token: 2831, token usage: 0.00, gen throughput (token/s): 1750.45, largest-len: 0, #queue-req: 0, 
[2025-08-25 14:51:53 TP0] Decode batch. #running-req: 8, #token: 3151, token usage: 0.00, gen throughput (token/s): 1768.60, largest-len: 0, #queue-req: 0, 
[2025-08-25 14:51:53 TP0] Decode batch. #running-req: 8, #token: 3471, token usage: 0.00, gen throughput (token/s): 1668.73, largest-len: 0, #queue-req: 0, 
[2025-08-25 14:51:54 TP0] Decode batch. #running-req: 8, #token: 3791, token usage: 0.00, gen throughput (token/s): 1711.60, largest-len: 0, #queue-req: 0, 
[2025-08-25 14:51:54 TP0] Decode batch. #running-req: 8, #token: 4111, token usage: 0.00, gen throughput (token/s): 1659.42, largest-len: 0, #queue-req: 0, 
[2025-08-25 14:51:54] INFO:     127.0.0.1:11570 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 14:51:54] INFO:     127.0.0.1:11562 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 14:51:54] INFO:     127.0.0.1:11612 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 14:51:54] INFO:     127.0.0.1:11586 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 14:51:54] INFO:     127.0.0.1:11596 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 14:51:54] INFO:     127.0.0.1:11598 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 14:51:54] INFO:     127.0.0.1:11600 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 14:51:54] INFO:     127.0.0.1:11610 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 14:51:54 TP0] Prefill batch. #new-seq: 1, #new-token: 614, #cached-token: 42, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-08-25 14:51:54 TP0] Prefill batch. #new-seq: 5, #new-token: 3070, #cached-token: 210, token usage: 0.02, #running-req: 1, #queue-req: 0, 
[2025-08-25 14:51:55 TP0] Prefill batch. #new-seq: 2, #new-token: 1000, #cached-token: 312, token usage: 0.08, #running-req: 6, #queue-req: 0, 
[2025-08-25 14:51:55] INFO:     127.0.0.1:43444 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 14:51:55] INFO:     127.0.0.1:18998 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 14:51:55] INFO:     127.0.0.1:19000 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 14:51:55] INFO:     127.0.0.1:19016 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 14:51:55] INFO:     127.0.0.1:19022 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 14:51:55] INFO:     127.0.0.1:19032 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 14:51:55 TP0] Prefill batch. #new-seq: 6, #new-token: 3000, #cached-token: 936, token usage: 0.00, #running-req: 2, #queue-req: 0, 
[2025-08-25 14:51:55] INFO:     127.0.0.1:19036 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 14:51:55] INFO:     127.0.0.1:19040 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 14:51:56 TP0] Prefill batch. #new-seq: 2, #new-token: 1000, #cached-token: 312, token usage: 0.08, #running-req: 8, #queue-req: 0, 
[2025-08-25 14:51:56] INFO:     127.0.0.1:43444 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 14:51:56] INFO:     127.0.0.1:19000 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 14:51:56] INFO:     127.0.0.1:18998 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 14:51:56] INFO:     127.0.0.1:19016 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 14:51:56] INFO:     127.0.0.1:19022 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 14:51:56] INFO:     127.0.0.1:19032 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 14:51:57 TP0] Prefill batch. #new-seq: 2, #new-token: 1242, #cached-token: 88, token usage: 0.00, #running-req: 2, #queue-req: 0, 
[2025-08-25 14:51:57] INFO:     127.0.0.1:19036 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 14:51:57] INFO:     127.0.0.1:19040 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 14:51:59 TP0] Decode batch. #running-req: 2, #token: 1237, token usage: 0.03, gen throughput (token/s): 7.88, largest-len: 0, #queue-req: 0, 
[2025-08-25 14:52:00 TP0] Decode batch. #running-req: 2, #token: 1317, token usage: 0.03, gen throughput (token/s): 44.81, largest-len: 0, #queue-req: 0, 
[2025-08-25 14:52:02 TP0] Decode batch. #running-req: 2, #token: 1397, token usage: 0.04, gen throughput (token/s): 44.71, largest-len: 0, #queue-req: 0, 
[2025-08-25 14:52:04] INFO:     127.0.0.1:43444 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 14:52:04] INFO:     127.0.0.1:18998 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 14:52:04 TP0] Prefill batch. #new-seq: 8, #new-token: 464, #cached-token: 416, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-08-25 14:52:04 TP0] Decode batch. #running-req: 8, #token: 374, token usage: 0.00, gen throughput (token/s): 31.54, largest-len: 0, #queue-req: 0, 
[2025-08-25 14:52:04 TP0] Decode batch. #running-req: 8, #token: 694, token usage: 0.00, gen throughput (token/s): 1692.94, largest-len: 0, #queue-req: 0, 
[2025-08-25 14:52:04 TP0] Decode batch. #running-req: 8, #token: 1014, token usage: 0.00, gen throughput (token/s): 1668.18, largest-len: 0, #queue-req: 0, 
[2025-08-25 14:52:04 TP0] Decode batch. #running-req: 8, #token: 1334, token usage: 0.00, gen throughput (token/s): 1680.01, largest-len: 0, #queue-req: 0, 
[2025-08-25 14:52:05 TP0] Decode batch. #running-req: 8, #token: 1654, token usage: 0.00, gen throughput (token/s): 1774.08, largest-len: 0, #queue-req: 0, 
[2025-08-25 14:52:05 TP0] Decode batch. #running-req: 8, #token: 1974, token usage: 0.00, gen throughput (token/s): 1698.98, largest-len: 0, #queue-req: 0, 
[2025-08-25 14:52:05 TP0] Decode batch. #running-req: 8, #token: 2294, token usage: 0.00, gen throughput (token/s): 1803.53, largest-len: 0, #queue-req: 0, 
[2025-08-25 14:52:05 TP0] Decode batch. #running-req: 8, #token: 2614, token usage: 0.00, gen throughput (token/s): 1755.54, largest-len: 0, #queue-req: 0, 
[2025-08-25 14:52:05 TP0] Decode batch. #running-req: 8, #token: 2934, token usage: 0.00, gen throughput (token/s): 1765.76, largest-len: 0, #queue-req: 0, 
[2025-08-25 14:52:06 TP0] Decode batch. #running-req: 8, #token: 3254, token usage: 0.00, gen throughput (token/s): 1822.10, largest-len: 0, #queue-req: 0, 
[2025-08-25 14:52:06 TP0] Decode batch. #running-req: 8, #token: 3574, token usage: 0.00, gen throughput (token/s): 1724.06, largest-len: 0, #queue-req: 0, 
[2025-08-25 14:52:06 TP0] Decode batch. #running-req: 8, #token: 3894, token usage: 0.00, gen throughput (token/s): 1767.66, largest-len: 0, #queue-req: 0, 
[2025-08-25 14:52:06] INFO:     127.0.0.1:61068 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 14:52:06] INFO:     127.0.0.1:61074 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 14:52:06] INFO:     127.0.0.1:61082 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 14:52:06] INFO:     127.0.0.1:61088 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 14:52:06] INFO:     127.0.0.1:61092 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 14:52:06] INFO:     127.0.0.1:61104 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 14:52:06] INFO:     127.0.0.1:61110 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 14:52:06] INFO:     127.0.0.1:61126 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 14:52:06 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 109, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-08-25 14:52:06 TP0] Prefill batch. #new-seq: 7, #new-token: 7, #cached-token: 763, token usage: 0.00, #running-req: 1, #queue-req: 0, 
[2025-08-25 14:52:06 TP0] Decode batch. #running-req: 8, #token: 214, token usage: 0.00, gen throughput (token/s): 1061.41, largest-len: 0, #queue-req: 0, 
[2025-08-25 14:52:06 TP0] Decode batch. #running-req: 8, #token: 534, token usage: 0.00, gen throughput (token/s): 1789.60, largest-len: 0, #queue-req: 0, 
[2025-08-25 14:52:07 TP0] Decode batch. #running-req: 8, #token: 854, token usage: 0.00, gen throughput (token/s): 1792.46, largest-len: 0, #queue-req: 0, 
[2025-08-25 14:52:07 TP0] Decode batch. #running-req: 8, #token: 1174, token usage: 0.00, gen throughput (token/s): 1767.08, largest-len: 0, #queue-req: 0, 
[2025-08-25 14:52:07 TP0] Decode batch. #running-req: 8, #token: 1494, token usage: 0.00, gen throughput (token/s): 1764.19, largest-len: 0, #queue-req: 0, 
[2025-08-25 14:52:07 TP0] Decode batch. #running-req: 8, #token: 1814, token usage: 0.00, gen throughput (token/s): 1706.15, largest-len: 0, #queue-req: 0, 
[2025-08-25 14:52:07 TP0] Decode batch. #running-req: 8, #token: 2134, token usage: 0.00, gen throughput (token/s): 1744.68, largest-len: 0, #queue-req: 0, 
[2025-08-25 14:52:07 TP0] Decode batch. #running-req: 8, #token: 2454, token usage: 0.00, gen throughput (token/s): 1724.20, largest-len: 0, #queue-req: 0, 
[2025-08-25 14:52:08 TP0] Decode batch. #running-req: 8, #token: 2774, token usage: 0.00, gen throughput (token/s): 1799.58, largest-len: 0, #queue-req: 0, 
[2025-08-25 14:52:08 TP0] Decode batch. #running-req: 8, #token: 3094, token usage: 0.00, gen throughput (token/s): 1735.16, largest-len: 0, #queue-req: 0, 
[2025-08-25 14:52:08 TP0] Decode batch. #running-req: 8, #token: 3414, token usage: 0.00, gen throughput (token/s): 1784.13, largest-len: 0, #queue-req: 0, 
[2025-08-25 14:52:08 TP0] Decode batch. #running-req: 8, #token: 3734, token usage: 0.00, gen throughput (token/s): 1774.45, largest-len: 0, #queue-req: 0, 
[2025-08-25 14:52:08 TP0] Decode batch. #running-req: 8, #token: 4054, token usage: 0.00, gen throughput (token/s): 1837.03, largest-len: 0, #queue-req: 0, 
[2025-08-25 14:52:08] INFO:     127.0.0.1:61126 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 14:52:08] INFO:     127.0.0.1:61068 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 14:52:08] INFO:     127.0.0.1:61074 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 14:52:08] INFO:     127.0.0.1:61082 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 14:52:08] INFO:     127.0.0.1:61088 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 14:52:08] INFO:     127.0.0.1:61092 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 14:52:08] INFO:     127.0.0.1:61104 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 14:52:08] INFO:     127.0.0.1:61110 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 14:52:08 TP0] Prefill batch. #new-seq: 1, #new-token: 555, #cached-token: 44, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-08-25 14:52:08 TP0] Prefill batch. #new-seq: 1, #new-token: 555, #cached-token: 44, token usage: 0.02, #running-req: 1, #queue-req: 0, 
[2025-08-25 14:52:09 TP0] Prefill batch. #new-seq: 6, #new-token: 3000, #cached-token: 594, token usage: 0.02, #running-req: 2, #queue-req: 0, 
[2025-08-25 14:52:09] INFO:     127.0.0.1:43444 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 14:52:09] INFO:     127.0.0.1:18998 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 14:52:10 TP0] Prefill batch. #new-seq: 2, #new-token: 1000, #cached-token: 198, token usage: 0.00, #running-req: 6, #queue-req: 0, 
[2025-08-25 14:52:10] INFO:     127.0.0.1:40706 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 14:52:10] INFO:     127.0.0.1:40720 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 14:52:10] INFO:     127.0.0.1:40722 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 14:52:10] INFO:     127.0.0.1:40734 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 14:52:10] INFO:     127.0.0.1:40744 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 14:52:10] INFO:     127.0.0.1:40746 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 14:52:10 TP0] Prefill batch. #new-seq: 6, #new-token: 3000, #cached-token: 594, token usage: 0.03, #running-req: 8, #queue-req: 0, 
[2025-08-25 14:52:10] INFO:     127.0.0.1:43444 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 14:52:10] INFO:     127.0.0.1:18998 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 14:52:11] INFO:     127.0.0.1:40706 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 14:52:11] INFO:     127.0.0.1:40720 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 14:52:11] INFO:     127.0.0.1:40722 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 14:52:11] INFO:     127.0.0.1:40734 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 14:52:11] INFO:     127.0.0.1:40744 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 14:52:11] INFO:     127.0.0.1:40746 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 14:52:11 TP0] Prefill batch. #new-seq: 1, #new-token: 86, #cached-token: 50, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-08-25 14:52:11 TP0] Prefill batch. #new-seq: 7, #new-token: 602, #cached-token: 350, token usage: 0.00, #running-req: 1, #queue-req: 0, 
[2025-08-25 14:52:12 TP0] Decode batch. #running-req: 8, #token: 400, token usage: 0.00, gen throughput (token/s): 102.22, largest-len: 0, #queue-req: 0, 
[2025-08-25 14:52:12 TP0] Decode batch. #running-req: 8, #token: 720, token usage: 0.00, gen throughput (token/s): 1642.66, largest-len: 0, #queue-req: 0, 
[2025-08-25 14:52:12 TP0] Decode batch. #running-req: 8, #token: 1040, token usage: 0.00, gen throughput (token/s): 1687.75, largest-len: 0, #queue-req: 0, 
[2025-08-25 14:52:12 TP0] Decode batch. #running-req: 8, #token: 1360, token usage: 0.00, gen throughput (token/s): 1697.04, largest-len: 0, #queue-req: 0, 
[2025-08-25 14:52:12 TP0] Decode batch. #running-req: 8, #token: 1680, token usage: 0.00, gen throughput (token/s): 1740.55, largest-len: 0, #queue-req: 0, 
[2025-08-25 14:52:12 TP0] Decode batch. #running-req: 8, #token: 2000, token usage: 0.00, gen throughput (token/s): 1689.04, largest-len: 0, #queue-req: 0, 
[2025-08-25 14:52:13 TP0] Decode batch. #running-req: 8, #token: 2320, token usage: 0.00, gen throughput (token/s): 1624.55, largest-len: 0, #queue-req: 0, 
[2025-08-25 14:52:13 TP0] Decode batch. #running-req: 8, #token: 2640, token usage: 0.00, gen throughput (token/s): 1584.69, largest-len: 0, #queue-req: 0, 
[2025-08-25 14:56:56 TP0] Prefill batch. #new-seq: 8, #new-token: 8, #cached-token: 656, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-08-25 14:56:56 TP0] Decode batch. #running-req: 8, #token: 99, token usage: 0.00, gen throughput (token/s): 1.13, largest-len: 0, #queue-req: 0, 
[2025-08-25 14:56:57 TP0] Decode batch. #running-req: 8, #token: 419, token usage: 0.00, gen throughput (token/s): 1748.76, largest-len: 0, #queue-req: 0, 
[2025-08-25 14:56:57 TP0] Decode batch. #running-req: 8, #token: 739, token usage: 0.00, gen throughput (token/s): 1726.80, largest-len: 0, #queue-req: 0, 
[2025-08-25 14:56:57 TP0] Decode batch. #running-req: 8, #token: 1059, token usage: 0.00, gen throughput (token/s): 1629.77, largest-len: 0, #queue-req: 0, 
[2025-08-25 14:56:57 TP0] Decode batch. #running-req: 8, #token: 1379, token usage: 0.00, gen throughput (token/s): 1631.70, largest-len: 0, #queue-req: 0, 
[2025-08-25 14:56:57 TP0] Decode batch. #running-req: 8, #token: 1699, token usage: 0.00, gen throughput (token/s): 1659.48, largest-len: 0, #queue-req: 0, 
[2025-08-25 14:56:57 TP0] Decode batch. #running-req: 8, #token: 2019, token usage: 0.00, gen throughput (token/s): 1697.48, largest-len: 0, #queue-req: 0, 
[2025-08-25 14:56:58 TP0] Decode batch. #running-req: 8, #token: 2339, token usage: 0.00, gen throughput (token/s): 1672.95, largest-len: 0, #queue-req: 0, 
[2025-08-25 14:56:58 TP0] Decode batch. #running-req: 8, #token: 2659, token usage: 0.00, gen throughput (token/s): 1729.75, largest-len: 0, #queue-req: 0, 
[2025-08-25 14:56:58 TP0] Decode batch. #running-req: 8, #token: 2979, token usage: 0.00, gen throughput (token/s): 1698.65, largest-len: 0, #queue-req: 0, 
[2025-08-25 14:56:58 TP0] Decode batch. #running-req: 8, #token: 3299, token usage: 0.00, gen throughput (token/s): 1746.90, largest-len: 0, #queue-req: 0, 
[2025-08-25 14:56:58 TP0] Decode batch. #running-req: 8, #token: 3619, token usage: 0.00, gen throughput (token/s): 1726.23, largest-len: 0, #queue-req: 0, 
[2025-08-25 14:56:59 TP0] Decode batch. #running-req: 8, #token: 3939, token usage: 0.00, gen throughput (token/s): 1631.09, largest-len: 0, #queue-req: 0, 
[2025-08-25 14:56:59] INFO:     127.0.0.1:52326 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 14:56:59] INFO:     127.0.0.1:52366 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 14:56:59] INFO:     127.0.0.1:52338 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 14:56:59] INFO:     127.0.0.1:52342 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 14:56:59] INFO:     127.0.0.1:52348 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 14:56:59] INFO:     127.0.0.1:52358 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 14:56:59] INFO:     127.0.0.1:52360 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 14:56:59] INFO:     127.0.0.1:52362 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 14:56:59 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 82, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-08-25 14:56:59 TP0] Prefill batch. #new-seq: 7, #new-token: 7, #cached-token: 574, token usage: 0.00, #running-req: 1, #queue-req: 0, 
[2025-08-25 14:56:59 TP0] Decode batch. #running-req: 8, #token: 252, token usage: 0.00, gen throughput (token/s): 1004.15, largest-len: 0, #queue-req: 0, 
[2025-08-25 14:56:59 TP0] Decode batch. #running-req: 8, #token: 572, token usage: 0.00, gen throughput (token/s): 1626.91, largest-len: 0, #queue-req: 0, 
[2025-08-25 14:56:59 TP0] Decode batch. #running-req: 8, #token: 892, token usage: 0.00, gen throughput (token/s): 1711.65, largest-len: 0, #queue-req: 0, 
[2025-08-25 14:56:59 TP0] Decode batch. #running-req: 8, #token: 1212, token usage: 0.00, gen throughput (token/s): 1689.57, largest-len: 0, #queue-req: 0, 
[2025-08-25 14:57:00 TP0] Decode batch. #running-req: 8, #token: 1532, token usage: 0.00, gen throughput (token/s): 1700.81, largest-len: 0, #queue-req: 0, 
[2025-08-25 14:57:00 TP0] Decode batch. #running-req: 8, #token: 1852, token usage: 0.00, gen throughput (token/s): 1667.62, largest-len: 0, #queue-req: 0, 
[2025-08-25 14:57:00 TP0] Decode batch. #running-req: 8, #token: 2172, token usage: 0.00, gen throughput (token/s): 1710.07, largest-len: 0, #queue-req: 0, 
[2025-08-25 14:57:00 TP0] Decode batch. #running-req: 8, #token: 2492, token usage: 0.00, gen throughput (token/s): 1643.31, largest-len: 0, #queue-req: 0, 
[2025-08-25 14:57:00 TP0] Decode batch. #running-req: 8, #token: 2812, token usage: 0.00, gen throughput (token/s): 1712.90, largest-len: 0, #queue-req: 0, 
[2025-08-25 14:57:01 TP0] Decode batch. #running-req: 8, #token: 3132, token usage: 0.00, gen throughput (token/s): 1693.24, largest-len: 0, #queue-req: 0, 
[2025-08-25 14:57:01 TP0] Decode batch. #running-req: 8, #token: 3452, token usage: 0.00, gen throughput (token/s): 1709.56, largest-len: 0, #queue-req: 0, 
[2025-08-25 14:57:01 TP0] Decode batch. #running-req: 8, #token: 3772, token usage: 0.00, gen throughput (token/s): 1612.28, largest-len: 0, #queue-req: 0, 
[2025-08-25 14:57:01] INFO:     127.0.0.1:52326 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 14:57:01 TP0] Prefill batch. #new-seq: 1, #new-token: 500, #cached-token: 72, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-08-25 14:57:01] INFO:     127.0.0.1:52338 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 14:57:01] INFO:     127.0.0.1:52342 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 14:57:01] INFO:     127.0.0.1:52348 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 14:57:01] INFO:     127.0.0.1:52358 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 14:57:01] INFO:     127.0.0.1:52360 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 14:57:01] INFO:     127.0.0.1:52362 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 14:57:01] INFO:     127.0.0.1:52366 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 14:57:01 TP0] Decode batch. #running-req: 0, #token: 0, token usage: 0.00, gen throughput (token/s): 1500.67, largest-len: 0, #queue-req: 0, 
[2025-08-25 14:57:01 TP0] Prefill batch. #new-seq: 7, #new-token: 3500, #cached-token: 504, token usage: 0.00, #running-req: 1, #queue-req: 0, 
[2025-08-25 14:57:01] INFO:     127.0.0.1:10016 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 14:57:01 TP0] Prefill batch. #new-seq: 1, #new-token: 500, #cached-token: 72, token usage: 0.09, #running-req: 8, #queue-req: 0, 
[2025-08-25 14:57:03] INFO:     127.0.0.1:10026 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 14:57:03] INFO:     127.0.0.1:10040 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 14:57:03] INFO:     127.0.0.1:10050 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 14:57:03] INFO:     127.0.0.1:10064 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 14:57:03] INFO:     127.0.0.1:10076 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 14:57:03] INFO:     127.0.0.1:10086 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 14:57:03] INFO:     127.0.0.1:10098 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 14:57:03] INFO:     127.0.0.1:10016 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 14:57:03 TP0] Prefill batch. #new-seq: 7, #new-token: 3500, #cached-token: 504, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-08-25 14:57:04] INFO:     127.0.0.1:10026 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 14:57:04] INFO:     127.0.0.1:10040 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 14:57:04 TP0] Decode batch. #running-req: 0, #token: 0, token usage: 0.00, gen throughput (token/s): 0.30, largest-len: 0, #queue-req: 0, 
[2025-08-25 14:57:04] INFO:     127.0.0.1:10016 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 14:57:04] INFO:     127.0.0.1:10050 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 14:57:04] INFO:     127.0.0.1:10064 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 14:57:04] INFO:     127.0.0.1:10076 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 14:57:04] INFO:     127.0.0.1:10086 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 14:57:04 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 211, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-08-25 14:57:05 TP0] Prefill batch. #new-seq: 7, #new-token: 7, #cached-token: 1477, token usage: 0.00, #running-req: 1, #queue-req: 0, 
[2025-08-25 14:57:05 TP0] Decode batch. #running-req: 8, #token: 533, token usage: 0.00, gen throughput (token/s): 88.71, largest-len: 0, #queue-req: 0, 
[2025-08-25 14:57:05 TP0] Decode batch. #running-req: 8, #token: 853, token usage: 0.00, gen throughput (token/s): 1663.23, largest-len: 0, #queue-req: 0, 
[2025-08-25 14:57:05 TP0] Decode batch. #running-req: 8, #token: 1173, token usage: 0.00, gen throughput (token/s): 1679.64, largest-len: 0, #queue-req: 0, 
[2025-08-25 14:57:05 TP0] Decode batch. #running-req: 8, #token: 1493, token usage: 0.00, gen throughput (token/s): 1685.21, largest-len: 0, #queue-req: 0, 
[2025-08-25 14:57:06 TP0] Decode batch. #running-req: 8, #token: 1813, token usage: 0.00, gen throughput (token/s): 1748.84, largest-len: 0, #queue-req: 0, 
[2025-08-25 14:57:06 TP0] Decode batch. #running-req: 8, #token: 2133, token usage: 0.00, gen throughput (token/s): 1730.13, largest-len: 0, #queue-req: 0, 
[2025-08-25 14:57:06 TP0] Decode batch. #running-req: 8, #token: 2453, token usage: 0.00, gen throughput (token/s): 1724.22, largest-len: 0, #queue-req: 0, 
[2025-08-25 14:57:06 TP0] Decode batch. #running-req: 8, #token: 2773, token usage: 0.00, gen throughput (token/s): 1716.79, largest-len: 0, #queue-req: 0, 
[2025-08-25 14:57:06 TP0] Decode batch. #running-req: 8, #token: 3093, token usage: 0.00, gen throughput (token/s): 1725.23, largest-len: 0, #queue-req: 0, 
[2025-08-25 14:57:06 TP0] Decode batch. #running-req: 8, #token: 3413, token usage: 0.00, gen throughput (token/s): 1688.72, largest-len: 0, #queue-req: 0, 
[2025-08-25 14:57:07 TP0] Decode batch. #running-req: 8, #token: 3733, token usage: 0.00, gen throughput (token/s): 1744.59, largest-len: 0, #queue-req: 0, 
[2025-08-25 14:57:07 TP0] Decode batch. #running-req: 8, #token: 4053, token usage: 0.00, gen throughput (token/s): 1716.76, largest-len: 0, #queue-req: 0, 
[2025-08-25 14:57:07] INFO:     127.0.0.1:52326 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 14:57:07 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 211, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-08-25 14:57:07] INFO:     127.0.0.1:52338 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 14:57:07] INFO:     127.0.0.1:52342 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 14:57:07] INFO:     127.0.0.1:52348 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 14:57:07] INFO:     127.0.0.1:52358 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 14:57:07] INFO:     127.0.0.1:52360 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 14:57:07] INFO:     127.0.0.1:52362 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 14:57:07] INFO:     127.0.0.1:52366 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 14:57:07 TP0] Prefill batch. #new-seq: 6, #new-token: 6, #cached-token: 1266, token usage: 0.00, #running-req: 1, #queue-req: 0, 
[2025-08-25 14:57:07 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 211, token usage: 0.00, #running-req: 7, #queue-req: 0, 
[2025-08-25 14:57:07 TP0] Decode batch. #running-req: 8, #token: 365, token usage: 0.00, gen throughput (token/s): 1018.78, largest-len: 0, #queue-req: 0, 
[2025-08-25 14:57:07 TP0] Decode batch. #running-req: 8, #token: 685, token usage: 0.00, gen throughput (token/s): 1678.63, largest-len: 0, #queue-req: 0, 
[2025-08-25 14:57:08 TP0] Decode batch. #running-req: 8, #token: 1005, token usage: 0.00, gen throughput (token/s): 1686.83, largest-len: 0, #queue-req: 0, 
[2025-08-25 14:57:08 TP0] Decode batch. #running-req: 8, #token: 1325, token usage: 0.00, gen throughput (token/s): 1729.41, largest-len: 0, #queue-req: 0, 
[2025-08-25 14:57:08 TP0] Decode batch. #running-req: 8, #token: 1645, token usage: 0.00, gen throughput (token/s): 1675.06, largest-len: 0, #queue-req: 0, 
[2025-08-25 14:57:08 TP0] Decode batch. #running-req: 8, #token: 1965, token usage: 0.00, gen throughput (token/s): 1708.51, largest-len: 0, #queue-req: 0, 
[2025-08-25 14:57:08 TP0] Decode batch. #running-req: 8, #token: 2285, token usage: 0.00, gen throughput (token/s): 1707.51, largest-len: 0, #queue-req: 0, 
[2025-08-25 14:57:08 TP0] Decode batch. #running-req: 8, #token: 2605, token usage: 0.00, gen throughput (token/s): 1656.17, largest-len: 0, #queue-req: 0, 
[2025-08-25 14:57:09 TP0] Decode batch. #running-req: 8, #token: 2925, token usage: 0.00, gen throughput (token/s): 1609.00, largest-len: 0, #queue-req: 0, 
[2025-08-25 14:57:09 TP0] Decode batch. #running-req: 8, #token: 3245, token usage: 0.00, gen throughput (token/s): 1641.74, largest-len: 0, #queue-req: 0, 
[2025-08-25 14:57:09 TP0] Decode batch. #running-req: 8, #token: 3565, token usage: 0.00, gen throughput (token/s): 1685.92, largest-len: 0, #queue-req: 0, 
[2025-08-25 14:57:09 TP0] Decode batch. #running-req: 8, #token: 3885, token usage: 0.00, gen throughput (token/s): 1635.00, largest-len: 0, #queue-req: 0, 
[2025-08-25 14:57:09 TP0] Decode batch. #running-req: 8, #token: 3706, token usage: 0.00, gen throughput (token/s): 1669.28, largest-len: 0, #queue-req: 0, 
[2025-08-25 14:57:09] INFO:     127.0.0.1:52326 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 14:57:09] INFO:     127.0.0.1:52338 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 14:57:09] INFO:     127.0.0.1:52342 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 14:57:09] INFO:     127.0.0.1:52348 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 14:57:09] INFO:     127.0.0.1:52358 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 14:57:09] INFO:     127.0.0.1:52360 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 14:57:09] INFO:     127.0.0.1:52362 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 14:57:09] INFO:     127.0.0.1:52366 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 14:57:09 TP0] Prefill batch. #new-seq: 1, #new-token: 500, #cached-token: 201, token usage: 0.01, #running-req: 0, #queue-req: 0, 
[2025-08-25 14:57:10 TP0] Prefill batch. #new-seq: 7, #new-token: 3500, #cached-token: 1407, token usage: 0.01, #running-req: 1, #queue-req: 0, 
[2025-08-25 14:57:10] INFO:     127.0.0.1:10076 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 14:57:10 TP0] Prefill batch. #new-seq: 1, #new-token: 500, #cached-token: 201, token usage: 0.09, #running-req: 8, #queue-req: 0, 
[2025-08-25 14:57:11] INFO:     127.0.0.1:10112 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 14:57:11] INFO:     127.0.0.1:10118 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 14:57:11] INFO:     127.0.0.1:10132 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 14:57:11] INFO:     127.0.0.1:10144 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 14:57:11] INFO:     127.0.0.1:10160 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 14:57:11] INFO:     127.0.0.1:10164 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 14:57:11] INFO:     127.0.0.1:10174 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 14:57:11] INFO:     127.0.0.1:10076 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 14:57:11 TP0] Prefill batch. #new-seq: 5, #new-token: 2500, #cached-token: 1005, token usage: 0.01, #running-req: 0, #queue-req: 0, 
[2025-08-25 14:57:12 TP0] Prefill batch. #new-seq: 3, #new-token: 1496, #cached-token: 616, token usage: 0.07, #running-req: 5, #queue-req: 0, 
[2025-08-25 14:57:13] INFO:     127.0.0.1:10174 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 14:57:13] INFO:     127.0.0.1:10076 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 14:57:13] INFO:     127.0.0.1:10112 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 14:57:13] INFO:     127.0.0.1:10118 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 14:57:13] INFO:     127.0.0.1:10132 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 14:57:13 TP0] Prefill batch. #new-seq: 1, #new-token: 496, #cached-token: 214, token usage: 0.02, #running-req: 3, #queue-req: 0, 
[2025-08-25 14:57:13] INFO:     127.0.0.1:10160 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 14:57:13] INFO:     127.0.0.1:10164 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 14:57:13 TP0] Prefill batch. #new-seq: 1, #new-token: 491, #cached-token: 219, token usage: 0.03, #running-req: 4, #queue-req: 0, 
[2025-08-25 14:57:15 TP0] Decode batch. #running-req: 3, #token: 1817, token usage: 0.05, gen throughput (token/s): 10.94, largest-len: 0, #queue-req: 0, 
[2025-08-25 14:57:17 TP0] Decode batch. #running-req: 3, #token: 1937, token usage: 0.05, gen throughput (token/s): 66.30, largest-len: 0, #queue-req: 0, 
[2025-08-25 14:57:19 TP0] Decode batch. #running-req: 3, #token: 2057, token usage: 0.05, gen throughput (token/s): 66.71, largest-len: 0, #queue-req: 0, 
[2025-08-25 14:57:20] INFO:     127.0.0.1:10144 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 14:57:20] INFO:     127.0.0.1:10076 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 14:57:20] INFO:     127.0.0.1:10174 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 14:58:37 TP0] Prefill batch. #new-seq: 8, #new-token: 8, #cached-token: 656, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-08-25 14:58:37 TP0] Decode batch. #running-req: 8, #token: 395, token usage: 0.00, gen throughput (token/s): 3.63, largest-len: 0, #queue-req: 0, 
[2025-08-25 14:58:38 TP0] Decode batch. #running-req: 8, #token: 715, token usage: 0.00, gen throughput (token/s): 1694.08, largest-len: 0, #queue-req: 0, 
[2025-08-25 14:58:38 TP0] Decode batch. #running-req: 8, #token: 1035, token usage: 0.00, gen throughput (token/s): 1711.10, largest-len: 0, #queue-req: 0, 
[2025-08-25 14:58:38 TP0] Decode batch. #running-req: 8, #token: 1355, token usage: 0.00, gen throughput (token/s): 1803.80, largest-len: 0, #queue-req: 0, 
[2025-08-25 14:58:38 TP0] Decode batch. #running-req: 8, #token: 1675, token usage: 0.00, gen throughput (token/s): 1746.69, largest-len: 0, #queue-req: 0, 
[2025-08-25 14:58:38 TP0] Decode batch. #running-req: 8, #token: 1995, token usage: 0.00, gen throughput (token/s): 1754.78, largest-len: 0, #queue-req: 0, 
[2025-08-25 14:58:38 TP0] Decode batch. #running-req: 8, #token: 2315, token usage: 0.00, gen throughput (token/s): 1748.50, largest-len: 0, #queue-req: 0, 
[2025-08-25 14:58:39 TP0] Decode batch. #running-req: 8, #token: 2635, token usage: 0.00, gen throughput (token/s): 1758.08, largest-len: 0, #queue-req: 0, 
[2025-08-25 14:58:39 TP0] Decode batch. #running-req: 8, #token: 2955, token usage: 0.00, gen throughput (token/s): 1744.92, largest-len: 0, #queue-req: 0, 
[2025-08-25 14:58:39 TP0] Decode batch. #running-req: 8, #token: 3275, token usage: 0.00, gen throughput (token/s): 1764.96, largest-len: 0, #queue-req: 0, 
[2025-08-25 14:58:39 TP0] Decode batch. #running-req: 8, #token: 3595, token usage: 0.00, gen throughput (token/s): 1726.28, largest-len: 0, #queue-req: 0, 
[2025-08-25 14:58:39 TP0] Decode batch. #running-req: 8, #token: 3915, token usage: 0.00, gen throughput (token/s): 1758.98, largest-len: 0, #queue-req: 0, 
[2025-08-25 14:58:39] INFO:     127.0.0.1:56378 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 14:58:39] INFO:     127.0.0.1:56390 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 14:58:39] INFO:     127.0.0.1:56394 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 14:58:39] INFO:     127.0.0.1:56396 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 14:58:39] INFO:     127.0.0.1:56412 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 14:58:39] INFO:     127.0.0.1:56418 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 14:58:39] INFO:     127.0.0.1:56432 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 14:58:39] INFO:     127.0.0.1:56440 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 14:58:39 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 82, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-08-25 14:58:40 TP0] Prefill batch. #new-seq: 7, #new-token: 7, #cached-token: 574, token usage: 0.00, #running-req: 1, #queue-req: 0, 
[2025-08-25 14:58:40 TP0] Decode batch. #running-req: 8, #token: 235, token usage: 0.00, gen throughput (token/s): 1026.44, largest-len: 0, #queue-req: 0, 
[2025-08-25 14:58:40 TP0] Decode batch. #running-req: 8, #token: 555, token usage: 0.00, gen throughput (token/s): 1711.15, largest-len: 0, #queue-req: 0, 
[2025-08-25 14:58:40 TP0] Decode batch. #running-req: 8, #token: 875, token usage: 0.00, gen throughput (token/s): 1678.80, largest-len: 0, #queue-req: 0, 
[2025-08-25 14:58:40 TP0] Decode batch. #running-req: 8, #token: 1195, token usage: 0.00, gen throughput (token/s): 1684.05, largest-len: 0, #queue-req: 0, 
[2025-08-25 14:58:40 TP0] Decode batch. #running-req: 8, #token: 1515, token usage: 0.00, gen throughput (token/s): 1586.30, largest-len: 0, #queue-req: 0, 
[2025-08-25 14:58:41 TP0] Decode batch. #running-req: 8, #token: 1835, token usage: 0.00, gen throughput (token/s): 1647.23, largest-len: 0, #queue-req: 0, 
[2025-08-25 14:58:41 TP0] Decode batch. #running-req: 8, #token: 2155, token usage: 0.00, gen throughput (token/s): 1698.63, largest-len: 0, #queue-req: 0, 
[2025-08-25 14:58:41 TP0] Decode batch. #running-req: 8, #token: 2475, token usage: 0.00, gen throughput (token/s): 1733.46, largest-len: 0, #queue-req: 0, 
[2025-08-25 14:58:41 TP0] Decode batch. #running-req: 8, #token: 2795, token usage: 0.00, gen throughput (token/s): 1741.00, largest-len: 0, #queue-req: 0, 
[2025-08-25 14:58:41 TP0] Decode batch. #running-req: 8, #token: 3115, token usage: 0.00, gen throughput (token/s): 1548.96, largest-len: 0, #queue-req: 0, 
[2025-08-25 14:58:42 TP0] Decode batch. #running-req: 8, #token: 3435, token usage: 0.00, gen throughput (token/s): 1669.72, largest-len: 0, #queue-req: 0, 
[2025-08-25 14:58:42 TP0] Decode batch. #running-req: 8, #token: 3755, token usage: 0.00, gen throughput (token/s): 1584.33, largest-len: 0, #queue-req: 0, 
[2025-08-25 14:58:42 TP0] Decode batch. #running-req: 8, #token: 4075, token usage: 0.00, gen throughput (token/s): 1685.95, largest-len: 0, #queue-req: 0, 
[2025-08-25 14:58:42] INFO:     127.0.0.1:56378 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 14:58:42] INFO:     127.0.0.1:56390 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 14:58:42] INFO:     127.0.0.1:56394 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 14:58:42] INFO:     127.0.0.1:56396 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 14:58:42] INFO:     127.0.0.1:56412 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 14:58:42] INFO:     127.0.0.1:56418 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 14:58:42] INFO:     127.0.0.1:56432 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 14:58:42] INFO:     127.0.0.1:56440 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 14:58:42 TP0] Prefill batch. #new-seq: 3, #new-token: 1500, #cached-token: 216, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-08-25 14:58:42 TP0] Prefill batch. #new-seq: 5, #new-token: 2500, #cached-token: 360, token usage: 0.04, #running-req: 3, #queue-req: 0, 
[2025-08-25 14:58:43] INFO:     127.0.0.1:21510 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 14:58:43] INFO:     127.0.0.1:21524 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 14:58:43] INFO:     127.0.0.1:21528 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 14:58:43 TP0] Prefill batch. #new-seq: 1, #new-token: 500, #cached-token: 72, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-08-25 14:58:43] INFO:     127.0.0.1:21538 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 14:58:43] INFO:     127.0.0.1:21554 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 14:58:43] INFO:     127.0.0.1:21558 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 14:58:43] INFO:     127.0.0.1:21562 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 14:58:43] INFO:     127.0.0.1:21578 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 14:58:44 TP0] Prefill batch. #new-seq: 7, #new-token: 3500, #cached-token: 504, token usage: 0.00, #running-req: 1, #queue-req: 0, 
[2025-08-25 14:58:44] INFO:     127.0.0.1:21528 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 14:58:45] INFO:     127.0.0.1:21524 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 14:58:45] INFO:     127.0.0.1:21510 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 14:58:45] INFO:     127.0.0.1:21538 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 14:58:45] INFO:     127.0.0.1:21554 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 14:58:45] INFO:     127.0.0.1:21558 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 14:58:45] INFO:     127.0.0.1:21562 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 14:58:45] INFO:     127.0.0.1:21578 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 14:58:45 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 211, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-08-25 14:58:45 TP0] Prefill batch. #new-seq: 4, #new-token: 4, #cached-token: 844, token usage: 0.00, #running-req: 1, #queue-req: 0, 
[2025-08-25 14:58:45 TP0] Prefill batch. #new-seq: 3, #new-token: 3, #cached-token: 633, token usage: 0.00, #running-req: 5, #queue-req: 0, 
[2025-08-25 14:58:45 TP0] Decode batch. #running-req: 8, #token: 524, token usage: 0.00, gen throughput (token/s): 100.25, largest-len: 0, #queue-req: 0, 
[2025-08-25 14:58:45 TP0] Decode batch. #running-req: 8, #token: 844, token usage: 0.00, gen throughput (token/s): 1627.90, largest-len: 0, #queue-req: 0, 
[2025-08-25 14:58:46 TP0] Decode batch. #running-req: 8, #token: 1164, token usage: 0.00, gen throughput (token/s): 1654.59, largest-len: 0, #queue-req: 0, 
[2025-08-25 14:58:46 TP0] Decode batch. #running-req: 8, #token: 1484, token usage: 0.00, gen throughput (token/s): 1722.58, largest-len: 0, #queue-req: 0, 
[2025-08-25 14:58:46 TP0] Decode batch. #running-req: 8, #token: 1804, token usage: 0.00, gen throughput (token/s): 1701.26, largest-len: 0, #queue-req: 0, 
[2025-08-25 14:58:46 TP0] Decode batch. #running-req: 8, #token: 2124, token usage: 0.00, gen throughput (token/s): 1697.34, largest-len: 0, #queue-req: 0, 
[2025-08-25 14:58:46 TP0] Decode batch. #running-req: 8, #token: 2444, token usage: 0.00, gen throughput (token/s): 1741.43, largest-len: 0, #queue-req: 0, 
[2025-08-25 14:58:46 TP0] Decode batch. #running-req: 8, #token: 2764, token usage: 0.00, gen throughput (token/s): 1690.21, largest-len: 0, #queue-req: 0, 
[2025-08-25 14:58:47 TP0] Decode batch. #running-req: 8, #token: 3084, token usage: 0.00, gen throughput (token/s): 1673.74, largest-len: 0, #queue-req: 0, 
[2025-08-25 14:58:47 TP0] Decode batch. #running-req: 8, #token: 3404, token usage: 0.00, gen throughput (token/s): 1636.22, largest-len: 0, #queue-req: 0, 
[2025-08-25 14:58:47 TP0] Decode batch. #running-req: 8, #token: 3724, token usage: 0.00, gen throughput (token/s): 1674.66, largest-len: 0, #queue-req: 0, 
[2025-08-25 14:58:47 TP0] Decode batch. #running-req: 8, #token: 4044, token usage: 0.00, gen throughput (token/s): 1723.88, largest-len: 0, #queue-req: 0, 
[2025-08-25 14:58:47] INFO:     127.0.0.1:56378 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 14:58:47] INFO:     127.0.0.1:56390 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 14:58:47] INFO:     127.0.0.1:56394 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 14:58:47] INFO:     127.0.0.1:56396 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 14:58:47] INFO:     127.0.0.1:56412 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 14:58:47] INFO:     127.0.0.1:56418 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 14:58:47] INFO:     127.0.0.1:56432 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 14:58:47] INFO:     127.0.0.1:56440 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 14:58:47 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 211, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-08-25 14:58:47 TP0] Prefill batch. #new-seq: 7, #new-token: 7, #cached-token: 1477, token usage: 0.00, #running-req: 1, #queue-req: 0, 
[2025-08-25 14:58:48 TP0] Decode batch. #running-req: 8, #token: 364, token usage: 0.00, gen throughput (token/s): 1077.06, largest-len: 0, #queue-req: 0, 
[2025-08-25 14:58:48 TP0] Decode batch. #running-req: 8, #token: 684, token usage: 0.00, gen throughput (token/s): 1697.44, largest-len: 0, #queue-req: 0, 
[2025-08-25 14:58:48 TP0] Decode batch. #running-req: 8, #token: 1004, token usage: 0.00, gen throughput (token/s): 1710.36, largest-len: 0, #queue-req: 0, 
[2025-08-25 14:58:48 TP0] Decode batch. #running-req: 8, #token: 1324, token usage: 0.00, gen throughput (token/s): 1760.67, largest-len: 0, #queue-req: 0, 
[2025-08-25 14:58:48 TP0] Decode batch. #running-req: 8, #token: 1644, token usage: 0.00, gen throughput (token/s): 1758.41, largest-len: 0, #queue-req: 0, 
[2025-08-25 14:58:48 TP0] Decode batch. #running-req: 8, #token: 1964, token usage: 0.00, gen throughput (token/s): 1752.56, largest-len: 0, #queue-req: 0, 
[2025-08-25 14:58:49 TP0] Decode batch. #running-req: 8, #token: 2284, token usage: 0.00, gen throughput (token/s): 1801.42, largest-len: 0, #queue-req: 0, 
[2025-08-25 14:58:49 TP0] Decode batch. #running-req: 8, #token: 2604, token usage: 0.00, gen throughput (token/s): 1762.96, largest-len: 0, #queue-req: 0, 
[2025-08-25 14:58:49 TP0] Decode batch. #running-req: 8, #token: 2924, token usage: 0.00, gen throughput (token/s): 1707.99, largest-len: 0, #queue-req: 0, 
[2025-08-25 14:58:49 TP0] Decode batch. #running-req: 8, #token: 3244, token usage: 0.00, gen throughput (token/s): 1594.30, largest-len: 0, #queue-req: 0, 
[2025-08-25 14:58:49 TP0] Decode batch. #running-req: 8, #token: 3564, token usage: 0.00, gen throughput (token/s): 1677.36, largest-len: 0, #queue-req: 0, 
[2025-08-25 14:58:50 TP0] Decode batch. #running-req: 8, #token: 3884, token usage: 0.00, gen throughput (token/s): 1596.04, largest-len: 0, #queue-req: 0, 
[2025-08-25 14:58:50 TP0] Decode batch. #running-req: 8, #token: 4204, token usage: 0.00, gen throughput (token/s): 1695.13, largest-len: 0, #queue-req: 0, 
[2025-08-25 14:58:50] INFO:     127.0.0.1:56378 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 14:58:50] INFO:     127.0.0.1:56390 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 14:58:50] INFO:     127.0.0.1:56394 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 14:58:50] INFO:     127.0.0.1:56396 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 14:58:50] INFO:     127.0.0.1:56412 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 14:58:50] INFO:     127.0.0.1:56418 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 14:58:50] INFO:     127.0.0.1:56432 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 14:58:50] INFO:     127.0.0.1:56440 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 14:58:50 TP0] Prefill batch. #new-seq: 1, #new-token: 500, #cached-token: 201, token usage: 0.01, #running-req: 0, #queue-req: 0, 
[2025-08-25 14:58:50 TP0] Prefill batch. #new-seq: 6, #new-token: 3000, #cached-token: 1206, token usage: 0.02, #running-req: 1, #queue-req: 0, 
[2025-08-25 14:58:51 TP0] Prefill batch. #new-seq: 1, #new-token: 500, #cached-token: 201, token usage: 0.08, #running-req: 7, #queue-req: 0, 
[2025-08-25 14:58:51] INFO:     127.0.0.1:21594 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 14:58:51] INFO:     127.0.0.1:21604 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 14:58:51] INFO:     127.0.0.1:21606 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 14:58:51] INFO:     127.0.0.1:21622 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 14:58:51] INFO:     127.0.0.1:21636 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 14:58:51] INFO:     127.0.0.1:21638 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 14:58:51] INFO:     127.0.0.1:21640 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 14:58:51 TP0] Prefill batch. #new-seq: 7, #new-token: 3500, #cached-token: 1407, token usage: 0.01, #running-req: 1, #queue-req: 0, 
[2025-08-25 14:58:51] INFO:     127.0.0.1:21654 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 14:58:52 TP0] Prefill batch. #new-seq: 1, #new-token: 500, #cached-token: 201, token usage: 0.09, #running-req: 8, #queue-req: 0, 
[2025-08-25 14:58:52] INFO:     127.0.0.1:21594 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 14:58:52] INFO:     127.0.0.1:21604 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 14:58:52] INFO:     127.0.0.1:21606 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 14:58:52] INFO:     127.0.0.1:21622 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 14:58:52] INFO:     127.0.0.1:21636 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 14:58:52] INFO:     127.0.0.1:21638 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 14:58:52] INFO:     127.0.0.1:21640 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 14:58:52 TP0] Prefill batch. #new-seq: 2, #new-token: 978, #cached-token: 442, token usage: 0.01, #running-req: 1, #queue-req: 0, 
[2025-08-25 14:58:52] INFO:     127.0.0.1:21654 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 14:58:53 TP0] Decode batch. #running-req: 2, #token: 1216, token usage: 0.03, gen throughput (token/s): 1.24, largest-len: 0, #queue-req: 0, 
[2025-08-25 14:58:55 TP0] Decode batch. #running-req: 2, #token: 1296, token usage: 0.03, gen throughput (token/s): 45.03, largest-len: 0, #queue-req: 0, 
[2025-08-25 14:58:56 TP0] Decode batch. #running-req: 2, #token: 1376, token usage: 0.03, gen throughput (token/s): 44.97, largest-len: 0, #queue-req: 0, 
[2025-08-25 14:58:58 TP0] Decode batch. #running-req: 2, #token: 1456, token usage: 0.04, gen throughput (token/s): 44.96, largest-len: 0, #queue-req: 0, 
[2025-08-25 14:58:59] INFO:     127.0.0.1:21604 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 14:58:59] INFO:     127.0.0.1:21594 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 14:58:59 TP0] Prefill batch. #new-seq: 7, #new-token: 7, #cached-token: 1162, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-08-25 14:58:59 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 166, token usage: 0.00, #running-req: 7, #queue-req: 0, 
[2025-08-25 14:59:00 TP0] Decode batch. #running-req: 8, #token: 479, token usage: 0.00, gen throughput (token/s): 32.25, largest-len: 0, #queue-req: 0, 
[2025-08-25 14:59:00 TP0] Decode batch. #running-req: 8, #token: 799, token usage: 0.00, gen throughput (token/s): 1706.05, largest-len: 0, #queue-req: 0, 
[2025-08-25 14:59:00 TP0] Decode batch. #running-req: 8, #token: 1119, token usage: 0.00, gen throughput (token/s): 1729.38, largest-len: 0, #queue-req: 0, 
[2025-08-25 14:59:00 TP0] Decode batch. #running-req: 8, #token: 1439, token usage: 0.00, gen throughput (token/s): 1687.41, largest-len: 0, #queue-req: 0, 
[2025-08-25 14:59:00 TP0] Decode batch. #running-req: 8, #token: 1759, token usage: 0.00, gen throughput (token/s): 1764.89, largest-len: 0, #queue-req: 0, 
[2025-08-25 14:59:01 TP0] Decode batch. #running-req: 8, #token: 2079, token usage: 0.00, gen throughput (token/s): 1747.85, largest-len: 0, #queue-req: 0, 
[2025-08-25 14:59:01 TP0] Decode batch. #running-req: 8, #token: 2399, token usage: 0.00, gen throughput (token/s): 1751.69, largest-len: 0, #queue-req: 0, 
[2025-08-25 14:59:01 TP0] Decode batch. #running-req: 8, #token: 2719, token usage: 0.00, gen throughput (token/s): 1768.03, largest-len: 0, #queue-req: 0, 
[2025-08-25 14:59:01 TP0] Decode batch. #running-req: 8, #token: 3039, token usage: 0.00, gen throughput (token/s): 1712.02, largest-len: 0, #queue-req: 0, 
[2025-08-25 14:59:01 TP0] Decode batch. #running-req: 8, #token: 3359, token usage: 0.00, gen throughput (token/s): 1681.68, largest-len: 0, #queue-req: 0, 
[2025-08-25 14:59:02 TP0] Decode batch. #running-req: 8, #token: 3679, token usage: 0.00, gen throughput (token/s): 1602.16, largest-len: 0, #queue-req: 0, 
[2025-08-25 14:59:02 TP0] Decode batch. #running-req: 8, #token: 3999, token usage: 0.00, gen throughput (token/s): 1596.30, largest-len: 0, #queue-req: 0, 
[2025-08-25 14:59:02] INFO:     127.0.0.1:10712 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 14:59:02] INFO:     127.0.0.1:10724 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 14:59:02] INFO:     127.0.0.1:10738 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 14:59:02] INFO:     127.0.0.1:10754 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 14:59:02] INFO:     127.0.0.1:10762 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 14:59:02] INFO:     127.0.0.1:10768 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 14:59:02] INFO:     127.0.0.1:10780 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 14:59:02] INFO:     127.0.0.1:10796 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 14:59:02 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 166, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-08-25 14:59:02 TP0] Prefill batch. #new-seq: 7, #new-token: 7, #cached-token: 1162, token usage: 0.00, #running-req: 1, #queue-req: 0, 
[2025-08-25 14:59:02 TP0] Decode batch. #running-req: 8, #token: 319, token usage: 0.00, gen throughput (token/s): 1005.65, largest-len: 0, #queue-req: 0, 
[2025-08-25 14:59:02 TP0] Decode batch. #running-req: 8, #token: 639, token usage: 0.00, gen throughput (token/s): 1726.53, largest-len: 0, #queue-req: 0, 
[2025-08-25 14:59:02 TP0] Decode batch. #running-req: 8, #token: 959, token usage: 0.00, gen throughput (token/s): 1724.41, largest-len: 0, #queue-req: 0, 
[2025-08-25 14:59:03 TP0] Decode batch. #running-req: 8, #token: 1279, token usage: 0.00, gen throughput (token/s): 1770.30, largest-len: 0, #queue-req: 0, 
[2025-08-25 14:59:03 TP0] Decode batch. #running-req: 8, #token: 1599, token usage: 0.00, gen throughput (token/s): 1783.32, largest-len: 0, #queue-req: 0, 
[2025-08-25 14:59:03 TP0] Decode batch. #running-req: 8, #token: 1919, token usage: 0.00, gen throughput (token/s): 1772.97, largest-len: 0, #queue-req: 0, 
[2025-08-25 14:59:03 TP0] Decode batch. #running-req: 8, #token: 2239, token usage: 0.00, gen throughput (token/s): 1729.32, largest-len: 0, #queue-req: 0, 
[2025-08-25 14:59:03 TP0] Decode batch. #running-req: 8, #token: 2559, token usage: 0.00, gen throughput (token/s): 1786.54, largest-len: 0, #queue-req: 0, 
[2025-08-25 14:59:04 TP0] Decode batch. #running-req: 8, #token: 2879, token usage: 0.00, gen throughput (token/s): 1785.48, largest-len: 0, #queue-req: 0, 
[2025-08-25 14:59:04 TP0] Decode batch. #running-req: 8, #token: 3199, token usage: 0.00, gen throughput (token/s): 1785.31, largest-len: 0, #queue-req: 0, 
[2025-08-25 14:59:04 TP0] Decode batch. #running-req: 8, #token: 3519, token usage: 0.00, gen throughput (token/s): 1756.76, largest-len: 0, #queue-req: 0, 
[2025-08-25 14:59:04 TP0] Decode batch. #running-req: 8, #token: 3839, token usage: 0.00, gen throughput (token/s): 1708.30, largest-len: 0, #queue-req: 0, 
[2025-08-25 14:59:04 TP0] Decode batch. #running-req: 8, #token: 4159, token usage: 0.00, gen throughput (token/s): 1715.68, largest-len: 0, #queue-req: 0, 
[2025-08-25 14:59:04] INFO:     127.0.0.1:10796 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 14:59:04] INFO:     127.0.0.1:10712 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 14:59:04] INFO:     127.0.0.1:10724 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 14:59:04] INFO:     127.0.0.1:10738 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 14:59:04] INFO:     127.0.0.1:10754 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 14:59:04] INFO:     127.0.0.1:10762 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 14:59:04] INFO:     127.0.0.1:10768 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 14:59:04] INFO:     127.0.0.1:10780 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 14:59:04 TP0] Prefill batch. #new-seq: 1, #new-token: 614, #cached-token: 42, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-08-25 14:59:04 TP0] Prefill batch. #new-seq: 5, #new-token: 3069, #cached-token: 210, token usage: 0.02, #running-req: 1, #queue-req: 0, 
[2025-08-25 14:59:05 TP0] Prefill batch. #new-seq: 2, #new-token: 1000, #cached-token: 312, token usage: 0.08, #running-req: 6, #queue-req: 0, 
[2025-08-25 14:59:05] INFO:     127.0.0.1:21594 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 14:59:05] INFO:     127.0.0.1:21604 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 14:59:06] INFO:     127.0.0.1:9142 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 14:59:06] INFO:     127.0.0.1:9148 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 14:59:06] INFO:     127.0.0.1:9150 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 14:59:06] INFO:     127.0.0.1:9164 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 14:59:06 TP0] Prefill batch. #new-seq: 6, #new-token: 3000, #cached-token: 936, token usage: 0.00, #running-req: 2, #queue-req: 0, 
[2025-08-25 14:59:06] INFO:     127.0.0.1:9180 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 14:59:06] INFO:     127.0.0.1:9190 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 14:59:07 TP0] Prefill batch. #new-seq: 2, #new-token: 1000, #cached-token: 312, token usage: 0.08, #running-req: 8, #queue-req: 0, 
[2025-08-25 14:59:07] INFO:     127.0.0.1:21594 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 14:59:07] INFO:     127.0.0.1:21604 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 14:59:07] INFO:     127.0.0.1:9142 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 14:59:07] INFO:     127.0.0.1:9148 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 14:59:07] INFO:     127.0.0.1:9150 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 14:59:07] INFO:     127.0.0.1:9164 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 14:59:07 TP0] Prefill batch. #new-seq: 6, #new-token: 3725, #cached-token: 264, token usage: 0.00, #running-req: 2, #queue-req: 0, 
[2025-08-25 14:59:07] INFO:     127.0.0.1:9180 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 14:59:07] INFO:     127.0.0.1:9190 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 14:59:07 TP0] Prefill batch. #new-seq: 1, #new-token: 621, #cached-token: 44, token usage: 0.09, #running-req: 8, #queue-req: 0, 
[2025-08-25 14:59:09 TP0] Decode batch. #running-req: 7, #token: 3712, token usage: 0.09, gen throughput (token/s): 12.15, largest-len: 0, #queue-req: 0, 
[2025-08-25 14:59:11 TP0] Decode batch. #running-req: 7, #token: 3992, token usage: 0.10, gen throughput (token/s): 151.66, largest-len: 0, #queue-req: 0, 
[2025-08-25 14:59:13 TP0] Decode batch. #running-req: 7, #token: 4272, token usage: 0.11, gen throughput (token/s): 151.47, largest-len: 0, #queue-req: 0, 
[2025-08-25 14:59:14 TP0] Decode batch. #running-req: 7, #token: 4552, token usage: 0.11, gen throughput (token/s): 150.18, largest-len: 0, #queue-req: 0, 
[2025-08-25 14:59:15] INFO:     127.0.0.1:21594 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 14:59:15] INFO:     127.0.0.1:21604 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 14:59:15] INFO:     127.0.0.1:9142 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 14:59:15] INFO:     127.0.0.1:9148 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 14:59:15] INFO:     127.0.0.1:9150 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 14:59:15] INFO:     127.0.0.1:9164 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 14:59:15] INFO:     127.0.0.1:9180 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 14:59:15 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 109, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-08-25 14:59:15 TP0] Prefill batch. #new-seq: 7, #new-token: 7, #cached-token: 763, token usage: 0.00, #running-req: 1, #queue-req: 0, 
[2025-08-25 14:59:16 TP0] Decode batch. #running-req: 8, #token: 422, token usage: 0.00, gen throughput (token/s): 28.07, largest-len: 0, #queue-req: 0, 
[2025-08-25 14:59:16 TP0] Decode batch. #running-req: 8, #token: 742, token usage: 0.00, gen throughput (token/s): 1695.75, largest-len: 0, #queue-req: 0, 
[2025-08-25 14:59:16 TP0] Decode batch. #running-req: 8, #token: 1062, token usage: 0.00, gen throughput (token/s): 1609.70, largest-len: 0, #queue-req: 0, 
[2025-08-25 14:59:16 TP0] Decode batch. #running-req: 8, #token: 1382, token usage: 0.00, gen throughput (token/s): 1639.74, largest-len: 0, #queue-req: 0, 
[2025-08-25 14:59:16 TP0] Decode batch. #running-req: 8, #token: 1702, token usage: 0.00, gen throughput (token/s): 1765.22, largest-len: 0, #queue-req: 0, 
[2025-08-25 14:59:17 TP0] Decode batch. #running-req: 8, #token: 2022, token usage: 0.00, gen throughput (token/s): 1603.48, largest-len: 0, #queue-req: 0, 
[2025-08-25 14:59:17 TP0] Decode batch. #running-req: 8, #token: 2342, token usage: 0.00, gen throughput (token/s): 1575.65, largest-len: 0, #queue-req: 0, 
[2025-08-25 14:59:17 TP0] Decode batch. #running-req: 8, #token: 2662, token usage: 0.00, gen throughput (token/s): 1611.25, largest-len: 0, #queue-req: 0, 
[2025-08-25 14:59:17 TP0] Decode batch. #running-req: 8, #token: 2982, token usage: 0.00, gen throughput (token/s): 1614.16, largest-len: 0, #queue-req: 0, 
[2025-08-25 14:59:17 TP0] Decode batch. #running-req: 8, #token: 3302, token usage: 0.00, gen throughput (token/s): 1704.09, largest-len: 0, #queue-req: 0, 
[2025-08-25 14:59:18 TP0] Decode batch. #running-req: 8, #token: 3622, token usage: 0.00, gen throughput (token/s): 1634.71, largest-len: 0, #queue-req: 0, 
[2025-08-25 14:59:18 TP0] Decode batch. #running-req: 8, #token: 3942, token usage: 0.00, gen throughput (token/s): 1637.27, largest-len: 0, #queue-req: 0, 
[2025-08-25 14:59:18] INFO:     127.0.0.1:13446 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 14:59:18] INFO:     127.0.0.1:13460 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 14:59:18] INFO:     127.0.0.1:13462 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 14:59:18] INFO:     127.0.0.1:13472 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 14:59:18] INFO:     127.0.0.1:13486 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 14:59:18] INFO:     127.0.0.1:13490 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 14:59:18] INFO:     127.0.0.1:13496 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 14:59:18] INFO:     127.0.0.1:13504 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 14:59:18 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 109, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-08-25 14:59:18 TP0] Prefill batch. #new-seq: 7, #new-token: 7, #cached-token: 763, token usage: 0.00, #running-req: 1, #queue-req: 0, 
[2025-08-25 14:59:18 TP0] Decode batch. #running-req: 8, #token: 262, token usage: 0.00, gen throughput (token/s): 1021.17, largest-len: 0, #queue-req: 0, 
[2025-08-25 14:59:18 TP0] Decode batch. #running-req: 8, #token: 582, token usage: 0.00, gen throughput (token/s): 1651.64, largest-len: 0, #queue-req: 0, 
[2025-08-25 14:59:19 TP0] Decode batch. #running-req: 8, #token: 902, token usage: 0.00, gen throughput (token/s): 1729.79, largest-len: 0, #queue-req: 0, 
[2025-08-25 14:59:19 TP0] Decode batch. #running-req: 8, #token: 1222, token usage: 0.00, gen throughput (token/s): 1641.33, largest-len: 0, #queue-req: 0, 
[2025-08-25 14:59:19 TP0] Decode batch. #running-req: 8, #token: 1542, token usage: 0.00, gen throughput (token/s): 1639.78, largest-len: 0, #queue-req: 0, 
[2025-08-25 14:59:19 TP0] Decode batch. #running-req: 8, #token: 1862, token usage: 0.00, gen throughput (token/s): 1647.70, largest-len: 0, #queue-req: 0, 
[2025-08-25 14:59:19 TP0] Decode batch. #running-req: 8, #token: 2182, token usage: 0.00, gen throughput (token/s): 1649.62, largest-len: 0, #queue-req: 0, 
[2025-08-25 14:59:19 TP0] Decode batch. #running-req: 8, #token: 2502, token usage: 0.00, gen throughput (token/s): 1675.80, largest-len: 0, #queue-req: 0, 
[2025-08-25 14:59:20 TP0] Decode batch. #running-req: 8, #token: 2822, token usage: 0.00, gen throughput (token/s): 1624.41, largest-len: 0, #queue-req: 0, 
[2025-08-25 14:59:20 TP0] Decode batch. #running-req: 8, #token: 3142, token usage: 0.00, gen throughput (token/s): 1657.54, largest-len: 0, #queue-req: 0, 
[2025-08-25 14:59:20 TP0] Decode batch. #running-req: 8, #token: 3462, token usage: 0.00, gen throughput (token/s): 1625.44, largest-len: 0, #queue-req: 0, 
[2025-08-25 14:59:20 TP0] Decode batch. #running-req: 8, #token: 3782, token usage: 0.00, gen throughput (token/s): 1639.83, largest-len: 0, #queue-req: 0, 
[2025-08-25 14:59:20 TP0] Decode batch. #running-req: 8, #token: 4102, token usage: 0.00, gen throughput (token/s): 1668.88, largest-len: 0, #queue-req: 0, 
[2025-08-25 14:59:20] INFO:     127.0.0.1:13504 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 14:59:20] INFO:     127.0.0.1:13446 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 14:59:20] INFO:     127.0.0.1:13460 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 14:59:20] INFO:     127.0.0.1:13462 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 14:59:20] INFO:     127.0.0.1:13472 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 14:59:20] INFO:     127.0.0.1:13486 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 14:59:20] INFO:     127.0.0.1:13490 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 14:59:20] INFO:     127.0.0.1:13496 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 14:59:21 TP0] Prefill batch. #new-seq: 1, #new-token: 555, #cached-token: 44, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-08-25 14:59:21 TP0] Prefill batch. #new-seq: 7, #new-token: 3885, #cached-token: 308, token usage: 0.02, #running-req: 1, #queue-req: 0, 
[2025-08-25 14:59:22] INFO:     127.0.0.1:41428 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 14:59:22] INFO:     127.0.0.1:41438 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 14:59:22] INFO:     127.0.0.1:41450 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 14:59:22] INFO:     127.0.0.1:41464 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 14:59:22] INFO:     127.0.0.1:41472 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 14:59:22] INFO:     127.0.0.1:41480 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 14:59:22] INFO:     127.0.0.1:41494 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 14:59:22] INFO:     127.0.0.1:41504 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 14:59:22 TP0] Prefill batch. #new-seq: 1, #new-token: 500, #cached-token: 99, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-08-25 14:59:22 TP0] Prefill batch. #new-seq: 7, #new-token: 3500, #cached-token: 693, token usage: 0.00, #running-req: 1, #queue-req: 0, 
[2025-08-25 14:59:22] INFO:     127.0.0.1:41428 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 14:59:23] INFO:     127.0.0.1:41504 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 14:59:23] INFO:     127.0.0.1:41438 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 14:59:23] INFO:     127.0.0.1:41450 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 14:59:23] INFO:     127.0.0.1:41464 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 14:59:23] INFO:     127.0.0.1:41472 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 14:59:24] INFO:     127.0.0.1:41480 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 14:59:24] INFO:     127.0.0.1:41494 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 14:59:24 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 135, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-08-25 14:59:24 TP0] Prefill batch. #new-seq: 7, #new-token: 7, #cached-token: 945, token usage: 0.00, #running-req: 1, #queue-req: 0, 
[2025-08-25 14:59:24 TP0] Decode batch. #running-req: 8, #token: 448, token usage: 0.00, gen throughput (token/s): 94.34, largest-len: 0, #queue-req: 0, 
[2025-08-25 14:59:24 TP0] Decode batch. #running-req: 8, #token: 768, token usage: 0.00, gen throughput (token/s): 1642.01, largest-len: 0, #queue-req: 0, 
[2025-08-25 14:59:24 TP0] Decode batch. #running-req: 8, #token: 1088, token usage: 0.00, gen throughput (token/s): 1694.51, largest-len: 0, #queue-req: 0, 
[2025-08-25 14:59:24 TP0] Decode batch. #running-req: 8, #token: 1408, token usage: 0.00, gen throughput (token/s): 1678.93, largest-len: 0, #queue-req: 0, 
[2025-08-25 14:59:25 TP0] Decode batch. #running-req: 8, #token: 1728, token usage: 0.00, gen throughput (token/s): 1695.34, largest-len: 0, #queue-req: 0, 
[2025-08-25 14:59:25 TP0] Decode batch. #running-req: 8, #token: 2048, token usage: 0.00, gen throughput (token/s): 1652.47, largest-len: 0, #queue-req: 0, 
[2025-08-25 14:59:25 TP0] Decode batch. #running-req: 8, #token: 2368, token usage: 0.00, gen throughput (token/s): 1702.67, largest-len: 0, #queue-req: 0, 
[2025-08-25 14:59:25 TP0] Decode batch. #running-req: 8, #token: 2688, token usage: 0.00, gen throughput (token/s): 1727.73, largest-len: 0, #queue-req: 0, 
[2025-08-25 14:59:25 TP0] Decode batch. #running-req: 8, #token: 3008, token usage: 0.00, gen throughput (token/s): 1710.91, largest-len: 0, #queue-req: 0, 
[2025-08-25 14:59:26 TP0] Decode batch. #running-req: 8, #token: 3328, token usage: 0.00, gen throughput (token/s): 1743.25, largest-len: 0, #queue-req: 0, 
[2025-08-25 14:59:26 TP0] Decode batch. #running-req: 8, #token: 3648, token usage: 0.00, gen throughput (token/s): 1685.57, largest-len: 0, #queue-req: 0, 
[2025-08-25 14:59:26 TP0] Decode batch. #running-req: 8, #token: 3968, token usage: 0.00, gen throughput (token/s): 1762.56, largest-len: 0, #queue-req: 0, 
[2025-08-25 14:59:26] INFO:     127.0.0.1:13504 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 14:59:26] INFO:     127.0.0.1:13446 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 14:59:26] INFO:     127.0.0.1:13460 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 14:59:26] INFO:     127.0.0.1:13462 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 14:59:26] INFO:     127.0.0.1:13472 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 14:59:26] INFO:     127.0.0.1:13486 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 14:59:26] INFO:     127.0.0.1:13490 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 14:59:26] INFO:     127.0.0.1:13496 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 14:59:26 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 135, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-08-25 14:59:26 TP0] Prefill batch. #new-seq: 7, #new-token: 7, #cached-token: 945, token usage: 0.00, #running-req: 1, #queue-req: 0, 
[2025-08-25 14:59:26 TP0] Decode batch. #running-req: 8, #token: 288, token usage: 0.00, gen throughput (token/s): 1104.10, largest-len: 0, #queue-req: 0, 
[2025-08-25 14:59:26 TP0] Decode batch. #running-req: 8, #token: 608, token usage: 0.00, gen throughput (token/s): 1695.96, largest-len: 0, #queue-req: 0, 
[2025-08-25 14:59:27 TP0] Decode batch. #running-req: 8, #token: 928, token usage: 0.00, gen throughput (token/s): 1720.60, largest-len: 0, #queue-req: 0, 
[2025-08-25 14:59:27 TP0] Decode batch. #running-req: 8, #token: 1248, token usage: 0.00, gen throughput (token/s): 1685.25, largest-len: 0, #queue-req: 0, 
[2025-08-25 14:59:27 TP0] Decode batch. #running-req: 8, #token: 1568, token usage: 0.00, gen throughput (token/s): 1742.35, largest-len: 0, #queue-req: 0, 
[2025-08-25 14:59:27 TP0] Decode batch. #running-req: 8, #token: 1888, token usage: 0.00, gen throughput (token/s): 1698.58, largest-len: 0, #queue-req: 0, 
[2025-08-25 14:59:27 TP0] Decode batch. #running-req: 8, #token: 2208, token usage: 0.00, gen throughput (token/s): 1722.09, largest-len: 0, #queue-req: 0, 
[2025-08-25 14:59:28 TP0] Decode batch. #running-req: 8, #token: 2528, token usage: 0.00, gen throughput (token/s): 1745.90, largest-len: 0, #queue-req: 0, 
[2025-08-25 14:59:28 TP0] Decode batch. #running-req: 8, #token: 2848, token usage: 0.00, gen throughput (token/s): 1724.35, largest-len: 0, #queue-req: 0, 
[2025-08-25 14:59:28 TP0] Decode batch. #running-req: 8, #token: 3168, token usage: 0.00, gen throughput (token/s): 1720.64, largest-len: 0, #queue-req: 0, 
[2025-08-25 14:59:28 TP0] Decode batch. #running-req: 8, #token: 3488, token usage: 0.00, gen throughput (token/s): 1710.34, largest-len: 0, #queue-req: 0, 
[2025-08-25 14:59:28 TP0] Decode batch. #running-req: 8, #token: 3808, token usage: 0.00, gen throughput (token/s): 1764.85, largest-len: 0, #queue-req: 0, 
[2025-08-25 14:59:28 TP0] Decode batch. #running-req: 8, #token: 4128, token usage: 0.00, gen throughput (token/s): 1726.96, largest-len: 0, #queue-req: 0, 
[2025-08-25 14:59:28] INFO:     127.0.0.1:13504 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 14:59:28] INFO:     127.0.0.1:13446 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 14:59:28] INFO:     127.0.0.1:13460 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 14:59:28] INFO:     127.0.0.1:13462 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 14:59:28] INFO:     127.0.0.1:13472 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 14:59:28] INFO:     127.0.0.1:13486 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 14:59:28] INFO:     127.0.0.1:13490 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 14:59:28] INFO:     127.0.0.1:13496 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 14:59:28 TP0] Prefill batch. #new-seq: 3, #new-token: 1749, #cached-token: 126, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-08-25 14:59:29 TP0] Prefill batch. #new-seq: 5, #new-token: 2915, #cached-token: 210, token usage: 0.04, #running-req: 3, #queue-req: 0, 
[2025-08-25 14:59:30] INFO:     127.0.0.1:41472 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 14:59:30] INFO:     127.0.0.1:41480 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 14:59:30] INFO:     127.0.0.1:41494 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 14:59:30] INFO:     127.0.0.1:41514 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 14:59:30] INFO:     127.0.0.1:41530 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 14:59:30] INFO:     127.0.0.1:41544 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 14:59:30] INFO:     127.0.0.1:41560 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 14:59:30] INFO:     127.0.0.1:41576 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 14:59:30 TP0] Prefill batch. #new-seq: 2, #new-token: 1000, #cached-token: 250, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-08-25 14:59:30 TP0] Prefill batch. #new-seq: 1, #new-token: 500, #cached-token: 125, token usage: 0.03, #running-req: 2, #queue-req: 0, 
[2025-08-25 14:59:31 TP0] Prefill batch. #new-seq: 5, #new-token: 2500, #cached-token: 625, token usage: 0.02, #running-req: 3, #queue-req: 0, 
[2025-08-25 14:59:31] INFO:     127.0.0.1:41480 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 14:59:31] INFO:     127.0.0.1:41472 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 14:59:31] INFO:     127.0.0.1:41494 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 14:59:31] INFO:     127.0.0.1:41514 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 14:59:31] INFO:     127.0.0.1:41530 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 14:59:31] INFO:     127.0.0.1:41544 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 14:59:31] INFO:     127.0.0.1:41560 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 14:59:32] INFO:     127.0.0.1:41576 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 14:59:32 TP0] Prefill batch. #new-seq: 1, #new-token: 85, #cached-token: 50, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-08-25 14:59:32 TP0] Prefill batch. #new-seq: 7, #new-token: 595, #cached-token: 350, token usage: 0.00, #running-req: 1, #queue-req: 0, 
[2025-08-25 14:59:32 TP0] Decode batch. #running-req: 8, #token: 447, token usage: 0.00, gen throughput (token/s): 95.23, largest-len: 0, #queue-req: 0, 
[2025-08-25 14:59:32 TP0] Decode batch. #running-req: 8, #token: 767, token usage: 0.00, gen throughput (token/s): 1693.68, largest-len: 0, #queue-req: 0, 
[2025-08-25 14:59:32 TP0] Decode batch. #running-req: 8, #token: 1087, token usage: 0.00, gen throughput (token/s): 1681.46, largest-len: 0, #queue-req: 0, 
[2025-08-25 14:59:32 TP0] Decode batch. #running-req: 8, #token: 1407, token usage: 0.00, gen throughput (token/s): 1715.63, largest-len: 0, #queue-req: 0, 
[2025-08-25 14:59:33 TP0] Decode batch. #running-req: 8, #token: 1727, token usage: 0.00, gen throughput (token/s): 1701.34, largest-len: 0, #queue-req: 0, 
[2025-08-25 14:59:33 TP0] Decode batch. #running-req: 8, #token: 2047, token usage: 0.00, gen throughput (token/s): 1693.93, largest-len: 0, #queue-req: 0, 
[2025-08-25 14:59:33 TP0] Decode batch. #running-req: 8, #token: 2367, token usage: 0.00, gen throughput (token/s): 1734.83, largest-len: 0, #queue-req: 0, 
[2025-08-25 14:59:33 TP0] Decode batch. #running-req: 8, #token: 2687, token usage: 0.00, gen throughput (token/s): 1783.60, largest-len: 0, #queue-req: 0, 
[2025-08-25 14:59:33 TP0] Decode batch. #running-req: 8, #token: 3007, token usage: 0.00, gen throughput (token/s): 1750.20, largest-len: 0, #queue-req: 0, 
[2025-08-25 14:59:33 TP0] Decode batch. #running-req: 8, #token: 3327, token usage: 0.00, gen throughput (token/s): 1753.58, largest-len: 0, #queue-req: 0, 
[2025-08-25 14:59:34 TP0] Decode batch. #running-req: 8, #token: 3647, token usage: 0.00, gen throughput (token/s): 1769.62, largest-len: 0, #queue-req: 0, 
[2025-08-25 14:59:34 TP0] Decode batch. #running-req: 8, #token: 3967, token usage: 0.00, gen throughput (token/s): 1739.77, largest-len: 0, #queue-req: 0, 
[2025-08-25 14:59:34] INFO:     127.0.0.1:13504 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 14:59:34] INFO:     127.0.0.1:13446 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 14:59:34] INFO:     127.0.0.1:13460 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 14:59:34] INFO:     127.0.0.1:13462 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 14:59:34] INFO:     127.0.0.1:13472 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 14:59:34] INFO:     127.0.0.1:13486 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 14:59:34] INFO:     127.0.0.1:13490 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 14:59:34] INFO:     127.0.0.1:13496 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 14:59:34 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 134, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-08-25 14:59:34 TP0] Prefill batch. #new-seq: 7, #new-token: 7, #cached-token: 938, token usage: 0.00, #running-req: 1, #queue-req: 0, 
[2025-08-25 14:59:34 TP0] Decode batch. #running-req: 8, #token: 287, token usage: 0.00, gen throughput (token/s): 1069.84, largest-len: 0, #queue-req: 0, 
[2025-08-25 14:59:34 TP0] Decode batch. #running-req: 8, #token: 607, token usage: 0.00, gen throughput (token/s): 1722.78, largest-len: 0, #queue-req: 0, 
[2025-08-25 14:59:35 TP0] Decode batch. #running-req: 8, #token: 927, token usage: 0.00, gen throughput (token/s): 1738.44, largest-len: 0, #queue-req: 0, 
[2025-08-25 14:59:35 TP0] Decode batch. #running-req: 8, #token: 1247, token usage: 0.00, gen throughput (token/s): 1779.04, largest-len: 0, #queue-req: 0, 
[2025-08-25 14:59:35 TP0] Decode batch. #running-req: 8, #token: 1567, token usage: 0.00, gen throughput (token/s): 1728.82, largest-len: 0, #queue-req: 0, 
[2025-08-25 14:59:35 TP0] Decode batch. #running-req: 8, #token: 1887, token usage: 0.00, gen throughput (token/s): 1735.78, largest-len: 0, #queue-req: 0, 
[2025-08-25 14:59:35 TP0] Decode batch. #running-req: 8, #token: 2207, token usage: 0.00, gen throughput (token/s): 1712.32, largest-len: 0, #queue-req: 0, 
[2025-08-25 14:59:35 TP0] Decode batch. #running-req: 8, #token: 2527, token usage: 0.00, gen throughput (token/s): 1680.35, largest-len: 0, #queue-req: 0, 
[2025-08-25 14:59:36 TP0] Decode batch. #running-req: 8, #token: 2847, token usage: 0.00, gen throughput (token/s): 1802.71, largest-len: 0, #queue-req: 0, 
[2025-08-25 14:59:36 TP0] Decode batch. #running-req: 8, #token: 3167, token usage: 0.00, gen throughput (token/s): 1841.28, largest-len: 0, #queue-req: 0, 
[2025-08-25 14:59:36 TP0] Decode batch. #running-req: 8, #token: 3487, token usage: 0.00, gen throughput (token/s): 1786.94, largest-len: 0, #queue-req: 0, 
[2025-08-25 14:59:36 TP0] Decode batch. #running-req: 8, #token: 3807, token usage: 0.00, gen throughput (token/s): 1667.85, largest-len: 0, #queue-req: 0, 
[2025-08-25 14:59:36 TP0] Decode batch. #running-req: 8, #token: 4127, token usage: 0.00, gen throughput (token/s): 1684.31, largest-len: 0, #queue-req: 0, 
[2025-08-25 14:59:36] INFO:     127.0.0.1:13504 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 14:59:36] INFO:     127.0.0.1:13446 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 14:59:36] INFO:     127.0.0.1:13460 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 14:59:36] INFO:     127.0.0.1:13462 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 14:59:36] INFO:     127.0.0.1:13472 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 14:59:36] INFO:     127.0.0.1:13486 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 14:59:36] INFO:     127.0.0.1:13490 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 14:59:36] INFO:     127.0.0.1:13496 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 14:59:36 TP0] Prefill batch. #new-seq: 2, #new-token: 1164, #cached-token: 84, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-08-25 14:59:36 TP0] Prefill batch. #new-seq: 6, #new-token: 3492, #cached-token: 252, token usage: 0.03, #running-req: 2, #queue-req: 0, 
[2025-08-25 14:59:38] INFO:     127.0.0.1:41514 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 14:59:38] INFO:     127.0.0.1:41530 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 14:59:38] INFO:     127.0.0.1:41544 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 14:59:38] INFO:     127.0.0.1:41560 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 14:59:38] INFO:     127.0.0.1:41576 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 14:59:38] INFO:     127.0.0.1:7408 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 14:59:38] INFO:     127.0.0.1:7424 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 14:59:38] INFO:     127.0.0.1:7438 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 14:59:38 TP0] Prefill batch. #new-seq: 1, #new-token: 500, #cached-token: 124, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-08-25 14:59:38 TP0] Prefill batch. #new-seq: 1, #new-token: 500, #cached-token: 124, token usage: 0.02, #running-req: 1, #queue-req: 0, 
[2025-08-25 14:59:38 TP0] Prefill batch. #new-seq: 6, #new-token: 3000, #cached-token: 744, token usage: 0.02, #running-req: 2, #queue-req: 0, 
[2025-08-25 14:59:39] INFO:     127.0.0.1:41514 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 14:59:39] INFO:     127.0.0.1:41530 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 14:59:39] INFO:     127.0.0.1:41544 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 14:59:39] INFO:     127.0.0.1:41560 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 14:59:39] INFO:     127.0.0.1:41576 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 14:59:39] INFO:     127.0.0.1:7408 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 14:59:39] INFO:     127.0.0.1:7424 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 14:59:39] INFO:     127.0.0.1:7438 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 14:59:40 TP0] Prefill batch. #new-seq: 1, #new-token: 146, #cached-token: 51, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-08-25 14:59:40 TP0] Prefill batch. #new-seq: 6, #new-token: 876, #cached-token: 306, token usage: 0.00, #running-req: 1, #queue-req: 0, 
[2025-08-25 14:59:40 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 196, token usage: 0.00, #running-req: 7, #queue-req: 0, 
[2025-08-25 14:59:40 TP0] Decode batch. #running-req: 8, #token: 509, token usage: 0.00, gen throughput (token/s): 92.42, largest-len: 0, #queue-req: 0, 
[2025-08-25 14:59:40 TP0] Decode batch. #running-req: 8, #token: 829, token usage: 0.00, gen throughput (token/s): 1709.48, largest-len: 0, #queue-req: 0, 
[2025-08-25 14:59:40 TP0] Decode batch. #running-req: 8, #token: 1149, token usage: 0.00, gen throughput (token/s): 1708.39, largest-len: 0, #queue-req: 0, 
[2025-08-25 14:59:40 TP0] Decode batch. #running-req: 8, #token: 1469, token usage: 0.00, gen throughput (token/s): 1700.61, largest-len: 0, #queue-req: 0, 
[2025-08-25 14:59:41 TP0] Decode batch. #running-req: 8, #token: 1789, token usage: 0.00, gen throughput (token/s): 1708.28, largest-len: 0, #queue-req: 0, 
[2025-08-25 14:59:41 TP0] Decode batch. #running-req: 8, #token: 2109, token usage: 0.00, gen throughput (token/s): 1717.71, largest-len: 0, #queue-req: 0, 
[2025-08-25 14:59:41 TP0] Decode batch. #running-req: 8, #token: 2429, token usage: 0.00, gen throughput (token/s): 1730.79, largest-len: 0, #queue-req: 0, 
[2025-08-25 14:59:41 TP0] Decode batch. #running-req: 8, #token: 2749, token usage: 0.00, gen throughput (token/s): 1630.64, largest-len: 0, #queue-req: 0, 
[2025-08-25 14:59:41 TP0] Decode batch. #running-req: 8, #token: 3069, token usage: 0.00, gen throughput (token/s): 1683.53, largest-len: 0, #queue-req: 0, 
[2025-08-25 14:59:42 TP0] Decode batch. #running-req: 8, #token: 3389, token usage: 0.00, gen throughput (token/s): 1681.36, largest-len: 0, #queue-req: 0, 
[2025-08-25 14:59:42 TP0] Decode batch. #running-req: 8, #token: 3709, token usage: 0.00, gen throughput (token/s): 1686.75, largest-len: 0, #queue-req: 0, 
[2025-08-25 14:59:42 TP0] Decode batch. #running-req: 8, #token: 4029, token usage: 0.00, gen throughput (token/s): 1571.10, largest-len: 0, #queue-req: 0, 
[2025-08-25 14:59:42] INFO:     127.0.0.1:13504 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 14:59:42] INFO:     127.0.0.1:13446 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 14:59:42] INFO:     127.0.0.1:13460 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 14:59:42] INFO:     127.0.0.1:13462 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 14:59:42] INFO:     127.0.0.1:13472 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 14:59:42] INFO:     127.0.0.1:13486 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 14:59:42] INFO:     127.0.0.1:13490 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 14:59:42] INFO:     127.0.0.1:13496 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 14:59:42 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 196, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-08-25 14:59:42 TP0] Prefill batch. #new-seq: 7, #new-token: 7, #cached-token: 1372, token usage: 0.00, #running-req: 1, #queue-req: 0, 
[2025-08-25 14:59:42 TP0] Decode batch. #running-req: 8, #token: 349, token usage: 0.00, gen throughput (token/s): 1054.23, largest-len: 0, #queue-req: 0, 
[2025-08-25 14:59:42 TP0] Decode batch. #running-req: 8, #token: 669, token usage: 0.00, gen throughput (token/s): 1677.18, largest-len: 0, #queue-req: 0, 
[2025-08-25 14:59:43 TP0] Decode batch. #running-req: 8, #token: 989, token usage: 0.00, gen throughput (token/s): 1689.01, largest-len: 0, #queue-req: 0, 
[2025-08-25 14:59:43 TP0] Decode batch. #running-req: 8, #token: 1309, token usage: 0.00, gen throughput (token/s): 1693.12, largest-len: 0, #queue-req: 0, 
[2025-08-25 14:59:43 TP0] Decode batch. #running-req: 8, #token: 1629, token usage: 0.00, gen throughput (token/s): 1716.48, largest-len: 0, #queue-req: 0, 
[2025-08-25 14:59:43 TP0] Decode batch. #running-req: 8, #token: 1949, token usage: 0.00, gen throughput (token/s): 1700.56, largest-len: 0, #queue-req: 0, 
[2025-08-25 14:59:43 TP0] Decode batch. #running-req: 8, #token: 2269, token usage: 0.00, gen throughput (token/s): 1699.25, largest-len: 0, #queue-req: 0, 
[2025-08-25 14:59:44 TP0] Decode batch. #running-req: 8, #token: 2589, token usage: 0.00, gen throughput (token/s): 1665.98, largest-len: 0, #queue-req: 0, 
[2025-08-25 14:59:44 TP0] Decode batch. #running-req: 8, #token: 2909, token usage: 0.00, gen throughput (token/s): 1688.80, largest-len: 0, #queue-req: 0, 
[2025-08-25 14:59:44 TP0] Decode batch. #running-req: 8, #token: 3229, token usage: 0.00, gen throughput (token/s): 1726.07, largest-len: 0, #queue-req: 0, 
[2025-08-25 14:59:44 TP0] Decode batch. #running-req: 8, #token: 3549, token usage: 0.00, gen throughput (token/s): 1647.14, largest-len: 0, #queue-req: 0, 
[2025-08-25 14:59:44 TP0] Decode batch. #running-req: 8, #token: 3869, token usage: 0.00, gen throughput (token/s): 1611.62, largest-len: 0, #queue-req: 0, 
[2025-08-25 14:59:44 TP0] Decode batch. #running-req: 8, #token: 4189, token usage: 0.00, gen throughput (token/s): 1668.10, largest-len: 0, #queue-req: 0, 
[2025-08-25 14:59:45] INFO:     127.0.0.1:13504 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 14:59:45] INFO:     127.0.0.1:13446 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 14:59:45] INFO:     127.0.0.1:13460 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 14:59:45] INFO:     127.0.0.1:13462 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 14:59:45] INFO:     127.0.0.1:13472 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 14:59:45] INFO:     127.0.0.1:13486 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 14:59:45] INFO:     127.0.0.1:13490 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 14:59:45] INFO:     127.0.0.1:13496 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 14:59:45 TP0] Prefill batch. #new-seq: 5, #new-token: 3215, #cached-token: 215, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-08-25 14:59:45 TP0] Prefill batch. #new-seq: 3, #new-token: 1929, #cached-token: 129, token usage: 0.08, #running-req: 5, #queue-req: 0, 
[2025-08-25 14:59:46] INFO:     127.0.0.1:55584 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 14:59:46] INFO:     127.0.0.1:55594 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 14:59:46] INFO:     127.0.0.1:55604 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 14:59:46] INFO:     127.0.0.1:55606 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 14:59:46] INFO:     127.0.0.1:55608 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 14:59:47 TP0] Prefill batch. #new-seq: 5, #new-token: 2500, #cached-token: 930, token usage: 0.00, #running-req: 3, #queue-req: 0, 
[2025-08-25 14:59:47] INFO:     127.0.0.1:55624 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 14:59:47] INFO:     127.0.0.1:55626 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 14:59:47] INFO:     127.0.0.1:55634 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 14:59:47 TP0] Prefill batch. #new-seq: 3, #new-token: 1500, #cached-token: 558, token usage: 0.07, #running-req: 8, #queue-req: 0, 
[2025-08-25 14:59:47] INFO:     127.0.0.1:55584 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 14:59:47] INFO:     127.0.0.1:55594 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 14:59:47] INFO:     127.0.0.1:55604 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 14:59:48] INFO:     127.0.0.1:55606 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 14:59:48] INFO:     127.0.0.1:55608 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 14:59:48 TP0] Prefill batch. #new-seq: 5, #new-token: 3250, #cached-token: 225, token usage: 0.00, #running-req: 3, #queue-req: 0, 
[2025-08-25 14:59:48] INFO:     127.0.0.1:55634 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 14:59:48] INFO:     127.0.0.1:55624 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 14:59:48] INFO:     127.0.0.1:55626 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 14:59:48 TP0] Prefill batch. #new-seq: 3, #new-token: 1950, #cached-token: 135, token usage: 0.08, #running-req: 8, #queue-req: 0, 
[2025-08-25 14:59:50 TP0] Decode batch. #running-req: 8, #token: 4235, token usage: 0.11, gen throughput (token/s): 7.63, largest-len: 0, #queue-req: 0, 
[2025-08-25 14:59:52 TP0] Decode batch. #running-req: 8, #token: 4555, token usage: 0.11, gen throughput (token/s): 173.24, largest-len: 0, #queue-req: 0, 
[2025-08-25 14:59:54 TP0] Decode batch. #running-req: 8, #token: 4875, token usage: 0.12, gen throughput (token/s): 172.55, largest-len: 0, #queue-req: 0, 
[2025-08-25 14:59:56 TP0] Decode batch. #running-req: 8, #token: 5195, token usage: 0.13, gen throughput (token/s): 171.78, largest-len: 0, #queue-req: 0, 
[2025-08-25 14:59:56] INFO:     127.0.0.1:55584 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 14:59:56] INFO:     127.0.0.1:55594 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 14:59:56] INFO:     127.0.0.1:55604 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 14:59:56] INFO:     127.0.0.1:55606 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 14:59:56] INFO:     127.0.0.1:55608 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 14:59:56] INFO:     127.0.0.1:55634 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 14:59:56] INFO:     127.0.0.1:55624 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 14:59:56] INFO:     127.0.0.1:55626 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 14:59:56 TP0] Prefill batch. #new-seq: 1, #new-token: 470, #cached-token: 225, token usage: 0.01, #running-req: 0, #queue-req: 0, 
[2025-08-25 14:59:56 TP0] Prefill batch. #new-seq: 2, #new-token: 970, #cached-token: 420, token usage: 0.02, #running-req: 1, #queue-req: 0, 
[2025-08-25 14:59:58 TP0] Decode batch. #running-req: 3, #token: 1749, token usage: 0.04, gen throughput (token/s): 93.20, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:00:00 TP0] Decode batch. #running-req: 3, #token: 1869, token usage: 0.05, gen throughput (token/s): 66.47, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:00:01 TP0] Decode batch. #running-req: 3, #token: 1989, token usage: 0.05, gen throughput (token/s): 66.25, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:00:03 TP0] Decode batch. #running-req: 3, #token: 2109, token usage: 0.05, gen throughput (token/s): 66.21, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:00:04] INFO:     127.0.0.1:55634 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:00:04] INFO:     127.0.0.1:55584 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:00:04] INFO:     127.0.0.1:55594 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:00:04 TP0] Prefill batch. #new-seq: 1, #new-token: 123, #cached-token: 50, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-08-25 15:00:04 TP0] Prefill batch. #new-seq: 7, #new-token: 861, #cached-token: 350, token usage: 0.00, #running-req: 1, #queue-req: 0, 
[2025-08-25 15:00:04 TP0] Decode batch. #running-req: 8, #token: 485, token usage: 0.00, gen throughput (token/s): 16.43, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:00:04 TP0] Decode batch. #running-req: 8, #token: 805, token usage: 0.00, gen throughput (token/s): 1643.16, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:00:04 TP0] Decode batch. #running-req: 8, #token: 1125, token usage: 0.00, gen throughput (token/s): 1629.68, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:00:05 TP0] Decode batch. #running-req: 8, #token: 1445, token usage: 0.00, gen throughput (token/s): 1618.40, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:00:05 TP0] Decode batch. #running-req: 8, #token: 1765, token usage: 0.00, gen throughput (token/s): 1679.28, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:00:05 TP0] Decode batch. #running-req: 8, #token: 2085, token usage: 0.00, gen throughput (token/s): 1570.49, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:00:05 TP0] Decode batch. #running-req: 8, #token: 2405, token usage: 0.00, gen throughput (token/s): 1721.70, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:00:05 TP0] Decode batch. #running-req: 8, #token: 2725, token usage: 0.00, gen throughput (token/s): 1732.57, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:00:06 TP0] Decode batch. #running-req: 8, #token: 3045, token usage: 0.00, gen throughput (token/s): 1772.49, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:00:06 TP0] Decode batch. #running-req: 8, #token: 3365, token usage: 0.00, gen throughput (token/s): 1740.36, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:00:06 TP0] Decode batch. #running-req: 8, #token: 3685, token usage: 0.00, gen throughput (token/s): 1716.65, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:00:06 TP0] Decode batch. #running-req: 8, #token: 4005, token usage: 0.00, gen throughput (token/s): 1713.50, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:00:06] INFO:     127.0.0.1:25394 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:00:06] INFO:     127.0.0.1:25406 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:00:06] INFO:     127.0.0.1:25422 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:00:06] INFO:     127.0.0.1:25426 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:00:06] INFO:     127.0.0.1:25438 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:00:06] INFO:     127.0.0.1:25444 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:00:06] INFO:     127.0.0.1:25456 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:00:06] INFO:     127.0.0.1:25464 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:00:06 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 172, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-08-25 15:00:06 TP0] Prefill batch. #new-seq: 6, #new-token: 6, #cached-token: 1032, token usage: 0.00, #running-req: 1, #queue-req: 0, 
[2025-08-25 15:00:06 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 172, token usage: 0.00, #running-req: 7, #queue-req: 0, 
[2025-08-25 15:00:06 TP0] Decode batch. #running-req: 8, #token: 325, token usage: 0.00, gen throughput (token/s): 972.99, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:00:07 TP0] Decode batch. #running-req: 8, #token: 645, token usage: 0.00, gen throughput (token/s): 1762.93, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:00:07 TP0] Decode batch. #running-req: 8, #token: 965, token usage: 0.00, gen throughput (token/s): 1736.72, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:00:07 TP0] Decode batch. #running-req: 8, #token: 1285, token usage: 0.00, gen throughput (token/s): 1714.58, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:00:07 TP0] Decode batch. #running-req: 8, #token: 1605, token usage: 0.00, gen throughput (token/s): 1714.47, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:00:07 TP0] Decode batch. #running-req: 8, #token: 1925, token usage: 0.00, gen throughput (token/s): 1725.58, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:00:07 TP0] Decode batch. #running-req: 8, #token: 2245, token usage: 0.00, gen throughput (token/s): 1719.64, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:00:08 TP0] Decode batch. #running-req: 8, #token: 2565, token usage: 0.00, gen throughput (token/s): 1706.99, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:00:08 TP0] Decode batch. #running-req: 8, #token: 2885, token usage: 0.00, gen throughput (token/s): 1739.36, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:00:08 TP0] Decode batch. #running-req: 8, #token: 3205, token usage: 0.00, gen throughput (token/s): 1775.00, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:00:08 TP0] Decode batch. #running-req: 8, #token: 3525, token usage: 0.00, gen throughput (token/s): 1772.18, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:00:08 TP0] Decode batch. #running-req: 8, #token: 3845, token usage: 0.00, gen throughput (token/s): 1771.22, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:00:09 TP0] Decode batch. #running-req: 8, #token: 4165, token usage: 0.00, gen throughput (token/s): 1768.63, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:00:09] INFO:     127.0.0.1:25464 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:00:09] INFO:     127.0.0.1:25394 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:00:09] INFO:     127.0.0.1:25406 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:00:09] INFO:     127.0.0.1:25422 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:00:09] INFO:     127.0.0.1:25426 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:00:09] INFO:     127.0.0.1:25438 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:00:09] INFO:     127.0.0.1:25444 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:00:09] INFO:     127.0.0.1:25456 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:00:09 TP0] Prefill batch. #new-seq: 1, #new-token: 620, #cached-token: 42, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-08-25 15:00:09 TP0] Prefill batch. #new-seq: 6, #new-token: 3720, #cached-token: 252, token usage: 0.02, #running-req: 1, #queue-req: 0, 
[2025-08-25 15:00:09 TP0] Prefill batch. #new-seq: 1, #new-token: 500, #cached-token: 162, token usage: 0.10, #running-req: 7, #queue-req: 0, 
[2025-08-25 15:00:09] INFO:     127.0.0.1:55634 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 15:00:10 TP0] Prefill batch. #new-seq: 1, #new-token: 500, #cached-token: 162, token usage: 0.02, #running-req: 8, #queue-req: 0, 
[2025-08-25 15:00:10] INFO:     127.0.0.1:55584 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 15:00:10] INFO:     127.0.0.1:55594 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 15:00:10] INFO:     127.0.0.1:60438 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 15:00:10] INFO:     127.0.0.1:60446 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 15:00:10] INFO:     127.0.0.1:60448 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 15:00:10] INFO:     127.0.0.1:60454 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 15:00:10 TP0] Prefill batch. #new-seq: 6, #new-token: 3000, #cached-token: 972, token usage: 0.02, #running-req: 9, #queue-req: 0, 
[2025-08-25 15:00:10] INFO:     127.0.0.1:60468 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 15:00:11 TP0] Prefill batch. #new-seq: 1, #new-token: 500, #cached-token: 162, token usage: 0.08, #running-req: 15, #queue-req: 0, 
[2025-08-25 15:00:11] INFO:     127.0.0.1:55634 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 15:00:11] INFO:     127.0.0.1:55584 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 15:00:11] INFO:     127.0.0.1:55594 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 15:00:12] INFO:     127.0.0.1:60438 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 15:00:12] INFO:     127.0.0.1:60446 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 15:00:12] INFO:     127.0.0.1:60448 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 15:00:12] INFO:     127.0.0.1:60454 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 15:00:12] INFO:     127.0.0.1:60468 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 15:00:12 TP0] Prefill batch. #new-seq: 1, #new-token: 104, #cached-token: 51, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-08-25 15:00:12 TP0] Prefill batch. #new-seq: 7, #new-token: 728, #cached-token: 357, token usage: 0.00, #running-req: 1, #queue-req: 0, 
[2025-08-25 15:00:12 TP0] Decode batch. #running-req: 8, #token: 467, token usage: 0.00, gen throughput (token/s): 97.31, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:00:12 TP0] Decode batch. #running-req: 8, #token: 787, token usage: 0.00, gen throughput (token/s): 1724.27, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:00:12 TP0] Decode batch. #running-req: 8, #token: 1107, token usage: 0.00, gen throughput (token/s): 1702.62, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:00:12 TP0] Decode batch. #running-req: 8, #token: 1427, token usage: 0.00, gen throughput (token/s): 1687.91, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:00:13 TP0] Decode batch. #running-req: 8, #token: 1747, token usage: 0.00, gen throughput (token/s): 1721.56, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:00:13 TP0] Decode batch. #running-req: 8, #token: 2067, token usage: 0.00, gen throughput (token/s): 1688.53, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:00:13 TP0] Decode batch. #running-req: 8, #token: 2387, token usage: 0.00, gen throughput (token/s): 1703.32, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:00:13 TP0] Decode batch. #running-req: 8, #token: 2707, token usage: 0.00, gen throughput (token/s): 1614.89, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:00:13 TP0] Decode batch. #running-req: 8, #token: 3027, token usage: 0.00, gen throughput (token/s): 1574.68, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:00:14 TP0] Decode batch. #running-req: 8, #token: 3347, token usage: 0.00, gen throughput (token/s): 1663.49, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:00:14 TP0] Decode batch. #running-req: 8, #token: 3667, token usage: 0.00, gen throughput (token/s): 1586.53, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:00:14 TP0] Decode batch. #running-req: 8, #token: 3987, token usage: 0.00, gen throughput (token/s): 1566.60, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:00:14] INFO:     127.0.0.1:25464 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:00:14] INFO:     127.0.0.1:25394 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:00:14] INFO:     127.0.0.1:25406 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:00:14] INFO:     127.0.0.1:25422 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:00:14] INFO:     127.0.0.1:25426 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:00:14] INFO:     127.0.0.1:25438 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:00:14] INFO:     127.0.0.1:25444 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:00:14] INFO:     127.0.0.1:25456 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:00:14 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 154, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-08-25 15:00:14 TP0] Prefill batch. #new-seq: 7, #new-token: 7, #cached-token: 1078, token usage: 0.00, #running-req: 1, #queue-req: 0, 
[2025-08-25 15:00:14 TP0] Decode batch. #running-req: 8, #token: 307, token usage: 0.00, gen throughput (token/s): 1047.15, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:00:15 TP0] Decode batch. #running-req: 8, #token: 627, token usage: 0.00, gen throughput (token/s): 1682.72, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:00:15 TP0] Decode batch. #running-req: 8, #token: 947, token usage: 0.00, gen throughput (token/s): 1676.12, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:00:15 TP0] Decode batch. #running-req: 8, #token: 1267, token usage: 0.00, gen throughput (token/s): 1690.84, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:00:15 TP0] Decode batch. #running-req: 8, #token: 1587, token usage: 0.00, gen throughput (token/s): 1736.77, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:00:15 TP0] Decode batch. #running-req: 8, #token: 1907, token usage: 0.00, gen throughput (token/s): 1695.94, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:00:15 TP0] Decode batch. #running-req: 8, #token: 2227, token usage: 0.00, gen throughput (token/s): 1762.84, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:00:16 TP0] Decode batch. #running-req: 8, #token: 2547, token usage: 0.00, gen throughput (token/s): 1790.09, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:00:16 TP0] Decode batch. #running-req: 8, #token: 2867, token usage: 0.00, gen throughput (token/s): 1756.91, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:00:16 TP0] Decode batch. #running-req: 8, #token: 3187, token usage: 0.00, gen throughput (token/s): 1819.21, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:00:16 TP0] Decode batch. #running-req: 8, #token: 3507, token usage: 0.00, gen throughput (token/s): 1766.33, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:00:16 TP0] Decode batch. #running-req: 8, #token: 3827, token usage: 0.00, gen throughput (token/s): 1766.66, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:00:17 TP0] Decode batch. #running-req: 8, #token: 4147, token usage: 0.00, gen throughput (token/s): 1769.75, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:00:17] INFO:     127.0.0.1:25464 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:00:17] INFO:     127.0.0.1:25394 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:00:17] INFO:     127.0.0.1:25406 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:00:17] INFO:     127.0.0.1:25422 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:00:17] INFO:     127.0.0.1:25426 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:00:17] INFO:     127.0.0.1:25438 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:00:17] INFO:     127.0.0.1:25444 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:00:17] INFO:     127.0.0.1:25456 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:00:17 TP0] Prefill batch. #new-seq: 2, #new-token: 1202, #cached-token: 86, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-08-25 15:00:17 TP0] Prefill batch. #new-seq: 6, #new-token: 3606, #cached-token: 258, token usage: 0.03, #running-req: 2, #queue-req: 0, 
[2025-08-25 15:00:18] INFO:     127.0.0.1:60454 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 15:00:18] INFO:     127.0.0.1:60468 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 15:00:18] INFO:     127.0.0.1:4754 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 15:00:18] INFO:     127.0.0.1:4770 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 15:00:18] INFO:     127.0.0.1:4776 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 15:00:18] INFO:     127.0.0.1:4786 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 15:00:18] INFO:     127.0.0.1:4794 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 15:00:18] INFO:     127.0.0.1:4796 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 15:00:18 TP0] Prefill batch. #new-seq: 1, #new-token: 500, #cached-token: 144, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-08-25 15:00:18 TP0] Prefill batch. #new-seq: 1, #new-token: 500, #cached-token: 144, token usage: 0.02, #running-req: 1, #queue-req: 0, 
[2025-08-25 15:00:19 TP0] Prefill batch. #new-seq: 6, #new-token: 3000, #cached-token: 864, token usage: 0.02, #running-req: 2, #queue-req: 0, 
[2025-08-25 15:00:19] INFO:     127.0.0.1:60454 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 15:00:19] INFO:     127.0.0.1:60468 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 15:00:20] INFO:     127.0.0.1:4754 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 15:00:20] INFO:     127.0.0.1:4770 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 15:00:20] INFO:     127.0.0.1:4776 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 15:00:20] INFO:     127.0.0.1:4786 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 15:00:20] INFO:     127.0.0.1:4794 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 15:00:20] INFO:     127.0.0.1:4796 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 15:00:20 TP0] Prefill batch. #new-seq: 5, #new-token: 1285, #cached-token: 260, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-08-25 15:00:20 TP0] Prefill batch. #new-seq: 3, #new-token: 771, #cached-token: 156, token usage: 0.00, #running-req: 5, #queue-req: 0, 
[2025-08-25 15:00:20 TP0] Decode batch. #running-req: 8, #token: 621, token usage: 0.00, gen throughput (token/s): 86.35, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:00:20 TP0] Decode batch. #running-req: 8, #token: 941, token usage: 0.00, gen throughput (token/s): 1766.30, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:00:21 TP0] Decode batch. #running-req: 8, #token: 1261, token usage: 0.00, gen throughput (token/s): 1740.36, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:00:21 TP0] Decode batch. #running-req: 8, #token: 1581, token usage: 0.00, gen throughput (token/s): 1642.33, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:00:21 TP0] Decode batch. #running-req: 8, #token: 1901, token usage: 0.00, gen throughput (token/s): 1656.92, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:00:21 TP0] Decode batch. #running-req: 8, #token: 2221, token usage: 0.00, gen throughput (token/s): 1704.22, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:00:21 TP0] Decode batch. #running-req: 8, #token: 2541, token usage: 0.00, gen throughput (token/s): 1715.41, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:00:22 TP0] Decode batch. #running-req: 8, #token: 2861, token usage: 0.00, gen throughput (token/s): 1611.01, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:00:22 TP0] Decode batch. #running-req: 8, #token: 3181, token usage: 0.00, gen throughput (token/s): 1674.71, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:00:22 TP0] Decode batch. #running-req: 8, #token: 3501, token usage: 0.00, gen throughput (token/s): 1670.29, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:00:22 TP0] Decode batch. #running-req: 8, #token: 3821, token usage: 0.00, gen throughput (token/s): 1664.23, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:00:22 TP0] Decode batch. #running-req: 8, #token: 4141, token usage: 0.00, gen throughput (token/s): 1612.26, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:00:22] INFO:     127.0.0.1:25464 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:00:22] INFO:     127.0.0.1:25394 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:00:22] INFO:     127.0.0.1:25406 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:00:22] INFO:     127.0.0.1:25422 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:00:22] INFO:     127.0.0.1:25426 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:00:22] INFO:     127.0.0.1:25438 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:00:22] INFO:     127.0.0.1:25444 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:00:22] INFO:     127.0.0.1:25456 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:00:22 TP0] Prefill batch. #new-seq: 4, #new-token: 4, #cached-token: 1232, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-08-25 15:00:22 TP0] Prefill batch. #new-seq: 4, #new-token: 4, #cached-token: 1232, token usage: 0.00, #running-req: 4, #queue-req: 0, 
[2025-08-25 15:00:23 TP0] Decode batch. #running-req: 8, #token: 461, token usage: 0.00, gen throughput (token/s): 1051.50, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:00:23 TP0] Decode batch. #running-req: 8, #token: 781, token usage: 0.00, gen throughput (token/s): 1681.78, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:00:23 TP0] Decode batch. #running-req: 8, #token: 1101, token usage: 0.00, gen throughput (token/s): 1709.86, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:00:23 TP0] Decode batch. #running-req: 8, #token: 1421, token usage: 0.00, gen throughput (token/s): 1702.00, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:00:23 TP0] Decode batch. #running-req: 8, #token: 1741, token usage: 0.00, gen throughput (token/s): 1730.66, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:00:24 TP0] Decode batch. #running-req: 8, #token: 2061, token usage: 0.00, gen throughput (token/s): 1742.51, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:00:24 TP0] Decode batch. #running-req: 8, #token: 2381, token usage: 0.00, gen throughput (token/s): 1696.85, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:00:24 TP0] Decode batch. #running-req: 8, #token: 2701, token usage: 0.00, gen throughput (token/s): 1675.22, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:00:24 TP0] Decode batch. #running-req: 8, #token: 3021, token usage: 0.00, gen throughput (token/s): 1702.89, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:00:24 TP0] Decode batch. #running-req: 8, #token: 3341, token usage: 0.00, gen throughput (token/s): 1674.28, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:00:24 TP0] Decode batch. #running-req: 8, #token: 3661, token usage: 0.00, gen throughput (token/s): 1765.71, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:00:25 TP0] Decode batch. #running-req: 8, #token: 3981, token usage: 0.00, gen throughput (token/s): 1747.30, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:00:25 TP0] Decode batch. #running-req: 8, #token: 4301, token usage: 0.00, gen throughput (token/s): 1730.22, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:00:25] INFO:     127.0.0.1:25464 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:00:25] INFO:     127.0.0.1:25394 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:00:25] INFO:     127.0.0.1:25406 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:00:25] INFO:     127.0.0.1:25422 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:00:25] INFO:     127.0.0.1:25426 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:00:25] INFO:     127.0.0.1:25438 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:00:25] INFO:     127.0.0.1:25444 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:00:25] INFO:     127.0.0.1:25456 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:00:25 TP0] Prefill batch. #new-seq: 1, #new-token: 754, #cached-token: 44, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-08-25 15:00:25 TP0] Prefill batch. #new-seq: 7, #new-token: 3500, #cached-token: 2086, token usage: 0.01, #running-req: 1, #queue-req: 0, 
[2025-08-25 15:00:25] INFO:     127.0.0.1:38838 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 15:00:25 TP0] Prefill batch. #new-seq: 1, #new-token: 500, #cached-token: 298, token usage: 0.10, #running-req: 8, #queue-req: 0, 
[2025-08-25 15:00:26] INFO:     127.0.0.1:38842 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 15:00:26] INFO:     127.0.0.1:38852 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 15:00:26] INFO:     127.0.0.1:38830 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 15:00:26] INFO:     127.0.0.1:38864 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 15:00:26] INFO:     127.0.0.1:38868 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 15:00:26] INFO:     127.0.0.1:38874 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 15:00:26] INFO:     127.0.0.1:38880 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 15:00:26 TP0] Prefill batch. #new-seq: 5, #new-token: 2500, #cached-token: 1490, token usage: 0.01, #running-req: 1, #queue-req: 0, 
[2025-08-25 15:00:27] INFO:     127.0.0.1:38838 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 15:00:27 TP0] Prefill batch. #new-seq: 3, #new-token: 1761, #cached-token: 642, token usage: 0.07, #running-req: 6, #queue-req: 0, 
[2025-08-25 15:00:27] INFO:     127.0.0.1:38842 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 15:00:27] INFO:     127.0.0.1:38880 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 15:00:27] INFO:     127.0.0.1:38830 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 15:00:27] INFO:     127.0.0.1:38852 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 15:00:27] INFO:     127.0.0.1:38864 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 15:00:28 TP0] Prefill batch. #new-seq: 5, #new-token: 2474, #cached-token: 1561, token usage: 0.02, #running-req: 3, #queue-req: 0, 
[2025-08-25 15:00:28] INFO:     127.0.0.1:38868 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 15:00:28] INFO:     127.0.0.1:38874 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 15:00:28 TP0] Prefill batch. #new-seq: 2, #new-token: 980, #cached-token: 634, token usage: 0.08, #running-req: 8, #queue-req: 0, 
[2025-08-25 15:00:30 TP0] Decode batch. #running-req: 8, #token: 4470, token usage: 0.11, gen throughput (token/s): 9.13, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:00:32 TP0] Decode batch. #running-req: 8, #token: 4790, token usage: 0.12, gen throughput (token/s): 172.04, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:00:34 TP0] Decode batch. #running-req: 8, #token: 5110, token usage: 0.13, gen throughput (token/s): 172.29, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:00:36 TP0] Decode batch. #running-req: 8, #token: 5430, token usage: 0.14, gen throughput (token/s): 171.60, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:11:39 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 82, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-08-25 15:11:39 TP0] Prefill batch. #new-seq: 7, #new-token: 7, #cached-token: 574, token usage: 0.00, #running-req: 1, #queue-req: 0, 
[2025-08-25 15:11:39 TP0] Decode batch. #running-req: 8, #token: 395, token usage: 0.00, gen throughput (token/s): 0.47, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:11:39 TP0] Decode batch. #running-req: 8, #token: 715, token usage: 0.00, gen throughput (token/s): 1750.06, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:11:39 TP0] Decode batch. #running-req: 8, #token: 1035, token usage: 0.00, gen throughput (token/s): 1787.40, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:11:39 TP0] Decode batch. #running-req: 8, #token: 1355, token usage: 0.00, gen throughput (token/s): 1790.35, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:11:40 TP0] Decode batch. #running-req: 8, #token: 1675, token usage: 0.00, gen throughput (token/s): 1800.72, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:11:40 TP0] Decode batch. #running-req: 8, #token: 1995, token usage: 0.00, gen throughput (token/s): 1807.58, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:11:40 TP0] Decode batch. #running-req: 8, #token: 2315, token usage: 0.00, gen throughput (token/s): 1795.20, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:11:40 TP0] Decode batch. #running-req: 8, #token: 2635, token usage: 0.00, gen throughput (token/s): 1821.90, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:11:40 TP0] Decode batch. #running-req: 8, #token: 2955, token usage: 0.00, gen throughput (token/s): 1783.47, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:11:41 TP0] Decode batch. #running-req: 8, #token: 3275, token usage: 0.00, gen throughput (token/s): 1792.93, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:11:41 TP0] Decode batch. #running-req: 8, #token: 3595, token usage: 0.00, gen throughput (token/s): 1802.21, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:11:41 TP0] Decode batch. #running-req: 8, #token: 3915, token usage: 0.00, gen throughput (token/s): 1765.13, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:11:41] INFO:     127.0.0.1:2992 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:11:41] INFO:     127.0.0.1:3004 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:11:41] INFO:     127.0.0.1:3018 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:11:41] INFO:     127.0.0.1:3020 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:11:41] INFO:     127.0.0.1:3022 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:11:41] INFO:     127.0.0.1:3024 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:11:41] INFO:     127.0.0.1:3028 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:11:41] INFO:     127.0.0.1:3044 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:11:41 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 82, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-08-25 15:11:41 TP0] Prefill batch. #new-seq: 7, #new-token: 7, #cached-token: 574, token usage: 0.00, #running-req: 1, #queue-req: 0, 
[2025-08-25 15:11:41 TP0] Decode batch. #running-req: 8, #token: 235, token usage: 0.00, gen throughput (token/s): 1016.47, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:11:41 TP0] Decode batch. #running-req: 8, #token: 555, token usage: 0.00, gen throughput (token/s): 1747.89, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:11:42 TP0] Decode batch. #running-req: 8, #token: 875, token usage: 0.00, gen throughput (token/s): 1734.94, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:11:42 TP0] Decode batch. #running-req: 8, #token: 1195, token usage: 0.00, gen throughput (token/s): 1652.99, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:11:42 TP0] Decode batch. #running-req: 8, #token: 1515, token usage: 0.00, gen throughput (token/s): 1701.33, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:11:42 TP0] Decode batch. #running-req: 8, #token: 1835, token usage: 0.00, gen throughput (token/s): 1704.43, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:11:42 TP0] Decode batch. #running-req: 8, #token: 2155, token usage: 0.00, gen throughput (token/s): 1709.09, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:11:43 TP0] Decode batch. #running-req: 8, #token: 2475, token usage: 0.00, gen throughput (token/s): 1752.31, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:11:43 TP0] Decode batch. #running-req: 8, #token: 2795, token usage: 0.00, gen throughput (token/s): 1726.40, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:11:43 TP0] Decode batch. #running-req: 8, #token: 3115, token usage: 0.00, gen throughput (token/s): 1714.79, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:11:43 TP0] Decode batch. #running-req: 8, #token: 3435, token usage: 0.00, gen throughput (token/s): 1722.36, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:11:43 TP0] Decode batch. #running-req: 8, #token: 3755, token usage: 0.00, gen throughput (token/s): 1743.67, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:11:43 TP0] Decode batch. #running-req: 8, #token: 4075, token usage: 0.00, gen throughput (token/s): 1743.52, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:11:43] INFO:     127.0.0.1:2992 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:11:43] INFO:     127.0.0.1:3004 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:11:43] INFO:     127.0.0.1:3018 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:11:43] INFO:     127.0.0.1:3020 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:11:43] INFO:     127.0.0.1:3022 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:11:43] INFO:     127.0.0.1:3024 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:11:43] INFO:     127.0.0.1:3028 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:11:43] INFO:     127.0.0.1:3044 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:11:44 TP0] Prefill batch. #new-seq: 1, #new-token: 530, #cached-token: 42, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-08-25 15:11:44 TP0] Prefill batch. #new-seq: 6, #new-token: 3180, #cached-token: 252, token usage: 0.01, #running-req: 1, #queue-req: 0, 
[2025-08-25 15:11:45 TP0] Prefill batch. #new-seq: 1, #new-token: 500, #cached-token: 72, token usage: 0.08, #running-req: 7, #queue-req: 0, 
[2025-08-25 15:11:45] INFO:     127.0.0.1:57256 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 15:11:45] INFO:     127.0.0.1:57264 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 15:11:45] INFO:     127.0.0.1:57274 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 15:11:45] INFO:     127.0.0.1:57284 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 15:11:45] INFO:     127.0.0.1:57286 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 15:11:45] INFO:     127.0.0.1:57302 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 15:11:45] INFO:     127.0.0.1:57308 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 15:11:45 TP0] Prefill batch. #new-seq: 7, #new-token: 3500, #cached-token: 504, token usage: 0.00, #running-req: 1, #queue-req: 0, 
[2025-08-25 15:11:45] INFO:     127.0.0.1:57314 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 15:11:46 TP0] Prefill batch. #new-seq: 1, #new-token: 500, #cached-token: 72, token usage: 0.09, #running-req: 8, #queue-req: 0, 
[2025-08-25 15:11:46] INFO:     127.0.0.1:57256 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 15:11:46] INFO:     127.0.0.1:57264 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 15:11:46] INFO:     127.0.0.1:57274 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 15:11:46] INFO:     127.0.0.1:57284 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 15:11:46] INFO:     127.0.0.1:57286 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 15:11:46] INFO:     127.0.0.1:57302 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 15:11:46] INFO:     127.0.0.1:57308 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 15:11:46] INFO:     127.0.0.1:57314 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 15:11:46 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 211, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-08-25 15:11:46 TP0] Prefill batch. #new-seq: 4, #new-token: 4, #cached-token: 844, token usage: 0.00, #running-req: 1, #queue-req: 0, 
[2025-08-25 15:11:46 TP0] Prefill batch. #new-seq: 3, #new-token: 3, #cached-token: 633, token usage: 0.00, #running-req: 5, #queue-req: 0, 
[2025-08-25 15:11:46 TP0] Decode batch. #running-req: 8, #token: 524, token usage: 0.00, gen throughput (token/s): 105.40, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:11:47 TP0] Decode batch. #running-req: 8, #token: 844, token usage: 0.00, gen throughput (token/s): 1704.55, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:11:47 TP0] Decode batch. #running-req: 8, #token: 1164, token usage: 0.00, gen throughput (token/s): 1721.99, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:11:47 TP0] Decode batch. #running-req: 8, #token: 1484, token usage: 0.00, gen throughput (token/s): 1715.87, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:11:47 TP0] Decode batch. #running-req: 8, #token: 1804, token usage: 0.00, gen throughput (token/s): 1706.05, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:11:47 TP0] Decode batch. #running-req: 8, #token: 2124, token usage: 0.00, gen throughput (token/s): 1717.65, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:11:48 TP0] Decode batch. #running-req: 8, #token: 2444, token usage: 0.00, gen throughput (token/s): 1708.78, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:11:48 TP0] Decode batch. #running-req: 8, #token: 2764, token usage: 0.00, gen throughput (token/s): 1700.41, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:11:48 TP0] Decode batch. #running-req: 8, #token: 3084, token usage: 0.00, gen throughput (token/s): 1703.49, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:11:48 TP0] Decode batch. #running-req: 8, #token: 3404, token usage: 0.00, gen throughput (token/s): 1690.96, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:11:48 TP0] Decode batch. #running-req: 8, #token: 3724, token usage: 0.00, gen throughput (token/s): 1713.31, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:11:49 TP0] Decode batch. #running-req: 8, #token: 4044, token usage: 0.00, gen throughput (token/s): 1707.77, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:11:49] INFO:     127.0.0.1:2992 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:11:49] INFO:     127.0.0.1:3004 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:11:49] INFO:     127.0.0.1:3018 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:11:49] INFO:     127.0.0.1:3020 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:11:49] INFO:     127.0.0.1:3022 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:11:49] INFO:     127.0.0.1:3024 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:11:49] INFO:     127.0.0.1:3028 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:11:49] INFO:     127.0.0.1:3044 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:11:49 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 211, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-08-25 15:11:49 TP0] Prefill batch. #new-seq: 7, #new-token: 7, #cached-token: 1477, token usage: 0.00, #running-req: 1, #queue-req: 0, 
[2025-08-25 15:11:49 TP0] Decode batch. #running-req: 8, #token: 364, token usage: 0.00, gen throughput (token/s): 1018.84, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:11:49 TP0] Decode batch. #running-req: 8, #token: 684, token usage: 0.00, gen throughput (token/s): 1709.02, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:11:49 TP0] Decode batch. #running-req: 8, #token: 1004, token usage: 0.00, gen throughput (token/s): 1731.48, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:11:49 TP0] Decode batch. #running-req: 8, #token: 1324, token usage: 0.00, gen throughput (token/s): 1679.13, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:11:50 TP0] Decode batch. #running-req: 8, #token: 1644, token usage: 0.00, gen throughput (token/s): 1704.45, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:11:50 TP0] Decode batch. #running-req: 8, #token: 1964, token usage: 0.00, gen throughput (token/s): 1737.75, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:11:50 TP0] Decode batch. #running-req: 8, #token: 2284, token usage: 0.00, gen throughput (token/s): 1665.40, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:11:50 TP0] Decode batch. #running-req: 8, #token: 2604, token usage: 0.00, gen throughput (token/s): 1726.07, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:11:50 TP0] Decode batch. #running-req: 8, #token: 2924, token usage: 0.00, gen throughput (token/s): 1728.04, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:11:51 TP0] Decode batch. #running-req: 8, #token: 3244, token usage: 0.00, gen throughput (token/s): 1732.43, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:11:51 TP0] Decode batch. #running-req: 8, #token: 3564, token usage: 0.00, gen throughput (token/s): 1758.64, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:11:51 TP0] Decode batch. #running-req: 8, #token: 3884, token usage: 0.00, gen throughput (token/s): 1765.29, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:11:51 TP0] Decode batch. #running-req: 8, #token: 4204, token usage: 0.00, gen throughput (token/s): 1756.08, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:11:51] INFO:     127.0.0.1:2992 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:11:51] INFO:     127.0.0.1:3004 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:11:51] INFO:     127.0.0.1:3018 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:11:51] INFO:     127.0.0.1:3020 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:11:51] INFO:     127.0.0.1:3022 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:11:51] INFO:     127.0.0.1:3024 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:11:51] INFO:     127.0.0.1:3028 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:11:51] INFO:     127.0.0.1:3044 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:11:51 TP0] Prefill batch. #new-seq: 1, #new-token: 659, #cached-token: 42, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-08-25 15:11:51 TP0] Prefill batch. #new-seq: 4, #new-token: 2636, #cached-token: 168, token usage: 0.02, #running-req: 1, #queue-req: 0, 
[2025-08-25 15:11:52 TP0] Prefill batch. #new-seq: 3, #new-token: 1500, #cached-token: 603, token usage: 0.07, #running-req: 5, #queue-req: 0, 
[2025-08-25 15:11:52] INFO:     127.0.0.1:57314 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 15:11:52] INFO:     127.0.0.1:32336 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 15:11:52] INFO:     127.0.0.1:32350 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 15:11:52] INFO:     127.0.0.1:32362 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 15:11:52] INFO:     127.0.0.1:32366 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 15:11:53 TP0] Prefill batch. #new-seq: 5, #new-token: 2500, #cached-token: 1005, token usage: 0.01, #running-req: 3, #queue-req: 0, 
[2025-08-25 15:11:53] INFO:     127.0.0.1:32370 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 15:11:53] INFO:     127.0.0.1:32386 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 15:11:53] INFO:     127.0.0.1:32394 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 15:11:53 TP0] Prefill batch. #new-seq: 3, #new-token: 1500, #cached-token: 603, token usage: 0.07, #running-req: 8, #queue-req: 0, 
[2025-08-25 15:11:54] INFO:     127.0.0.1:57314 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 15:11:54] INFO:     127.0.0.1:32336 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 15:11:54] INFO:     127.0.0.1:32350 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 15:11:54] INFO:     127.0.0.1:32362 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 15:11:54] INFO:     127.0.0.1:32366 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 15:11:54] INFO:     127.0.0.1:32370 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 15:11:54] INFO:     127.0.0.1:32386 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 15:11:54] INFO:     127.0.0.1:32394 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 15:11:54 TP0] Prefill batch. #new-seq: 1, #new-token: 666, #cached-token: 44, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-08-25 15:11:56 TP0] Decode batch. #running-req: 1, #token: 742, token usage: 0.02, gen throughput (token/s): 0.11, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:11:58 TP0] Decode batch. #running-req: 1, #token: 782, token usage: 0.02, gen throughput (token/s): 22.65, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:11:59 TP0] Decode batch. #running-req: 1, #token: 822, token usage: 0.02, gen throughput (token/s): 22.69, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:12:01] INFO:     127.0.0.1:57314 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:12:01 TP0] Prefill batch. #new-seq: 8, #new-token: 8, #cached-token: 1328, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-08-25 15:12:01 TP0] Decode batch. #running-req: 8, #token: 479, token usage: 0.00, gen throughput (token/s): 31.02, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:12:02 TP0] Decode batch. #running-req: 8, #token: 799, token usage: 0.00, gen throughput (token/s): 1734.50, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:12:02 TP0] Decode batch. #running-req: 8, #token: 1119, token usage: 0.00, gen throughput (token/s): 1741.34, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:12:02 TP0] Decode batch. #running-req: 8, #token: 1439, token usage: 0.00, gen throughput (token/s): 1739.84, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:12:02 TP0] Decode batch. #running-req: 8, #token: 1759, token usage: 0.00, gen throughput (token/s): 1752.47, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:12:02 TP0] Decode batch. #running-req: 8, #token: 2079, token usage: 0.00, gen throughput (token/s): 1742.17, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:12:03 TP0] Decode batch. #running-req: 8, #token: 2399, token usage: 0.00, gen throughput (token/s): 1710.45, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:12:03 TP0] Decode batch. #running-req: 8, #token: 2719, token usage: 0.00, gen throughput (token/s): 1720.87, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:12:03 TP0] Decode batch. #running-req: 8, #token: 3039, token usage: 0.00, gen throughput (token/s): 1732.67, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:12:03 TP0] Decode batch. #running-req: 8, #token: 3359, token usage: 0.00, gen throughput (token/s): 1735.20, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:12:03 TP0] Decode batch. #running-req: 8, #token: 3679, token usage: 0.00, gen throughput (token/s): 1737.91, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:12:03 TP0] Decode batch. #running-req: 8, #token: 3999, token usage: 0.00, gen throughput (token/s): 1721.26, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:12:04] INFO:     127.0.0.1:49772 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:12:04] INFO:     127.0.0.1:49782 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:12:04] INFO:     127.0.0.1:49796 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:12:04] INFO:     127.0.0.1:49800 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:12:04] INFO:     127.0.0.1:49808 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:12:04] INFO:     127.0.0.1:49812 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:12:04] INFO:     127.0.0.1:49818 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:12:04] INFO:     127.0.0.1:49830 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:12:04 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 166, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-08-25 15:12:04 TP0] Prefill batch. #new-seq: 7, #new-token: 7, #cached-token: 1162, token usage: 0.00, #running-req: 1, #queue-req: 0, 
[2025-08-25 15:12:04 TP0] Decode batch. #running-req: 8, #token: 319, token usage: 0.00, gen throughput (token/s): 1021.36, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:12:04 TP0] Decode batch. #running-req: 8, #token: 639, token usage: 0.00, gen throughput (token/s): 1711.20, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:12:04 TP0] Decode batch. #running-req: 8, #token: 959, token usage: 0.00, gen throughput (token/s): 1727.93, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:12:04 TP0] Decode batch. #running-req: 8, #token: 1279, token usage: 0.00, gen throughput (token/s): 1690.75, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:12:04 TP0] Decode batch. #running-req: 8, #token: 1599, token usage: 0.00, gen throughput (token/s): 1735.89, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:12:05 TP0] Decode batch. #running-req: 8, #token: 1919, token usage: 0.00, gen throughput (token/s): 1711.53, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:12:05 TP0] Decode batch. #running-req: 8, #token: 2239, token usage: 0.00, gen throughput (token/s): 1686.29, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:12:05 TP0] Decode batch. #running-req: 8, #token: 2559, token usage: 0.00, gen throughput (token/s): 1720.02, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:12:05 TP0] Decode batch. #running-req: 8, #token: 2879, token usage: 0.00, gen throughput (token/s): 1667.62, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:12:05 TP0] Decode batch. #running-req: 8, #token: 3199, token usage: 0.00, gen throughput (token/s): 1606.49, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:12:06 TP0] Decode batch. #running-req: 8, #token: 3519, token usage: 0.00, gen throughput (token/s): 1618.88, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:12:06 TP0] Decode batch. #running-req: 8, #token: 3839, token usage: 0.00, gen throughput (token/s): 1664.01, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:12:06 TP0] Decode batch. #running-req: 8, #token: 4159, token usage: 0.00, gen throughput (token/s): 1703.81, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:12:06] INFO:     127.0.0.1:49772 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:12:06] INFO:     127.0.0.1:49830 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:12:06] INFO:     127.0.0.1:49782 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:12:06] INFO:     127.0.0.1:49796 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:12:06] INFO:     127.0.0.1:49800 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:12:06] INFO:     127.0.0.1:49808 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:12:06] INFO:     127.0.0.1:49812 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:12:06] INFO:     127.0.0.1:49818 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:12:06 TP0] Prefill batch. #new-seq: 1, #new-token: 500, #cached-token: 156, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-08-25 15:12:06 TP0] Prefill batch. #new-seq: 5, #new-token: 2500, #cached-token: 780, token usage: 0.02, #running-req: 1, #queue-req: 0, 
[2025-08-25 15:12:06 TP0] Prefill batch. #new-seq: 2, #new-token: 1000, #cached-token: 312, token usage: 0.07, #running-req: 6, #queue-req: 0, 
[2025-08-25 15:12:06] INFO:     127.0.0.1:57314 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 15:12:07 TP0] Prefill batch. #new-seq: 1, #new-token: 500, #cached-token: 156, token usage: 0.03, #running-req: 8, #queue-req: 0, 
[2025-08-25 15:12:07] INFO:     127.0.0.1:38688 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 15:12:07] INFO:     127.0.0.1:38700 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 15:12:07] INFO:     127.0.0.1:38712 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 15:12:07] INFO:     127.0.0.1:38714 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 15:12:07] INFO:     127.0.0.1:38726 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 15:12:07 TP0] Prefill batch. #new-seq: 5, #new-token: 2500, #cached-token: 780, token usage: 0.02, #running-req: 9, #queue-req: 0, 
[2025-08-25 15:12:07] INFO:     127.0.0.1:38736 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 15:12:07] INFO:     127.0.0.1:38738 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 15:12:08 TP0] Prefill batch. #new-seq: 2, #new-token: 1000, #cached-token: 312, token usage: 0.07, #running-req: 14, #queue-req: 0, 
[2025-08-25 15:12:08] INFO:     127.0.0.1:57314 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 15:12:09 TP0] Prefill batch. #new-seq: 1, #new-token: 500, #cached-token: 165, token usage: 0.03, #running-req: 16, #queue-req: 0, 
[2025-08-25 15:12:09] INFO:     127.0.0.1:38688 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 15:12:09] INFO:     127.0.0.1:38700 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 15:12:09] INFO:     127.0.0.1:38712 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 15:12:09] INFO:     127.0.0.1:38714 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 15:12:09] INFO:     127.0.0.1:38726 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 15:12:09] INFO:     127.0.0.1:38736 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 15:12:09] INFO:     127.0.0.1:38738 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 15:12:09 TP0] Prefill batch. #new-seq: 3, #new-token: 1500, #cached-token: 495, token usage: 0.02, #running-req: 1, #queue-req: 0, 
[2025-08-25 15:12:09 TP0] Decode batch. #running-req: 1, #token: 2166, token usage: 0.05, gen throughput (token/s): 4.24, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:12:11 TP0] Decode batch. #running-req: 4, #token: 2324, token usage: 0.06, gen throughput (token/s): 72.79, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:12:13 TP0] Decode batch. #running-req: 4, #token: 2484, token usage: 0.06, gen throughput (token/s): 88.57, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:12:15 TP0] Decode batch. #running-req: 4, #token: 2644, token usage: 0.07, gen throughput (token/s): 88.15, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:12:16] INFO:     127.0.0.1:57314 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:12:16] INFO:     127.0.0.1:38688 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:12:16] INFO:     127.0.0.1:38700 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:12:16] INFO:     127.0.0.1:38712 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:12:16 TP0] Prefill batch. #new-seq: 5, #new-token: 5, #cached-token: 545, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-08-25 15:12:16 TP0] Prefill batch. #new-seq: 3, #new-token: 3, #cached-token: 327, token usage: 0.00, #running-req: 5, #queue-req: 0, 
[2025-08-25 15:12:16 TP0] Decode batch. #running-req: 8, #token: 422, token usage: 0.00, gen throughput (token/s): 31.11, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:12:16 TP0] Decode batch. #running-req: 8, #token: 742, token usage: 0.00, gen throughput (token/s): 1754.16, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:12:17 TP0] Decode batch. #running-req: 8, #token: 1062, token usage: 0.00, gen throughput (token/s): 1696.36, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:12:17 TP0] Decode batch. #running-req: 8, #token: 1382, token usage: 0.00, gen throughput (token/s): 1764.86, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:12:17 TP0] Decode batch. #running-req: 8, #token: 1702, token usage: 0.00, gen throughput (token/s): 1753.82, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:12:17 TP0] Decode batch. #running-req: 8, #token: 2022, token usage: 0.00, gen throughput (token/s): 1758.98, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:12:17 TP0] Decode batch. #running-req: 8, #token: 2342, token usage: 0.00, gen throughput (token/s): 1795.42, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:12:18 TP0] Decode batch. #running-req: 8, #token: 2662, token usage: 0.00, gen throughput (token/s): 1772.40, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:12:18 TP0] Decode batch. #running-req: 8, #token: 2982, token usage: 0.00, gen throughput (token/s): 1766.11, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:12:18 TP0] Decode batch. #running-req: 8, #token: 3302, token usage: 0.00, gen throughput (token/s): 1745.65, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:12:18 TP0] Decode batch. #running-req: 8, #token: 3622, token usage: 0.00, gen throughput (token/s): 1747.01, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:12:18 TP0] Decode batch. #running-req: 8, #token: 3942, token usage: 0.00, gen throughput (token/s): 1600.66, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:12:18] INFO:     127.0.0.1:20442 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:12:18] INFO:     127.0.0.1:20444 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:12:18] INFO:     127.0.0.1:20450 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:12:18] INFO:     127.0.0.1:20458 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:12:18] INFO:     127.0.0.1:20474 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:12:18] INFO:     127.0.0.1:20482 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:12:18] INFO:     127.0.0.1:20494 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:12:18] INFO:     127.0.0.1:20502 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:12:18 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 109, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-08-25 15:12:19 TP0] Prefill batch. #new-seq: 7, #new-token: 7, #cached-token: 763, token usage: 0.00, #running-req: 1, #queue-req: 0, 
[2025-08-25 15:12:19 TP0] Decode batch. #running-req: 8, #token: 262, token usage: 0.00, gen throughput (token/s): 1047.65, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:12:19 TP0] Decode batch. #running-req: 8, #token: 582, token usage: 0.00, gen throughput (token/s): 1704.45, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:12:19 TP0] Decode batch. #running-req: 8, #token: 902, token usage: 0.00, gen throughput (token/s): 1750.23, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:12:19 TP0] Decode batch. #running-req: 8, #token: 1222, token usage: 0.00, gen throughput (token/s): 1636.21, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:12:19 TP0] Decode batch. #running-req: 8, #token: 1542, token usage: 0.00, gen throughput (token/s): 1697.54, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:12:20 TP0] Decode batch. #running-req: 8, #token: 1862, token usage: 0.00, gen throughput (token/s): 1711.71, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:12:20 TP0] Decode batch. #running-req: 8, #token: 2182, token usage: 0.00, gen throughput (token/s): 1707.12, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:12:20 TP0] Decode batch. #running-req: 8, #token: 2502, token usage: 0.00, gen throughput (token/s): 1709.90, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:12:20 TP0] Decode batch. #running-req: 8, #token: 2822, token usage: 0.00, gen throughput (token/s): 1715.20, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:12:20 TP0] Decode batch. #running-req: 8, #token: 3142, token usage: 0.00, gen throughput (token/s): 1591.85, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:12:21 TP0] Decode batch. #running-req: 8, #token: 3462, token usage: 0.00, gen throughput (token/s): 1518.60, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:12:21 TP0] Decode batch. #running-req: 8, #token: 3782, token usage: 0.00, gen throughput (token/s): 1651.91, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:12:21 TP0] Decode batch. #running-req: 8, #token: 4102, token usage: 0.00, gen throughput (token/s): 1668.41, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:12:21] INFO:     127.0.0.1:20502 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:12:21] INFO:     127.0.0.1:20442 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:12:21] INFO:     127.0.0.1:20444 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:12:21] INFO:     127.0.0.1:20450 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:12:21] INFO:     127.0.0.1:20458 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:12:21] INFO:     127.0.0.1:20474 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:12:21] INFO:     127.0.0.1:20482 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:12:21] INFO:     127.0.0.1:20494 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:12:21 TP0] Prefill batch. #new-seq: 1, #new-token: 555, #cached-token: 44, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-08-25 15:12:21 TP0] Prefill batch. #new-seq: 1, #new-token: 555, #cached-token: 44, token usage: 0.02, #running-req: 1, #queue-req: 0, 
[2025-08-25 15:12:21 TP0] Prefill batch. #new-seq: 6, #new-token: 3000, #cached-token: 594, token usage: 0.02, #running-req: 2, #queue-req: 0, 
[2025-08-25 15:12:21] INFO:     127.0.0.1:38688 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 15:12:21] INFO:     127.0.0.1:38700 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 15:12:22 TP0] Prefill batch. #new-seq: 2, #new-token: 1000, #cached-token: 198, token usage: 0.00, #running-req: 6, #queue-req: 0, 
[2025-08-25 15:12:22] INFO:     127.0.0.1:38712 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 15:12:22] INFO:     127.0.0.1:58612 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 15:12:22] INFO:     127.0.0.1:58628 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 15:12:22] INFO:     127.0.0.1:58642 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 15:12:22] INFO:     127.0.0.1:58658 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 15:12:22] INFO:     127.0.0.1:58666 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 15:12:23 TP0] Prefill batch. #new-seq: 6, #new-token: 3000, #cached-token: 594, token usage: 0.03, #running-req: 8, #queue-req: 0, 
[2025-08-25 15:12:23] INFO:     127.0.0.1:38688 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 15:12:23] INFO:     127.0.0.1:38700 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 15:12:24] INFO:     127.0.0.1:38712 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 15:12:24] INFO:     127.0.0.1:58612 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 15:12:24] INFO:     127.0.0.1:58628 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 15:12:24] INFO:     127.0.0.1:58642 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 15:12:24] INFO:     127.0.0.1:58658 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 15:12:24] INFO:     127.0.0.1:58666 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 15:12:24 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 135, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-08-25 15:12:24 TP0] Prefill batch. #new-seq: 7, #new-token: 7, #cached-token: 945, token usage: 0.00, #running-req: 1, #queue-req: 0, 
[2025-08-25 15:12:25 TP0] Decode batch. #running-req: 8, #token: 448, token usage: 0.00, gen throughput (token/s): 87.47, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:12:25 TP0] Decode batch. #running-req: 8, #token: 768, token usage: 0.00, gen throughput (token/s): 1660.72, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:12:25 TP0] Decode batch. #running-req: 8, #token: 1088, token usage: 0.00, gen throughput (token/s): 1653.64, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:12:25 TP0] Decode batch. #running-req: 8, #token: 1408, token usage: 0.00, gen throughput (token/s): 1628.09, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:12:25 TP0] Decode batch. #running-req: 8, #token: 1728, token usage: 0.00, gen throughput (token/s): 1675.50, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:12:26 TP0] Decode batch. #running-req: 8, #token: 2048, token usage: 0.00, gen throughput (token/s): 1690.99, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:12:26 TP0] Decode batch. #running-req: 8, #token: 2368, token usage: 0.00, gen throughput (token/s): 1688.16, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:12:26 TP0] Decode batch. #running-req: 8, #token: 2688, token usage: 0.00, gen throughput (token/s): 1677.70, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:12:26 TP0] Decode batch. #running-req: 8, #token: 3008, token usage: 0.00, gen throughput (token/s): 1677.64, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:12:26 TP0] Decode batch. #running-req: 8, #token: 3328, token usage: 0.00, gen throughput (token/s): 1735.99, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:12:27 TP0] Decode batch. #running-req: 8, #token: 3648, token usage: 0.00, gen throughput (token/s): 1725.49, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:12:27 TP0] Decode batch. #running-req: 8, #token: 3968, token usage: 0.00, gen throughput (token/s): 1612.88, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:12:27] INFO:     127.0.0.1:20502 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:12:27] INFO:     127.0.0.1:20442 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:12:27] INFO:     127.0.0.1:20444 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:12:27] INFO:     127.0.0.1:20450 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:12:27] INFO:     127.0.0.1:20458 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:12:27] INFO:     127.0.0.1:20474 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:12:27] INFO:     127.0.0.1:20482 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:12:27] INFO:     127.0.0.1:20494 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:12:27 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 135, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-08-25 15:12:27 TP0] Prefill batch. #new-seq: 7, #new-token: 7, #cached-token: 945, token usage: 0.00, #running-req: 1, #queue-req: 0, 
[2025-08-25 15:12:27 TP0] Decode batch. #running-req: 8, #token: 288, token usage: 0.00, gen throughput (token/s): 1097.18, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:12:27 TP0] Decode batch. #running-req: 8, #token: 608, token usage: 0.00, gen throughput (token/s): 1718.06, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:12:27 TP0] Decode batch. #running-req: 8, #token: 928, token usage: 0.00, gen throughput (token/s): 1724.44, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:12:28 TP0] Decode batch. #running-req: 8, #token: 1248, token usage: 0.00, gen throughput (token/s): 1730.13, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:12:28 TP0] Decode batch. #running-req: 8, #token: 1568, token usage: 0.00, gen throughput (token/s): 1667.57, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:12:28 TP0] Decode batch. #running-req: 8, #token: 1888, token usage: 0.00, gen throughput (token/s): 1762.72, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:12:28 TP0] Decode batch. #running-req: 8, #token: 2208, token usage: 0.00, gen throughput (token/s): 1799.08, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:12:28 TP0] Decode batch. #running-req: 8, #token: 2528, token usage: 0.00, gen throughput (token/s): 1782.56, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:12:28 TP0] Decode batch. #running-req: 8, #token: 2848, token usage: 0.00, gen throughput (token/s): 1748.09, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:12:29 TP0] Decode batch. #running-req: 8, #token: 3168, token usage: 0.00, gen throughput (token/s): 1752.91, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:12:29 TP0] Decode batch. #running-req: 8, #token: 3488, token usage: 0.00, gen throughput (token/s): 1733.09, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:12:29 TP0] Decode batch. #running-req: 8, #token: 3808, token usage: 0.00, gen throughput (token/s): 1690.18, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:12:29 TP0] Decode batch. #running-req: 8, #token: 4128, token usage: 0.00, gen throughput (token/s): 1747.97, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:12:29] INFO:     127.0.0.1:20502 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:12:29] INFO:     127.0.0.1:20442 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:12:29] INFO:     127.0.0.1:20444 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:12:29] INFO:     127.0.0.1:20450 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:12:29] INFO:     127.0.0.1:20458 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:12:29] INFO:     127.0.0.1:20474 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:12:29] INFO:     127.0.0.1:20482 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:12:29] INFO:     127.0.0.1:20494 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:12:29 TP0] Prefill batch. #new-seq: 2, #new-token: 1166, #cached-token: 84, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-08-25 15:12:29 TP0] Prefill batch. #new-seq: 3, #new-token: 1749, #cached-token: 126, token usage: 0.03, #running-req: 2, #queue-req: 0, 
[2025-08-25 15:12:30 TP0] Prefill batch. #new-seq: 3, #new-token: 1500, #cached-token: 375, token usage: 0.05, #running-req: 5, #queue-req: 0, 
[2025-08-25 15:12:30] INFO:     127.0.0.1:58658 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 15:12:30] INFO:     127.0.0.1:58666 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 15:12:30] INFO:     127.0.0.1:58672 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 15:12:30] INFO:     127.0.0.1:58684 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 15:12:30] INFO:     127.0.0.1:58686 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 15:12:31 TP0] Prefill batch. #new-seq: 5, #new-token: 2500, #cached-token: 625, token usage: 0.00, #running-req: 3, #queue-req: 0, 
[2025-08-25 15:12:31] INFO:     127.0.0.1:58702 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 15:12:31] INFO:     127.0.0.1:58710 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 15:12:31] INFO:     127.0.0.1:58726 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 15:12:32 TP0] Prefill batch. #new-seq: 3, #new-token: 1500, #cached-token: 375, token usage: 0.07, #running-req: 8, #queue-req: 0, 
[2025-08-25 15:12:32] INFO:     127.0.0.1:58666 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 15:12:32] INFO:     127.0.0.1:58658 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 15:12:32] INFO:     127.0.0.1:58672 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 15:12:32] INFO:     127.0.0.1:58684 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 15:12:32] INFO:     127.0.0.1:58686 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 15:12:32] INFO:     127.0.0.1:58702 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 15:12:32] INFO:     127.0.0.1:58710 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 15:12:32] INFO:     127.0.0.1:58726 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 15:12:32 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 134, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-08-25 15:12:32 TP0] Prefill batch. #new-seq: 7, #new-token: 7, #cached-token: 938, token usage: 0.00, #running-req: 1, #queue-req: 0, 
[2025-08-25 15:12:32 TP0] Decode batch. #running-req: 8, #token: 440, token usage: 0.00, gen throughput (token/s): 99.83, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:12:33 TP0] Decode batch. #running-req: 8, #token: 760, token usage: 0.00, gen throughput (token/s): 1731.28, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:12:33 TP0] Decode batch. #running-req: 8, #token: 1080, token usage: 0.00, gen throughput (token/s): 1717.83, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:12:33 TP0] Decode batch. #running-req: 8, #token: 1400, token usage: 0.00, gen throughput (token/s): 1743.25, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:12:33 TP0] Decode batch. #running-req: 8, #token: 1720, token usage: 0.00, gen throughput (token/s): 1729.19, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:12:33 TP0] Decode batch. #running-req: 8, #token: 2040, token usage: 0.00, gen throughput (token/s): 1711.86, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:12:33 TP0] Decode batch. #running-req: 8, #token: 2360, token usage: 0.00, gen throughput (token/s): 1716.02, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:12:34 TP0] Decode batch. #running-req: 8, #token: 2680, token usage: 0.00, gen throughput (token/s): 1739.71, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:12:34 TP0] Decode batch. #running-req: 8, #token: 3000, token usage: 0.00, gen throughput (token/s): 1685.85, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:12:34 TP0] Decode batch. #running-req: 8, #token: 3320, token usage: 0.00, gen throughput (token/s): 1705.88, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:12:34 TP0] Decode batch. #running-req: 8, #token: 3640, token usage: 0.00, gen throughput (token/s): 1696.14, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:12:34 TP0] Decode batch. #running-req: 8, #token: 3960, token usage: 0.00, gen throughput (token/s): 1620.90, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:12:34] INFO:     127.0.0.1:20502 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:12:35] INFO:     127.0.0.1:20442 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:12:35 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 134, token usage: 0.00, #running-req: 7, #queue-req: 0, 
[2025-08-25 15:12:35] INFO:     127.0.0.1:20444 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:12:35] INFO:     127.0.0.1:20450 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:12:35] INFO:     127.0.0.1:20458 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:12:35] INFO:     127.0.0.1:20474 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:12:35] INFO:     127.0.0.1:20482 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:12:35] INFO:     127.0.0.1:20494 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:12:35 TP0] Prefill batch. #new-seq: 7, #new-token: 7, #cached-token: 938, token usage: 0.00, #running-req: 1, #queue-req: 0, 
[2025-08-25 15:12:35 TP0] Decode batch. #running-req: 8, #token: 272, token usage: 0.00, gen throughput (token/s): 1090.64, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:12:35 TP0] Decode batch. #running-req: 8, #token: 592, token usage: 0.00, gen throughput (token/s): 1692.87, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:12:35 TP0] Decode batch. #running-req: 8, #token: 912, token usage: 0.00, gen throughput (token/s): 1720.70, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:12:35 TP0] Decode batch. #running-req: 8, #token: 1232, token usage: 0.00, gen throughput (token/s): 1788.79, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:12:35 TP0] Decode batch. #running-req: 8, #token: 1552, token usage: 0.00, gen throughput (token/s): 1760.10, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:12:36 TP0] Decode batch. #running-req: 8, #token: 1872, token usage: 0.00, gen throughput (token/s): 1796.82, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:12:36 TP0] Decode batch. #running-req: 8, #token: 2192, token usage: 0.00, gen throughput (token/s): 1768.42, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:12:36 TP0] Decode batch. #running-req: 8, #token: 2512, token usage: 0.00, gen throughput (token/s): 1733.92, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:12:36 TP0] Decode batch. #running-req: 8, #token: 2832, token usage: 0.00, gen throughput (token/s): 1761.12, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:12:36 TP0] Decode batch. #running-req: 8, #token: 3152, token usage: 0.00, gen throughput (token/s): 1678.33, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:12:37 TP0] Decode batch. #running-req: 8, #token: 3472, token usage: 0.00, gen throughput (token/s): 1766.72, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:12:37 TP0] Decode batch. #running-req: 8, #token: 3792, token usage: 0.00, gen throughput (token/s): 1718.34, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:12:37 TP0] Decode batch. #running-req: 8, #token: 4112, token usage: 0.00, gen throughput (token/s): 1747.99, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:12:37] INFO:     127.0.0.1:20502 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:12:37] INFO:     127.0.0.1:20442 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:12:37] INFO:     127.0.0.1:20444 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:12:37] INFO:     127.0.0.1:20450 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:12:37] INFO:     127.0.0.1:20458 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:12:37] INFO:     127.0.0.1:20474 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:12:37] INFO:     127.0.0.1:20482 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:12:37] INFO:     127.0.0.1:20494 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:12:37 TP0] Prefill batch. #new-seq: 1, #new-token: 582, #cached-token: 42, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-08-25 15:12:37 TP0] Prefill batch. #new-seq: 7, #new-token: 3500, #cached-token: 868, token usage: 0.00, #running-req: 1, #queue-req: 0, 
[2025-08-25 15:12:37] INFO:     127.0.0.1:58702 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 15:12:37 TP0] Prefill batch. #new-seq: 1, #new-token: 500, #cached-token: 124, token usage: 0.09, #running-req: 8, #queue-req: 0, 
[2025-08-25 15:12:38] INFO:     127.0.0.1:58710 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 15:12:38] INFO:     127.0.0.1:58726 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 15:12:38] INFO:     127.0.0.1:7450 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 15:12:38] INFO:     127.0.0.1:7458 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 15:12:38] INFO:     127.0.0.1:7466 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 15:12:38] INFO:     127.0.0.1:7470 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 15:12:38] INFO:     127.0.0.1:7480 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 15:12:38] INFO:     127.0.0.1:58702 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 15:12:38 TP0] Prefill batch. #new-seq: 7, #new-token: 3500, #cached-token: 868, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-08-25 15:12:40] INFO:     127.0.0.1:7450 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 15:12:40] INFO:     127.0.0.1:58710 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 15:12:40] INFO:     127.0.0.1:58702 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 15:12:40] INFO:     127.0.0.1:58726 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 15:12:40] INFO:     127.0.0.1:7458 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 15:12:40] INFO:     127.0.0.1:7466 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 15:12:40] INFO:     127.0.0.1:7470 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 15:12:40 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 196, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-08-25 15:12:40 TP0] Prefill batch. #new-seq: 7, #new-token: 7, #cached-token: 1372, token usage: 0.00, #running-req: 1, #queue-req: 0, 
[2025-08-25 15:12:40 TP0] Decode batch. #running-req: 8, #token: 493, token usage: 0.00, gen throughput (token/s): 101.04, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:12:40 TP0] Decode batch. #running-req: 8, #token: 813, token usage: 0.00, gen throughput (token/s): 1711.95, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:12:40 TP0] Decode batch. #running-req: 8, #token: 1133, token usage: 0.00, gen throughput (token/s): 1647.58, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:12:41 TP0] Decode batch. #running-req: 8, #token: 1453, token usage: 0.00, gen throughput (token/s): 1693.10, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:12:41 TP0] Decode batch. #running-req: 8, #token: 1773, token usage: 0.00, gen throughput (token/s): 1682.10, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:12:41 TP0] Decode batch. #running-req: 8, #token: 2093, token usage: 0.00, gen throughput (token/s): 1607.93, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:12:41 TP0] Decode batch. #running-req: 8, #token: 2413, token usage: 0.00, gen throughput (token/s): 1597.90, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:12:41 TP0] Decode batch. #running-req: 8, #token: 2733, token usage: 0.00, gen throughput (token/s): 1606.89, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:12:42 TP0] Decode batch. #running-req: 8, #token: 3053, token usage: 0.00, gen throughput (token/s): 1599.57, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:12:42 TP0] Decode batch. #running-req: 8, #token: 3373, token usage: 0.00, gen throughput (token/s): 1655.40, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:12:42 TP0] Decode batch. #running-req: 8, #token: 3693, token usage: 0.00, gen throughput (token/s): 1657.64, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:12:42 TP0] Decode batch. #running-req: 8, #token: 4013, token usage: 0.00, gen throughput (token/s): 1728.06, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:12:42] INFO:     127.0.0.1:20502 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:12:42] INFO:     127.0.0.1:20442 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:12:42] INFO:     127.0.0.1:20444 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:12:42] INFO:     127.0.0.1:20450 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:12:42] INFO:     127.0.0.1:20458 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:12:42] INFO:     127.0.0.1:20474 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:12:42] INFO:     127.0.0.1:20482 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:12:42] INFO:     127.0.0.1:20494 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:12:42 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 196, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-08-25 15:12:42 TP0] Prefill batch. #new-seq: 7, #new-token: 7, #cached-token: 1372, token usage: 0.00, #running-req: 1, #queue-req: 0, 
[2025-08-25 15:12:42 TP0] Decode batch. #running-req: 8, #token: 326, token usage: 0.00, gen throughput (token/s): 1035.40, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:12:43 TP0] Decode batch. #running-req: 8, #token: 646, token usage: 0.00, gen throughput (token/s): 1721.95, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:12:43 TP0] Decode batch. #running-req: 8, #token: 966, token usage: 0.00, gen throughput (token/s): 1723.53, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:12:43 TP0] Decode batch. #running-req: 8, #token: 1286, token usage: 0.00, gen throughput (token/s): 1673.63, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:12:43 TP0] Decode batch. #running-req: 8, #token: 1606, token usage: 0.00, gen throughput (token/s): 1612.82, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:12:43 TP0] Decode batch. #running-req: 8, #token: 1926, token usage: 0.00, gen throughput (token/s): 1672.52, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:12:44 TP0] Decode batch. #running-req: 8, #token: 2246, token usage: 0.00, gen throughput (token/s): 1675.67, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:12:44 TP0] Decode batch. #running-req: 8, #token: 2566, token usage: 0.00, gen throughput (token/s): 1703.57, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:12:44 TP0] Decode batch. #running-req: 8, #token: 2886, token usage: 0.00, gen throughput (token/s): 1710.57, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:12:44 TP0] Decode batch. #running-req: 8, #token: 3206, token usage: 0.00, gen throughput (token/s): 1688.06, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:12:44 TP0] Decode batch. #running-req: 8, #token: 3526, token usage: 0.00, gen throughput (token/s): 1701.45, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:12:45 TP0] Decode batch. #running-req: 8, #token: 3846, token usage: 0.00, gen throughput (token/s): 1607.22, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:12:45 TP0] Decode batch. #running-req: 8, #token: 4166, token usage: 0.00, gen throughput (token/s): 1700.05, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:12:45] INFO:     127.0.0.1:20502 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:12:45 TP0] Prefill batch. #new-seq: 1, #new-token: 643, #cached-token: 43, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-08-25 15:12:45] INFO:     127.0.0.1:20442 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:12:45] INFO:     127.0.0.1:20444 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:12:45] INFO:     127.0.0.1:20450 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:12:45] INFO:     127.0.0.1:20458 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:12:45] INFO:     127.0.0.1:20474 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:12:45] INFO:     127.0.0.1:20482 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:12:45] INFO:     127.0.0.1:20494 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:12:45 TP0] Prefill batch. #new-seq: 7, #new-token: 3500, #cached-token: 1302, token usage: 0.00, #running-req: 1, #queue-req: 0, 
[2025-08-25 15:12:45] INFO:     127.0.0.1:25700 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 15:12:45 TP0] Prefill batch. #new-seq: 1, #new-token: 499, #cached-token: 186, token usage: 0.09, #running-req: 8, #queue-req: 0, 
[2025-08-25 15:12:46] INFO:     127.0.0.1:25714 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 15:12:46] INFO:     127.0.0.1:25716 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 15:12:46] INFO:     127.0.0.1:25724 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 15:12:46] INFO:     127.0.0.1:25736 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 15:12:46] INFO:     127.0.0.1:25750 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 15:12:46] INFO:     127.0.0.1:25764 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 15:12:46] INFO:     127.0.0.1:25772 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 15:12:46 TP0] Prefill batch. #new-seq: 7, #new-token: 3500, #cached-token: 1302, token usage: 0.00, #running-req: 1, #queue-req: 0, 
[2025-08-25 15:12:46] INFO:     127.0.0.1:25700 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 15:12:48 TP0] Prefill batch. #new-seq: 1, #new-token: 650, #cached-token: 45, token usage: 0.09, #running-req: 8, #queue-req: 0, 
[2025-08-25 15:12:48] INFO:     127.0.0.1:25772 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 15:12:48] INFO:     127.0.0.1:25714 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 15:12:48] INFO:     127.0.0.1:25716 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 15:12:48] INFO:     127.0.0.1:25724 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 15:12:48] INFO:     127.0.0.1:25736 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 15:12:48] INFO:     127.0.0.1:25750 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 15:12:48] INFO:     127.0.0.1:25764 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 15:12:48 TP0] Prefill batch. #new-seq: 7, #new-token: 3460, #cached-token: 1404, token usage: 0.02, #running-req: 1, #queue-req: 0, 
[2025-08-25 15:12:48 TP0] Decode batch. #running-req: 1, #token: 4156, token usage: 0.10, gen throughput (token/s): 4.49, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:12:51 TP0] Decode batch. #running-req: 8, #token: 4461, token usage: 0.11, gen throughput (token/s): 112.75, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:12:53 TP0] Decode batch. #running-req: 8, #token: 4781, token usage: 0.12, gen throughput (token/s): 173.03, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:12:54 TP0] Decode batch. #running-req: 8, #token: 5101, token usage: 0.13, gen throughput (token/s): 172.34, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:12:56] INFO:     127.0.0.1:25700 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:12:56] INFO:     127.0.0.1:25714 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:12:56] INFO:     127.0.0.1:25716 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:12:56] INFO:     127.0.0.1:25724 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:12:56] INFO:     127.0.0.1:25736 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:12:56] INFO:     127.0.0.1:25750 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:12:56] INFO:     127.0.0.1:25764 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:12:56] INFO:     127.0.0.1:25772 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:12:56 TP0] Prefill batch. #new-seq: 1, #new-token: 472, #cached-token: 223, token usage: 0.01, #running-req: 7, #queue-req: 0, 
[2025-08-25 15:12:56 TP0] Prefill batch. #new-seq: 1, #new-token: 492, #cached-token: 203, token usage: 0.02, #running-req: 8, #queue-req: 0, 
[2025-08-25 15:12:57 TP0] Decode batch. #running-req: 2, #token: 1213, token usage: 0.03, gen throughput (token/s): 120.05, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:12:58 TP0] Decode batch. #running-req: 2, #token: 1293, token usage: 0.03, gen throughput (token/s): 44.99, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:13:00 TP0] Decode batch. #running-req: 2, #token: 1373, token usage: 0.03, gen throughput (token/s): 44.84, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:13:02 TP0] Decode batch. #running-req: 2, #token: 1453, token usage: 0.04, gen throughput (token/s): 44.93, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:13:03] INFO:     127.0.0.1:25700 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:13:03] INFO:     127.0.0.1:25714 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:13:03 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 172, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-08-25 15:13:03 TP0] Prefill batch. #new-seq: 7, #new-token: 7, #cached-token: 1204, token usage: 0.00, #running-req: 1, #queue-req: 0, 
[2025-08-25 15:13:03 TP0] Decode batch. #running-req: 8, #token: 461, token usage: 0.00, gen throughput (token/s): 17.46, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:13:03 TP0] Decode batch. #running-req: 8, #token: 781, token usage: 0.00, gen throughput (token/s): 1689.93, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:13:03 TP0] Decode batch. #running-req: 8, #token: 1101, token usage: 0.00, gen throughput (token/s): 1631.31, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:13:04 TP0] Decode batch. #running-req: 8, #token: 1421, token usage: 0.00, gen throughput (token/s): 1638.37, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:13:04 TP0] Decode batch. #running-req: 8, #token: 1741, token usage: 0.00, gen throughput (token/s): 1698.43, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:13:04 TP0] Decode batch. #running-req: 8, #token: 2061, token usage: 0.00, gen throughput (token/s): 1635.94, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:13:04 TP0] Decode batch. #running-req: 8, #token: 2381, token usage: 0.00, gen throughput (token/s): 1806.93, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:13:04 TP0] Decode batch. #running-req: 8, #token: 2701, token usage: 0.00, gen throughput (token/s): 1761.16, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:13:05 TP0] Decode batch. #running-req: 8, #token: 3021, token usage: 0.00, gen throughput (token/s): 1750.40, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:13:05 TP0] Decode batch. #running-req: 8, #token: 3341, token usage: 0.00, gen throughput (token/s): 1736.97, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:13:05 TP0] Decode batch. #running-req: 8, #token: 3661, token usage: 0.00, gen throughput (token/s): 1760.62, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:13:05 TP0] Decode batch. #running-req: 8, #token: 3981, token usage: 0.00, gen throughput (token/s): 1743.67, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:13:05] INFO:     127.0.0.1:42556 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:13:05] INFO:     127.0.0.1:42568 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:13:05] INFO:     127.0.0.1:42578 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:13:05] INFO:     127.0.0.1:42588 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:13:05] INFO:     127.0.0.1:42602 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:13:05] INFO:     127.0.0.1:42612 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:13:05] INFO:     127.0.0.1:42622 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:13:05] INFO:     127.0.0.1:42638 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:13:05 TP0] Prefill batch. #new-seq: 2, #new-token: 2, #cached-token: 344, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-08-25 15:13:05 TP0] Prefill batch. #new-seq: 6, #new-token: 6, #cached-token: 1032, token usage: 0.00, #running-req: 2, #queue-req: 0, 
[2025-08-25 15:13:05 TP0] Decode batch. #running-req: 8, #token: 301, token usage: 0.00, gen throughput (token/s): 1012.13, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:13:06 TP0] Decode batch. #running-req: 8, #token: 621, token usage: 0.00, gen throughput (token/s): 1737.62, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:13:06 TP0] Decode batch. #running-req: 8, #token: 941, token usage: 0.00, gen throughput (token/s): 1731.15, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:13:06 TP0] Decode batch. #running-req: 8, #token: 1261, token usage: 0.00, gen throughput (token/s): 1744.75, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:13:06 TP0] Decode batch. #running-req: 8, #token: 1581, token usage: 0.00, gen throughput (token/s): 1758.51, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:13:06 TP0] Decode batch. #running-req: 8, #token: 1901, token usage: 0.00, gen throughput (token/s): 1708.73, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:13:07 TP0] Decode batch. #running-req: 8, #token: 2221, token usage: 0.00, gen throughput (token/s): 1737.28, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:13:07 TP0] Decode batch. #running-req: 8, #token: 2541, token usage: 0.00, gen throughput (token/s): 1726.29, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:13:07 TP0] Decode batch. #running-req: 8, #token: 2861, token usage: 0.00, gen throughput (token/s): 1714.24, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:13:07 TP0] Decode batch. #running-req: 8, #token: 3181, token usage: 0.00, gen throughput (token/s): 1654.13, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:13:07 TP0] Decode batch. #running-req: 8, #token: 3501, token usage: 0.00, gen throughput (token/s): 1716.73, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:13:07 TP0] Decode batch. #running-req: 8, #token: 3821, token usage: 0.00, gen throughput (token/s): 1709.66, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:13:08 TP0] Decode batch. #running-req: 8, #token: 4141, token usage: 0.00, gen throughput (token/s): 1662.11, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:13:08] INFO:     127.0.0.1:42556 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:13:08] INFO:     127.0.0.1:42638 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:13:08] INFO:     127.0.0.1:42568 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:13:08] INFO:     127.0.0.1:42578 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:13:08] INFO:     127.0.0.1:42588 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:13:08] INFO:     127.0.0.1:42602 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:13:08] INFO:     127.0.0.1:42612 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:13:08] INFO:     127.0.0.1:42622 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:13:08 TP0] Prefill batch. #new-seq: 2, #new-token: 1240, #cached-token: 84, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-08-25 15:13:08 TP0] Prefill batch. #new-seq: 5, #new-token: 3100, #cached-token: 210, token usage: 0.03, #running-req: 2, #queue-req: 0, 
[2025-08-25 15:13:09 TP0] Prefill batch. #new-seq: 1, #new-token: 500, #cached-token: 162, token usage: 0.08, #running-req: 7, #queue-req: 0, 
[2025-08-25 15:13:09] INFO:     127.0.0.1:25700 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 15:13:09] INFO:     127.0.0.1:25714 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 15:13:09] INFO:     127.0.0.1:14892 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 15:13:09] INFO:     127.0.0.1:14898 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 15:13:09] INFO:     127.0.0.1:14902 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 15:13:09] INFO:     127.0.0.1:14918 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 15:13:09] INFO:     127.0.0.1:14926 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 15:13:09 TP0] Prefill batch. #new-seq: 2, #new-token: 1000, #cached-token: 324, token usage: 0.00, #running-req: 1, #queue-req: 0, 
[2025-08-25 15:13:09] INFO:     127.0.0.1:14932 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 15:13:10 TP0] Prefill batch. #new-seq: 6, #new-token: 3000, #cached-token: 972, token usage: 0.03, #running-req: 3, #queue-req: 0, 
[2025-08-25 15:13:10] INFO:     127.0.0.1:25700 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 15:13:10] INFO:     127.0.0.1:25714 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 15:13:11] INFO:     127.0.0.1:14892 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 15:13:11] INFO:     127.0.0.1:14898 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 15:13:11] INFO:     127.0.0.1:14902 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 15:13:11] INFO:     127.0.0.1:14918 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 15:13:11] INFO:     127.0.0.1:14926 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 15:13:11] INFO:     127.0.0.1:14932 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 15:13:11 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 154, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-08-25 15:13:11 TP0] Prefill batch. #new-seq: 7, #new-token: 7, #cached-token: 1078, token usage: 0.00, #running-req: 1, #queue-req: 0, 
[2025-08-25 15:13:12 TP0] Decode batch. #running-req: 8, #token: 443, token usage: 0.00, gen throughput (token/s): 81.19, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:13:12 TP0] Decode batch. #running-req: 8, #token: 763, token usage: 0.00, gen throughput (token/s): 1670.30, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:13:12 TP0] Decode batch. #running-req: 8, #token: 1083, token usage: 0.00, gen throughput (token/s): 1664.36, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:13:12 TP0] Decode batch. #running-req: 8, #token: 1403, token usage: 0.00, gen throughput (token/s): 1683.14, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:13:12 TP0] Decode batch. #running-req: 8, #token: 1723, token usage: 0.00, gen throughput (token/s): 1659.00, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:13:13 TP0] Decode batch. #running-req: 8, #token: 2043, token usage: 0.00, gen throughput (token/s): 1660.10, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:13:13 TP0] Decode batch. #running-req: 8, #token: 2363, token usage: 0.00, gen throughput (token/s): 1698.34, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:13:13 TP0] Decode batch. #running-req: 8, #token: 2683, token usage: 0.00, gen throughput (token/s): 1656.78, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:13:13 TP0] Decode batch. #running-req: 8, #token: 3003, token usage: 0.00, gen throughput (token/s): 1710.69, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:13:13 TP0] Decode batch. #running-req: 8, #token: 3323, token usage: 0.00, gen throughput (token/s): 1673.86, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:13:13 TP0] Decode batch. #running-req: 8, #token: 3643, token usage: 0.00, gen throughput (token/s): 1701.23, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:13:14 TP0] Decode batch. #running-req: 8, #token: 3963, token usage: 0.00, gen throughput (token/s): 1681.00, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:13:14] INFO:     127.0.0.1:42638 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:13:14] INFO:     127.0.0.1:42556 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:13:14] INFO:     127.0.0.1:42568 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:13:14] INFO:     127.0.0.1:42578 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:13:14] INFO:     127.0.0.1:42588 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:13:14] INFO:     127.0.0.1:42602 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:13:14] INFO:     127.0.0.1:42612 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:13:14] INFO:     127.0.0.1:42622 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:13:14 TP0] Prefill batch. #new-seq: 2, #new-token: 2, #cached-token: 308, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-08-25 15:13:14 TP0] Prefill batch. #new-seq: 6, #new-token: 6, #cached-token: 924, token usage: 0.00, #running-req: 2, #queue-req: 0, 
[2025-08-25 15:13:14 TP0] Decode batch. #running-req: 8, #token: 283, token usage: 0.00, gen throughput (token/s): 1047.34, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:13:14 TP0] Decode batch. #running-req: 8, #token: 603, token usage: 0.00, gen throughput (token/s): 1668.39, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:13:14 TP0] Decode batch. #running-req: 8, #token: 923, token usage: 0.00, gen throughput (token/s): 1564.82, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:13:15 TP0] Decode batch. #running-req: 8, #token: 1243, token usage: 0.00, gen throughput (token/s): 1698.19, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:13:15 TP0] Decode batch. #running-req: 8, #token: 1563, token usage: 0.00, gen throughput (token/s): 1680.97, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:13:15 TP0] Decode batch. #running-req: 8, #token: 1883, token usage: 0.00, gen throughput (token/s): 1730.11, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:13:15 TP0] Decode batch. #running-req: 8, #token: 2203, token usage: 0.00, gen throughput (token/s): 1688.26, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:13:15 TP0] Decode batch. #running-req: 8, #token: 2523, token usage: 0.00, gen throughput (token/s): 1678.10, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:13:16 TP0] Decode batch. #running-req: 8, #token: 2843, token usage: 0.00, gen throughput (token/s): 1589.14, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:13:16 TP0] Decode batch. #running-req: 8, #token: 3163, token usage: 0.00, gen throughput (token/s): 1642.53, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:13:16 TP0] Decode batch. #running-req: 8, #token: 3483, token usage: 0.00, gen throughput (token/s): 1595.41, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:13:16 TP0] Decode batch. #running-req: 8, #token: 3803, token usage: 0.00, gen throughput (token/s): 1615.73, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:13:16 TP0] Decode batch. #running-req: 8, #token: 4123, token usage: 0.00, gen throughput (token/s): 1697.88, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:13:16] INFO:     127.0.0.1:42556 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:13:16] INFO:     127.0.0.1:42638 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:13:16] INFO:     127.0.0.1:42568 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:13:16] INFO:     127.0.0.1:42578 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:13:16] INFO:     127.0.0.1:42588 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:13:16] INFO:     127.0.0.1:42602 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:13:16] INFO:     127.0.0.1:42612 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:13:16] INFO:     127.0.0.1:42622 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:13:16 TP0] Prefill batch. #new-seq: 1, #new-token: 601, #cached-token: 43, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-08-25 15:13:16 TP0] Prefill batch. #new-seq: 5, #new-token: 3005, #cached-token: 215, token usage: 0.02, #running-req: 1, #queue-req: 0, 
[2025-08-25 15:13:18 TP0] Prefill batch. #new-seq: 2, #new-token: 1000, #cached-token: 288, token usage: 0.08, #running-req: 6, #queue-req: 0, 
[2025-08-25 15:13:18] INFO:     127.0.0.1:57766 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 15:13:18] INFO:     127.0.0.1:57768 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 15:13:18] INFO:     127.0.0.1:57770 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 15:13:18] INFO:     127.0.0.1:57772 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 15:13:18] INFO:     127.0.0.1:57774 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 15:13:18] INFO:     127.0.0.1:57778 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 15:13:18 TP0] Prefill batch. #new-seq: 6, #new-token: 3000, #cached-token: 864, token usage: 0.00, #running-req: 2, #queue-req: 0, 
[2025-08-25 15:13:18] INFO:     127.0.0.1:57784 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 15:13:18] INFO:     127.0.0.1:57790 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 15:13:19 TP0] Prefill batch. #new-seq: 2, #new-token: 1000, #cached-token: 288, token usage: 0.08, #running-req: 8, #queue-req: 0, 
[2025-08-25 15:13:19] INFO:     127.0.0.1:57766 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 15:13:19] INFO:     127.0.0.1:57768 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 15:13:19] INFO:     127.0.0.1:57770 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 15:13:19] INFO:     127.0.0.1:57772 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 15:13:19] INFO:     127.0.0.1:57774 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 15:13:19] INFO:     127.0.0.1:57778 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 15:13:19] INFO:     127.0.0.1:57790 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 15:13:19] INFO:     127.0.0.1:57784 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 15:13:19 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 308, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-08-25 15:13:19 TP0] Prefill batch. #new-seq: 7, #new-token: 7, #cached-token: 2156, token usage: 0.00, #running-req: 1, #queue-req: 0, 
[2025-08-25 15:13:19 TP0] Decode batch. #running-req: 8, #token: 590, token usage: 0.00, gen throughput (token/s): 98.96, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:13:20 TP0] Decode batch. #running-req: 8, #token: 910, token usage: 0.00, gen throughput (token/s): 1652.13, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:13:20 TP0] Decode batch. #running-req: 8, #token: 1230, token usage: 0.00, gen throughput (token/s): 1584.81, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:13:20 TP0] Decode batch. #running-req: 8, #token: 1550, token usage: 0.00, gen throughput (token/s): 1623.96, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:13:20 TP0] Decode batch. #running-req: 8, #token: 1870, token usage: 0.00, gen throughput (token/s): 1704.86, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:13:20 TP0] Decode batch. #running-req: 8, #token: 2190, token usage: 0.00, gen throughput (token/s): 1639.60, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:13:21 TP0] Decode batch. #running-req: 8, #token: 2510, token usage: 0.00, gen throughput (token/s): 1748.51, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:13:21 TP0] Decode batch. #running-req: 8, #token: 2830, token usage: 0.00, gen throughput (token/s): 1731.66, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:13:21 TP0] Decode batch. #running-req: 8, #token: 3150, token usage: 0.00, gen throughput (token/s): 1686.29, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:13:21 TP0] Decode batch. #running-req: 8, #token: 3470, token usage: 0.00, gen throughput (token/s): 1654.09, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:13:21 TP0] Decode batch. #running-req: 8, #token: 3790, token usage: 0.00, gen throughput (token/s): 1616.19, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:13:22 TP0] Decode batch. #running-req: 8, #token: 4110, token usage: 0.00, gen throughput (token/s): 1689.33, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:13:22] INFO:     127.0.0.1:42638 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:13:22 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 308, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-08-25 15:13:22] INFO:     127.0.0.1:42556 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:13:22] INFO:     127.0.0.1:42568 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:13:22] INFO:     127.0.0.1:42578 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:13:22] INFO:     127.0.0.1:42588 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:13:22] INFO:     127.0.0.1:42602 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:13:22] INFO:     127.0.0.1:42612 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:13:22] INFO:     127.0.0.1:42622 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:13:22 TP0] Prefill batch. #new-seq: 2, #new-token: 2, #cached-token: 616, token usage: 0.00, #running-req: 1, #queue-req: 0, 
[2025-08-25 15:13:22 TP0] Prefill batch. #new-seq: 5, #new-token: 5, #cached-token: 1540, token usage: 0.00, #running-req: 3, #queue-req: 0, 
[2025-08-25 15:13:22 TP0] Decode batch. #running-req: 8, #token: 401, token usage: 0.00, gen throughput (token/s): 1006.95, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:13:22 TP0] Decode batch. #running-req: 8, #token: 721, token usage: 0.00, gen throughput (token/s): 1683.28, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:13:22 TP0] Decode batch. #running-req: 8, #token: 1041, token usage: 0.00, gen throughput (token/s): 1683.84, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:13:22 TP0] Decode batch. #running-req: 8, #token: 1361, token usage: 0.00, gen throughput (token/s): 1727.96, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:13:23 TP0] Decode batch. #running-req: 8, #token: 1681, token usage: 0.00, gen throughput (token/s): 1706.13, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:13:23 TP0] Decode batch. #running-req: 8, #token: 2001, token usage: 0.00, gen throughput (token/s): 1734.85, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:13:23 TP0] Decode batch. #running-req: 8, #token: 2321, token usage: 0.00, gen throughput (token/s): 1583.32, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:13:23 TP0] Decode batch. #running-req: 8, #token: 2641, token usage: 0.00, gen throughput (token/s): 1707.63, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:13:23 TP0] Decode batch. #running-req: 8, #token: 2961, token usage: 0.00, gen throughput (token/s): 1647.99, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:13:24 TP0] Decode batch. #running-req: 8, #token: 3281, token usage: 0.00, gen throughput (token/s): 1688.62, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:13:24 TP0] Decode batch. #running-req: 8, #token: 3601, token usage: 0.00, gen throughput (token/s): 1689.34, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:13:24 TP0] Decode batch. #running-req: 8, #token: 3921, token usage: 0.00, gen throughput (token/s): 1701.47, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:13:24 TP0] Decode batch. #running-req: 8, #token: 4241, token usage: 0.00, gen throughput (token/s): 1678.55, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:13:24] INFO:     127.0.0.1:42638 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:16:35 TP0] Prefill batch. #new-seq: 4, #new-token: 4, #cached-token: 328, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-08-25 15:16:35 TP0] Decode batch. #running-req: 4, #token: 207, token usage: 0.00, gen throughput (token/s): 1.03, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:16:35 TP0] Decode batch. #running-req: 4, #token: 367, token usage: 0.00, gen throughput (token/s): 874.49, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:16:35 TP0] Decode batch. #running-req: 4, #token: 527, token usage: 0.00, gen throughput (token/s): 876.09, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:16:35 TP0] Decode batch. #running-req: 4, #token: 687, token usage: 0.00, gen throughput (token/s): 879.56, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:16:36 TP0] Decode batch. #running-req: 4, #token: 847, token usage: 0.00, gen throughput (token/s): 885.33, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:16:36 TP0] Decode batch. #running-req: 4, #token: 1007, token usage: 0.00, gen throughput (token/s): 876.74, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:16:36 TP0] Decode batch. #running-req: 4, #token: 1167, token usage: 0.00, gen throughput (token/s): 878.98, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:16:36 TP0] Decode batch. #running-req: 4, #token: 1327, token usage: 0.00, gen throughput (token/s): 887.20, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:16:36 TP0] Decode batch. #running-req: 4, #token: 1487, token usage: 0.00, gen throughput (token/s): 866.55, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:16:36 TP0] Decode batch. #running-req: 4, #token: 1647, token usage: 0.00, gen throughput (token/s): 891.07, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:16:37 TP0] Decode batch. #running-req: 4, #token: 1807, token usage: 0.00, gen throughput (token/s): 876.80, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:16:37 TP0] Decode batch. #running-req: 4, #token: 1967, token usage: 0.00, gen throughput (token/s): 873.51, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:16:37] INFO:     127.0.0.1:53850 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:16:37] INFO:     127.0.0.1:53854 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:16:37] INFO:     127.0.0.1:53868 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:16:37] INFO:     127.0.0.1:53880 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:16:37 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 82, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-08-25 15:16:37 TP0] Prefill batch. #new-seq: 3, #new-token: 3, #cached-token: 246, token usage: 0.00, #running-req: 1, #queue-req: 0, 
[2025-08-25 15:16:37 TP0] Decode batch. #running-req: 4, #token: 127, token usage: 0.00, gen throughput (token/s): 568.31, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:16:37 TP0] Decode batch. #running-req: 4, #token: 287, token usage: 0.00, gen throughput (token/s): 900.44, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:16:37 TP0] Decode batch. #running-req: 4, #token: 447, token usage: 0.00, gen throughput (token/s): 884.55, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:16:38 TP0] Decode batch. #running-req: 4, #token: 607, token usage: 0.00, gen throughput (token/s): 878.34, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:16:38 TP0] Decode batch. #running-req: 4, #token: 767, token usage: 0.00, gen throughput (token/s): 864.44, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:16:38 TP0] Decode batch. #running-req: 4, #token: 927, token usage: 0.00, gen throughput (token/s): 864.20, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:16:38 TP0] Decode batch. #running-req: 4, #token: 1087, token usage: 0.00, gen throughput (token/s): 856.09, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:16:38 TP0] Decode batch. #running-req: 4, #token: 1247, token usage: 0.00, gen throughput (token/s): 882.22, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:16:39 TP0] Decode batch. #running-req: 4, #token: 1407, token usage: 0.00, gen throughput (token/s): 849.18, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:16:39 TP0] Decode batch. #running-req: 4, #token: 1567, token usage: 0.00, gen throughput (token/s): 839.87, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:16:39 TP0] Decode batch. #running-req: 4, #token: 1727, token usage: 0.00, gen throughput (token/s): 873.25, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:16:39 TP0] Decode batch. #running-req: 4, #token: 1887, token usage: 0.00, gen throughput (token/s): 856.27, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:16:39 TP0] Decode batch. #running-req: 4, #token: 2047, token usage: 0.00, gen throughput (token/s): 881.90, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:16:39] INFO:     127.0.0.1:53850 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:16:39] INFO:     127.0.0.1:53854 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:16:39] INFO:     127.0.0.1:53868 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:16:39] INFO:     127.0.0.1:53880 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:16:39 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 82, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-08-25 15:16:39 TP0] Prefill batch. #new-seq: 3, #new-token: 3, #cached-token: 246, token usage: 0.00, #running-req: 1, #queue-req: 0, 
[2025-08-25 15:16:40 TP0] Decode batch. #running-req: 4, #token: 207, token usage: 0.00, gen throughput (token/s): 597.60, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:16:40 TP0] Decode batch. #running-req: 4, #token: 367, token usage: 0.00, gen throughput (token/s): 883.65, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:16:40 TP0] Decode batch. #running-req: 4, #token: 527, token usage: 0.00, gen throughput (token/s): 863.41, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:16:40 TP0] Decode batch. #running-req: 4, #token: 687, token usage: 0.00, gen throughput (token/s): 885.46, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:16:40 TP0] Decode batch. #running-req: 4, #token: 847, token usage: 0.00, gen throughput (token/s): 883.76, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:16:40 TP0] Decode batch. #running-req: 4, #token: 1007, token usage: 0.00, gen throughput (token/s): 875.75, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:16:41 TP0] Decode batch. #running-req: 4, #token: 1167, token usage: 0.00, gen throughput (token/s): 866.58, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:16:41 TP0] Decode batch. #running-req: 4, #token: 1327, token usage: 0.00, gen throughput (token/s): 864.02, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:16:41 TP0] Decode batch. #running-req: 4, #token: 1487, token usage: 0.00, gen throughput (token/s): 878.49, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:16:41 TP0] Decode batch. #running-req: 4, #token: 1647, token usage: 0.00, gen throughput (token/s): 916.85, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:16:41 TP0] Decode batch. #running-req: 4, #token: 1807, token usage: 0.00, gen throughput (token/s): 904.94, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:16:42 TP0] Decode batch. #running-req: 4, #token: 1967, token usage: 0.00, gen throughput (token/s): 899.97, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:16:42] INFO:     127.0.0.1:53850 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:16:42] INFO:     127.0.0.1:53854 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:16:42] INFO:     127.0.0.1:53868 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:16:42] INFO:     127.0.0.1:53880 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:16:42 TP0] Prefill batch. #new-seq: 2, #new-token: 2, #cached-token: 164, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-08-25 15:16:42 TP0] Prefill batch. #new-seq: 2, #new-token: 2, #cached-token: 164, token usage: 0.00, #running-req: 2, #queue-req: 0, 
[2025-08-25 15:16:42 TP0] Decode batch. #running-req: 4, #token: 127, token usage: 0.00, gen throughput (token/s): 589.71, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:16:42 TP0] Decode batch. #running-req: 4, #token: 287, token usage: 0.00, gen throughput (token/s): 894.75, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:16:42 TP0] Decode batch. #running-req: 4, #token: 447, token usage: 0.00, gen throughput (token/s): 920.08, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:16:42 TP0] Decode batch. #running-req: 4, #token: 607, token usage: 0.00, gen throughput (token/s): 903.06, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:16:43 TP0] Decode batch. #running-req: 4, #token: 767, token usage: 0.00, gen throughput (token/s): 909.15, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:16:43 TP0] Decode batch. #running-req: 4, #token: 927, token usage: 0.00, gen throughput (token/s): 910.91, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:16:43 TP0] Decode batch. #running-req: 4, #token: 1087, token usage: 0.00, gen throughput (token/s): 895.74, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:16:43 TP0] Decode batch. #running-req: 4, #token: 1247, token usage: 0.00, gen throughput (token/s): 916.47, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:16:43 TP0] Decode batch. #running-req: 4, #token: 1407, token usage: 0.00, gen throughput (token/s): 897.19, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:16:43 TP0] Decode batch. #running-req: 4, #token: 1567, token usage: 0.00, gen throughput (token/s): 910.02, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:16:44 TP0] Decode batch. #running-req: 4, #token: 1727, token usage: 0.00, gen throughput (token/s): 893.64, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:16:44 TP0] Decode batch. #running-req: 4, #token: 1887, token usage: 0.00, gen throughput (token/s): 913.27, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:16:44 TP0] Decode batch. #running-req: 4, #token: 2047, token usage: 0.00, gen throughput (token/s): 908.94, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:16:44] INFO:     127.0.0.1:53854 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:16:44] INFO:     127.0.0.1:53850 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:16:44] INFO:     127.0.0.1:53868 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:16:44] INFO:     127.0.0.1:53880 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:16:44 TP0] Prefill batch. #new-seq: 1, #new-token: 530, #cached-token: 42, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-08-25 15:16:44 TP0] Prefill batch. #new-seq: 3, #new-token: 1590, #cached-token: 126, token usage: 0.01, #running-req: 1, #queue-req: 0, 
[2025-08-25 15:16:45] INFO:     127.0.0.1:3620 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 15:16:45] INFO:     127.0.0.1:3632 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 15:16:45] INFO:     127.0.0.1:3642 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 15:16:45] INFO:     127.0.0.1:3644 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 15:16:45 TP0] Prefill batch. #new-seq: 1, #new-token: 500, #cached-token: 72, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-08-25 15:16:45 TP0] Prefill batch. #new-seq: 3, #new-token: 1500, #cached-token: 216, token usage: 0.00, #running-req: 1, #queue-req: 0, 
[2025-08-25 15:16:45] INFO:     127.0.0.1:3620 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 15:16:45 TP0] Prefill batch. #new-seq: 1, #new-token: 500, #cached-token: 72, token usage: 0.04, #running-req: 4, #queue-req: 0, 
[2025-08-25 15:16:46] INFO:     127.0.0.1:3632 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 15:16:46] INFO:     127.0.0.1:3642 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 15:16:46] INFO:     127.0.0.1:3644 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 15:16:46 TP0] Prefill batch. #new-seq: 3, #new-token: 1500, #cached-token: 216, token usage: 0.00, #running-req: 1, #queue-req: 0, 
[2025-08-25 15:16:46] INFO:     127.0.0.1:3620 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 15:16:46 TP0] Prefill batch. #new-seq: 1, #new-token: 500, #cached-token: 72, token usage: 0.04, #running-req: 4, #queue-req: 0, 
[2025-08-25 15:16:46] INFO:     127.0.0.1:3632 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 15:16:46] INFO:     127.0.0.1:3642 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 15:16:46] INFO:     127.0.0.1:3644 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 15:16:46 TP0] Prefill batch. #new-seq: 3, #new-token: 1500, #cached-token: 216, token usage: 0.00, #running-req: 1, #queue-req: 0, 
[2025-08-25 15:16:46] INFO:     127.0.0.1:3620 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 15:16:47] INFO:     127.0.0.1:3632 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 15:16:47] INFO:     127.0.0.1:3642 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 15:16:47] INFO:     127.0.0.1:3644 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 15:16:47 TP0] Prefill batch. #new-seq: 4, #new-token: 4, #cached-token: 844, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-08-25 15:16:47 TP0] Decode batch. #running-req: 4, #token: 336, token usage: 0.00, gen throughput (token/s): 49.23, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:16:47 TP0] Decode batch. #running-req: 4, #token: 496, token usage: 0.00, gen throughput (token/s): 881.25, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:16:48 TP0] Decode batch. #running-req: 4, #token: 656, token usage: 0.00, gen throughput (token/s): 849.12, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:16:48 TP0] Decode batch. #running-req: 4, #token: 816, token usage: 0.00, gen throughput (token/s): 881.09, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:16:48 TP0] Decode batch. #running-req: 4, #token: 976, token usage: 0.00, gen throughput (token/s): 866.34, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:16:48 TP0] Decode batch. #running-req: 4, #token: 1136, token usage: 0.00, gen throughput (token/s): 869.95, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:16:48 TP0] Decode batch. #running-req: 4, #token: 1296, token usage: 0.00, gen throughput (token/s): 883.21, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:16:48 TP0] Decode batch. #running-req: 4, #token: 1456, token usage: 0.00, gen throughput (token/s): 865.99, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:16:49 TP0] Decode batch. #running-req: 4, #token: 1616, token usage: 0.00, gen throughput (token/s): 879.26, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:16:49 TP0] Decode batch. #running-req: 4, #token: 1776, token usage: 0.00, gen throughput (token/s): 831.33, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:16:49 TP0] Decode batch. #running-req: 4, #token: 1936, token usage: 0.00, gen throughput (token/s): 862.07, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:16:49 TP0] Decode batch. #running-req: 4, #token: 2096, token usage: 0.00, gen throughput (token/s): 878.78, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:16:49] INFO:     127.0.0.1:53850 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:16:49] INFO:     127.0.0.1:53854 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:16:49] INFO:     127.0.0.1:53868 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:16:49] INFO:     127.0.0.1:53880 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:16:49 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 211, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-08-25 15:16:49 TP0] Prefill batch. #new-seq: 3, #new-token: 3, #cached-token: 633, token usage: 0.00, #running-req: 1, #queue-req: 0, 
[2025-08-25 15:16:49 TP0] Decode batch. #running-req: 4, #token: 256, token usage: 0.00, gen throughput (token/s): 586.15, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:16:50 TP0] Decode batch. #running-req: 4, #token: 416, token usage: 0.00, gen throughput (token/s): 882.91, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:16:50 TP0] Decode batch. #running-req: 4, #token: 576, token usage: 0.00, gen throughput (token/s): 863.74, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:16:50 TP0] Decode batch. #running-req: 4, #token: 736, token usage: 0.00, gen throughput (token/s): 875.00, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:16:50 TP0] Decode batch. #running-req: 4, #token: 896, token usage: 0.00, gen throughput (token/s): 876.17, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:16:50 TP0] Decode batch. #running-req: 4, #token: 1056, token usage: 0.00, gen throughput (token/s): 873.68, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:16:51 TP0] Decode batch. #running-req: 4, #token: 1216, token usage: 0.00, gen throughput (token/s): 904.61, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:16:51 TP0] Decode batch. #running-req: 4, #token: 1376, token usage: 0.00, gen throughput (token/s): 880.15, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:16:51 TP0] Decode batch. #running-req: 4, #token: 1536, token usage: 0.00, gen throughput (token/s): 878.44, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:16:51 TP0] Decode batch. #running-req: 4, #token: 1696, token usage: 0.00, gen throughput (token/s): 877.67, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:16:51 TP0] Decode batch. #running-req: 4, #token: 1856, token usage: 0.00, gen throughput (token/s): 848.33, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:16:52 TP0] Decode batch. #running-req: 4, #token: 2016, token usage: 0.00, gen throughput (token/s): 840.97, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:16:52 TP0] Decode batch. #running-req: 4, #token: 2176, token usage: 0.00, gen throughput (token/s): 847.13, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:16:52] INFO:     127.0.0.1:53850 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:16:52] INFO:     127.0.0.1:53854 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:16:52] INFO:     127.0.0.1:53868 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:16:52] INFO:     127.0.0.1:53880 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:16:52 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 211, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-08-25 15:16:52 TP0] Prefill batch. #new-seq: 3, #new-token: 3, #cached-token: 633, token usage: 0.00, #running-req: 1, #queue-req: 0, 
[2025-08-25 15:16:52 TP0] Decode batch. #running-req: 4, #token: 336, token usage: 0.00, gen throughput (token/s): 601.93, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:16:52 TP0] Decode batch. #running-req: 4, #token: 496, token usage: 0.00, gen throughput (token/s): 878.88, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:16:52 TP0] Decode batch. #running-req: 4, #token: 656, token usage: 0.00, gen throughput (token/s): 861.91, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:16:53 TP0] Decode batch. #running-req: 4, #token: 816, token usage: 0.00, gen throughput (token/s): 855.34, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:16:53 TP0] Decode batch. #running-req: 4, #token: 976, token usage: 0.00, gen throughput (token/s): 901.97, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:16:53 TP0] Decode batch. #running-req: 4, #token: 1136, token usage: 0.00, gen throughput (token/s): 815.86, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:16:53 TP0] Decode batch. #running-req: 4, #token: 1296, token usage: 0.00, gen throughput (token/s): 877.36, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:16:53 TP0] Decode batch. #running-req: 4, #token: 1456, token usage: 0.00, gen throughput (token/s): 870.89, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:16:53 TP0] Decode batch. #running-req: 4, #token: 1616, token usage: 0.00, gen throughput (token/s): 847.03, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:16:54 TP0] Decode batch. #running-req: 4, #token: 1776, token usage: 0.00, gen throughput (token/s): 859.84, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:16:54 TP0] Decode batch. #running-req: 4, #token: 1936, token usage: 0.00, gen throughput (token/s): 878.61, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:16:54 TP0] Decode batch. #running-req: 4, #token: 2096, token usage: 0.00, gen throughput (token/s): 828.17, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:16:54] INFO:     127.0.0.1:53850 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:16:54] INFO:     127.0.0.1:53854 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:16:54] INFO:     127.0.0.1:53868 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:16:54] INFO:     127.0.0.1:53880 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:16:54 TP0] Prefill batch. #new-seq: 4, #new-token: 4, #cached-token: 844, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-08-25 15:16:54 TP0] Decode batch. #running-req: 4, #token: 256, token usage: 0.00, gen throughput (token/s): 659.28, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:16:54 TP0] Decode batch. #running-req: 4, #token: 416, token usage: 0.00, gen throughput (token/s): 879.65, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:16:55 TP0] Decode batch. #running-req: 4, #token: 576, token usage: 0.00, gen throughput (token/s): 912.72, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:16:55 TP0] Decode batch. #running-req: 4, #token: 736, token usage: 0.00, gen throughput (token/s): 813.98, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:16:55 TP0] Decode batch. #running-req: 4, #token: 896, token usage: 0.00, gen throughput (token/s): 880.44, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:16:55 TP0] Decode batch. #running-req: 4, #token: 1056, token usage: 0.00, gen throughput (token/s): 862.76, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:16:55 TP0] Decode batch. #running-req: 4, #token: 1216, token usage: 0.00, gen throughput (token/s): 876.96, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:16:56 TP0] Decode batch. #running-req: 4, #token: 1376, token usage: 0.00, gen throughput (token/s): 868.34, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:16:56 TP0] Decode batch. #running-req: 4, #token: 1536, token usage: 0.00, gen throughput (token/s): 843.94, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:16:56 TP0] Decode batch. #running-req: 4, #token: 1696, token usage: 0.00, gen throughput (token/s): 860.04, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:16:56 TP0] Decode batch. #running-req: 4, #token: 1856, token usage: 0.00, gen throughput (token/s): 855.13, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:16:56 TP0] Decode batch. #running-req: 4, #token: 2016, token usage: 0.00, gen throughput (token/s): 843.95, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:16:56 TP0] Decode batch. #running-req: 4, #token: 2176, token usage: 0.00, gen throughput (token/s): 859.82, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:16:57] INFO:     127.0.0.1:53850 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:16:57] INFO:     127.0.0.1:53854 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:16:57] INFO:     127.0.0.1:53868 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:16:57] INFO:     127.0.0.1:53880 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:16:57 TP0] Prefill batch. #new-seq: 4, #new-token: 2636, #cached-token: 168, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-08-25 15:16:57] INFO:     127.0.0.1:58390 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 15:16:57] INFO:     127.0.0.1:58406 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 15:16:57] INFO:     127.0.0.1:58418 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 15:16:57] INFO:     127.0.0.1:58428 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 15:16:57 TP0] Prefill batch. #new-seq: 1, #new-token: 500, #cached-token: 201, token usage: 0.01, #running-req: 0, #queue-req: 0, 
[2025-08-25 15:16:58 TP0] Prefill batch. #new-seq: 3, #new-token: 1500, #cached-token: 603, token usage: 0.02, #running-req: 1, #queue-req: 0, 
[2025-08-25 15:16:58] INFO:     127.0.0.1:58390 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 15:16:58] INFO:     127.0.0.1:58428 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 15:16:58] INFO:     127.0.0.1:58406 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 15:16:58] INFO:     127.0.0.1:58418 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 15:16:58 TP0] Prefill batch. #new-seq: 1, #new-token: 500, #cached-token: 201, token usage: 0.01, #running-req: 0, #queue-req: 0, 
[2025-08-25 15:16:58 TP0] Prefill batch. #new-seq: 3, #new-token: 1500, #cached-token: 603, token usage: 0.02, #running-req: 1, #queue-req: 0, 
[2025-08-25 15:16:58] INFO:     127.0.0.1:58390 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 15:16:59 TP0] Prefill batch. #new-seq: 1, #new-token: 500, #cached-token: 201, token usage: 0.01, #running-req: 3, #queue-req: 0, 
[2025-08-25 15:16:59] INFO:     127.0.0.1:58428 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 15:16:59] INFO:     127.0.0.1:58406 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 15:16:59] INFO:     127.0.0.1:58418 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 15:16:59 TP0] Prefill batch. #new-seq: 3, #new-token: 1500, #cached-token: 603, token usage: 0.02, #running-req: 4, #queue-req: 0, 
[2025-08-25 15:16:59] INFO:     127.0.0.1:58390 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 15:17:00] INFO:     127.0.0.1:58428 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 15:17:00] INFO:     127.0.0.1:58406 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 15:17:00] INFO:     127.0.0.1:58418 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 15:17:00 TP0] Prefill batch. #new-seq: 4, #new-token: 4, #cached-token: 664, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-08-25 15:17:00 TP0] Decode batch. #running-req: 4, #token: 291, token usage: 0.00, gen throughput (token/s): 47.31, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:17:00 TP0] Decode batch. #running-req: 4, #token: 451, token usage: 0.00, gen throughput (token/s): 898.35, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:17:00 TP0] Decode batch. #running-req: 4, #token: 611, token usage: 0.00, gen throughput (token/s): 880.78, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:17:00 TP0] Decode batch. #running-req: 4, #token: 771, token usage: 0.00, gen throughput (token/s): 872.90, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:17:01 TP0] Decode batch. #running-req: 4, #token: 931, token usage: 0.00, gen throughput (token/s): 886.31, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:17:01 TP0] Decode batch. #running-req: 4, #token: 1091, token usage: 0.00, gen throughput (token/s): 890.71, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:17:01 TP0] Decode batch. #running-req: 4, #token: 1251, token usage: 0.00, gen throughput (token/s): 879.14, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:17:01 TP0] Decode batch. #running-req: 4, #token: 1411, token usage: 0.00, gen throughput (token/s): 859.88, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:17:01 TP0] Decode batch. #running-req: 4, #token: 1571, token usage: 0.00, gen throughput (token/s): 831.91, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:17:01 TP0] Decode batch. #running-req: 4, #token: 1731, token usage: 0.00, gen throughput (token/s): 880.19, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:17:02 TP0] Decode batch. #running-req: 4, #token: 1891, token usage: 0.00, gen throughput (token/s): 857.45, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:17:02 TP0] Decode batch. #running-req: 4, #token: 2051, token usage: 0.00, gen throughput (token/s): 874.42, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:17:02] INFO:     127.0.0.1:53850 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:17:02] INFO:     127.0.0.1:53854 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:17:02] INFO:     127.0.0.1:53868 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:17:02] INFO:     127.0.0.1:53880 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:17:02 TP0] Prefill batch. #new-seq: 4, #new-token: 4, #cached-token: 664, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-08-25 15:17:02 TP0] Decode batch. #running-req: 4, #token: 211, token usage: 0.00, gen throughput (token/s): 640.48, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:17:02 TP0] Decode batch. #running-req: 4, #token: 371, token usage: 0.00, gen throughput (token/s): 845.45, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:17:02 TP0] Decode batch. #running-req: 4, #token: 531, token usage: 0.00, gen throughput (token/s): 881.34, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:17:03 TP0] Decode batch. #running-req: 4, #token: 691, token usage: 0.00, gen throughput (token/s): 841.74, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:17:03 TP0] Decode batch. #running-req: 4, #token: 851, token usage: 0.00, gen throughput (token/s): 849.62, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:17:03 TP0] Decode batch. #running-req: 4, #token: 1011, token usage: 0.00, gen throughput (token/s): 861.10, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:17:03 TP0] Decode batch. #running-req: 4, #token: 1171, token usage: 0.00, gen throughput (token/s): 855.89, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:17:03 TP0] Decode batch. #running-req: 4, #token: 1331, token usage: 0.00, gen throughput (token/s): 858.80, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:17:04 TP0] Decode batch. #running-req: 4, #token: 1491, token usage: 0.00, gen throughput (token/s): 848.97, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:17:04 TP0] Decode batch. #running-req: 4, #token: 1651, token usage: 0.00, gen throughput (token/s): 851.29, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:17:04 TP0] Decode batch. #running-req: 4, #token: 1811, token usage: 0.00, gen throughput (token/s): 837.54, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:17:04 TP0] Decode batch. #running-req: 4, #token: 1971, token usage: 0.00, gen throughput (token/s): 853.00, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:17:04 TP0] Decode batch. #running-req: 4, #token: 2131, token usage: 0.00, gen throughput (token/s): 874.31, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:17:04] INFO:     127.0.0.1:53850 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:17:04] INFO:     127.0.0.1:53854 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:17:04] INFO:     127.0.0.1:53868 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:17:04] INFO:     127.0.0.1:53880 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:17:04 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 166, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-08-25 15:17:04 TP0] Prefill batch. #new-seq: 3, #new-token: 3, #cached-token: 498, token usage: 0.00, #running-req: 1, #queue-req: 0, 
[2025-08-25 15:17:05 TP0] Decode batch. #running-req: 4, #token: 291, token usage: 0.00, gen throughput (token/s): 587.81, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:17:05 TP0] Decode batch. #running-req: 4, #token: 451, token usage: 0.00, gen throughput (token/s): 893.56, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:17:05 TP0] Decode batch. #running-req: 4, #token: 611, token usage: 0.00, gen throughput (token/s): 868.94, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:17:05 TP0] Decode batch. #running-req: 4, #token: 771, token usage: 0.00, gen throughput (token/s): 845.15, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:17:05 TP0] Decode batch. #running-req: 4, #token: 931, token usage: 0.00, gen throughput (token/s): 882.17, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:17:06 TP0] Decode batch. #running-req: 4, #token: 1091, token usage: 0.00, gen throughput (token/s): 853.99, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:17:06 TP0] Decode batch. #running-req: 4, #token: 1251, token usage: 0.00, gen throughput (token/s): 867.16, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:17:06 TP0] Decode batch. #running-req: 4, #token: 1411, token usage: 0.00, gen throughput (token/s): 881.94, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:17:06 TP0] Decode batch. #running-req: 4, #token: 1571, token usage: 0.00, gen throughput (token/s): 883.89, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:17:06 TP0] Decode batch. #running-req: 4, #token: 1731, token usage: 0.00, gen throughput (token/s): 879.94, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:17:06 TP0] Decode batch. #running-req: 4, #token: 1891, token usage: 0.00, gen throughput (token/s): 847.76, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:17:07 TP0] Decode batch. #running-req: 4, #token: 2051, token usage: 0.00, gen throughput (token/s): 862.21, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:17:07] INFO:     127.0.0.1:53850 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:17:07] INFO:     127.0.0.1:53854 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:17:07] INFO:     127.0.0.1:53868 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:17:07] INFO:     127.0.0.1:53880 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:17:07 TP0] Prefill batch. #new-seq: 4, #new-token: 4, #cached-token: 664, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-08-25 15:17:07 TP0] Decode batch. #running-req: 4, #token: 211, token usage: 0.00, gen throughput (token/s): 657.28, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:17:07 TP0] Decode batch. #running-req: 4, #token: 371, token usage: 0.00, gen throughput (token/s): 849.67, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:17:07 TP0] Decode batch. #running-req: 4, #token: 531, token usage: 0.00, gen throughput (token/s): 851.62, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:17:07 TP0] Decode batch. #running-req: 4, #token: 691, token usage: 0.00, gen throughput (token/s): 868.29, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:17:08 TP0] Decode batch. #running-req: 4, #token: 851, token usage: 0.00, gen throughput (token/s): 876.58, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:17:08 TP0] Decode batch. #running-req: 4, #token: 1011, token usage: 0.00, gen throughput (token/s): 885.23, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:17:08 TP0] Decode batch. #running-req: 4, #token: 1171, token usage: 0.00, gen throughput (token/s): 892.81, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:17:08 TP0] Decode batch. #running-req: 4, #token: 1331, token usage: 0.00, gen throughput (token/s): 901.35, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:17:08 TP0] Decode batch. #running-req: 4, #token: 1491, token usage: 0.00, gen throughput (token/s): 909.75, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:17:09 TP0] Decode batch. #running-req: 4, #token: 1651, token usage: 0.00, gen throughput (token/s): 905.56, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:17:09 TP0] Decode batch. #running-req: 4, #token: 1811, token usage: 0.00, gen throughput (token/s): 887.99, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:17:09 TP0] Decode batch. #running-req: 4, #token: 1971, token usage: 0.00, gen throughput (token/s): 875.85, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:17:09 TP0] Decode batch. #running-req: 4, #token: 2131, token usage: 0.00, gen throughput (token/s): 881.18, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:17:09] INFO:     127.0.0.1:53854 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:17:09] INFO:     127.0.0.1:53850 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:17:09] INFO:     127.0.0.1:53868 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:17:09] INFO:     127.0.0.1:53880 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:17:09 TP0] Prefill batch. #new-seq: 1, #new-token: 613, #cached-token: 43, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-08-25 15:17:09 TP0] Prefill batch. #new-seq: 3, #new-token: 1839, #cached-token: 129, token usage: 0.02, #running-req: 1, #queue-req: 0, 
[2025-08-25 15:17:10] INFO:     127.0.0.1:31250 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 15:17:10] INFO:     127.0.0.1:31258 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 15:17:10] INFO:     127.0.0.1:31268 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 15:17:10] INFO:     127.0.0.1:31278 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 15:17:10 TP0] Prefill batch. #new-seq: 1, #new-token: 500, #cached-token: 156, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-08-25 15:17:10 TP0] Prefill batch. #new-seq: 2, #new-token: 1000, #cached-token: 312, token usage: 0.02, #running-req: 1, #queue-req: 0, 
[2025-08-25 15:17:10 TP0] Prefill batch. #new-seq: 1, #new-token: 500, #cached-token: 156, token usage: 0.03, #running-req: 3, #queue-req: 0, 
[2025-08-25 15:17:10] INFO:     127.0.0.1:31250 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 15:17:11 TP0] Prefill batch. #new-seq: 1, #new-token: 500, #cached-token: 156, token usage: 0.02, #running-req: 4, #queue-req: 0, 
[2025-08-25 15:17:11] INFO:     127.0.0.1:31278 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 15:17:11] INFO:     127.0.0.1:31258 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 15:17:11 TP0] Prefill batch. #new-seq: 2, #new-token: 1000, #cached-token: 312, token usage: 0.02, #running-req: 5, #queue-req: 0, 
[2025-08-25 15:17:11] INFO:     127.0.0.1:31268 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 15:17:11 TP0] Prefill batch. #new-seq: 1, #new-token: 500, #cached-token: 156, token usage: 0.03, #running-req: 7, #queue-req: 0, 
[2025-08-25 15:17:11] INFO:     127.0.0.1:31250 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 15:17:12 TP0] Prefill batch. #new-seq: 1, #new-token: 500, #cached-token: 156, token usage: 0.02, #running-req: 8, #queue-req: 0, 
[2025-08-25 15:17:12] INFO:     127.0.0.1:31278 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 15:17:12] INFO:     127.0.0.1:31258 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 15:17:12 TP0] Prefill batch. #new-seq: 2, #new-token: 1000, #cached-token: 312, token usage: 0.02, #running-req: 9, #queue-req: 0, 
[2025-08-25 15:17:12] INFO:     127.0.0.1:31268 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 15:17:12 TP0] Prefill batch. #new-seq: 1, #new-token: 500, #cached-token: 156, token usage: 0.03, #running-req: 11, #queue-req: 0, 
[2025-08-25 15:17:12] INFO:     127.0.0.1:31250 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 15:17:12 TP0] Prefill batch. #new-seq: 1, #new-token: 665, #cached-token: 0, token usage: 0.02, #running-req: 12, #queue-req: 0, 
[2025-08-25 15:17:12] INFO:     127.0.0.1:31278 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 15:17:12] INFO:     127.0.0.1:31258 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 15:17:13] INFO:     127.0.0.1:31268 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 15:17:13 TP0] Decode batch. #running-req: 1, #token: 672, token usage: 0.02, gen throughput (token/s): 0.33, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:17:15 TP0] Decode batch. #running-req: 1, #token: 712, token usage: 0.02, gen throughput (token/s): 22.79, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:17:16 TP0] Decode batch. #running-req: 1, #token: 752, token usage: 0.02, gen throughput (token/s): 22.79, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:17:18 TP0] Decode batch. #running-req: 1, #token: 792, token usage: 0.02, gen throughput (token/s): 22.75, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:17:19] INFO:     127.0.0.1:31250 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:17:19 TP0] Prefill batch. #new-seq: 4, #new-token: 4, #cached-token: 436, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-08-25 15:17:19 TP0] Decode batch. #running-req: 4, #token: 234, token usage: 0.00, gen throughput (token/s): 15.47, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:17:20 TP0] Decode batch. #running-req: 4, #token: 394, token usage: 0.00, gen throughput (token/s): 893.67, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:17:20 TP0] Decode batch. #running-req: 4, #token: 554, token usage: 0.00, gen throughput (token/s): 898.01, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:17:20 TP0] Decode batch. #running-req: 4, #token: 714, token usage: 0.00, gen throughput (token/s): 950.15, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:17:20 TP0] Decode batch. #running-req: 4, #token: 874, token usage: 0.00, gen throughput (token/s): 935.60, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:17:20 TP0] Decode batch. #running-req: 4, #token: 1034, token usage: 0.00, gen throughput (token/s): 905.99, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:17:20 TP0] Decode batch. #running-req: 4, #token: 1194, token usage: 0.00, gen throughput (token/s): 930.75, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:17:21 TP0] Decode batch. #running-req: 4, #token: 1354, token usage: 0.00, gen throughput (token/s): 922.66, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:17:21 TP0] Decode batch. #running-req: 4, #token: 1514, token usage: 0.00, gen throughput (token/s): 942.61, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:17:21 TP0] Decode batch. #running-req: 4, #token: 1674, token usage: 0.00, gen throughput (token/s): 922.10, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:17:21 TP0] Decode batch. #running-req: 4, #token: 1834, token usage: 0.00, gen throughput (token/s): 902.98, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:17:21 TP0] Decode batch. #running-req: 4, #token: 1994, token usage: 0.00, gen throughput (token/s): 896.95, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:17:21] INFO:     127.0.0.1:17686 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:17:21] INFO:     127.0.0.1:17702 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:17:21] INFO:     127.0.0.1:17710 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:17:21] INFO:     127.0.0.1:17724 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:17:21 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 109, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-08-25 15:17:22 TP0] Prefill batch. #new-seq: 3, #new-token: 3, #cached-token: 327, token usage: 0.00, #running-req: 1, #queue-req: 0, 
[2025-08-25 15:17:22 TP0] Decode batch. #running-req: 4, #token: 154, token usage: 0.00, gen throughput (token/s): 602.30, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:17:22 TP0] Decode batch. #running-req: 4, #token: 314, token usage: 0.00, gen throughput (token/s): 896.77, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:17:22 TP0] Decode batch. #running-req: 4, #token: 474, token usage: 0.00, gen throughput (token/s): 897.21, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:17:22 TP0] Decode batch. #running-req: 4, #token: 634, token usage: 0.00, gen throughput (token/s): 910.40, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:17:22 TP0] Decode batch. #running-req: 4, #token: 794, token usage: 0.00, gen throughput (token/s): 884.64, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:17:22 TP0] Decode batch. #running-req: 4, #token: 954, token usage: 0.00, gen throughput (token/s): 890.32, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:17:23 TP0] Decode batch. #running-req: 4, #token: 1114, token usage: 0.00, gen throughput (token/s): 896.64, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:17:23 TP0] Decode batch. #running-req: 4, #token: 1274, token usage: 0.00, gen throughput (token/s): 887.89, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:17:23 TP0] Decode batch. #running-req: 4, #token: 1434, token usage: 0.00, gen throughput (token/s): 899.47, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:17:23 TP0] Decode batch. #running-req: 4, #token: 1594, token usage: 0.00, gen throughput (token/s): 897.03, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:17:23 TP0] Decode batch. #running-req: 4, #token: 1754, token usage: 0.00, gen throughput (token/s): 907.21, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:17:24 TP0] Decode batch. #running-req: 4, #token: 1914, token usage: 0.00, gen throughput (token/s): 898.88, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:17:24 TP0] Decode batch. #running-req: 4, #token: 2074, token usage: 0.00, gen throughput (token/s): 893.58, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:17:24] INFO:     127.0.0.1:17724 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:17:24] INFO:     127.0.0.1:17686 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:17:24] INFO:     127.0.0.1:17702 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:17:24] INFO:     127.0.0.1:17710 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:17:24 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 109, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-08-25 15:17:24 TP0] Prefill batch. #new-seq: 3, #new-token: 3, #cached-token: 327, token usage: 0.00, #running-req: 1, #queue-req: 0, 
[2025-08-25 15:17:24 TP0] Decode batch. #running-req: 4, #token: 234, token usage: 0.00, gen throughput (token/s): 605.09, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:17:24 TP0] Decode batch. #running-req: 4, #token: 394, token usage: 0.00, gen throughput (token/s): 881.67, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:17:24 TP0] Decode batch. #running-req: 4, #token: 554, token usage: 0.00, gen throughput (token/s): 883.35, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:17:25 TP0] Decode batch. #running-req: 4, #token: 714, token usage: 0.00, gen throughput (token/s): 893.90, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:17:25 TP0] Decode batch. #running-req: 4, #token: 874, token usage: 0.00, gen throughput (token/s): 894.87, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:17:25 TP0] Decode batch. #running-req: 4, #token: 1034, token usage: 0.00, gen throughput (token/s): 918.04, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:17:25 TP0] Decode batch. #running-req: 4, #token: 1194, token usage: 0.00, gen throughput (token/s): 900.60, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:17:25 TP0] Decode batch. #running-req: 4, #token: 1354, token usage: 0.00, gen throughput (token/s): 904.47, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:17:25 TP0] Decode batch. #running-req: 4, #token: 1514, token usage: 0.00, gen throughput (token/s): 909.49, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:17:26 TP0] Decode batch. #running-req: 4, #token: 1674, token usage: 0.00, gen throughput (token/s): 922.30, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:17:26 TP0] Decode batch. #running-req: 4, #token: 1834, token usage: 0.00, gen throughput (token/s): 901.21, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:17:26 TP0] Decode batch. #running-req: 4, #token: 1994, token usage: 0.00, gen throughput (token/s): 913.41, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:17:26] INFO:     127.0.0.1:17724 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:17:26] INFO:     127.0.0.1:17686 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:17:26] INFO:     127.0.0.1:17702 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:17:26] INFO:     127.0.0.1:17710 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:17:26 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 109, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-08-25 15:17:26 TP0] Prefill batch. #new-seq: 3, #new-token: 3, #cached-token: 327, token usage: 0.00, #running-req: 1, #queue-req: 0, 
[2025-08-25 15:17:26 TP0] Decode batch. #running-req: 4, #token: 154, token usage: 0.00, gen throughput (token/s): 592.26, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:17:26 TP0] Decode batch. #running-req: 4, #token: 314, token usage: 0.00, gen throughput (token/s): 869.89, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:17:27 TP0] Decode batch. #running-req: 4, #token: 474, token usage: 0.00, gen throughput (token/s): 863.00, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:17:27 TP0] Decode batch. #running-req: 4, #token: 634, token usage: 0.00, gen throughput (token/s): 858.06, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:17:27 TP0] Decode batch. #running-req: 4, #token: 794, token usage: 0.00, gen throughput (token/s): 877.51, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:17:27 TP0] Decode batch. #running-req: 4, #token: 954, token usage: 0.00, gen throughput (token/s): 861.84, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:17:27 TP0] Decode batch. #running-req: 4, #token: 1114, token usage: 0.00, gen throughput (token/s): 846.53, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:17:28 TP0] Decode batch. #running-req: 4, #token: 1274, token usage: 0.00, gen throughput (token/s): 883.70, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:17:28 TP0] Decode batch. #running-req: 4, #token: 1434, token usage: 0.00, gen throughput (token/s): 860.30, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:17:28 TP0] Decode batch. #running-req: 4, #token: 1594, token usage: 0.00, gen throughput (token/s): 865.34, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:17:28 TP0] Decode batch. #running-req: 4, #token: 1754, token usage: 0.00, gen throughput (token/s): 875.92, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:17:28 TP0] Decode batch. #running-req: 4, #token: 1914, token usage: 0.00, gen throughput (token/s): 859.86, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:17:28 TP0] Decode batch. #running-req: 4, #token: 2074, token usage: 0.00, gen throughput (token/s): 862.63, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:17:28] INFO:     127.0.0.1:17724 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:17:28] INFO:     127.0.0.1:17686 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:17:28] INFO:     127.0.0.1:17702 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:17:28] INFO:     127.0.0.1:17710 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:17:29 TP0] Prefill batch. #new-seq: 4, #new-token: 2220, #cached-token: 176, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-08-25 15:17:29] INFO:     127.0.0.1:1786 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 15:17:29] INFO:     127.0.0.1:1792 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 15:17:29] INFO:     127.0.0.1:1798 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 15:17:29] INFO:     127.0.0.1:1810 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 15:17:29 TP0] Prefill batch. #new-seq: 1, #new-token: 500, #cached-token: 99, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-08-25 15:17:29 TP0] Prefill batch. #new-seq: 3, #new-token: 1500, #cached-token: 297, token usage: 0.02, #running-req: 1, #queue-req: 0, 
[2025-08-25 15:17:30] INFO:     127.0.0.1:1810 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 15:17:30] INFO:     127.0.0.1:1786 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 15:17:30] INFO:     127.0.0.1:1792 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 15:17:30] INFO:     127.0.0.1:1798 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 15:17:30 TP0] Prefill batch. #new-seq: 1, #new-token: 500, #cached-token: 99, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-08-25 15:17:30 TP0] Prefill batch. #new-seq: 3, #new-token: 1500, #cached-token: 297, token usage: 0.02, #running-req: 1, #queue-req: 0, 
[2025-08-25 15:17:31] INFO:     127.0.0.1:1810 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 15:17:31] INFO:     127.0.0.1:1786 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 15:17:31] INFO:     127.0.0.1:1792 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 15:17:31] INFO:     127.0.0.1:1798 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 15:17:31 TP0] Prefill batch. #new-seq: 1, #new-token: 500, #cached-token: 99, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-08-25 15:17:31 TP0] Prefill batch. #new-seq: 3, #new-token: 1500, #cached-token: 297, token usage: 0.00, #running-req: 1, #queue-req: 0, 
[2025-08-25 15:17:31] INFO:     127.0.0.1:1810 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 15:17:32] INFO:     127.0.0.1:1786 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 15:17:32] INFO:     127.0.0.1:1792 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 15:17:32] INFO:     127.0.0.1:1798 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 15:17:32 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 135, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-08-25 15:17:32 TP0] Prefill batch. #new-seq: 3, #new-token: 3, #cached-token: 405, token usage: 0.00, #running-req: 1, #queue-req: 0, 
[2025-08-25 15:17:32 TP0] Decode batch. #running-req: 4, #token: 257, token usage: 0.00, gen throughput (token/s): 47.28, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:17:32 TP0] Decode batch. #running-req: 4, #token: 417, token usage: 0.00, gen throughput (token/s): 873.62, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:17:32 TP0] Decode batch. #running-req: 4, #token: 577, token usage: 0.00, gen throughput (token/s): 872.95, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:17:32 TP0] Decode batch. #running-req: 4, #token: 737, token usage: 0.00, gen throughput (token/s): 863.89, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:17:33 TP0] Decode batch. #running-req: 4, #token: 897, token usage: 0.00, gen throughput (token/s): 894.14, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:17:33 TP0] Decode batch. #running-req: 4, #token: 1057, token usage: 0.00, gen throughput (token/s): 851.67, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:17:33 TP0] Decode batch. #running-req: 4, #token: 1217, token usage: 0.00, gen throughput (token/s): 852.17, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:17:33 TP0] Decode batch. #running-req: 4, #token: 1377, token usage: 0.00, gen throughput (token/s): 859.58, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:17:33 TP0] Decode batch. #running-req: 4, #token: 1537, token usage: 0.00, gen throughput (token/s): 849.49, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:17:33 TP0] Decode batch. #running-req: 4, #token: 1697, token usage: 0.00, gen throughput (token/s): 917.04, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:17:34 TP0] Decode batch. #running-req: 4, #token: 1857, token usage: 0.00, gen throughput (token/s): 875.88, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:17:34 TP0] Decode batch. #running-req: 4, #token: 2017, token usage: 0.00, gen throughput (token/s): 913.64, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:17:34] INFO:     127.0.0.1:17724 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:17:34] INFO:     127.0.0.1:17686 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:17:34] INFO:     127.0.0.1:17702 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:17:34] INFO:     127.0.0.1:17710 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:17:34 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 135, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-08-25 15:17:34 TP0] Prefill batch. #new-seq: 3, #new-token: 3, #cached-token: 405, token usage: 0.00, #running-req: 1, #queue-req: 0, 
[2025-08-25 15:17:34 TP0] Decode batch. #running-req: 4, #token: 176, token usage: 0.00, gen throughput (token/s): 631.44, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:17:34 TP0] Decode batch. #running-req: 4, #token: 336, token usage: 0.00, gen throughput (token/s): 883.39, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:17:34 TP0] Decode batch. #running-req: 4, #token: 496, token usage: 0.00, gen throughput (token/s): 870.68, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:17:35 TP0] Decode batch. #running-req: 4, #token: 656, token usage: 0.00, gen throughput (token/s): 899.30, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:17:35 TP0] Decode batch. #running-req: 4, #token: 816, token usage: 0.00, gen throughput (token/s): 907.44, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:17:35 TP0] Decode batch. #running-req: 4, #token: 976, token usage: 0.00, gen throughput (token/s): 903.01, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:17:35 TP0] Decode batch. #running-req: 4, #token: 1136, token usage: 0.00, gen throughput (token/s): 904.72, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:17:35 TP0] Decode batch. #running-req: 4, #token: 1296, token usage: 0.00, gen throughput (token/s): 926.75, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:17:35 TP0] Decode batch. #running-req: 4, #token: 1456, token usage: 0.00, gen throughput (token/s): 918.37, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:17:36 TP0] Decode batch. #running-req: 4, #token: 1616, token usage: 0.00, gen throughput (token/s): 905.61, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:17:36 TP0] Decode batch. #running-req: 4, #token: 1776, token usage: 0.00, gen throughput (token/s): 901.84, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:17:36 TP0] Decode batch. #running-req: 4, #token: 1936, token usage: 0.00, gen throughput (token/s): 894.13, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:17:36 TP0] Decode batch. #running-req: 4, #token: 2096, token usage: 0.00, gen throughput (token/s): 935.71, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:17:36] INFO:     127.0.0.1:17724 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:17:36] INFO:     127.0.0.1:17702 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:17:36] INFO:     127.0.0.1:17686 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:17:36] INFO:     127.0.0.1:17710 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:17:36 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 135, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-08-25 15:17:36 TP0] Prefill batch. #new-seq: 3, #new-token: 3, #cached-token: 405, token usage: 0.00, #running-req: 1, #queue-req: 0, 
[2025-08-25 15:17:36 TP0] Decode batch. #running-req: 4, #token: 256, token usage: 0.00, gen throughput (token/s): 601.21, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:17:37 TP0] Decode batch. #running-req: 4, #token: 416, token usage: 0.00, gen throughput (token/s): 904.62, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:17:37 TP0] Decode batch. #running-req: 4, #token: 576, token usage: 0.00, gen throughput (token/s): 903.13, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:17:37 TP0] Decode batch. #running-req: 4, #token: 736, token usage: 0.00, gen throughput (token/s): 896.37, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:17:37 TP0] Decode batch. #running-req: 4, #token: 896, token usage: 0.00, gen throughput (token/s): 902.14, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:17:37 TP0] Decode batch. #running-req: 4, #token: 1056, token usage: 0.00, gen throughput (token/s): 911.83, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:17:37 TP0] Decode batch. #running-req: 4, #token: 1216, token usage: 0.00, gen throughput (token/s): 887.31, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:17:38 TP0] Decode batch. #running-req: 4, #token: 1376, token usage: 0.00, gen throughput (token/s): 894.56, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:17:38 TP0] Decode batch. #running-req: 4, #token: 1536, token usage: 0.00, gen throughput (token/s): 885.90, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:17:38 TP0] Decode batch. #running-req: 4, #token: 1696, token usage: 0.00, gen throughput (token/s): 913.74, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:17:38 TP0] Decode batch. #running-req: 4, #token: 1856, token usage: 0.00, gen throughput (token/s): 849.04, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:17:38 TP0] Decode batch. #running-req: 4, #token: 2016, token usage: 0.00, gen throughput (token/s): 905.72, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:17:39] INFO:     127.0.0.1:17724 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:17:39] INFO:     127.0.0.1:17686 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:17:39] INFO:     127.0.0.1:17702 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:17:39] INFO:     127.0.0.1:17710 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:17:39 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 135, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-08-25 15:17:39 TP0] Prefill batch. #new-seq: 3, #new-token: 3, #cached-token: 405, token usage: 0.00, #running-req: 1, #queue-req: 0, 
[2025-08-25 15:17:39 TP0] Decode batch. #running-req: 4, #token: 176, token usage: 0.00, gen throughput (token/s): 599.65, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:17:39 TP0] Decode batch. #running-req: 4, #token: 336, token usage: 0.00, gen throughput (token/s): 851.22, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:17:39 TP0] Decode batch. #running-req: 4, #token: 496, token usage: 0.00, gen throughput (token/s): 878.39, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:17:39 TP0] Decode batch. #running-req: 4, #token: 656, token usage: 0.00, gen throughput (token/s): 870.05, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:17:39 TP0] Decode batch. #running-req: 4, #token: 816, token usage: 0.00, gen throughput (token/s): 875.03, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:17:40 TP0] Decode batch. #running-req: 4, #token: 976, token usage: 0.00, gen throughput (token/s): 882.10, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:17:40 TP0] Decode batch. #running-req: 4, #token: 1136, token usage: 0.00, gen throughput (token/s): 868.54, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:17:40 TP0] Decode batch. #running-req: 4, #token: 1296, token usage: 0.00, gen throughput (token/s): 877.25, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:17:40 TP0] Decode batch. #running-req: 4, #token: 1456, token usage: 0.00, gen throughput (token/s): 882.04, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:17:40 TP0] Decode batch. #running-req: 4, #token: 1616, token usage: 0.00, gen throughput (token/s): 871.17, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:17:40 TP0] Decode batch. #running-req: 4, #token: 1776, token usage: 0.00, gen throughput (token/s): 877.49, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:17:41 TP0] Decode batch. #running-req: 4, #token: 1936, token usage: 0.00, gen throughput (token/s): 851.45, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:17:41 TP0] Decode batch. #running-req: 4, #token: 2096, token usage: 0.00, gen throughput (token/s): 870.91, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:17:41] INFO:     127.0.0.1:17724 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:17:41] INFO:     127.0.0.1:17686 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:17:41] INFO:     127.0.0.1:17702 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:17:41] INFO:     127.0.0.1:17710 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:17:41 TP0] Prefill batch. #new-seq: 4, #new-token: 2332, #cached-token: 168, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-08-25 15:17:42] INFO:     127.0.0.1:36444 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 15:17:42] INFO:     127.0.0.1:36456 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 15:17:42] INFO:     127.0.0.1:36464 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 15:17:42] INFO:     127.0.0.1:36470 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 15:17:42 TP0] Prefill batch. #new-seq: 2, #new-token: 1000, #cached-token: 250, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-08-25 15:17:42 TP0] Prefill batch. #new-seq: 2, #new-token: 1000, #cached-token: 250, token usage: 0.03, #running-req: 2, #queue-req: 0, 
[2025-08-25 15:17:42] INFO:     127.0.0.1:36444 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 15:17:42] INFO:     127.0.0.1:36470 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 15:17:42 TP0] Prefill batch. #new-seq: 2, #new-token: 1000, #cached-token: 250, token usage: 0.00, #running-req: 2, #queue-req: 0, 
[2025-08-25 15:17:42] INFO:     127.0.0.1:36456 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 15:17:42] INFO:     127.0.0.1:36464 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 15:17:43 TP0] Prefill batch. #new-seq: 2, #new-token: 1000, #cached-token: 250, token usage: 0.03, #running-req: 4, #queue-req: 0, 
[2025-08-25 15:17:43] INFO:     127.0.0.1:36470 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 15:17:43] INFO:     127.0.0.1:36444 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 15:17:43 TP0] Prefill batch. #new-seq: 2, #new-token: 1000, #cached-token: 250, token usage: 0.00, #running-req: 2, #queue-req: 0, 
[2025-08-25 15:17:43] INFO:     127.0.0.1:36456 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 15:17:43] INFO:     127.0.0.1:36464 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 15:17:44 TP0] Prefill batch. #new-seq: 2, #new-token: 1000, #cached-token: 250, token usage: 0.03, #running-req: 4, #queue-req: 0, 
[2025-08-25 15:17:44] INFO:     127.0.0.1:36470 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 15:17:44] INFO:     127.0.0.1:36444 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 15:17:44] INFO:     127.0.0.1:36456 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 15:17:44] INFO:     127.0.0.1:36464 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 15:17:44 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 134, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-08-25 15:17:44 TP0] Prefill batch. #new-seq: 3, #new-token: 3, #cached-token: 402, token usage: 0.00, #running-req: 1, #queue-req: 0, 
[2025-08-25 15:17:44 TP0] Decode batch. #running-req: 4, #token: 255, token usage: 0.00, gen throughput (token/s): 49.54, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:17:44 TP0] Decode batch. #running-req: 4, #token: 415, token usage: 0.00, gen throughput (token/s): 882.95, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:17:44 TP0] Decode batch. #running-req: 4, #token: 575, token usage: 0.00, gen throughput (token/s): 871.48, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:17:45 TP0] Decode batch. #running-req: 4, #token: 735, token usage: 0.00, gen throughput (token/s): 835.67, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:17:45 TP0] Decode batch. #running-req: 4, #token: 895, token usage: 0.00, gen throughput (token/s): 876.36, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:17:45 TP0] Decode batch. #running-req: 4, #token: 1055, token usage: 0.00, gen throughput (token/s): 883.31, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:17:45 TP0] Decode batch. #running-req: 4, #token: 1215, token usage: 0.00, gen throughput (token/s): 874.52, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:17:45 TP0] Decode batch. #running-req: 4, #token: 1375, token usage: 0.00, gen throughput (token/s): 879.16, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:17:46 TP0] Decode batch. #running-req: 4, #token: 1535, token usage: 0.00, gen throughput (token/s): 841.32, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:17:46 TP0] Decode batch. #running-req: 4, #token: 1695, token usage: 0.00, gen throughput (token/s): 881.41, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:17:46 TP0] Decode batch. #running-req: 4, #token: 1855, token usage: 0.00, gen throughput (token/s): 841.33, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:17:46 TP0] Decode batch. #running-req: 4, #token: 2015, token usage: 0.00, gen throughput (token/s): 871.38, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:17:46] INFO:     127.0.0.1:17724 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:17:46] INFO:     127.0.0.1:17686 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:17:46] INFO:     127.0.0.1:17702 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:17:46] INFO:     127.0.0.1:17710 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:17:46 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 134, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-08-25 15:17:46 TP0] Prefill batch. #new-seq: 3, #new-token: 3, #cached-token: 402, token usage: 0.00, #running-req: 1, #queue-req: 0, 
[2025-08-25 15:17:46 TP0] Decode batch. #running-req: 4, #token: 175, token usage: 0.00, gen throughput (token/s): 594.03, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:17:47 TP0] Decode batch. #running-req: 4, #token: 335, token usage: 0.00, gen throughput (token/s): 866.21, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:17:47 TP0] Decode batch. #running-req: 4, #token: 495, token usage: 0.00, gen throughput (token/s): 893.94, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:17:47 TP0] Decode batch. #running-req: 4, #token: 655, token usage: 0.00, gen throughput (token/s): 883.63, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:17:47 TP0] Decode batch. #running-req: 4, #token: 815, token usage: 0.00, gen throughput (token/s): 888.44, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:17:47 TP0] Decode batch. #running-req: 4, #token: 975, token usage: 0.00, gen throughput (token/s): 869.22, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:17:47 TP0] Decode batch. #running-req: 4, #token: 1135, token usage: 0.00, gen throughput (token/s): 885.90, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:17:48 TP0] Decode batch. #running-req: 4, #token: 1295, token usage: 0.00, gen throughput (token/s): 912.92, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:17:48 TP0] Decode batch. #running-req: 4, #token: 1455, token usage: 0.00, gen throughput (token/s): 915.86, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:17:48 TP0] Decode batch. #running-req: 4, #token: 1615, token usage: 0.00, gen throughput (token/s): 916.76, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:17:48 TP0] Decode batch. #running-req: 4, #token: 1775, token usage: 0.00, gen throughput (token/s): 896.77, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:17:48 TP0] Decode batch. #running-req: 4, #token: 1935, token usage: 0.00, gen throughput (token/s): 860.72, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:17:49 TP0] Decode batch. #running-req: 4, #token: 2095, token usage: 0.00, gen throughput (token/s): 862.99, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:17:49] INFO:     127.0.0.1:17724 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:17:49] INFO:     127.0.0.1:17686 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:17:49] INFO:     127.0.0.1:17702 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:17:49] INFO:     127.0.0.1:17710 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:17:49 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 134, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-08-25 15:17:49 TP0] Prefill batch. #new-seq: 3, #new-token: 3, #cached-token: 402, token usage: 0.00, #running-req: 1, #queue-req: 0, 
[2025-08-25 15:17:49 TP0] Decode batch. #running-req: 4, #token: 255, token usage: 0.00, gen throughput (token/s): 596.42, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:17:49 TP0] Decode batch. #running-req: 4, #token: 415, token usage: 0.00, gen throughput (token/s): 872.04, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:17:49 TP0] Decode batch. #running-req: 4, #token: 575, token usage: 0.00, gen throughput (token/s): 838.40, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:17:49 TP0] Decode batch. #running-req: 4, #token: 735, token usage: 0.00, gen throughput (token/s): 886.83, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:17:50 TP0] Decode batch. #running-req: 4, #token: 895, token usage: 0.00, gen throughput (token/s): 874.45, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:17:50 TP0] Decode batch. #running-req: 4, #token: 1055, token usage: 0.00, gen throughput (token/s): 890.70, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:17:50 TP0] Decode batch. #running-req: 4, #token: 1215, token usage: 0.00, gen throughput (token/s): 874.74, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:17:50 TP0] Decode batch. #running-req: 4, #token: 1375, token usage: 0.00, gen throughput (token/s): 880.74, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:17:50 TP0] Decode batch. #running-req: 4, #token: 1535, token usage: 0.00, gen throughput (token/s): 866.76, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:17:50 TP0] Decode batch. #running-req: 4, #token: 1695, token usage: 0.00, gen throughput (token/s): 890.35, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:17:51 TP0] Decode batch. #running-req: 4, #token: 1855, token usage: 0.00, gen throughput (token/s): 870.50, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:17:51 TP0] Decode batch. #running-req: 4, #token: 2015, token usage: 0.00, gen throughput (token/s): 879.34, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:17:51] INFO:     127.0.0.1:17724 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:17:51] INFO:     127.0.0.1:17686 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:17:51] INFO:     127.0.0.1:17702 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:17:51] INFO:     127.0.0.1:17710 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:17:51 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 134, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-08-25 15:17:51 TP0] Prefill batch. #new-seq: 3, #new-token: 3, #cached-token: 402, token usage: 0.00, #running-req: 1, #queue-req: 0, 
[2025-08-25 15:17:51 TP0] Decode batch. #running-req: 4, #token: 175, token usage: 0.00, gen throughput (token/s): 596.60, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:17:51 TP0] Decode batch. #running-req: 4, #token: 335, token usage: 0.00, gen throughput (token/s): 888.95, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:17:51 TP0] Decode batch. #running-req: 4, #token: 495, token usage: 0.00, gen throughput (token/s): 899.95, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:17:52 TP0] Decode batch. #running-req: 4, #token: 655, token usage: 0.00, gen throughput (token/s): 920.72, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:17:52 TP0] Decode batch. #running-req: 4, #token: 815, token usage: 0.00, gen throughput (token/s): 912.66, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:17:52 TP0] Decode batch. #running-req: 4, #token: 975, token usage: 0.00, gen throughput (token/s): 848.03, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:17:52 TP0] Decode batch. #running-req: 4, #token: 1135, token usage: 0.00, gen throughput (token/s): 862.28, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:17:52 TP0] Decode batch. #running-req: 4, #token: 1295, token usage: 0.00, gen throughput (token/s): 891.99, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:17:53 TP0] Decode batch. #running-req: 4, #token: 1455, token usage: 0.00, gen throughput (token/s): 856.57, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:17:53 TP0] Decode batch. #running-req: 4, #token: 1615, token usage: 0.00, gen throughput (token/s): 917.36, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:17:53 TP0] Decode batch. #running-req: 4, #token: 1775, token usage: 0.00, gen throughput (token/s): 896.67, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:17:53 TP0] Decode batch. #running-req: 4, #token: 1935, token usage: 0.00, gen throughput (token/s): 838.55, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:17:53 TP0] Decode batch. #running-req: 4, #token: 2095, token usage: 0.00, gen throughput (token/s): 922.38, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:17:53] INFO:     127.0.0.1:17724 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:17:53] INFO:     127.0.0.1:17686 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:17:53] INFO:     127.0.0.1:17702 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:17:53] INFO:     127.0.0.1:17710 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:17:53 TP0] Prefill batch. #new-seq: 3, #new-token: 1746, #cached-token: 126, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-08-25 15:17:53 TP0] Prefill batch. #new-seq: 1, #new-token: 582, #cached-token: 42, token usage: 0.04, #running-req: 3, #queue-req: 0, 
[2025-08-25 15:17:54] INFO:     127.0.0.1:16646 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 15:17:54] INFO:     127.0.0.1:16662 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 15:17:54] INFO:     127.0.0.1:16674 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 15:17:54] INFO:     127.0.0.1:16676 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 15:17:54 TP0] Prefill batch. #new-seq: 1, #new-token: 500, #cached-token: 124, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-08-25 15:17:54 TP0] Prefill batch. #new-seq: 3, #new-token: 1500, #cached-token: 372, token usage: 0.02, #running-req: 1, #queue-req: 0, 
[2025-08-25 15:17:55] INFO:     127.0.0.1:16646 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 15:17:55] INFO:     127.0.0.1:16662 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 15:17:55] INFO:     127.0.0.1:16674 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 15:17:55] INFO:     127.0.0.1:16676 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 15:17:55 TP0] Prefill batch. #new-seq: 1, #new-token: 500, #cached-token: 124, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-08-25 15:17:55 TP0] Prefill batch. #new-seq: 3, #new-token: 1500, #cached-token: 372, token usage: 0.02, #running-req: 1, #queue-req: 0, 
[2025-08-25 15:17:56] INFO:     127.0.0.1:16646 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 15:17:56] INFO:     127.0.0.1:16676 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 15:17:56] INFO:     127.0.0.1:16662 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 15:17:56] INFO:     127.0.0.1:16674 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 15:17:56 TP0] Prefill batch. #new-seq: 1, #new-token: 500, #cached-token: 124, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-08-25 15:17:56 TP0] Prefill batch. #new-seq: 3, #new-token: 1500, #cached-token: 372, token usage: 0.00, #running-req: 1, #queue-req: 0, 
[2025-08-25 15:17:56] INFO:     127.0.0.1:16646 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 15:17:56] INFO:     127.0.0.1:16676 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 15:17:57] INFO:     127.0.0.1:16662 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 15:17:57] INFO:     127.0.0.1:16674 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 15:17:57 TP0] Prefill batch. #new-seq: 4, #new-token: 4, #cached-token: 784, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-08-25 15:17:57 TP0] Decode batch. #running-req: 4, #token: 317, token usage: 0.00, gen throughput (token/s): 42.16, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:17:57 TP0] Decode batch. #running-req: 4, #token: 477, token usage: 0.00, gen throughput (token/s): 884.67, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:17:57 TP0] Decode batch. #running-req: 4, #token: 637, token usage: 0.00, gen throughput (token/s): 889.78, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:17:58 TP0] Decode batch. #running-req: 4, #token: 797, token usage: 0.00, gen throughput (token/s): 843.08, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:17:58 TP0] Decode batch. #running-req: 4, #token: 957, token usage: 0.00, gen throughput (token/s): 897.84, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:17:58 TP0] Decode batch. #running-req: 4, #token: 1117, token usage: 0.00, gen throughput (token/s): 862.01, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:17:58 TP0] Decode batch. #running-req: 4, #token: 1277, token usage: 0.00, gen throughput (token/s): 864.86, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:17:58 TP0] Decode batch. #running-req: 4, #token: 1437, token usage: 0.00, gen throughput (token/s): 876.53, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:17:59 TP0] Decode batch. #running-req: 4, #token: 1597, token usage: 0.00, gen throughput (token/s): 875.52, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:17:59 TP0] Decode batch. #running-req: 4, #token: 1757, token usage: 0.00, gen throughput (token/s): 906.17, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:17:59 TP0] Decode batch. #running-req: 4, #token: 1917, token usage: 0.00, gen throughput (token/s): 870.00, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:17:59 TP0] Decode batch. #running-req: 4, #token: 2077, token usage: 0.00, gen throughput (token/s): 859.14, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:17:59] INFO:     127.0.0.1:17724 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:17:59] INFO:     127.0.0.1:17686 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:17:59] INFO:     127.0.0.1:17702 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:17:59] INFO:     127.0.0.1:17710 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:17:59 TP0] Prefill batch. #new-seq: 4, #new-token: 4, #cached-token: 784, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-08-25 15:17:59 TP0] Decode batch. #running-req: 4, #token: 237, token usage: 0.00, gen throughput (token/s): 644.58, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:17:59 TP0] Decode batch. #running-req: 4, #token: 397, token usage: 0.00, gen throughput (token/s): 920.06, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:18:00 TP0] Decode batch. #running-req: 4, #token: 557, token usage: 0.00, gen throughput (token/s): 939.57, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:18:00 TP0] Decode batch. #running-req: 4, #token: 717, token usage: 0.00, gen throughput (token/s): 905.71, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:18:00 TP0] Decode batch. #running-req: 4, #token: 877, token usage: 0.00, gen throughput (token/s): 888.50, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:18:00 TP0] Decode batch. #running-req: 4, #token: 1037, token usage: 0.00, gen throughput (token/s): 870.37, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:18:00 TP0] Decode batch. #running-req: 4, #token: 1197, token usage: 0.00, gen throughput (token/s): 862.87, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:18:01 TP0] Decode batch. #running-req: 4, #token: 1357, token usage: 0.00, gen throughput (token/s): 896.16, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:18:01 TP0] Decode batch. #running-req: 4, #token: 1517, token usage: 0.00, gen throughput (token/s): 849.32, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:18:01 TP0] Decode batch. #running-req: 4, #token: 1677, token usage: 0.00, gen throughput (token/s): 865.57, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:18:01 TP0] Decode batch. #running-req: 4, #token: 1837, token usage: 0.00, gen throughput (token/s): 887.89, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:18:01 TP0] Decode batch. #running-req: 4, #token: 1997, token usage: 0.00, gen throughput (token/s): 907.61, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:18:01 TP0] Decode batch. #running-req: 4, #token: 2157, token usage: 0.00, gen throughput (token/s): 906.56, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:18:02] INFO:     127.0.0.1:17724 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:18:02] INFO:     127.0.0.1:17686 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:18:02] INFO:     127.0.0.1:17702 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:18:02] INFO:     127.0.0.1:17710 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:18:02 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 196, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-08-25 15:18:02 TP0] Prefill batch. #new-seq: 3, #new-token: 3, #cached-token: 588, token usage: 0.00, #running-req: 1, #queue-req: 0, 
[2025-08-25 15:18:02 TP0] Decode batch. #running-req: 4, #token: 317, token usage: 0.00, gen throughput (token/s): 593.71, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:18:02 TP0] Decode batch. #running-req: 4, #token: 477, token usage: 0.00, gen throughput (token/s): 879.81, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:18:02 TP0] Decode batch. #running-req: 4, #token: 637, token usage: 0.00, gen throughput (token/s): 855.55, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:18:02 TP0] Decode batch. #running-req: 4, #token: 797, token usage: 0.00, gen throughput (token/s): 893.85, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:18:02 TP0] Decode batch. #running-req: 4, #token: 957, token usage: 0.00, gen throughput (token/s): 865.60, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:18:03 TP0] Decode batch. #running-req: 4, #token: 1117, token usage: 0.00, gen throughput (token/s): 857.68, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:18:03 TP0] Decode batch. #running-req: 4, #token: 1277, token usage: 0.00, gen throughput (token/s): 876.34, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:18:03 TP0] Decode batch. #running-req: 4, #token: 1437, token usage: 0.00, gen throughput (token/s): 894.36, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:18:03 TP0] Decode batch. #running-req: 4, #token: 1597, token usage: 0.00, gen throughput (token/s): 860.25, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:18:03 TP0] Decode batch. #running-req: 4, #token: 1757, token usage: 0.00, gen throughput (token/s): 901.26, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:18:04 TP0] Decode batch. #running-req: 4, #token: 1917, token usage: 0.00, gen throughput (token/s): 846.41, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:18:04 TP0] Decode batch. #running-req: 4, #token: 2077, token usage: 0.00, gen throughput (token/s): 879.99, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:18:04] INFO:     127.0.0.1:17724 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:18:04] INFO:     127.0.0.1:17686 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:18:04] INFO:     127.0.0.1:17702 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:18:04] INFO:     127.0.0.1:17710 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:18:04 TP0] Prefill batch. #new-seq: 4, #new-token: 4, #cached-token: 784, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-08-25 15:18:04 TP0] Decode batch. #running-req: 4, #token: 237, token usage: 0.00, gen throughput (token/s): 646.99, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:18:04 TP0] Decode batch. #running-req: 4, #token: 397, token usage: 0.00, gen throughput (token/s): 879.75, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:18:04 TP0] Decode batch. #running-req: 4, #token: 557, token usage: 0.00, gen throughput (token/s): 874.01, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:18:05 TP0] Decode batch. #running-req: 4, #token: 717, token usage: 0.00, gen throughput (token/s): 844.12, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:18:05 TP0] Decode batch. #running-req: 4, #token: 877, token usage: 0.00, gen throughput (token/s): 862.15, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:18:05 TP0] Decode batch. #running-req: 4, #token: 1037, token usage: 0.00, gen throughput (token/s): 848.90, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:18:05 TP0] Decode batch. #running-req: 4, #token: 1197, token usage: 0.00, gen throughput (token/s): 932.74, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:18:05 TP0] Decode batch. #running-req: 4, #token: 1357, token usage: 0.00, gen throughput (token/s): 907.31, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:18:05 TP0] Decode batch. #running-req: 4, #token: 1517, token usage: 0.00, gen throughput (token/s): 891.99, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:18:06 TP0] Decode batch. #running-req: 4, #token: 1677, token usage: 0.00, gen throughput (token/s): 876.50, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:18:06 TP0] Decode batch. #running-req: 4, #token: 1837, token usage: 0.00, gen throughput (token/s): 879.91, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:18:06 TP0] Decode batch. #running-req: 4, #token: 1997, token usage: 0.00, gen throughput (token/s): 877.69, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:18:06 TP0] Decode batch. #running-req: 4, #token: 2157, token usage: 0.00, gen throughput (token/s): 868.43, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:18:06] INFO:     127.0.0.1:17724 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:18:06] INFO:     127.0.0.1:17686 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:18:06] INFO:     127.0.0.1:17702 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:18:06] INFO:     127.0.0.1:17710 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:18:06 TP0] Prefill batch. #new-seq: 4, #new-token: 2572, #cached-token: 172, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-08-25 15:18:07] INFO:     127.0.0.1:63586 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 15:18:07] INFO:     127.0.0.1:63600 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 15:18:07] INFO:     127.0.0.1:63606 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 15:18:07] INFO:     127.0.0.1:63616 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 15:18:07 TP0] Prefill batch. #new-seq: 4, #new-token: 2000, #cached-token: 744, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-08-25 15:18:08] INFO:     127.0.0.1:63616 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 15:18:08] INFO:     127.0.0.1:63586 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 15:18:08 TP0] Decode batch. #running-req: 0, #token: 0, token usage: 0.00, gen throughput (token/s): 1.35, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:18:08] INFO:     127.0.0.1:63600 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 15:18:08] INFO:     127.0.0.1:63606 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 15:18:08 TP0] Prefill batch. #new-seq: 4, #new-token: 2000, #cached-token: 744, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-08-25 15:18:09] INFO:     127.0.0.1:63616 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 15:18:09] INFO:     127.0.0.1:63586 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 15:18:09] INFO:     127.0.0.1:63600 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 15:18:09] INFO:     127.0.0.1:63606 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 15:18:09 TP0] Prefill batch. #new-seq: 1, #new-token: 500, #cached-token: 186, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-08-25 15:18:09 TP0] Prefill batch. #new-seq: 3, #new-token: 1500, #cached-token: 558, token usage: 0.02, #running-req: 1, #queue-req: 0, 
[2025-08-25 15:18:09] INFO:     127.0.0.1:63616 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 15:18:09] INFO:     127.0.0.1:63586 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 15:18:09] INFO:     127.0.0.1:63600 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 15:18:09] INFO:     127.0.0.1:63606 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 15:18:09 TP0] Prefill batch. #new-seq: 1, #new-token: 650, #cached-token: 45, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-08-25 15:18:09 TP0] Prefill batch. #new-seq: 1, #new-token: 650, #cached-token: 45, token usage: 0.02, #running-req: 1, #queue-req: 0, 
[2025-08-25 15:18:10 TP0] Prefill batch. #new-seq: 2, #new-token: 994, #cached-token: 396, token usage: 0.03, #running-req: 2, #queue-req: 0, 
[2025-08-25 15:18:12 TP0] Decode batch. #running-req: 4, #token: 2345, token usage: 0.06, gen throughput (token/s): 39.59, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:18:14 TP0] Decode batch. #running-req: 4, #token: 2505, token usage: 0.06, gen throughput (token/s): 88.57, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:18:16 TP0] Decode batch. #running-req: 4, #token: 2665, token usage: 0.07, gen throughput (token/s): 87.68, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:18:17] INFO:     127.0.0.1:63616 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:18:17] INFO:     127.0.0.1:63586 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:18:17] INFO:     127.0.0.1:63600 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:18:17] INFO:     127.0.0.1:63606 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:18:17 TP0] Prefill batch. #new-seq: 4, #new-token: 1953, #cached-token: 827, token usage: 0.01, #running-req: 0, #queue-req: 0, 
[2025-08-25 15:18:18 TP0] Decode batch. #running-req: 4, #token: 2210, token usage: 0.06, gen throughput (token/s): 66.50, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:18:20 TP0] Decode batch. #running-req: 4, #token: 2370, token usage: 0.06, gen throughput (token/s): 88.09, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:18:22 TP0] Decode batch. #running-req: 4, #token: 2530, token usage: 0.06, gen throughput (token/s): 88.18, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:18:23 TP0] Decode batch. #running-req: 4, #token: 2690, token usage: 0.07, gen throughput (token/s): 87.68, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:18:24] INFO:     127.0.0.1:63616 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:18:24] INFO:     127.0.0.1:63586 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:18:24] INFO:     127.0.0.1:63600 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:18:24] INFO:     127.0.0.1:63606 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:18:24 TP0] Prefill batch. #new-seq: 4, #new-token: 1984, #cached-token: 796, token usage: 0.01, #running-req: 0, #queue-req: 0, 
[2025-08-25 15:18:26 TP0] Decode batch. #running-req: 4, #token: 2265, token usage: 0.06, gen throughput (token/s): 66.52, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:18:28 TP0] Decode batch. #running-req: 4, #token: 2425, token usage: 0.06, gen throughput (token/s): 88.46, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:18:29 TP0] Decode batch. #running-req: 4, #token: 2585, token usage: 0.06, gen throughput (token/s): 88.22, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:18:31 TP0] Decode batch. #running-req: 4, #token: 2745, token usage: 0.07, gen throughput (token/s): 87.96, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:18:32] INFO:     127.0.0.1:63616 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:18:32] INFO:     127.0.0.1:63586 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:18:32] INFO:     127.0.0.1:63600 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:18:32] INFO:     127.0.0.1:63606 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:18:32 TP0] Prefill batch. #new-seq: 2, #new-token: 974, #cached-token: 416, token usage: 0.01, #running-req: 0, #queue-req: 0, 
[2025-08-25 15:18:33 TP0] Decode batch. #running-req: 2, #token: 1253, token usage: 0.03, gen throughput (token/s): 49.41, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:18:35 TP0] Decode batch. #running-req: 2, #token: 1333, token usage: 0.03, gen throughput (token/s): 44.83, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:18:37 TP0] Decode batch. #running-req: 2, #token: 1413, token usage: 0.04, gen throughput (token/s): 44.76, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:18:39 TP0] Decode batch. #running-req: 2, #token: 1493, token usage: 0.04, gen throughput (token/s): 44.82, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:18:39] INFO:     127.0.0.1:63616 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:18:39] INFO:     127.0.0.1:63586 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:18:39 TP0] Prefill batch. #new-seq: 3, #new-token: 3, #cached-token: 516, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-08-25 15:18:39 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 172, token usage: 0.00, #running-req: 3, #queue-req: 0, 
[2025-08-25 15:18:39 TP0] Decode batch. #running-req: 4, #token: 293, token usage: 0.00, gen throughput (token/s): 4.88, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:18:39 TP0] Decode batch. #running-req: 4, #token: 453, token usage: 0.00, gen throughput (token/s): 878.73, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:18:39 TP0] Decode batch. #running-req: 4, #token: 613, token usage: 0.00, gen throughput (token/s): 942.71, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:18:39 TP0] Decode batch. #running-req: 4, #token: 773, token usage: 0.00, gen throughput (token/s): 941.07, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:18:40 TP0] Decode batch. #running-req: 4, #token: 933, token usage: 0.00, gen throughput (token/s): 958.57, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:18:40 TP0] Decode batch. #running-req: 4, #token: 1093, token usage: 0.00, gen throughput (token/s): 947.70, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:18:40 TP0] Decode batch. #running-req: 4, #token: 1253, token usage: 0.00, gen throughput (token/s): 930.38, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:18:40 TP0] Decode batch. #running-req: 4, #token: 1413, token usage: 0.00, gen throughput (token/s): 930.48, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:18:40 TP0] Decode batch. #running-req: 4, #token: 1573, token usage: 0.00, gen throughput (token/s): 937.98, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:18:41 TP0] Decode batch. #running-req: 4, #token: 1733, token usage: 0.00, gen throughput (token/s): 944.61, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:18:41 TP0] Decode batch. #running-req: 4, #token: 1893, token usage: 0.00, gen throughput (token/s): 950.57, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:18:41 TP0] Decode batch. #running-req: 4, #token: 2053, token usage: 0.00, gen throughput (token/s): 946.65, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:18:41] INFO:     127.0.0.1:5396 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:18:41] INFO:     127.0.0.1:5412 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:18:41] INFO:     127.0.0.1:5414 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:18:41] INFO:     127.0.0.1:5420 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:18:41 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 172, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-08-25 15:18:41 TP0] Prefill batch. #new-seq: 3, #new-token: 3, #cached-token: 516, token usage: 0.00, #running-req: 1, #queue-req: 0, 
[2025-08-25 15:18:41 TP0] Decode batch. #running-req: 4, #token: 213, token usage: 0.00, gen throughput (token/s): 614.78, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:18:41 TP0] Decode batch. #running-req: 4, #token: 373, token usage: 0.00, gen throughput (token/s): 901.09, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:18:41 TP0] Decode batch. #running-req: 4, #token: 533, token usage: 0.00, gen throughput (token/s): 894.04, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:18:42 TP0] Decode batch. #running-req: 4, #token: 693, token usage: 0.00, gen throughput (token/s): 894.94, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:18:42 TP0] Decode batch. #running-req: 4, #token: 853, token usage: 0.00, gen throughput (token/s): 904.32, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:18:42 TP0] Decode batch. #running-req: 4, #token: 1013, token usage: 0.00, gen throughput (token/s): 902.74, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:18:42 TP0] Decode batch. #running-req: 4, #token: 1173, token usage: 0.00, gen throughput (token/s): 916.67, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:18:42 TP0] Decode batch. #running-req: 4, #token: 1333, token usage: 0.00, gen throughput (token/s): 901.84, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:18:43 TP0] Decode batch. #running-req: 4, #token: 1493, token usage: 0.00, gen throughput (token/s): 849.50, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:18:43 TP0] Decode batch. #running-req: 4, #token: 1653, token usage: 0.00, gen throughput (token/s): 860.10, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:18:43 TP0] Decode batch. #running-req: 4, #token: 1813, token usage: 0.00, gen throughput (token/s): 873.96, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:18:43 TP0] Decode batch. #running-req: 4, #token: 1973, token usage: 0.00, gen throughput (token/s): 863.84, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:18:43 TP0] Decode batch. #running-req: 4, #token: 2133, token usage: 0.00, gen throughput (token/s): 877.49, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:18:43] INFO:     127.0.0.1:5420 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:18:43] INFO:     127.0.0.1:5396 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:18:43] INFO:     127.0.0.1:5412 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:18:43] INFO:     127.0.0.1:5414 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:18:43 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 172, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-08-25 15:18:43 TP0] Prefill batch. #new-seq: 3, #new-token: 3, #cached-token: 516, token usage: 0.00, #running-req: 1, #queue-req: 0, 
[2025-08-25 15:18:44 TP0] Decode batch. #running-req: 4, #token: 293, token usage: 0.00, gen throughput (token/s): 597.46, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:18:44 TP0] Decode batch. #running-req: 4, #token: 453, token usage: 0.00, gen throughput (token/s): 881.60, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:18:44 TP0] Decode batch. #running-req: 4, #token: 613, token usage: 0.00, gen throughput (token/s): 889.06, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:18:44 TP0] Decode batch. #running-req: 4, #token: 773, token usage: 0.00, gen throughput (token/s): 907.77, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:18:44 TP0] Decode batch. #running-req: 4, #token: 933, token usage: 0.00, gen throughput (token/s): 902.61, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:18:44 TP0] Decode batch. #running-req: 4, #token: 1093, token usage: 0.00, gen throughput (token/s): 911.29, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:18:45 TP0] Decode batch. #running-req: 4, #token: 1253, token usage: 0.00, gen throughput (token/s): 899.46, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:18:45 TP0] Decode batch. #running-req: 4, #token: 1413, token usage: 0.00, gen throughput (token/s): 904.97, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:18:45 TP0] Decode batch. #running-req: 4, #token: 1573, token usage: 0.00, gen throughput (token/s): 902.50, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:18:45 TP0] Decode batch. #running-req: 4, #token: 1733, token usage: 0.00, gen throughput (token/s): 905.87, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:18:45 TP0] Decode batch. #running-req: 4, #token: 1893, token usage: 0.00, gen throughput (token/s): 901.65, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:18:45 TP0] Decode batch. #running-req: 4, #token: 2053, token usage: 0.00, gen throughput (token/s): 910.31, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:18:46] INFO:     127.0.0.1:5420 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:18:46] INFO:     127.0.0.1:5396 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:18:46] INFO:     127.0.0.1:5412 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:18:46] INFO:     127.0.0.1:5414 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:18:46 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 172, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-08-25 15:18:46 TP0] Prefill batch. #new-seq: 3, #new-token: 3, #cached-token: 516, token usage: 0.00, #running-req: 1, #queue-req: 0, 
[2025-08-25 15:18:46 TP0] Decode batch. #running-req: 4, #token: 213, token usage: 0.00, gen throughput (token/s): 606.04, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:18:46 TP0] Decode batch. #running-req: 4, #token: 373, token usage: 0.00, gen throughput (token/s): 917.82, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:18:46 TP0] Decode batch. #running-req: 4, #token: 533, token usage: 0.00, gen throughput (token/s): 900.74, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:18:46 TP0] Decode batch. #running-req: 4, #token: 693, token usage: 0.00, gen throughput (token/s): 905.76, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:18:46 TP0] Decode batch. #running-req: 4, #token: 853, token usage: 0.00, gen throughput (token/s): 907.61, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:18:47 TP0] Decode batch. #running-req: 4, #token: 1013, token usage: 0.00, gen throughput (token/s): 918.04, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:18:47 TP0] Decode batch. #running-req: 4, #token: 1173, token usage: 0.00, gen throughput (token/s): 912.97, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:18:47 TP0] Decode batch. #running-req: 4, #token: 1333, token usage: 0.00, gen throughput (token/s): 906.28, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:18:47 TP0] Decode batch. #running-req: 4, #token: 1493, token usage: 0.00, gen throughput (token/s): 908.89, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:18:47 TP0] Decode batch. #running-req: 4, #token: 1653, token usage: 0.00, gen throughput (token/s): 898.54, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:18:48 TP0] Decode batch. #running-req: 4, #token: 1813, token usage: 0.00, gen throughput (token/s): 895.66, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:18:48 TP0] Decode batch. #running-req: 4, #token: 1973, token usage: 0.00, gen throughput (token/s): 896.95, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:18:48 TP0] Decode batch. #running-req: 4, #token: 2133, token usage: 0.00, gen throughput (token/s): 904.72, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:18:48] INFO:     127.0.0.1:5420 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:18:48] INFO:     127.0.0.1:5396 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:18:48] INFO:     127.0.0.1:5412 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:18:48] INFO:     127.0.0.1:5414 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:18:48 TP0] Prefill batch. #new-seq: 1, #new-token: 620, #cached-token: 42, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-08-25 15:18:48 TP0] Prefill batch. #new-seq: 3, #new-token: 1860, #cached-token: 126, token usage: 0.02, #running-req: 1, #queue-req: 0, 
[2025-08-25 15:18:48] INFO:     127.0.0.1:48668 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 15:18:49 TP0] Prefill batch. #new-seq: 1, #new-token: 500, #cached-token: 162, token usage: 0.00, #running-req: 3, #queue-req: 0, 
[2025-08-25 15:18:49] INFO:     127.0.0.1:48674 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 15:18:49] INFO:     127.0.0.1:48686 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 15:18:49] INFO:     127.0.0.1:48696 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 15:18:49 TP0] Prefill batch. #new-seq: 3, #new-token: 1500, #cached-token: 486, token usage: 0.02, #running-req: 4, #queue-req: 0, 
[2025-08-25 15:18:49] INFO:     127.0.0.1:48668 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 15:18:49 TP0] Prefill batch. #new-seq: 1, #new-token: 500, #cached-token: 162, token usage: 0.00, #running-req: 3, #queue-req: 0, 
[2025-08-25 15:18:49] INFO:     127.0.0.1:48696 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 15:18:50] INFO:     127.0.0.1:48674 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 15:18:50] INFO:     127.0.0.1:48686 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 15:18:50 TP0] Prefill batch. #new-seq: 3, #new-token: 1500, #cached-token: 486, token usage: 0.02, #running-req: 4, #queue-req: 0, 
[2025-08-25 15:18:50] INFO:     127.0.0.1:48668 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 15:18:50 TP0] Prefill batch. #new-seq: 1, #new-token: 500, #cached-token: 162, token usage: 0.00, #running-req: 3, #queue-req: 0, 
[2025-08-25 15:18:50] INFO:     127.0.0.1:48696 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 15:18:50] INFO:     127.0.0.1:48674 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 15:18:50] INFO:     127.0.0.1:48686 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 15:18:50 TP0] Prefill batch. #new-seq: 3, #new-token: 1500, #cached-token: 486, token usage: 0.02, #running-req: 4, #queue-req: 0, 
[2025-08-25 15:18:50] INFO:     127.0.0.1:48668 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 15:18:51] INFO:     127.0.0.1:48696 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 15:18:51] INFO:     127.0.0.1:48674 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 15:18:51] INFO:     127.0.0.1:48686 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 15:18:51 TP0] Prefill batch. #new-seq: 4, #new-token: 4, #cached-token: 616, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-08-25 15:18:51 TP0] Decode batch. #running-req: 4, #token: 275, token usage: 0.00, gen throughput (token/s): 48.86, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:18:51 TP0] Decode batch. #running-req: 4, #token: 435, token usage: 0.00, gen throughput (token/s): 887.14, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:18:52 TP0] Decode batch. #running-req: 4, #token: 595, token usage: 0.00, gen throughput (token/s): 853.96, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:18:52 TP0] Decode batch. #running-req: 4, #token: 755, token usage: 0.00, gen throughput (token/s): 865.51, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:18:52 TP0] Decode batch. #running-req: 4, #token: 915, token usage: 0.00, gen throughput (token/s): 871.32, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:18:52 TP0] Decode batch. #running-req: 4, #token: 1075, token usage: 0.00, gen throughput (token/s): 869.44, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:18:52 TP0] Decode batch. #running-req: 4, #token: 1235, token usage: 0.00, gen throughput (token/s): 853.32, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:18:52 TP0] Decode batch. #running-req: 4, #token: 1395, token usage: 0.00, gen throughput (token/s): 847.30, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:18:53 TP0] Decode batch. #running-req: 4, #token: 1555, token usage: 0.00, gen throughput (token/s): 802.87, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:18:53 TP0] Decode batch. #running-req: 4, #token: 1715, token usage: 0.00, gen throughput (token/s): 847.83, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:18:53 TP0] Decode batch. #running-req: 4, #token: 1875, token usage: 0.00, gen throughput (token/s): 872.32, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:18:53 TP0] Decode batch. #running-req: 4, #token: 2035, token usage: 0.00, gen throughput (token/s): 831.46, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:18:53] INFO:     127.0.0.1:5420 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:18:53] INFO:     127.0.0.1:5396 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:18:53] INFO:     127.0.0.1:5412 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:18:53] INFO:     127.0.0.1:5414 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:18:53 TP0] Prefill batch. #new-seq: 4, #new-token: 4, #cached-token: 616, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-08-25 15:18:53 TP0] Decode batch. #running-req: 4, #token: 195, token usage: 0.00, gen throughput (token/s): 668.62, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:18:54 TP0] Decode batch. #running-req: 4, #token: 355, token usage: 0.00, gen throughput (token/s): 877.16, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:18:54 TP0] Decode batch. #running-req: 4, #token: 515, token usage: 0.00, gen throughput (token/s): 899.38, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:18:54 TP0] Decode batch. #running-req: 4, #token: 675, token usage: 0.00, gen throughput (token/s): 892.87, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:18:54 TP0] Decode batch. #running-req: 4, #token: 835, token usage: 0.00, gen throughput (token/s): 874.74, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:18:54 TP0] Decode batch. #running-req: 4, #token: 995, token usage: 0.00, gen throughput (token/s): 882.78, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:18:55 TP0] Decode batch. #running-req: 4, #token: 1155, token usage: 0.00, gen throughput (token/s): 847.12, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:18:55 TP0] Decode batch. #running-req: 4, #token: 1315, token usage: 0.00, gen throughput (token/s): 888.01, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:18:55 TP0] Decode batch. #running-req: 4, #token: 1475, token usage: 0.00, gen throughput (token/s): 865.09, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:18:55 TP0] Decode batch. #running-req: 4, #token: 1635, token usage: 0.00, gen throughput (token/s): 846.56, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:18:55 TP0] Decode batch. #running-req: 4, #token: 1795, token usage: 0.00, gen throughput (token/s): 862.86, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:18:55 TP0] Decode batch. #running-req: 4, #token: 1955, token usage: 0.00, gen throughput (token/s): 850.40, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:18:56 TP0] Decode batch. #running-req: 4, #token: 2115, token usage: 0.00, gen throughput (token/s): 877.80, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:18:56] INFO:     127.0.0.1:5420 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:18:56] INFO:     127.0.0.1:5396 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:18:56] INFO:     127.0.0.1:5412 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:18:56] INFO:     127.0.0.1:5414 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:18:56 TP0] Prefill batch. #new-seq: 4, #new-token: 4, #cached-token: 616, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-08-25 15:18:56 TP0] Decode batch. #running-req: 4, #token: 275, token usage: 0.00, gen throughput (token/s): 658.70, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:18:56 TP0] Decode batch. #running-req: 4, #token: 435, token usage: 0.00, gen throughput (token/s): 898.16, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:18:56 TP0] Decode batch. #running-req: 4, #token: 595, token usage: 0.00, gen throughput (token/s): 856.45, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:18:56 TP0] Decode batch. #running-req: 4, #token: 755, token usage: 0.00, gen throughput (token/s): 878.72, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:18:57 TP0] Decode batch. #running-req: 4, #token: 915, token usage: 0.00, gen throughput (token/s): 894.23, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:18:57 TP0] Decode batch. #running-req: 4, #token: 1075, token usage: 0.00, gen throughput (token/s): 868.52, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:18:57 TP0] Decode batch. #running-req: 4, #token: 1235, token usage: 0.00, gen throughput (token/s): 870.08, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:18:57 TP0] Decode batch. #running-req: 4, #token: 1395, token usage: 0.00, gen throughput (token/s): 873.35, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:18:57 TP0] Decode batch. #running-req: 4, #token: 1555, token usage: 0.00, gen throughput (token/s): 860.27, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:18:58 TP0] Decode batch. #running-req: 4, #token: 1715, token usage: 0.00, gen throughput (token/s): 879.01, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:18:58 TP0] Decode batch. #running-req: 4, #token: 1875, token usage: 0.00, gen throughput (token/s): 866.10, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:18:58 TP0] Decode batch. #running-req: 4, #token: 2035, token usage: 0.00, gen throughput (token/s): 883.70, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:18:58] INFO:     127.0.0.1:5420 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:18:58] INFO:     127.0.0.1:5396 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:18:58] INFO:     127.0.0.1:5412 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:18:58] INFO:     127.0.0.1:5414 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:18:58 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 154, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-08-25 15:18:58 TP0] Prefill batch. #new-seq: 3, #new-token: 3, #cached-token: 462, token usage: 0.00, #running-req: 1, #queue-req: 0, 
[2025-08-25 15:18:58 TP0] Decode batch. #running-req: 4, #token: 195, token usage: 0.00, gen throughput (token/s): 591.34, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:18:58 TP0] Decode batch. #running-req: 4, #token: 355, token usage: 0.00, gen throughput (token/s): 865.31, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:18:59 TP0] Decode batch. #running-req: 4, #token: 515, token usage: 0.00, gen throughput (token/s): 876.30, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:18:59 TP0] Decode batch. #running-req: 4, #token: 675, token usage: 0.00, gen throughput (token/s): 881.90, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:18:59 TP0] Decode batch. #running-req: 4, #token: 835, token usage: 0.00, gen throughput (token/s): 868.57, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:18:59 TP0] Decode batch. #running-req: 4, #token: 995, token usage: 0.00, gen throughput (token/s): 872.78, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:18:59 TP0] Decode batch. #running-req: 4, #token: 1155, token usage: 0.00, gen throughput (token/s): 877.87, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:18:59 TP0] Decode batch. #running-req: 4, #token: 1315, token usage: 0.00, gen throughput (token/s): 878.29, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:19:00 TP0] Decode batch. #running-req: 4, #token: 1475, token usage: 0.00, gen throughput (token/s): 865.25, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:19:00 TP0] Decode batch. #running-req: 4, #token: 1635, token usage: 0.00, gen throughput (token/s): 882.33, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:19:00 TP0] Decode batch. #running-req: 4, #token: 1795, token usage: 0.00, gen throughput (token/s): 880.07, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:19:00 TP0] Decode batch. #running-req: 4, #token: 1955, token usage: 0.00, gen throughput (token/s): 865.41, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:19:00 TP0] Decode batch. #running-req: 4, #token: 2115, token usage: 0.00, gen throughput (token/s): 880.52, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:19:00] INFO:     127.0.0.1:5420 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:19:00] INFO:     127.0.0.1:5396 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:19:00] INFO:     127.0.0.1:5412 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:19:00] INFO:     127.0.0.1:5414 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:19:00 TP0] Prefill batch. #new-seq: 2, #new-token: 1202, #cached-token: 86, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-08-25 15:19:00 TP0] Prefill batch. #new-seq: 2, #new-token: 1202, #cached-token: 86, token usage: 0.03, #running-req: 2, #queue-req: 0, 
[2025-08-25 15:19:01] INFO:     127.0.0.1:53596 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 15:19:01] INFO:     127.0.0.1:53598 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 15:19:01] INFO:     127.0.0.1:53600 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 15:19:01] INFO:     127.0.0.1:53608 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 15:19:01 TP0] Prefill batch. #new-seq: 1, #new-token: 500, #cached-token: 144, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-08-25 15:19:01 TP0] Prefill batch. #new-seq: 1, #new-token: 500, #cached-token: 144, token usage: 0.02, #running-req: 1, #queue-req: 0, 
[2025-08-25 15:19:02 TP0] Prefill batch. #new-seq: 2, #new-token: 1000, #cached-token: 288, token usage: 0.02, #running-req: 2, #queue-req: 0, 
[2025-08-25 15:19:02] INFO:     127.0.0.1:53596 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 15:19:02] INFO:     127.0.0.1:53598 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 15:19:02 TP0] Prefill batch. #new-seq: 2, #new-token: 1000, #cached-token: 288, token usage: 0.00, #running-req: 2, #queue-req: 0, 
[2025-08-25 15:19:02] INFO:     127.0.0.1:53608 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 15:19:02] INFO:     127.0.0.1:53600 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 15:19:02 TP0] Prefill batch. #new-seq: 2, #new-token: 1000, #cached-token: 288, token usage: 0.03, #running-req: 4, #queue-req: 0, 
[2025-08-25 15:19:02] INFO:     127.0.0.1:53596 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 15:19:02] INFO:     127.0.0.1:53598 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 15:19:03 TP0] Prefill batch. #new-seq: 2, #new-token: 1000, #cached-token: 288, token usage: 0.00, #running-req: 2, #queue-req: 0, 
[2025-08-25 15:19:03] INFO:     127.0.0.1:53608 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 15:19:03] INFO:     127.0.0.1:53600 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 15:19:03 TP0] Prefill batch. #new-seq: 2, #new-token: 1000, #cached-token: 288, token usage: 0.03, #running-req: 4, #queue-req: 0, 
[2025-08-25 15:19:03] INFO:     127.0.0.1:53596 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 15:19:03] INFO:     127.0.0.1:53598 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 15:19:03] INFO:     127.0.0.1:53608 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 15:19:03] INFO:     127.0.0.1:53600 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 15:19:03 TP0] Prefill batch. #new-seq: 3, #new-token: 3, #cached-token: 924, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-08-25 15:19:03 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 308, token usage: 0.00, #running-req: 3, #queue-req: 0, 
[2025-08-25 15:19:04 TP0] Decode batch. #running-req: 4, #token: 429, token usage: 0.00, gen throughput (token/s): 49.22, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:19:04 TP0] Decode batch. #running-req: 4, #token: 589, token usage: 0.00, gen throughput (token/s): 881.37, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:19:04 TP0] Decode batch. #running-req: 4, #token: 749, token usage: 0.00, gen throughput (token/s): 873.50, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:19:04 TP0] Decode batch. #running-req: 4, #token: 909, token usage: 0.00, gen throughput (token/s): 880.74, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:19:04 TP0] Decode batch. #running-req: 4, #token: 1069, token usage: 0.00, gen throughput (token/s): 867.66, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:19:05 TP0] Decode batch. #running-req: 4, #token: 1229, token usage: 0.00, gen throughput (token/s): 892.41, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:19:05 TP0] Decode batch. #running-req: 4, #token: 1389, token usage: 0.00, gen throughput (token/s): 899.12, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:19:05 TP0] Decode batch. #running-req: 4, #token: 1549, token usage: 0.00, gen throughput (token/s): 914.10, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:19:05 TP0] Decode batch. #running-req: 4, #token: 1709, token usage: 0.00, gen throughput (token/s): 893.46, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:19:05 TP0] Decode batch. #running-req: 4, #token: 1869, token usage: 0.00, gen throughput (token/s): 912.44, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:19:05 TP0] Decode batch. #running-req: 4, #token: 2029, token usage: 0.00, gen throughput (token/s): 894.82, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:19:06 TP0] Decode batch. #running-req: 4, #token: 2189, token usage: 0.00, gen throughput (token/s): 911.41, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:19:06] INFO:     127.0.0.1:5420 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:19:06] INFO:     127.0.0.1:5396 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:19:06] INFO:     127.0.0.1:5412 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:19:06] INFO:     127.0.0.1:5414 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:19:06 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 308, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-08-25 15:19:06 TP0] Prefill batch. #new-seq: 3, #new-token: 3, #cached-token: 924, token usage: 0.00, #running-req: 1, #queue-req: 0, 
[2025-08-25 15:19:06 TP0] Decode batch. #running-req: 4, #token: 349, token usage: 0.00, gen throughput (token/s): 575.04, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:19:06 TP0] Decode batch. #running-req: 4, #token: 509, token usage: 0.00, gen throughput (token/s): 883.62, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:19:06 TP0] Decode batch. #running-req: 4, #token: 669, token usage: 0.00, gen throughput (token/s): 865.33, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:19:06 TP0] Decode batch. #running-req: 4, #token: 829, token usage: 0.00, gen throughput (token/s): 874.23, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:19:07 TP0] Decode batch. #running-req: 4, #token: 989, token usage: 0.00, gen throughput (token/s): 866.92, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:19:07 TP0] Decode batch. #running-req: 4, #token: 1149, token usage: 0.00, gen throughput (token/s): 854.98, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:19:07 TP0] Decode batch. #running-req: 4, #token: 1309, token usage: 0.00, gen throughput (token/s): 857.29, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:19:07 TP0] Decode batch. #running-req: 4, #token: 1469, token usage: 0.00, gen throughput (token/s): 899.43, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:19:07 TP0] Decode batch. #running-req: 4, #token: 1629, token usage: 0.00, gen throughput (token/s): 874.31, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:19:08 TP0] Decode batch. #running-req: 4, #token: 1789, token usage: 0.00, gen throughput (token/s): 849.37, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:19:08 TP0] Decode batch. #running-req: 4, #token: 1949, token usage: 0.00, gen throughput (token/s): 849.07, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:19:08 TP0] Decode batch. #running-req: 4, #token: 2109, token usage: 0.00, gen throughput (token/s): 861.42, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:19:08 TP0] Decode batch. #running-req: 4, #token: 2269, token usage: 0.00, gen throughput (token/s): 882.19, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:19:08] INFO:     127.0.0.1:5420 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:19:08] INFO:     127.0.0.1:5396 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:19:08] INFO:     127.0.0.1:5412 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:19:08] INFO:     127.0.0.1:5414 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:19:08 TP0] Prefill batch. #new-seq: 4, #new-token: 4, #cached-token: 1232, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-08-25 15:19:08 TP0] Decode batch. #running-req: 4, #token: 429, token usage: 0.00, gen throughput (token/s): 641.70, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:19:09 TP0] Decode batch. #running-req: 4, #token: 589, token usage: 0.00, gen throughput (token/s): 875.37, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:19:09 TP0] Decode batch. #running-req: 4, #token: 749, token usage: 0.00, gen throughput (token/s): 905.82, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:19:09 TP0] Decode batch. #running-req: 4, #token: 909, token usage: 0.00, gen throughput (token/s): 896.49, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:19:09 TP0] Decode batch. #running-req: 4, #token: 1069, token usage: 0.00, gen throughput (token/s): 896.42, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:19:09 TP0] Decode batch. #running-req: 4, #token: 1229, token usage: 0.00, gen throughput (token/s): 902.29, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:19:09 TP0] Decode batch. #running-req: 4, #token: 1389, token usage: 0.00, gen throughput (token/s): 908.49, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:19:10 TP0] Decode batch. #running-req: 4, #token: 1549, token usage: 0.00, gen throughput (token/s): 897.63, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:19:10 TP0] Decode batch. #running-req: 4, #token: 1709, token usage: 0.00, gen throughput (token/s): 896.18, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:19:10 TP0] Decode batch. #running-req: 4, #token: 1869, token usage: 0.00, gen throughput (token/s): 915.78, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:19:10 TP0] Decode batch. #running-req: 4, #token: 2029, token usage: 0.00, gen throughput (token/s): 921.17, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:19:10 TP0] Decode batch. #running-req: 4, #token: 2189, token usage: 0.00, gen throughput (token/s): 928.59, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:19:10] INFO:     127.0.0.1:5420 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:19:10] INFO:     127.0.0.1:5396 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:19:10] INFO:     127.0.0.1:5412 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:19:10] INFO:     127.0.0.1:5414 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:19:10 TP0] Prefill batch. #new-seq: 4, #new-token: 4, #cached-token: 1232, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-08-25 15:19:11 TP0] Decode batch. #running-req: 4, #token: 349, token usage: 0.00, gen throughput (token/s): 657.96, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:19:11 TP0] Decode batch. #running-req: 4, #token: 509, token usage: 0.00, gen throughput (token/s): 886.99, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:19:11 TP0] Decode batch. #running-req: 4, #token: 669, token usage: 0.00, gen throughput (token/s): 876.12, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:19:11 TP0] Decode batch. #running-req: 4, #token: 829, token usage: 0.00, gen throughput (token/s): 866.38, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:19:11 TP0] Decode batch. #running-req: 4, #token: 989, token usage: 0.00, gen throughput (token/s): 888.95, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:19:11 TP0] Decode batch. #running-req: 4, #token: 1149, token usage: 0.00, gen throughput (token/s): 863.65, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:19:12 TP0] Decode batch. #running-req: 4, #token: 1309, token usage: 0.00, gen throughput (token/s): 866.39, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:19:12 TP0] Decode batch. #running-req: 4, #token: 1469, token usage: 0.00, gen throughput (token/s): 886.17, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:19:12 TP0] Decode batch. #running-req: 4, #token: 1629, token usage: 0.00, gen throughput (token/s): 883.21, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:19:12 TP0] Decode batch. #running-req: 4, #token: 1789, token usage: 0.00, gen throughput (token/s): 865.76, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:19:12 TP0] Decode batch. #running-req: 4, #token: 1949, token usage: 0.00, gen throughput (token/s): 816.54, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:19:13 TP0] Decode batch. #running-req: 4, #token: 2109, token usage: 0.00, gen throughput (token/s): 866.34, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:19:13 TP0] Decode batch. #running-req: 4, #token: 2269, token usage: 0.00, gen throughput (token/s): 873.04, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:19:13] INFO:     127.0.0.1:5396 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:19:13] INFO:     127.0.0.1:5420 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:19:13] INFO:     127.0.0.1:5412 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:19:13] INFO:     127.0.0.1:5414 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:19:13 TP0] Prefill batch. #new-seq: 4, #new-token: 3020, #cached-token: 172, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-08-25 15:19:14] INFO:     127.0.0.1:3532 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 15:19:14] INFO:     127.0.0.1:3542 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 15:19:14] INFO:     127.0.0.1:3546 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 15:19:14] INFO:     127.0.0.1:3562 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 15:19:14 TP0] Prefill batch. #new-seq: 1, #new-token: 500, #cached-token: 298, token usage: 0.01, #running-req: 0, #queue-req: 0, 
[2025-08-25 15:19:14 TP0] Prefill batch. #new-seq: 3, #new-token: 1500, #cached-token: 894, token usage: 0.02, #running-req: 1, #queue-req: 0, 
[2025-08-25 15:19:15] INFO:     127.0.0.1:3562 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 15:19:15] INFO:     127.0.0.1:3532 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 15:19:15] INFO:     127.0.0.1:3542 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 15:19:15] INFO:     127.0.0.1:3546 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 15:19:15 TP0] Prefill batch. #new-seq: 1, #new-token: 500, #cached-token: 298, token usage: 0.01, #running-req: 0, #queue-req: 0, 
[2025-08-25 15:19:15 TP0] Prefill batch. #new-seq: 3, #new-token: 1500, #cached-token: 894, token usage: 0.01, #running-req: 1, #queue-req: 0, 
[2025-08-25 15:19:15] INFO:     127.0.0.1:3562 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 15:19:15 TP0] Prefill batch. #new-seq: 1, #new-token: 500, #cached-token: 298, token usage: 0.05, #running-req: 4, #queue-req: 0, 
[2025-08-25 15:19:15] INFO:     127.0.0.1:3532 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 15:19:15] INFO:     127.0.0.1:3542 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 15:19:15] INFO:     127.0.0.1:3546 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 15:19:15 TP0] Prefill batch. #new-seq: 3, #new-token: 1500, #cached-token: 894, token usage: 0.01, #running-req: 1, #queue-req: 0, 
[2025-08-25 15:19:16] INFO:     127.0.0.1:3562 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 15:19:16 TP0] Prefill batch. #new-seq: 1, #new-token: 761, #cached-token: 46, token usage: 0.05, #running-req: 4, #queue-req: 0, 
[2025-08-25 15:19:16] INFO:     127.0.0.1:3532 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 15:19:16] INFO:     127.0.0.1:3542 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 15:19:16] INFO:     127.0.0.1:3546 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 15:19:16 TP0] Prefill batch. #new-seq: 3, #new-token: 1464, #cached-token: 957, token usage: 0.02, #running-req: 1, #queue-req: 0, 
[2025-08-25 15:19:18 TP0] Decode batch. #running-req: 4, #token: 2376, token usage: 0.06, gen throughput (token/s): 3.42, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:19:20 TP0] Decode batch. #running-req: 4, #token: 2536, token usage: 0.06, gen throughput (token/s): 88.50, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:19:22 TP0] Decode batch. #running-req: 4, #token: 2696, token usage: 0.07, gen throughput (token/s): 87.98, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:19:23 TP0] Decode batch. #running-req: 4, #token: 2856, token usage: 0.07, gen throughput (token/s): 88.28, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:19:23] INFO:     127.0.0.1:3562 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:19:24 TP0] Prefill batch. #new-seq: 1, #new-token: 489, #cached-token: 318, token usage: 0.01, #running-req: 3, #queue-req: 0, 
[2025-08-25 15:19:24] INFO:     127.0.0.1:3532 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:19:24] INFO:     127.0.0.1:3542 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:19:24] INFO:     127.0.0.1:3546 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:19:24 TP0] Prefill batch. #new-seq: 3, #new-token: 1468, #cached-token: 953, token usage: 0.02, #running-req: 4, #queue-req: 0, 
[2025-08-25 15:19:26 TP0] Decode batch. #running-req: 4, #token: 2440, token usage: 0.06, gen throughput (token/s): 65.25, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:19:28 TP0] Decode batch. #running-req: 4, #token: 2600, token usage: 0.07, gen throughput (token/s): 88.21, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:19:29 TP0] Decode batch. #running-req: 4, #token: 2760, token usage: 0.07, gen throughput (token/s): 87.95, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:19:31] INFO:     127.0.0.1:3562 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:19:31] INFO:     127.0.0.1:3532 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:19:31] INFO:     127.0.0.1:3542 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:19:31] INFO:     127.0.0.1:3546 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:19:31 TP0] Prefill batch. #new-seq: 3, #new-token: 1462, #cached-token: 959, token usage: 0.01, #running-req: 0, #queue-req: 0, 
[2025-08-25 15:19:32 TP0] Decode batch. #running-req: 3, #token: 1814, token usage: 0.05, gen throughput (token/s): 68.20, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:19:33 TP0] Decode batch. #running-req: 3, #token: 1934, token usage: 0.05, gen throughput (token/s): 66.44, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:19:35 TP0] Decode batch. #running-req: 3, #token: 2054, token usage: 0.05, gen throughput (token/s): 66.28, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:19:37 TP0] Decode batch. #running-req: 3, #token: 2174, token usage: 0.05, gen throughput (token/s): 66.28, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:19:38] INFO:     127.0.0.1:3562 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:19:38] INFO:     127.0.0.1:3532 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:19:38] INFO:     127.0.0.1:3542 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:19:38 TP0] Prefill batch. #new-seq: 4, #new-token: 812, #cached-token: 200, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-08-25 15:19:38 TP0] Decode batch. #running-req: 4, #token: 373, token usage: 0.00, gen throughput (token/s): 6.24, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:19:39 TP0] Decode batch. #running-req: 4, #token: 533, token usage: 0.00, gen throughput (token/s): 865.02, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:19:39 TP0] Decode batch. #running-req: 4, #token: 693, token usage: 0.00, gen throughput (token/s): 915.61, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:19:39 TP0] Decode batch. #running-req: 4, #token: 853, token usage: 0.00, gen throughput (token/s): 919.67, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:19:39 TP0] Decode batch. #running-req: 4, #token: 1013, token usage: 0.00, gen throughput (token/s): 893.81, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:19:39 TP0] Decode batch. #running-req: 4, #token: 1173, token usage: 0.00, gen throughput (token/s): 913.36, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:19:39 TP0] Decode batch. #running-req: 4, #token: 1333, token usage: 0.00, gen throughput (token/s): 896.55, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:19:40 TP0] Decode batch. #running-req: 4, #token: 1493, token usage: 0.00, gen throughput (token/s): 918.84, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:19:40 TP0] Decode batch. #running-req: 4, #token: 1653, token usage: 0.00, gen throughput (token/s): 874.04, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:19:40 TP0] Decode batch. #running-req: 4, #token: 1813, token usage: 0.00, gen throughput (token/s): 911.31, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:19:40 TP0] Decode batch. #running-req: 4, #token: 1973, token usage: 0.00, gen throughput (token/s): 918.91, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:19:40 TP0] Decode batch. #running-req: 4, #token: 2133, token usage: 0.00, gen throughput (token/s): 896.23, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:19:40] INFO:     127.0.0.1:8684 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:19:40] INFO:     127.0.0.1:8692 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:19:40] INFO:     127.0.0.1:8708 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:19:40] INFO:     127.0.0.1:8712 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:19:40 TP0] Prefill batch. #new-seq: 4, #new-token: 4, #cached-token: 1008, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-08-25 15:19:41 TP0] Decode batch. #running-req: 4, #token: 293, token usage: 0.00, gen throughput (token/s): 651.28, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:19:41 TP0] Decode batch. #running-req: 4, #token: 453, token usage: 0.00, gen throughput (token/s): 914.40, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:19:41 TP0] Decode batch. #running-req: 4, #token: 613, token usage: 0.00, gen throughput (token/s): 924.15, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:19:41 TP0] Decode batch. #running-req: 4, #token: 773, token usage: 0.00, gen throughput (token/s): 918.65, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:19:41 TP0] Decode batch. #running-req: 4, #token: 933, token usage: 0.00, gen throughput (token/s): 881.73, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:19:41 TP0] Decode batch. #running-req: 4, #token: 1093, token usage: 0.00, gen throughput (token/s): 905.02, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:19:42 TP0] Decode batch. #running-req: 4, #token: 1253, token usage: 0.00, gen throughput (token/s): 901.10, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:19:42 TP0] Decode batch. #running-req: 4, #token: 1413, token usage: 0.00, gen throughput (token/s): 947.44, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:19:42 TP0] Decode batch. #running-req: 4, #token: 1573, token usage: 0.00, gen throughput (token/s): 913.14, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:19:42 TP0] Decode batch. #running-req: 4, #token: 1733, token usage: 0.00, gen throughput (token/s): 908.55, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:19:42 TP0] Decode batch. #running-req: 4, #token: 1893, token usage: 0.00, gen throughput (token/s): 867.55, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:19:43 TP0] Decode batch. #running-req: 4, #token: 2053, token usage: 0.00, gen throughput (token/s): 863.71, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:19:43 TP0] Decode batch. #running-req: 4, #token: 2213, token usage: 0.00, gen throughput (token/s): 957.74, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:19:43] INFO:     127.0.0.1:8712 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:19:43] INFO:     127.0.0.1:8684 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:19:43] INFO:     127.0.0.1:8692 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:19:43] INFO:     127.0.0.1:8708 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:19:43 TP0] Prefill batch. #new-seq: 4, #new-token: 4, #cached-token: 1008, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-08-25 15:19:43 TP0] Decode batch. #running-req: 4, #token: 373, token usage: 0.00, gen throughput (token/s): 683.53, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:19:43 TP0] Decode batch. #running-req: 4, #token: 533, token usage: 0.00, gen throughput (token/s): 888.37, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:19:43 TP0] Decode batch. #running-req: 4, #token: 693, token usage: 0.00, gen throughput (token/s): 886.19, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:19:43 TP0] Decode batch. #running-req: 4, #token: 853, token usage: 0.00, gen throughput (token/s): 890.91, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:19:44 TP0] Decode batch. #running-req: 4, #token: 1013, token usage: 0.00, gen throughput (token/s): 906.21, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:19:44 TP0] Decode batch. #running-req: 4, #token: 1173, token usage: 0.00, gen throughput (token/s): 884.86, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:19:44 TP0] Decode batch. #running-req: 4, #token: 1333, token usage: 0.00, gen throughput (token/s): 890.63, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:19:44 TP0] Decode batch. #running-req: 4, #token: 1493, token usage: 0.00, gen throughput (token/s): 915.49, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:19:44 TP0] Decode batch. #running-req: 4, #token: 1653, token usage: 0.00, gen throughput (token/s): 892.65, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:19:45 TP0] Decode batch. #running-req: 4, #token: 1813, token usage: 0.00, gen throughput (token/s): 897.69, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:19:45 TP0] Decode batch. #running-req: 4, #token: 1973, token usage: 0.00, gen throughput (token/s): 899.84, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:19:45 TP0] Decode batch. #running-req: 4, #token: 2133, token usage: 0.00, gen throughput (token/s): 882.42, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:19:45] INFO:     127.0.0.1:8712 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:19:45] INFO:     127.0.0.1:8684 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:19:45] INFO:     127.0.0.1:8692 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:19:45] INFO:     127.0.0.1:8708 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:19:45 TP0] Prefill batch. #new-seq: 4, #new-token: 4, #cached-token: 1008, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-08-25 15:19:45 TP0] Decode batch. #running-req: 4, #token: 293, token usage: 0.00, gen throughput (token/s): 666.44, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:19:45 TP0] Decode batch. #running-req: 4, #token: 453, token usage: 0.00, gen throughput (token/s): 884.63, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:19:45 TP0] Decode batch. #running-req: 4, #token: 613, token usage: 0.00, gen throughput (token/s): 891.76, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:19:46 TP0] Decode batch. #running-req: 4, #token: 773, token usage: 0.00, gen throughput (token/s): 903.52, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:19:46 TP0] Decode batch. #running-req: 4, #token: 933, token usage: 0.00, gen throughput (token/s): 896.94, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:19:46 TP0] Decode batch. #running-req: 4, #token: 1093, token usage: 0.00, gen throughput (token/s): 887.77, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:19:46 TP0] Decode batch. #running-req: 4, #token: 1253, token usage: 0.00, gen throughput (token/s): 881.79, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:19:46 TP0] Decode batch. #running-req: 4, #token: 1413, token usage: 0.00, gen throughput (token/s): 889.59, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:19:47 TP0] Decode batch. #running-req: 4, #token: 1573, token usage: 0.00, gen throughput (token/s): 873.46, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:19:47 TP0] Decode batch. #running-req: 4, #token: 1733, token usage: 0.00, gen throughput (token/s): 883.57, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:19:47 TP0] Decode batch. #running-req: 4, #token: 1893, token usage: 0.00, gen throughput (token/s): 888.91, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:19:47 TP0] Decode batch. #running-req: 4, #token: 2053, token usage: 0.00, gen throughput (token/s): 900.63, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:19:47 TP0] Decode batch. #running-req: 4, #token: 2213, token usage: 0.00, gen throughput (token/s): 872.50, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:19:47] INFO:     127.0.0.1:8712 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:19:47] INFO:     127.0.0.1:8684 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:19:47] INFO:     127.0.0.1:8692 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:19:47] INFO:     127.0.0.1:8708 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:19:47 TP0] Prefill batch. #new-seq: 1, #new-token: 700, #cached-token: 42, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-08-25 15:19:47 TP0] Prefill batch. #new-seq: 3, #new-token: 2100, #cached-token: 126, token usage: 0.02, #running-req: 1, #queue-req: 0, 
[2025-08-25 15:19:48] INFO:     127.0.0.1:58742 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 15:19:48 TP0] Prefill batch. #new-seq: 1, #new-token: 500, #cached-token: 242, token usage: 0.01, #running-req: 3, #queue-req: 0, 
[2025-08-25 15:19:48] INFO:     127.0.0.1:58758 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 15:19:48] INFO:     127.0.0.1:58762 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 15:19:48] INFO:     127.0.0.1:58772 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 15:19:49 TP0] Prefill batch. #new-seq: 3, #new-token: 1500, #cached-token: 726, token usage: 0.02, #running-req: 4, #queue-req: 0, 
[2025-08-25 15:19:49] INFO:     127.0.0.1:58742 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 15:19:49 TP0] Prefill batch. #new-seq: 1, #new-token: 500, #cached-token: 242, token usage: 0.01, #running-req: 3, #queue-req: 0, 
[2025-08-25 15:19:49] INFO:     127.0.0.1:58772 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 15:19:49] INFO:     127.0.0.1:58758 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 15:19:49] INFO:     127.0.0.1:58762 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 15:19:49 TP0] Prefill batch. #new-seq: 3, #new-token: 1500, #cached-token: 726, token usage: 0.02, #running-req: 4, #queue-req: 0, 
[2025-08-25 15:19:49] INFO:     127.0.0.1:58742 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 15:19:50 TP0] Prefill batch. #new-seq: 1, #new-token: 500, #cached-token: 242, token usage: 0.01, #running-req: 3, #queue-req: 0, 
[2025-08-25 15:19:50] INFO:     127.0.0.1:58772 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 15:19:50] INFO:     127.0.0.1:58758 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 15:19:50] INFO:     127.0.0.1:58762 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 15:19:50 TP0] Prefill batch. #new-seq: 3, #new-token: 1500, #cached-token: 726, token usage: 0.02, #running-req: 4, #queue-req: 0, 
[2025-08-25 15:19:50] INFO:     127.0.0.1:58742 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 15:19:50 TP0] Prefill batch. #new-seq: 1, #new-token: 707, #cached-token: 44, token usage: 0.00, #running-req: 3, #queue-req: 0, 
[2025-08-25 15:19:50] INFO:     127.0.0.1:58772 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 15:19:50] INFO:     127.0.0.1:58758 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 15:19:50] INFO:     127.0.0.1:58762 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 15:19:51 TP0] Prefill batch. #new-seq: 1, #new-token: 707, #cached-token: 44, token usage: 0.02, #running-req: 4, #queue-req: 0, 
[2025-08-25 15:19:51 TP0] Decode batch. #running-req: 2, #token: 1260, token usage: 0.03, gen throughput (token/s): 7.61, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:19:53 TP0] Decode batch. #running-req: 2, #token: 1340, token usage: 0.03, gen throughput (token/s): 45.00, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:19:55 TP0] Decode batch. #running-req: 2, #token: 1420, token usage: 0.04, gen throughput (token/s): 44.86, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:19:57 TP0] Decode batch. #running-req: 2, #token: 1500, token usage: 0.04, gen throughput (token/s): 44.82, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:19:58] INFO:     127.0.0.1:58742 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:19:58] INFO:     127.0.0.1:58772 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:19:58 TP0] Prefill batch. #new-seq: 3, #new-token: 339, #cached-token: 153, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-08-25 15:19:58 TP0] Prefill batch. #new-seq: 1, #new-token: 113, #cached-token: 51, token usage: 0.00, #running-req: 3, #queue-req: 0, 
[2025-08-25 15:19:58 TP0] Decode batch. #running-req: 4, #token: 284, token usage: 0.00, gen throughput (token/s): 15.24, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:19:58 TP0] Decode batch. #running-req: 4, #token: 444, token usage: 0.00, gen throughput (token/s): 877.92, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:19:58 TP0] Decode batch. #running-req: 4, #token: 604, token usage: 0.00, gen throughput (token/s): 881.90, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:19:58 TP0] Decode batch. #running-req: 4, #token: 764, token usage: 0.00, gen throughput (token/s): 896.52, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:19:59 TP0] Decode batch. #running-req: 4, #token: 924, token usage: 0.00, gen throughput (token/s): 887.64, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:19:59 TP0] Decode batch. #running-req: 4, #token: 1084, token usage: 0.00, gen throughput (token/s): 857.04, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:19:59 TP0] Decode batch. #running-req: 4, #token: 1244, token usage: 0.00, gen throughput (token/s): 870.66, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:19:59 TP0] Decode batch. #running-req: 4, #token: 1404, token usage: 0.00, gen throughput (token/s): 851.94, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:19:59 TP0] Decode batch. #running-req: 4, #token: 1564, token usage: 0.00, gen throughput (token/s): 890.34, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:19:59 TP0] Decode batch. #running-req: 4, #token: 1724, token usage: 0.00, gen throughput (token/s): 863.54, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:20:00 TP0] Decode batch. #running-req: 4, #token: 1884, token usage: 0.00, gen throughput (token/s): 914.73, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:20:00 TP0] Decode batch. #running-req: 4, #token: 2044, token usage: 0.00, gen throughput (token/s): 867.42, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:20:00] INFO:     127.0.0.1:46722 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:20:00] INFO:     127.0.0.1:46736 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:20:00] INFO:     127.0.0.1:46750 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:20:00] INFO:     127.0.0.1:46754 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:20:00 TP0] Prefill batch. #new-seq: 4, #new-token: 4, #cached-token: 652, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-08-25 15:20:00 TP0] Decode batch. #running-req: 4, #token: 204, token usage: 0.00, gen throughput (token/s): 662.80, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:20:00 TP0] Decode batch. #running-req: 4, #token: 364, token usage: 0.00, gen throughput (token/s): 876.52, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:20:00 TP0] Decode batch. #running-req: 4, #token: 524, token usage: 0.00, gen throughput (token/s): 904.82, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:20:01 TP0] Decode batch. #running-req: 4, #token: 684, token usage: 0.00, gen throughput (token/s): 861.24, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:20:01 TP0] Decode batch. #running-req: 4, #token: 844, token usage: 0.00, gen throughput (token/s): 893.61, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:20:01 TP0] Decode batch. #running-req: 4, #token: 1004, token usage: 0.00, gen throughput (token/s): 892.60, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:20:01 TP0] Decode batch. #running-req: 4, #token: 1164, token usage: 0.00, gen throughput (token/s): 862.98, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:20:01 TP0] Decode batch. #running-req: 4, #token: 1324, token usage: 0.00, gen throughput (token/s): 894.39, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:20:01 TP0] Decode batch. #running-req: 4, #token: 1484, token usage: 0.00, gen throughput (token/s): 870.92, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:20:02 TP0] Decode batch. #running-req: 4, #token: 1644, token usage: 0.00, gen throughput (token/s): 864.09, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:20:02 TP0] Decode batch. #running-req: 4, #token: 1804, token usage: 0.00, gen throughput (token/s): 858.92, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:20:02 TP0] Decode batch. #running-req: 4, #token: 1964, token usage: 0.00, gen throughput (token/s): 869.31, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:20:02 TP0] Decode batch. #running-req: 4, #token: 2124, token usage: 0.00, gen throughput (token/s): 864.47, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:20:02] INFO:     127.0.0.1:46754 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:20:02] INFO:     127.0.0.1:46722 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:20:02] INFO:     127.0.0.1:46736 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:20:02] INFO:     127.0.0.1:46750 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:20:02 TP0] Prefill batch. #new-seq: 4, #new-token: 4, #cached-token: 652, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-08-25 15:20:02 TP0] Decode batch. #running-req: 4, #token: 284, token usage: 0.00, gen throughput (token/s): 664.74, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:20:03 TP0] Decode batch. #running-req: 4, #token: 444, token usage: 0.00, gen throughput (token/s): 871.61, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:20:03 TP0] Decode batch. #running-req: 4, #token: 604, token usage: 0.00, gen throughput (token/s): 866.69, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:20:03 TP0] Decode batch. #running-req: 4, #token: 764, token usage: 0.00, gen throughput (token/s): 879.11, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:20:03 TP0] Decode batch. #running-req: 4, #token: 924, token usage: 0.00, gen throughput (token/s): 870.71, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:20:03 TP0] Decode batch. #running-req: 4, #token: 1084, token usage: 0.00, gen throughput (token/s): 882.39, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:20:04 TP0] Decode batch. #running-req: 4, #token: 1244, token usage: 0.00, gen throughput (token/s): 892.64, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:20:04 TP0] Decode batch. #running-req: 4, #token: 1404, token usage: 0.00, gen throughput (token/s): 899.78, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:20:04 TP0] Decode batch. #running-req: 4, #token: 1564, token usage: 0.00, gen throughput (token/s): 885.69, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:20:04 TP0] Decode batch. #running-req: 4, #token: 1724, token usage: 0.00, gen throughput (token/s): 929.23, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:20:04 TP0] Decode batch. #running-req: 4, #token: 1884, token usage: 0.00, gen throughput (token/s): 886.40, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:20:04 TP0] Decode batch. #running-req: 4, #token: 2044, token usage: 0.00, gen throughput (token/s): 850.17, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:20:05] INFO:     127.0.0.1:46754 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:20:05] INFO:     127.0.0.1:46722 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:20:05] INFO:     127.0.0.1:46736 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:20:05] INFO:     127.0.0.1:46750 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:20:05 TP0] Prefill batch. #new-seq: 2, #new-token: 2, #cached-token: 326, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-08-25 15:20:05 TP0] Prefill batch. #new-seq: 2, #new-token: 2, #cached-token: 326, token usage: 0.00, #running-req: 2, #queue-req: 0, 
[2025-08-25 15:20:05 TP0] Decode batch. #running-req: 4, #token: 204, token usage: 0.00, gen throughput (token/s): 584.37, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:20:05 TP0] Decode batch. #running-req: 4, #token: 364, token usage: 0.00, gen throughput (token/s): 868.65, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:20:05 TP0] Decode batch. #running-req: 4, #token: 524, token usage: 0.00, gen throughput (token/s): 882.24, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:20:05 TP0] Decode batch. #running-req: 4, #token: 684, token usage: 0.00, gen throughput (token/s): 887.29, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:20:05 TP0] Decode batch. #running-req: 4, #token: 844, token usage: 0.00, gen throughput (token/s): 869.41, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:20:06 TP0] Decode batch. #running-req: 4, #token: 1004, token usage: 0.00, gen throughput (token/s): 872.55, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:20:06 TP0] Decode batch. #running-req: 4, #token: 1164, token usage: 0.00, gen throughput (token/s): 878.46, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:20:06 TP0] Decode batch. #running-req: 4, #token: 1324, token usage: 0.00, gen throughput (token/s): 864.14, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:20:06 TP0] Decode batch. #running-req: 4, #token: 1484, token usage: 0.00, gen throughput (token/s): 870.05, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:20:06 TP0] Decode batch. #running-req: 4, #token: 1644, token usage: 0.00, gen throughput (token/s): 859.35, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:20:07 TP0] Decode batch. #running-req: 4, #token: 1804, token usage: 0.00, gen throughput (token/s): 863.87, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:20:07 TP0] Decode batch. #running-req: 4, #token: 1964, token usage: 0.00, gen throughput (token/s): 862.38, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:20:07 TP0] Decode batch. #running-req: 4, #token: 2124, token usage: 0.00, gen throughput (token/s): 910.29, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:20:07] INFO:     127.0.0.1:46754 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:20:07] INFO:     127.0.0.1:46722 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:20:07] INFO:     127.0.0.1:46736 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:20:07] INFO:     127.0.0.1:46750 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:20:07 TP0] Prefill batch. #new-seq: 1, #new-token: 610, #cached-token: 43, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-08-25 15:20:07 TP0] Prefill batch. #new-seq: 3, #new-token: 1830, #cached-token: 129, token usage: 0.02, #running-req: 1, #queue-req: 0, 
[2025-08-25 15:20:08] INFO:     127.0.0.1:7034 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 15:20:08] INFO:     127.0.0.1:7050 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 15:20:08] INFO:     127.0.0.1:7062 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 15:20:08] INFO:     127.0.0.1:7066 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 15:20:08 TP0] Prefill batch. #new-seq: 1, #new-token: 500, #cached-token: 153, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-08-25 15:20:08 TP0] Prefill batch. #new-seq: 3, #new-token: 1500, #cached-token: 459, token usage: 0.00, #running-req: 1, #queue-req: 0, 
[2025-08-25 15:20:08] INFO:     127.0.0.1:7034 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 15:20:08 TP0] Prefill batch. #new-seq: 1, #new-token: 500, #cached-token: 153, token usage: 0.04, #running-req: 4, #queue-req: 0, 
[2025-08-25 15:20:09] INFO:     127.0.0.1:7066 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 15:20:09] INFO:     127.0.0.1:7050 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 15:20:09] INFO:     127.0.0.1:7062 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 15:20:09 TP0] Prefill batch. #new-seq: 3, #new-token: 1500, #cached-token: 459, token usage: 0.00, #running-req: 1, #queue-req: 0, 
[2025-08-25 15:20:09] INFO:     127.0.0.1:7034 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 15:20:09 TP0] Prefill batch. #new-seq: 1, #new-token: 500, #cached-token: 153, token usage: 0.04, #running-req: 4, #queue-req: 0, 
[2025-08-25 15:20:09] INFO:     127.0.0.1:7066 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 15:20:09] INFO:     127.0.0.1:7050 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 15:20:09] INFO:     127.0.0.1:7062 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 15:20:10 TP0] Prefill batch. #new-seq: 3, #new-token: 1500, #cached-token: 459, token usage: 0.00, #running-req: 1, #queue-req: 0, 
[2025-08-25 15:20:10] INFO:     127.0.0.1:7034 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 15:20:10 TP0] Prefill batch. #new-seq: 1, #new-token: 617, #cached-token: 45, token usage: 0.04, #running-req: 4, #queue-req: 0, 
[2025-08-25 15:20:11] INFO:     127.0.0.1:7066 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 15:20:11] INFO:     127.0.0.1:7050 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 15:20:11] INFO:     127.0.0.1:7062 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 15:20:11 TP0] Decode batch. #running-req: 1, #token: 680, token usage: 0.02, gen throughput (token/s): 4.28, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:20:13 TP0] Decode batch. #running-req: 1, #token: 720, token usage: 0.02, gen throughput (token/s): 22.73, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:20:15 TP0] Decode batch. #running-req: 1, #token: 760, token usage: 0.02, gen throughput (token/s): 22.71, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:20:16 TP0] Decode batch. #running-req: 1, #token: 800, token usage: 0.02, gen throughput (token/s): 22.73, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:20:17] INFO:     127.0.0.1:7034 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:20:17 TP0] Prefill batch. #new-seq: 1, #new-token: 83, #cached-token: 50, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-08-25 15:20:17 TP0] Prefill batch. #new-seq: 3, #new-token: 249, #cached-token: 150, token usage: 0.00, #running-req: 1, #queue-req: 0, 
[2025-08-25 15:20:17 TP0] Decode batch. #running-req: 4, #token: 253, token usage: 0.00, gen throughput (token/s): 15.86, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:20:17 TP0] Decode batch. #running-req: 4, #token: 413, token usage: 0.00, gen throughput (token/s): 900.12, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:20:17 TP0] Decode batch. #running-req: 4, #token: 573, token usage: 0.00, gen throughput (token/s): 878.69, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:20:18 TP0] Decode batch. #running-req: 4, #token: 733, token usage: 0.00, gen throughput (token/s): 857.77, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:20:18 TP0] Decode batch. #running-req: 4, #token: 893, token usage: 0.00, gen throughput (token/s): 878.75, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:20:18 TP0] Decode batch. #running-req: 4, #token: 1053, token usage: 0.00, gen throughput (token/s): 877.03, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:20:18 TP0] Decode batch. #running-req: 4, #token: 1213, token usage: 0.00, gen throughput (token/s): 908.53, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:20:18 TP0] Decode batch. #running-req: 4, #token: 1373, token usage: 0.00, gen throughput (token/s): 891.26, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:20:18 TP0] Decode batch. #running-req: 4, #token: 1533, token usage: 0.00, gen throughput (token/s): 868.52, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:20:19 TP0] Decode batch. #running-req: 4, #token: 1693, token usage: 0.00, gen throughput (token/s): 892.44, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:20:19 TP0] Decode batch. #running-req: 4, #token: 1853, token usage: 0.00, gen throughput (token/s): 862.42, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:20:19 TP0] Decode batch. #running-req: 4, #token: 2013, token usage: 0.00, gen throughput (token/s): 838.15, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:20:19] INFO:     127.0.0.1:29100 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:20:19] INFO:     127.0.0.1:29116 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:20:19] INFO:     127.0.0.1:29132 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:20:19] INFO:     127.0.0.1:29148 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:20:19 TP0] Prefill batch. #new-seq: 4, #new-token: 4, #cached-token: 528, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-08-25 15:20:19 TP0] Decode batch. #running-req: 4, #token: 173, token usage: 0.00, gen throughput (token/s): 652.86, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:20:19 TP0] Decode batch. #running-req: 4, #token: 333, token usage: 0.00, gen throughput (token/s): 852.40, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:20:20 TP0] Decode batch. #running-req: 4, #token: 493, token usage: 0.00, gen throughput (token/s): 880.50, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:20:20 TP0] Decode batch. #running-req: 4, #token: 653, token usage: 0.00, gen throughput (token/s): 855.73, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:20:20 TP0] Decode batch. #running-req: 4, #token: 813, token usage: 0.00, gen throughput (token/s): 852.61, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:20:20 TP0] Decode batch. #running-req: 4, #token: 973, token usage: 0.00, gen throughput (token/s): 867.04, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:20:20 TP0] Decode batch. #running-req: 4, #token: 1133, token usage: 0.00, gen throughput (token/s): 837.82, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:20:21 TP0] Decode batch. #running-req: 4, #token: 1293, token usage: 0.00, gen throughput (token/s): 855.02, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:20:21 TP0] Decode batch. #running-req: 4, #token: 1453, token usage: 0.00, gen throughput (token/s): 874.75, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:20:21 TP0] Decode batch. #running-req: 4, #token: 1613, token usage: 0.00, gen throughput (token/s): 879.91, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:20:21 TP0] Decode batch. #running-req: 4, #token: 1773, token usage: 0.00, gen throughput (token/s): 877.49, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:20:21 TP0] Decode batch. #running-req: 4, #token: 1933, token usage: 0.00, gen throughput (token/s): 871.11, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:20:22 TP0] Decode batch. #running-req: 4, #token: 2093, token usage: 0.00, gen throughput (token/s): 860.43, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:20:22] INFO:     127.0.0.1:29148 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:20:22] INFO:     127.0.0.1:29100 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:20:22] INFO:     127.0.0.1:29116 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:20:22] INFO:     127.0.0.1:29132 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:20:22 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 132, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-08-25 15:20:22 TP0] Prefill batch. #new-seq: 3, #new-token: 3, #cached-token: 396, token usage: 0.00, #running-req: 1, #queue-req: 0, 
[2025-08-25 15:20:22 TP0] Decode batch. #running-req: 4, #token: 253, token usage: 0.00, gen throughput (token/s): 596.14, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:20:22 TP0] Decode batch. #running-req: 4, #token: 413, token usage: 0.00, gen throughput (token/s): 891.67, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:20:22 TP0] Decode batch. #running-req: 4, #token: 573, token usage: 0.00, gen throughput (token/s): 877.41, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:20:22 TP0] Decode batch. #running-req: 4, #token: 733, token usage: 0.00, gen throughput (token/s): 872.62, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:20:23 TP0] Decode batch. #running-req: 4, #token: 893, token usage: 0.00, gen throughput (token/s): 878.47, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:20:23 TP0] Decode batch. #running-req: 4, #token: 1053, token usage: 0.00, gen throughput (token/s): 879.30, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:20:23 TP0] Decode batch. #running-req: 4, #token: 1213, token usage: 0.00, gen throughput (token/s): 877.16, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:20:23 TP0] Decode batch. #running-req: 4, #token: 1373, token usage: 0.00, gen throughput (token/s): 871.52, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:20:23 TP0] Decode batch. #running-req: 4, #token: 1533, token usage: 0.00, gen throughput (token/s): 871.05, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:20:23 TP0] Decode batch. #running-req: 4, #token: 1693, token usage: 0.00, gen throughput (token/s): 883.67, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:20:24 TP0] Decode batch. #running-req: 4, #token: 1853, token usage: 0.00, gen throughput (token/s): 851.08, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:20:24 TP0] Decode batch. #running-req: 4, #token: 2013, token usage: 0.00, gen throughput (token/s): 879.75, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:20:24] INFO:     127.0.0.1:29148 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:20:24] INFO:     127.0.0.1:29100 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:20:24] INFO:     127.0.0.1:29116 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:20:24] INFO:     127.0.0.1:29132 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:20:24 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 132, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-08-25 15:20:24 TP0] Prefill batch. #new-seq: 3, #new-token: 3, #cached-token: 396, token usage: 0.00, #running-req: 1, #queue-req: 0, 
[2025-08-25 15:20:24 TP0] Decode batch. #running-req: 4, #token: 173, token usage: 0.00, gen throughput (token/s): 603.68, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:20:24 TP0] Decode batch. #running-req: 4, #token: 333, token usage: 0.00, gen throughput (token/s): 879.37, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:20:24 TP0] Decode batch. #running-req: 4, #token: 493, token usage: 0.00, gen throughput (token/s): 870.64, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:20:25 TP0] Decode batch. #running-req: 4, #token: 653, token usage: 0.00, gen throughput (token/s): 870.52, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:20:25 TP0] Decode batch. #running-req: 4, #token: 813, token usage: 0.00, gen throughput (token/s): 853.44, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:20:25 TP0] Decode batch. #running-req: 4, #token: 973, token usage: 0.00, gen throughput (token/s): 879.52, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:20:25 TP0] Decode batch. #running-req: 4, #token: 1133, token usage: 0.00, gen throughput (token/s): 880.49, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:20:25 TP0] Decode batch. #running-req: 4, #token: 1293, token usage: 0.00, gen throughput (token/s): 895.47, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:20:26 TP0] Decode batch. #running-req: 4, #token: 1453, token usage: 0.00, gen throughput (token/s): 894.34, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:20:26 TP0] Decode batch. #running-req: 4, #token: 1613, token usage: 0.00, gen throughput (token/s): 886.58, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:20:26 TP0] Decode batch. #running-req: 4, #token: 1773, token usage: 0.00, gen throughput (token/s): 876.18, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:20:26 TP0] Decode batch. #running-req: 4, #token: 1933, token usage: 0.00, gen throughput (token/s): 880.03, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:20:26 TP0] Decode batch. #running-req: 4, #token: 2093, token usage: 0.00, gen throughput (token/s): 895.85, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:20:26] INFO:     127.0.0.1:29148 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:20:26] INFO:     127.0.0.1:29100 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:20:26] INFO:     127.0.0.1:29116 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:20:26] INFO:     127.0.0.1:29132 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:20:26 TP0] Prefill batch. #new-seq: 4, #new-token: 2320, #cached-token: 168, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-08-25 15:20:27] INFO:     127.0.0.1:6426 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 15:20:27] INFO:     127.0.0.1:6438 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 15:20:27] INFO:     127.0.0.1:6446 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 15:20:27] INFO:     127.0.0.1:6450 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 15:20:27 TP0] Prefill batch. #new-seq: 1, #new-token: 500, #cached-token: 122, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-08-25 15:20:27 TP0] Prefill batch. #new-seq: 3, #new-token: 1500, #cached-token: 366, token usage: 0.02, #running-req: 1, #queue-req: 0, 
[2025-08-25 15:20:28] INFO:     127.0.0.1:6426 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 15:20:28] INFO:     127.0.0.1:6450 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 15:20:28] INFO:     127.0.0.1:6438 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 15:20:28] INFO:     127.0.0.1:6446 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 15:20:28 TP0] Prefill batch. #new-seq: 1, #new-token: 500, #cached-token: 122, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-08-25 15:20:28 TP0] Prefill batch. #new-seq: 1, #new-token: 500, #cached-token: 122, token usage: 0.02, #running-req: 1, #queue-req: 0, 
[2025-08-25 15:20:28 TP0] Prefill batch. #new-seq: 2, #new-token: 1000, #cached-token: 244, token usage: 0.02, #running-req: 2, #queue-req: 0, 
[2025-08-25 15:20:28] INFO:     127.0.0.1:6426 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 15:20:28] INFO:     127.0.0.1:6450 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 15:20:29 TP0] Prefill batch. #new-seq: 2, #new-token: 1000, #cached-token: 244, token usage: 0.00, #running-req: 2, #queue-req: 0, 
[2025-08-25 15:20:29] INFO:     127.0.0.1:6438 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 15:20:29] INFO:     127.0.0.1:6446 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 15:20:29 TP0] Prefill batch. #new-seq: 2, #new-token: 1000, #cached-token: 244, token usage: 0.03, #running-req: 4, #queue-req: 0, 
[2025-08-25 15:20:29] INFO:     127.0.0.1:6426 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 15:20:29] INFO:     127.0.0.1:6450 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 15:20:29 TP0] Prefill batch. #new-seq: 2, #new-token: 1174, #cached-token: 88, token usage: 0.00, #running-req: 2, #queue-req: 0, 
[2025-08-25 15:20:29] INFO:     127.0.0.1:6438 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 15:20:29] INFO:     127.0.0.1:6446 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 15:20:29 TP0] Prefill batch. #new-seq: 2, #new-token: 1174, #cached-token: 88, token usage: 0.03, #running-req: 4, #queue-req: 0, 
[2025-08-25 15:20:31 TP0] Decode batch. #running-req: 4, #token: 2192, token usage: 0.06, gen throughput (token/s): 7.85, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:20:33 TP0] Decode batch. #running-req: 4, #token: 2352, token usage: 0.06, gen throughput (token/s): 88.27, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:20:35 TP0] Decode batch. #running-req: 4, #token: 2512, token usage: 0.06, gen throughput (token/s): 88.36, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:20:37 TP0] Decode batch. #running-req: 4, #token: 2672, token usage: 0.07, gen throughput (token/s): 88.10, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:20:37] INFO:     127.0.0.1:6450 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:20:37] INFO:     127.0.0.1:6426 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:20:37] INFO:     127.0.0.1:6446 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:20:37] INFO:     127.0.0.1:6438 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:20:37 TP0] Prefill batch. #new-seq: 4, #new-token: 1952, #cached-token: 572, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-08-25 15:20:39 TP0] Decode batch. #running-req: 4, #token: 2251, token usage: 0.06, gen throughput (token/s): 66.43, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:20:41 TP0] Decode batch. #running-req: 4, #token: 2411, token usage: 0.06, gen throughput (token/s): 88.29, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:20:43 TP0] Decode batch. #running-req: 4, #token: 2571, token usage: 0.06, gen throughput (token/s): 88.09, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:20:44] INFO:     127.0.0.1:6450 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:20:44] INFO:     127.0.0.1:6426 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:20:44] INFO:     127.0.0.1:6438 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:20:44] INFO:     127.0.0.1:6446 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:20:44 TP0] Prefill batch. #new-seq: 4, #new-token: 1920, #cached-token: 604, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-08-25 15:20:45 TP0] Decode batch. #running-req: 4, #token: 2104, token usage: 0.05, gen throughput (token/s): 66.96, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:20:47 TP0] Decode batch. #running-req: 4, #token: 2264, token usage: 0.06, gen throughput (token/s): 88.50, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:20:49 TP0] Decode batch. #running-req: 4, #token: 2424, token usage: 0.06, gen throughput (token/s): 88.28, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:20:50 TP0] Decode batch. #running-req: 4, #token: 2584, token usage: 0.06, gen throughput (token/s): 88.07, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:20:52] INFO:     127.0.0.1:6450 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:20:52] INFO:     127.0.0.1:6426 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:20:52] INFO:     127.0.0.1:6438 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:20:52] INFO:     127.0.0.1:6446 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:20:52 TP0] Prefill batch. #new-seq: 4, #new-token: 1975, #cached-token: 549, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-08-25 15:20:53 TP0] Decode batch. #running-req: 4, #token: 2177, token usage: 0.05, gen throughput (token/s): 66.31, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:20:55 TP0] Decode batch. #running-req: 4, #token: 2337, token usage: 0.06, gen throughput (token/s): 88.16, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:20:56 TP0] Decode batch. #running-req: 4, #token: 2497, token usage: 0.06, gen throughput (token/s): 88.37, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:20:58 TP0] Decode batch. #running-req: 4, #token: 2657, token usage: 0.07, gen throughput (token/s): 87.93, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:20:59] INFO:     127.0.0.1:6450 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:20:59] INFO:     127.0.0.1:6426 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:20:59] INFO:     127.0.0.1:6438 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:20:59] INFO:     127.0.0.1:6446 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:20:59 TP0] Prefill batch. #new-seq: 1, #new-token: 129, #cached-token: 52, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-08-25 15:20:59 TP0] Prefill batch. #new-seq: 3, #new-token: 387, #cached-token: 156, token usage: 0.00, #running-req: 1, #queue-req: 0, 
[2025-08-25 15:20:59 TP0] Decode batch. #running-req: 4, #token: 301, token usage: 0.00, gen throughput (token/s): 4.85, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:20:59 TP0] Decode batch. #running-req: 4, #token: 461, token usage: 0.00, gen throughput (token/s): 883.92, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:21:00 TP0] Decode batch. #running-req: 4, #token: 621, token usage: 0.00, gen throughput (token/s): 867.26, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:21:00 TP0] Decode batch. #running-req: 4, #token: 781, token usage: 0.00, gen throughput (token/s): 868.19, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:21:00 TP0] Decode batch. #running-req: 4, #token: 941, token usage: 0.00, gen throughput (token/s): 909.24, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:21:00 TP0] Decode batch. #running-req: 4, #token: 1101, token usage: 0.00, gen throughput (token/s): 917.46, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:21:00 TP0] Decode batch. #running-req: 4, #token: 1261, token usage: 0.00, gen throughput (token/s): 905.28, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:21:00 TP0] Decode batch. #running-req: 4, #token: 1421, token usage: 0.00, gen throughput (token/s): 904.22, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:21:01 TP0] Decode batch. #running-req: 4, #token: 1581, token usage: 0.00, gen throughput (token/s): 891.38, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:21:01 TP0] Decode batch. #running-req: 4, #token: 1741, token usage: 0.00, gen throughput (token/s): 893.79, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:21:01 TP0] Decode batch. #running-req: 4, #token: 1901, token usage: 0.00, gen throughput (token/s): 881.84, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:21:01 TP0] Decode batch. #running-req: 4, #token: 2061, token usage: 0.00, gen throughput (token/s): 885.65, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:21:01] INFO:     127.0.0.1:16544 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:21:01] INFO:     127.0.0.1:16556 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:21:01] INFO:     127.0.0.1:16572 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:21:01] INFO:     127.0.0.1:16576 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:21:01 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 180, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-08-25 15:21:01 TP0] Prefill batch. #new-seq: 3, #new-token: 3, #cached-token: 540, token usage: 0.00, #running-req: 1, #queue-req: 0, 
[2025-08-25 15:21:01 TP0] Decode batch. #running-req: 4, #token: 221, token usage: 0.00, gen throughput (token/s): 582.30, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:21:02 TP0] Decode batch. #running-req: 4, #token: 381, token usage: 0.00, gen throughput (token/s): 910.80, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:21:02 TP0] Decode batch. #running-req: 4, #token: 541, token usage: 0.00, gen throughput (token/s): 923.47, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:21:02 TP0] Decode batch. #running-req: 4, #token: 701, token usage: 0.00, gen throughput (token/s): 899.86, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:21:02 TP0] Decode batch. #running-req: 4, #token: 861, token usage: 0.00, gen throughput (token/s): 935.64, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:21:02 TP0] Decode batch. #running-req: 4, #token: 1021, token usage: 0.00, gen throughput (token/s): 913.76, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:21:02 TP0] Decode batch. #running-req: 4, #token: 1181, token usage: 0.00, gen throughput (token/s): 921.88, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:21:03 TP0] Decode batch. #running-req: 4, #token: 1341, token usage: 0.00, gen throughput (token/s): 905.50, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:21:03 TP0] Decode batch. #running-req: 4, #token: 1501, token usage: 0.00, gen throughput (token/s): 898.77, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:21:03 TP0] Decode batch. #running-req: 4, #token: 1661, token usage: 0.00, gen throughput (token/s): 917.09, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:21:03 TP0] Decode batch. #running-req: 4, #token: 1821, token usage: 0.00, gen throughput (token/s): 921.99, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:21:03 TP0] Decode batch. #running-req: 4, #token: 1981, token usage: 0.00, gen throughput (token/s): 932.18, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:21:04 TP0] Decode batch. #running-req: 4, #token: 2141, token usage: 0.00, gen throughput (token/s): 925.49, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:21:04] INFO:     127.0.0.1:16576 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:21:04] INFO:     127.0.0.1:16544 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:21:04] INFO:     127.0.0.1:16556 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:21:04] INFO:     127.0.0.1:16572 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:21:04 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 180, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-08-25 15:21:04 TP0] Prefill batch. #new-seq: 3, #new-token: 3, #cached-token: 540, token usage: 0.00, #running-req: 1, #queue-req: 0, 
[2025-08-25 15:21:04 TP0] Decode batch. #running-req: 4, #token: 301, token usage: 0.00, gen throughput (token/s): 603.08, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:21:04 TP0] Decode batch. #running-req: 4, #token: 461, token usage: 0.00, gen throughput (token/s): 915.73, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:21:04 TP0] Decode batch. #running-req: 4, #token: 621, token usage: 0.00, gen throughput (token/s): 905.62, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:21:04 TP0] Decode batch. #running-req: 4, #token: 781, token usage: 0.00, gen throughput (token/s): 897.76, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:21:05 TP0] Decode batch. #running-req: 4, #token: 941, token usage: 0.00, gen throughput (token/s): 923.78, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:21:05 TP0] Decode batch. #running-req: 4, #token: 1101, token usage: 0.00, gen throughput (token/s): 872.44, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:21:05 TP0] Decode batch. #running-req: 4, #token: 1261, token usage: 0.00, gen throughput (token/s): 886.38, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:21:05 TP0] Decode batch. #running-req: 4, #token: 1421, token usage: 0.00, gen throughput (token/s): 873.11, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:21:05 TP0] Decode batch. #running-req: 4, #token: 1581, token usage: 0.00, gen throughput (token/s): 878.33, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:21:05 TP0] Decode batch. #running-req: 4, #token: 1741, token usage: 0.00, gen throughput (token/s): 876.92, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:21:06 TP0] Decode batch. #running-req: 4, #token: 1901, token usage: 0.00, gen throughput (token/s): 901.96, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:21:06 TP0] Decode batch. #running-req: 4, #token: 2061, token usage: 0.00, gen throughput (token/s): 910.73, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:21:06] INFO:     127.0.0.1:16576 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:21:06] INFO:     127.0.0.1:16544 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:21:06] INFO:     127.0.0.1:16556 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:21:06] INFO:     127.0.0.1:16572 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:21:06 TP0] Prefill batch. #new-seq: 4, #new-token: 4, #cached-token: 720, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-08-25 15:21:06 TP0] Decode batch. #running-req: 4, #token: 221, token usage: 0.00, gen throughput (token/s): 678.25, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:21:06 TP0] Decode batch. #running-req: 4, #token: 381, token usage: 0.00, gen throughput (token/s): 870.45, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:21:06 TP0] Decode batch. #running-req: 4, #token: 541, token usage: 0.00, gen throughput (token/s): 900.63, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:21:07 TP0] Decode batch. #running-req: 4, #token: 701, token usage: 0.00, gen throughput (token/s): 875.50, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:21:07 TP0] Decode batch. #running-req: 4, #token: 861, token usage: 0.00, gen throughput (token/s): 878.27, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:21:07 TP0] Decode batch. #running-req: 4, #token: 1021, token usage: 0.00, gen throughput (token/s): 905.84, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:21:07 TP0] Decode batch. #running-req: 4, #token: 1181, token usage: 0.00, gen throughput (token/s): 868.11, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:21:07 TP0] Decode batch. #running-req: 4, #token: 1341, token usage: 0.00, gen throughput (token/s): 916.05, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:21:07 TP0] Decode batch. #running-req: 4, #token: 1501, token usage: 0.00, gen throughput (token/s): 866.27, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:21:08 TP0] Decode batch. #running-req: 4, #token: 1661, token usage: 0.00, gen throughput (token/s): 870.07, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:21:08 TP0] Decode batch. #running-req: 4, #token: 1821, token usage: 0.00, gen throughput (token/s): 831.58, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:21:08 TP0] Decode batch. #running-req: 4, #token: 1981, token usage: 0.00, gen throughput (token/s): 882.64, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:21:08 TP0] Decode batch. #running-req: 4, #token: 2141, token usage: 0.00, gen throughput (token/s): 858.23, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:21:08] INFO:     127.0.0.1:16576 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:21:08] INFO:     127.0.0.1:16544 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:21:08] INFO:     127.0.0.1:16556 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:21:08] INFO:     127.0.0.1:16572 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:21:08 TP0] Prefill batch. #new-seq: 4, #new-token: 2512, #cached-token: 168, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-08-25 15:21:09] INFO:     127.0.0.1:43618 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 15:21:09] INFO:     127.0.0.1:43628 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 15:21:09] INFO:     127.0.0.1:43630 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 15:21:09] INFO:     127.0.0.1:43640 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 15:21:09 TP0] Prefill batch. #new-seq: 1, #new-token: 500, #cached-token: 170, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-08-25 15:21:09 TP0] Prefill batch. #new-seq: 3, #new-token: 1500, #cached-token: 510, token usage: 0.02, #running-req: 1, #queue-req: 0, 
[2025-08-25 15:21:11] INFO:     127.0.0.1:43640 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 15:21:11] INFO:     127.0.0.1:43618 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 15:21:11] INFO:     127.0.0.1:43628 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 15:21:11] INFO:     127.0.0.1:43630 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 15:21:11 TP0] Prefill batch. #new-seq: 1, #new-token: 500, #cached-token: 170, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-08-25 15:21:11 TP0] Prefill batch. #new-seq: 3, #new-token: 1500, #cached-token: 510, token usage: 0.02, #running-req: 1, #queue-req: 0, 
[2025-08-25 15:21:11] INFO:     127.0.0.1:43640 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 15:21:11] INFO:     127.0.0.1:43618 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 15:21:11] INFO:     127.0.0.1:43628 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 15:21:11] INFO:     127.0.0.1:43630 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 15:21:11 TP0] Prefill batch. #new-seq: 1, #new-token: 500, #cached-token: 170, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-08-25 15:21:11 TP0] Prefill batch. #new-seq: 1, #new-token: 500, #cached-token: 170, token usage: 0.02, #running-req: 1, #queue-req: 0, 
[2025-08-25 15:21:12 TP0] Prefill batch. #new-seq: 2, #new-token: 1000, #cached-token: 340, token usage: 0.02, #running-req: 2, #queue-req: 0, 
[2025-08-25 15:21:12] INFO:     127.0.0.1:43640 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 15:21:12 TP0] Prefill batch. #new-seq: 1, #new-token: 635, #cached-token: 44, token usage: 0.03, #running-req: 4, #queue-req: 0, 
[2025-08-25 15:21:12] INFO:     127.0.0.1:43618 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 15:21:12 TP0] Prefill batch. #new-seq: 1, #new-token: 635, #cached-token: 44, token usage: 0.02, #running-req: 5, #queue-req: 0, 
[2025-08-25 15:21:12] INFO:     127.0.0.1:43628 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 15:21:12] INFO:     127.0.0.1:43630 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 15:21:12 TP0] Prefill batch. #new-seq: 1, #new-token: 483, #cached-token: 196, token usage: 0.03, #running-req: 6, #queue-req: 0, 
[2025-08-25 15:21:14 TP0] Decode batch. #running-req: 3, #token: 1725, token usage: 0.04, gen throughput (token/s): 9.03, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:21:15 TP0] Decode batch. #running-req: 3, #token: 1845, token usage: 0.05, gen throughput (token/s): 66.59, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:21:17 TP0] Decode batch. #running-req: 3, #token: 1965, token usage: 0.05, gen throughput (token/s): 66.30, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:21:19 TP0] Decode batch. #running-req: 3, #token: 2085, token usage: 0.05, gen throughput (token/s): 66.47, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:21:19] INFO:     127.0.0.1:43640 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:21:19] INFO:     127.0.0.1:43618 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:21:19] INFO:     127.0.0.1:43628 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:21:19 TP0] Prefill batch. #new-seq: 4, #new-token: 312, #cached-token: 208, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-08-25 15:21:20 TP0] Decode batch. #running-req: 4, #token: 250, token usage: 0.00, gen throughput (token/s): 14.13, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:21:20 TP0] Decode batch. #running-req: 4, #token: 410, token usage: 0.00, gen throughput (token/s): 876.42, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:21:20 TP0] Decode batch. #running-req: 4, #token: 570, token usage: 0.00, gen throughput (token/s): 863.78, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:21:20 TP0] Decode batch. #running-req: 4, #token: 730, token usage: 0.00, gen throughput (token/s): 891.94, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:21:20 TP0] Decode batch. #running-req: 4, #token: 890, token usage: 0.00, gen throughput (token/s): 862.03, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:21:20 TP0] Decode batch. #running-req: 4, #token: 1050, token usage: 0.00, gen throughput (token/s): 836.49, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:21:21 TP0] Decode batch. #running-req: 4, #token: 1210, token usage: 0.00, gen throughput (token/s): 874.75, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:21:21 TP0] Decode batch. #running-req: 4, #token: 1370, token usage: 0.00, gen throughput (token/s): 864.68, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:21:21 TP0] Decode batch. #running-req: 4, #token: 1530, token usage: 0.00, gen throughput (token/s): 868.20, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:21:21 TP0] Decode batch. #running-req: 4, #token: 1690, token usage: 0.00, gen throughput (token/s): 889.18, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:21:21 TP0] Decode batch. #running-req: 4, #token: 1850, token usage: 0.00, gen throughput (token/s): 847.79, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:21:22 TP0] Decode batch. #running-req: 4, #token: 2010, token usage: 0.00, gen throughput (token/s): 858.84, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:21:22] INFO:     127.0.0.1:64346 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:21:22] INFO:     127.0.0.1:64348 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:21:22] INFO:     127.0.0.1:64352 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:21:22] INFO:     127.0.0.1:64354 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:21:22 TP0] Prefill batch. #new-seq: 4, #new-token: 4, #cached-token: 516, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-08-25 15:21:22 TP0] Decode batch. #running-req: 4, #token: 170, token usage: 0.00, gen throughput (token/s): 687.96, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:21:22 TP0] Decode batch. #running-req: 4, #token: 330, token usage: 0.00, gen throughput (token/s): 869.05, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:21:22 TP0] Decode batch. #running-req: 4, #token: 490, token usage: 0.00, gen throughput (token/s): 889.45, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:21:22 TP0] Decode batch. #running-req: 4, #token: 650, token usage: 0.00, gen throughput (token/s): 869.92, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:21:23 TP0] Decode batch. #running-req: 4, #token: 810, token usage: 0.00, gen throughput (token/s): 881.91, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:21:23 TP0] Decode batch. #running-req: 4, #token: 970, token usage: 0.00, gen throughput (token/s): 893.74, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:21:23 TP0] Decode batch. #running-req: 4, #token: 1130, token usage: 0.00, gen throughput (token/s): 879.40, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:21:23 TP0] Decode batch. #running-req: 4, #token: 1290, token usage: 0.00, gen throughput (token/s): 881.63, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:21:23 TP0] Decode batch. #running-req: 4, #token: 1450, token usage: 0.00, gen throughput (token/s): 885.65, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:21:23 TP0] Decode batch. #running-req: 4, #token: 1610, token usage: 0.00, gen throughput (token/s): 891.25, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:21:24 TP0] Decode batch. #running-req: 4, #token: 1770, token usage: 0.00, gen throughput (token/s): 898.95, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:21:24 TP0] Decode batch. #running-req: 4, #token: 1930, token usage: 0.00, gen throughput (token/s): 893.30, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:21:24 TP0] Decode batch. #running-req: 4, #token: 2090, token usage: 0.00, gen throughput (token/s): 911.48, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:21:24] INFO:     127.0.0.1:64354 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:21:24] INFO:     127.0.0.1:64346 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:21:24] INFO:     127.0.0.1:64348 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:21:24] INFO:     127.0.0.1:64352 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:21:24 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 129, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-08-25 15:21:24 TP0] Prefill batch. #new-seq: 3, #new-token: 3, #cached-token: 387, token usage: 0.00, #running-req: 1, #queue-req: 0, 
[2025-08-25 15:21:24 TP0] Decode batch. #running-req: 4, #token: 250, token usage: 0.00, gen throughput (token/s): 585.74, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:21:24 TP0] Decode batch. #running-req: 4, #token: 410, token usage: 0.00, gen throughput (token/s): 917.81, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:21:25 TP0] Decode batch. #running-req: 4, #token: 570, token usage: 0.00, gen throughput (token/s): 903.83, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:21:25 TP0] Decode batch. #running-req: 4, #token: 730, token usage: 0.00, gen throughput (token/s): 910.95, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:21:25 TP0] Decode batch. #running-req: 4, #token: 890, token usage: 0.00, gen throughput (token/s): 891.38, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:21:25 TP0] Decode batch. #running-req: 4, #token: 1050, token usage: 0.00, gen throughput (token/s): 874.06, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:21:25 TP0] Decode batch. #running-req: 4, #token: 1210, token usage: 0.00, gen throughput (token/s): 875.34, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:21:25 TP0] Decode batch. #running-req: 4, #token: 1370, token usage: 0.00, gen throughput (token/s): 856.21, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:21:26 TP0] Decode batch. #running-req: 4, #token: 1530, token usage: 0.00, gen throughput (token/s): 858.05, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:21:26 TP0] Decode batch. #running-req: 4, #token: 1690, token usage: 0.00, gen throughput (token/s): 871.58, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:21:26 TP0] Decode batch. #running-req: 4, #token: 1850, token usage: 0.00, gen throughput (token/s): 863.23, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:21:26 TP0] Decode batch. #running-req: 4, #token: 2010, token usage: 0.00, gen throughput (token/s): 850.52, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:21:26] INFO:     127.0.0.1:64354 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:21:26] INFO:     127.0.0.1:64346 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:21:26] INFO:     127.0.0.1:64348 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:21:26] INFO:     127.0.0.1:64352 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:21:26 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 129, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-08-25 15:21:26 TP0] Prefill batch. #new-seq: 3, #new-token: 3, #cached-token: 387, token usage: 0.00, #running-req: 1, #queue-req: 0, 
[2025-08-25 15:21:27 TP0] Decode batch. #running-req: 4, #token: 170, token usage: 0.00, gen throughput (token/s): 594.39, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:21:27 TP0] Decode batch. #running-req: 4, #token: 330, token usage: 0.00, gen throughput (token/s): 855.49, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:21:27 TP0] Decode batch. #running-req: 4, #token: 490, token usage: 0.00, gen throughput (token/s): 872.87, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:21:27 TP0] Decode batch. #running-req: 4, #token: 650, token usage: 0.00, gen throughput (token/s): 847.07, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:21:27 TP0] Decode batch. #running-req: 4, #token: 810, token usage: 0.00, gen throughput (token/s): 862.56, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:21:27 TP0] Decode batch. #running-req: 4, #token: 970, token usage: 0.00, gen throughput (token/s): 833.29, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:21:28 TP0] Decode batch. #running-req: 4, #token: 1130, token usage: 0.00, gen throughput (token/s): 866.92, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:21:28 TP0] Decode batch. #running-req: 4, #token: 1290, token usage: 0.00, gen throughput (token/s): 870.53, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:21:28 TP0] Decode batch. #running-req: 4, #token: 1450, token usage: 0.00, gen throughput (token/s): 868.77, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:21:28 TP0] Decode batch. #running-req: 4, #token: 1610, token usage: 0.00, gen throughput (token/s): 870.76, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:21:28 TP0] Decode batch. #running-req: 4, #token: 1770, token usage: 0.00, gen throughput (token/s): 870.52, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:21:29 TP0] Decode batch. #running-req: 4, #token: 1930, token usage: 0.00, gen throughput (token/s): 832.15, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:21:29 TP0] Decode batch. #running-req: 4, #token: 2090, token usage: 0.00, gen throughput (token/s): 843.51, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:21:29] INFO:     127.0.0.1:64354 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:21:29] INFO:     127.0.0.1:64346 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:21:29] INFO:     127.0.0.1:64348 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:21:29] INFO:     127.0.0.1:64352 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:21:29 TP0] Prefill batch. #new-seq: 1, #new-token: 575, #cached-token: 44, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-08-25 15:21:29 TP0] Prefill batch. #new-seq: 3, #new-token: 1725, #cached-token: 132, token usage: 0.02, #running-req: 1, #queue-req: 0, 
[2025-08-25 15:21:30] INFO:     127.0.0.1:5404 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 15:21:30] INFO:     127.0.0.1:5408 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 15:21:30] INFO:     127.0.0.1:5418 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 15:21:30] INFO:     127.0.0.1:5422 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 15:21:30 TP0] Prefill batch. #new-seq: 1, #new-token: 500, #cached-token: 119, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-08-25 15:21:30 TP0] Prefill batch. #new-seq: 3, #new-token: 1500, #cached-token: 357, token usage: 0.00, #running-req: 1, #queue-req: 0, 
[2025-08-25 15:21:30] INFO:     127.0.0.1:5404 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 15:21:30 TP0] Prefill batch. #new-seq: 1, #new-token: 500, #cached-token: 119, token usage: 0.04, #running-req: 4, #queue-req: 0, 
[2025-08-25 15:21:30] INFO:     127.0.0.1:5422 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 15:21:30] INFO:     127.0.0.1:5408 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 15:21:30] INFO:     127.0.0.1:5418 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 15:21:31 TP0] Prefill batch. #new-seq: 3, #new-token: 1500, #cached-token: 357, token usage: 0.00, #running-req: 1, #queue-req: 0, 
[2025-08-25 15:21:31] INFO:     127.0.0.1:5404 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 15:21:31 TP0] Prefill batch. #new-seq: 1, #new-token: 500, #cached-token: 119, token usage: 0.04, #running-req: 4, #queue-req: 0, 
[2025-08-25 15:21:31] INFO:     127.0.0.1:5422 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 15:21:31] INFO:     127.0.0.1:5408 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 15:21:31] INFO:     127.0.0.1:5418 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 15:21:31 TP0] Prefill batch. #new-seq: 3, #new-token: 1500, #cached-token: 357, token usage: 0.00, #running-req: 1, #queue-req: 0, 
[2025-08-25 15:21:31] INFO:     127.0.0.1:5404 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 15:21:32 TP0] Prefill batch. #new-seq: 1, #new-token: 582, #cached-token: 46, token usage: 0.04, #running-req: 4, #queue-req: 0, 
[2025-08-25 15:21:32] INFO:     127.0.0.1:5422 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 15:21:32] INFO:     127.0.0.1:5408 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 15:21:32] INFO:     127.0.0.1:5418 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 15:21:32 TP0] Prefill batch. #new-seq: 2, #new-token: 969, #cached-token: 287, token usage: 0.02, #running-req: 1, #queue-req: 0, 
[2025-08-25 15:21:34 TP0] Decode batch. #running-req: 3, #token: 1676, token usage: 0.04, gen throughput (token/s): 7.48, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:21:36 TP0] Decode batch. #running-req: 3, #token: 1796, token usage: 0.05, gen throughput (token/s): 66.47, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:21:38 TP0] Decode batch. #running-req: 3, #token: 1916, token usage: 0.05, gen throughput (token/s): 66.53, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:21:39 TP0] Decode batch. #running-req: 3, #token: 2036, token usage: 0.05, gen throughput (token/s): 66.28, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:21:39] INFO:     127.0.0.1:5404 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:21:39] INFO:     127.0.0.1:5422 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:21:39] INFO:     127.0.0.1:5408 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:28:56 TP0] Prefill batch. #new-seq: 4, #new-token: 4, #cached-token: 328, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-08-25 15:28:57 TP0] Decode batch. #running-req: 4, #token: 203, token usage: 0.00, gen throughput (token/s): 0.36, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:28:57 TP0] Decode batch. #running-req: 4, #token: 363, token usage: 0.00, gen throughput (token/s): 868.41, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:28:57 TP0] Decode batch. #running-req: 4, #token: 523, token usage: 0.00, gen throughput (token/s): 873.56, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:28:57 TP0] Decode batch. #running-req: 4, #token: 683, token usage: 0.00, gen throughput (token/s): 919.60, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:28:57 TP0] Decode batch. #running-req: 4, #token: 843, token usage: 0.00, gen throughput (token/s): 908.61, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:28:57 TP0] Decode batch. #running-req: 4, #token: 1003, token usage: 0.00, gen throughput (token/s): 906.59, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:28:58 TP0] Decode batch. #running-req: 4, #token: 1163, token usage: 0.00, gen throughput (token/s): 908.11, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:28:58 TP0] Decode batch. #running-req: 4, #token: 1323, token usage: 0.00, gen throughput (token/s): 896.03, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:28:58 TP0] Decode batch. #running-req: 4, #token: 1483, token usage: 0.00, gen throughput (token/s): 892.27, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:28:58 TP0] Decode batch. #running-req: 4, #token: 1643, token usage: 0.00, gen throughput (token/s): 893.61, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:28:58 TP0] Decode batch. #running-req: 4, #token: 1803, token usage: 0.00, gen throughput (token/s): 873.67, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:28:59 TP0] Decode batch. #running-req: 4, #token: 1963, token usage: 0.00, gen throughput (token/s): 864.75, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:28:59] INFO:     127.0.0.1:6608 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:28:59] INFO:     127.0.0.1:6646 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:28:59] INFO:     127.0.0.1:6624 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:28:59] INFO:     127.0.0.1:6630 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:28:59 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 82, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-08-25 15:28:59 TP0] Prefill batch. #new-seq: 3, #new-token: 3, #cached-token: 246, token usage: 0.00, #running-req: 1, #queue-req: 0, 
[2025-08-25 15:28:59 TP0] Decode batch. #running-req: 4, #token: 123, token usage: 0.00, gen throughput (token/s): 568.00, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:28:59 TP0] Decode batch. #running-req: 4, #token: 283, token usage: 0.00, gen throughput (token/s): 887.77, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:28:59 TP0] Decode batch. #running-req: 4, #token: 443, token usage: 0.00, gen throughput (token/s): 892.55, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:28:59 TP0] Decode batch. #running-req: 4, #token: 603, token usage: 0.00, gen throughput (token/s): 870.81, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:29:00 TP0] Decode batch. #running-req: 4, #token: 763, token usage: 0.00, gen throughput (token/s): 879.96, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:29:00 TP0] Decode batch. #running-req: 4, #token: 923, token usage: 0.00, gen throughput (token/s): 841.18, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:29:00 TP0] Decode batch. #running-req: 4, #token: 1083, token usage: 0.00, gen throughput (token/s): 852.12, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:29:00 TP0] Decode batch. #running-req: 4, #token: 1243, token usage: 0.00, gen throughput (token/s): 888.29, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:29:00 TP0] Decode batch. #running-req: 4, #token: 1403, token usage: 0.00, gen throughput (token/s): 851.11, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:29:00 TP0] Decode batch. #running-req: 4, #token: 1563, token usage: 0.00, gen throughput (token/s): 856.89, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:29:01 TP0] Decode batch. #running-req: 4, #token: 1723, token usage: 0.00, gen throughput (token/s): 843.20, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:29:01 TP0] Decode batch. #running-req: 4, #token: 1883, token usage: 0.00, gen throughput (token/s): 840.67, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:29:01 TP0] Decode batch. #running-req: 4, #token: 2043, token usage: 0.00, gen throughput (token/s): 902.83, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:29:01] INFO:     127.0.0.1:6608 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:29:01] INFO:     127.0.0.1:6624 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:29:01] INFO:     127.0.0.1:6630 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:29:01] INFO:     127.0.0.1:6646 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:29:01 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 82, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-08-25 15:29:01 TP0] Prefill batch. #new-seq: 3, #new-token: 3, #cached-token: 246, token usage: 0.00, #running-req: 1, #queue-req: 0, 
[2025-08-25 15:29:01 TP0] Decode batch. #running-req: 4, #token: 203, token usage: 0.00, gen throughput (token/s): 610.53, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:29:01 TP0] Decode batch. #running-req: 4, #token: 363, token usage: 0.00, gen throughput (token/s): 880.04, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:29:02 TP0] Decode batch. #running-req: 4, #token: 523, token usage: 0.00, gen throughput (token/s): 891.72, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:29:02 TP0] Decode batch. #running-req: 4, #token: 683, token usage: 0.00, gen throughput (token/s): 911.98, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:29:02 TP0] Decode batch. #running-req: 4, #token: 843, token usage: 0.00, gen throughput (token/s): 908.79, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:29:02 TP0] Decode batch. #running-req: 4, #token: 1003, token usage: 0.00, gen throughput (token/s): 911.74, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:29:02 TP0] Decode batch. #running-req: 4, #token: 1163, token usage: 0.00, gen throughput (token/s): 901.31, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:29:03 TP0] Decode batch. #running-req: 4, #token: 1323, token usage: 0.00, gen throughput (token/s): 874.55, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:29:03 TP0] Decode batch. #running-req: 4, #token: 1483, token usage: 0.00, gen throughput (token/s): 897.35, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:29:03 TP0] Decode batch. #running-req: 4, #token: 1643, token usage: 0.00, gen throughput (token/s): 898.00, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:29:03 TP0] Decode batch. #running-req: 4, #token: 1803, token usage: 0.00, gen throughput (token/s): 884.73, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:29:03 TP0] Decode batch. #running-req: 4, #token: 1963, token usage: 0.00, gen throughput (token/s): 888.88, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:29:03] INFO:     127.0.0.1:6608 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:29:03] INFO:     127.0.0.1:6624 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:29:03] INFO:     127.0.0.1:6630 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:29:03] INFO:     127.0.0.1:6646 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:29:03 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 82, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-08-25 15:29:03 TP0] Prefill batch. #new-seq: 3, #new-token: 3, #cached-token: 246, token usage: 0.00, #running-req: 1, #queue-req: 0, 
[2025-08-25 15:29:04 TP0] Decode batch. #running-req: 4, #token: 123, token usage: 0.00, gen throughput (token/s): 607.55, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:29:04 TP0] Decode batch. #running-req: 4, #token: 283, token usage: 0.00, gen throughput (token/s): 901.84, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:29:04 TP0] Decode batch. #running-req: 4, #token: 443, token usage: 0.00, gen throughput (token/s): 925.24, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:29:04 TP0] Decode batch. #running-req: 4, #token: 603, token usage: 0.00, gen throughput (token/s): 923.99, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:29:04 TP0] Decode batch. #running-req: 4, #token: 763, token usage: 0.00, gen throughput (token/s): 899.87, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:29:04 TP0] Decode batch. #running-req: 4, #token: 923, token usage: 0.00, gen throughput (token/s): 853.10, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:29:05 TP0] Decode batch. #running-req: 4, #token: 1083, token usage: 0.00, gen throughput (token/s): 862.02, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:29:05 TP0] Decode batch. #running-req: 4, #token: 1243, token usage: 0.00, gen throughput (token/s): 913.19, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:29:05 TP0] Decode batch. #running-req: 4, #token: 1403, token usage: 0.00, gen throughput (token/s): 886.70, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:29:05 TP0] Decode batch. #running-req: 4, #token: 1563, token usage: 0.00, gen throughput (token/s): 875.09, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:29:05 TP0] Decode batch. #running-req: 4, #token: 1723, token usage: 0.00, gen throughput (token/s): 896.77, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:29:06 TP0] Decode batch. #running-req: 4, #token: 1883, token usage: 0.00, gen throughput (token/s): 849.37, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:29:06 TP0] Decode batch. #running-req: 4, #token: 2043, token usage: 0.00, gen throughput (token/s): 881.48, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:29:06] INFO:     127.0.0.1:6608 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:29:06] INFO:     127.0.0.1:6624 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:29:06] INFO:     127.0.0.1:6630 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:29:06] INFO:     127.0.0.1:6646 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:29:06 TP0] Prefill batch. #new-seq: 4, #new-token: 2120, #cached-token: 168, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-08-25 15:29:06] INFO:     127.0.0.1:24394 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 15:29:06] INFO:     127.0.0.1:24408 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 15:29:06] INFO:     127.0.0.1:24420 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 15:29:07] INFO:     127.0.0.1:24426 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 15:29:07 TP0] Prefill batch. #new-seq: 1, #new-token: 500, #cached-token: 72, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-08-25 15:29:07 TP0] Prefill batch. #new-seq: 3, #new-token: 1500, #cached-token: 216, token usage: 0.01, #running-req: 1, #queue-req: 0, 
[2025-08-25 15:29:07] INFO:     127.0.0.1:24394 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 15:29:07] INFO:     127.0.0.1:24408 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 15:29:07] INFO:     127.0.0.1:24420 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 15:29:07] INFO:     127.0.0.1:24426 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 15:29:07 TP0] Prefill batch. #new-seq: 1, #new-token: 500, #cached-token: 72, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-08-25 15:29:07 TP0] Prefill batch. #new-seq: 3, #new-token: 1500, #cached-token: 216, token usage: 0.01, #running-req: 1, #queue-req: 0, 
[2025-08-25 15:29:08] INFO:     127.0.0.1:24394 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 15:29:08] INFO:     127.0.0.1:24408 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 15:29:08] INFO:     127.0.0.1:24420 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 15:29:08] INFO:     127.0.0.1:24426 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 15:29:08 TP0] Prefill batch. #new-seq: 1, #new-token: 500, #cached-token: 72, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-08-25 15:29:08 TP0] Prefill batch. #new-seq: 3, #new-token: 1500, #cached-token: 216, token usage: 0.01, #running-req: 1, #queue-req: 0, 
[2025-08-25 15:29:09] INFO:     127.0.0.1:24394 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 15:29:09] INFO:     127.0.0.1:24408 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 15:29:09] INFO:     127.0.0.1:24420 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 15:29:09] INFO:     127.0.0.1:24426 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 15:29:09 TP0] Prefill batch. #new-seq: 4, #new-token: 4, #cached-token: 844, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-08-25 15:29:09 TP0] Decode batch. #running-req: 4, #token: 332, token usage: 0.00, gen throughput (token/s): 49.40, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:29:09 TP0] Decode batch. #running-req: 4, #token: 492, token usage: 0.00, gen throughput (token/s): 890.98, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:29:09 TP0] Decode batch. #running-req: 4, #token: 652, token usage: 0.00, gen throughput (token/s): 859.58, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:29:09 TP0] Decode batch. #running-req: 4, #token: 812, token usage: 0.00, gen throughput (token/s): 853.71, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:29:10 TP0] Decode batch. #running-req: 4, #token: 972, token usage: 0.00, gen throughput (token/s): 882.63, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:29:10 TP0] Decode batch. #running-req: 4, #token: 1132, token usage: 0.00, gen throughput (token/s): 894.47, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:29:10 TP0] Decode batch. #running-req: 4, #token: 1292, token usage: 0.00, gen throughput (token/s): 864.17, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:29:10 TP0] Decode batch. #running-req: 4, #token: 1452, token usage: 0.00, gen throughput (token/s): 874.48, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:29:10 TP0] Decode batch. #running-req: 4, #token: 1612, token usage: 0.00, gen throughput (token/s): 872.91, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:29:11 TP0] Decode batch. #running-req: 4, #token: 1772, token usage: 0.00, gen throughput (token/s): 875.28, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:29:11 TP0] Decode batch. #running-req: 4, #token: 1932, token usage: 0.00, gen throughput (token/s): 859.14, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:29:11 TP0] Decode batch. #running-req: 4, #token: 2092, token usage: 0.00, gen throughput (token/s): 855.04, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:29:11] INFO:     127.0.0.1:6608 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:29:11] INFO:     127.0.0.1:6624 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:29:11] INFO:     127.0.0.1:6630 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:29:11] INFO:     127.0.0.1:6646 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:29:11 TP0] Prefill batch. #new-seq: 4, #new-token: 4, #cached-token: 844, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-08-25 15:29:11 TP0] Decode batch. #running-req: 4, #token: 252, token usage: 0.00, gen throughput (token/s): 658.42, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:29:11 TP0] Decode batch. #running-req: 4, #token: 412, token usage: 0.00, gen throughput (token/s): 855.90, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:29:12 TP0] Decode batch. #running-req: 4, #token: 572, token usage: 0.00, gen throughput (token/s): 871.32, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:29:12 TP0] Decode batch. #running-req: 4, #token: 732, token usage: 0.00, gen throughput (token/s): 879.08, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:29:12 TP0] Decode batch. #running-req: 4, #token: 892, token usage: 0.00, gen throughput (token/s): 870.52, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:29:12 TP0] Decode batch. #running-req: 4, #token: 1052, token usage: 0.00, gen throughput (token/s): 865.56, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:29:12 TP0] Decode batch. #running-req: 4, #token: 1212, token usage: 0.00, gen throughput (token/s): 879.67, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:29:12 TP0] Decode batch. #running-req: 4, #token: 1372, token usage: 0.00, gen throughput (token/s): 871.53, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:29:13 TP0] Decode batch. #running-req: 4, #token: 1532, token usage: 0.00, gen throughput (token/s): 864.02, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:29:13 TP0] Decode batch. #running-req: 4, #token: 1692, token usage: 0.00, gen throughput (token/s): 875.69, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:29:13 TP0] Decode batch. #running-req: 4, #token: 1852, token usage: 0.00, gen throughput (token/s): 871.71, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:29:13 TP0] Decode batch. #running-req: 4, #token: 2012, token usage: 0.00, gen throughput (token/s): 881.41, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:29:13 TP0] Decode batch. #running-req: 4, #token: 2172, token usage: 0.00, gen throughput (token/s): 870.63, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:29:13] INFO:     127.0.0.1:6646 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:29:13] INFO:     127.0.0.1:6608 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:29:13] INFO:     127.0.0.1:6624 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:29:13] INFO:     127.0.0.1:6630 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:29:13 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 211, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-08-25 15:29:13 TP0] Prefill batch. #new-seq: 3, #new-token: 3, #cached-token: 633, token usage: 0.00, #running-req: 1, #queue-req: 0, 
[2025-08-25 15:29:14 TP0] Decode batch. #running-req: 4, #token: 332, token usage: 0.00, gen throughput (token/s): 595.26, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:29:14 TP0] Decode batch. #running-req: 4, #token: 492, token usage: 0.00, gen throughput (token/s): 879.84, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:29:14 TP0] Decode batch. #running-req: 4, #token: 652, token usage: 0.00, gen throughput (token/s): 876.02, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:29:14 TP0] Decode batch. #running-req: 4, #token: 812, token usage: 0.00, gen throughput (token/s): 876.58, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:29:14 TP0] Decode batch. #running-req: 4, #token: 972, token usage: 0.00, gen throughput (token/s): 889.21, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:29:15 TP0] Decode batch. #running-req: 4, #token: 1132, token usage: 0.00, gen throughput (token/s): 877.95, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:29:15 TP0] Decode batch. #running-req: 4, #token: 1292, token usage: 0.00, gen throughput (token/s): 870.02, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:29:15 TP0] Decode batch. #running-req: 4, #token: 1452, token usage: 0.00, gen throughput (token/s): 878.79, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:29:15 TP0] Decode batch. #running-req: 4, #token: 1612, token usage: 0.00, gen throughput (token/s): 872.46, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:29:15 TP0] Decode batch. #running-req: 4, #token: 1772, token usage: 0.00, gen throughput (token/s): 862.34, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:29:15 TP0] Decode batch. #running-req: 4, #token: 1932, token usage: 0.00, gen throughput (token/s): 900.61, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:29:16 TP0] Decode batch. #running-req: 4, #token: 2092, token usage: 0.00, gen throughput (token/s): 908.29, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:29:16] INFO:     127.0.0.1:6608 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:29:16] INFO:     127.0.0.1:6624 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:29:16] INFO:     127.0.0.1:6630 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:29:16] INFO:     127.0.0.1:6646 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:29:16 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 211, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-08-25 15:29:16 TP0] Prefill batch. #new-seq: 3, #new-token: 3, #cached-token: 633, token usage: 0.00, #running-req: 1, #queue-req: 0, 
[2025-08-25 15:29:16 TP0] Decode batch. #running-req: 4, #token: 252, token usage: 0.00, gen throughput (token/s): 598.04, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:29:16 TP0] Decode batch. #running-req: 4, #token: 412, token usage: 0.00, gen throughput (token/s): 875.54, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:29:16 TP0] Decode batch. #running-req: 4, #token: 572, token usage: 0.00, gen throughput (token/s): 879.15, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:29:16 TP0] Decode batch. #running-req: 4, #token: 732, token usage: 0.00, gen throughput (token/s): 874.58, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:29:17 TP0] Decode batch. #running-req: 4, #token: 892, token usage: 0.00, gen throughput (token/s): 899.94, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:29:17 TP0] Decode batch. #running-req: 4, #token: 1052, token usage: 0.00, gen throughput (token/s): 877.66, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:29:17 TP0] Decode batch. #running-req: 4, #token: 1212, token usage: 0.00, gen throughput (token/s): 883.17, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:29:17 TP0] Decode batch. #running-req: 4, #token: 1372, token usage: 0.00, gen throughput (token/s): 889.27, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:29:17 TP0] Decode batch. #running-req: 4, #token: 1532, token usage: 0.00, gen throughput (token/s): 868.19, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:29:18 TP0] Decode batch. #running-req: 4, #token: 1692, token usage: 0.00, gen throughput (token/s): 883.73, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:29:18 TP0] Decode batch. #running-req: 4, #token: 1852, token usage: 0.00, gen throughput (token/s): 878.91, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:29:18 TP0] Decode batch. #running-req: 4, #token: 2012, token usage: 0.00, gen throughput (token/s): 881.82, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:29:18 TP0] Decode batch. #running-req: 4, #token: 2172, token usage: 0.00, gen throughput (token/s): 909.28, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:29:18] INFO:     127.0.0.1:6608 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:29:18] INFO:     127.0.0.1:6624 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:29:18] INFO:     127.0.0.1:6630 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:29:18] INFO:     127.0.0.1:6646 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:29:18 TP0] Prefill batch. #new-seq: 1, #new-token: 659, #cached-token: 42, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-08-25 15:29:18 TP0] Prefill batch. #new-seq: 1, #new-token: 659, #cached-token: 42, token usage: 0.02, #running-req: 1, #queue-req: 0, 
[2025-08-25 15:29:19 TP0] Prefill batch. #new-seq: 2, #new-token: 1000, #cached-token: 402, token usage: 0.02, #running-req: 2, #queue-req: 0, 
[2025-08-25 15:29:19] INFO:     127.0.0.1:22620 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 15:29:19] INFO:     127.0.0.1:22626 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 15:29:19 TP0] Prefill batch. #new-seq: 2, #new-token: 1000, #cached-token: 402, token usage: 0.01, #running-req: 2, #queue-req: 0, 
[2025-08-25 15:29:19] INFO:     127.0.0.1:22636 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 15:29:19] INFO:     127.0.0.1:22640 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 15:29:19 TP0] Prefill batch. #new-seq: 2, #new-token: 1000, #cached-token: 402, token usage: 0.03, #running-req: 4, #queue-req: 0, 
[2025-08-25 15:29:19] INFO:     127.0.0.1:22620 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 15:29:19] INFO:     127.0.0.1:22626 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 15:29:20 TP0] Prefill batch. #new-seq: 2, #new-token: 1000, #cached-token: 402, token usage: 0.01, #running-req: 2, #queue-req: 0, 
[2025-08-25 15:29:20] INFO:     127.0.0.1:22640 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 15:29:20] INFO:     127.0.0.1:22636 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 15:29:20 TP0] Prefill batch. #new-seq: 2, #new-token: 1000, #cached-token: 402, token usage: 0.03, #running-req: 4, #queue-req: 0, 
[2025-08-25 15:29:20] INFO:     127.0.0.1:22620 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 15:29:20] INFO:     127.0.0.1:22626 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 15:29:20 TP0] Prefill batch. #new-seq: 2, #new-token: 1000, #cached-token: 402, token usage: 0.01, #running-req: 2, #queue-req: 0, 
[2025-08-25 15:29:20] INFO:     127.0.0.1:22640 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 15:29:20] INFO:     127.0.0.1:22636 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 15:29:21 TP0] Prefill batch. #new-seq: 2, #new-token: 1000, #cached-token: 402, token usage: 0.03, #running-req: 4, #queue-req: 0, 
[2025-08-25 15:29:21] INFO:     127.0.0.1:22620 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 15:29:21] INFO:     127.0.0.1:22626 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 15:29:21 TP0] Prefill batch. #new-seq: 2, #new-token: 1332, #cached-token: 88, token usage: 0.00, #running-req: 2, #queue-req: 0, 
[2025-08-25 15:29:21] INFO:     127.0.0.1:22640 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 15:29:21] INFO:     127.0.0.1:22636 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 15:29:21 TP0] Prefill batch. #new-seq: 1, #new-token: 666, #cached-token: 44, token usage: 0.03, #running-req: 4, #queue-req: 0, 
[2025-08-25 15:29:23 TP0] Decode batch. #running-req: 3, #token: 1790, token usage: 0.04, gen throughput (token/s): 0.25, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:29:25 TP0] Decode batch. #running-req: 3, #token: 1910, token usage: 0.05, gen throughput (token/s): 66.55, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:29:27 TP0] Decode batch. #running-req: 3, #token: 2030, token usage: 0.05, gen throughput (token/s): 66.49, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:29:28 TP0] Decode batch. #running-req: 3, #token: 2150, token usage: 0.05, gen throughput (token/s): 66.15, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:29:29] INFO:     127.0.0.1:22620 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:29:29] INFO:     127.0.0.1:22626 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:29:29] INFO:     127.0.0.1:22640 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:29:29 TP0] Prefill batch. #new-seq: 4, #new-token: 4, #cached-token: 664, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-08-25 15:29:29 TP0] Decode batch. #running-req: 4, #token: 287, token usage: 0.00, gen throughput (token/s): 15.02, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:29:29 TP0] Decode batch. #running-req: 4, #token: 447, token usage: 0.00, gen throughput (token/s): 883.26, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:29:29 TP0] Decode batch. #running-req: 4, #token: 607, token usage: 0.00, gen throughput (token/s): 862.12, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:29:29 TP0] Decode batch. #running-req: 4, #token: 767, token usage: 0.00, gen throughput (token/s): 813.31, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:29:29 TP0] Decode batch. #running-req: 4, #token: 927, token usage: 0.00, gen throughput (token/s): 885.09, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:29:30 TP0] Decode batch. #running-req: 4, #token: 1087, token usage: 0.00, gen throughput (token/s): 871.43, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:29:30 TP0] Decode batch. #running-req: 4, #token: 1247, token usage: 0.00, gen throughput (token/s): 865.47, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:29:30 TP0] Decode batch. #running-req: 4, #token: 1407, token usage: 0.00, gen throughput (token/s): 849.87, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:29:30 TP0] Decode batch. #running-req: 4, #token: 1567, token usage: 0.00, gen throughput (token/s): 869.64, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:29:30 TP0] Decode batch. #running-req: 4, #token: 1727, token usage: 0.00, gen throughput (token/s): 861.30, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:29:31 TP0] Decode batch. #running-req: 4, #token: 1887, token usage: 0.00, gen throughput (token/s): 836.48, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:29:31 TP0] Decode batch. #running-req: 4, #token: 2047, token usage: 0.00, gen throughput (token/s): 871.36, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:29:31] INFO:     127.0.0.1:14028 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:29:31] INFO:     127.0.0.1:14038 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:29:31] INFO:     127.0.0.1:14050 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:29:31] INFO:     127.0.0.1:14062 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:29:31 TP0] Prefill batch. #new-seq: 4, #new-token: 4, #cached-token: 664, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-08-25 15:29:31 TP0] Decode batch. #running-req: 4, #token: 207, token usage: 0.00, gen throughput (token/s): 642.76, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:29:31 TP0] Decode batch. #running-req: 4, #token: 367, token usage: 0.00, gen throughput (token/s): 882.41, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:29:31 TP0] Decode batch. #running-req: 4, #token: 527, token usage: 0.00, gen throughput (token/s): 879.62, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:29:32 TP0] Decode batch. #running-req: 4, #token: 687, token usage: 0.00, gen throughput (token/s): 854.25, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:29:32 TP0] Decode batch. #running-req: 4, #token: 847, token usage: 0.00, gen throughput (token/s): 878.68, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:29:32 TP0] Decode batch. #running-req: 4, #token: 1007, token usage: 0.00, gen throughput (token/s): 884.18, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:29:32 TP0] Decode batch. #running-req: 4, #token: 1167, token usage: 0.00, gen throughput (token/s): 881.19, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:29:32 TP0] Decode batch. #running-req: 4, #token: 1327, token usage: 0.00, gen throughput (token/s): 878.77, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:29:33 TP0] Decode batch. #running-req: 4, #token: 1487, token usage: 0.00, gen throughput (token/s): 869.45, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:29:33 TP0] Decode batch. #running-req: 4, #token: 1647, token usage: 0.00, gen throughput (token/s): 905.35, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:29:33 TP0] Decode batch. #running-req: 4, #token: 1807, token usage: 0.00, gen throughput (token/s): 921.26, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:29:33 TP0] Decode batch. #running-req: 4, #token: 1967, token usage: 0.00, gen throughput (token/s): 912.28, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:29:33 TP0] Decode batch. #running-req: 4, #token: 2127, token usage: 0.00, gen throughput (token/s): 909.65, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:29:33] INFO:     127.0.0.1:14050 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:29:33] INFO:     127.0.0.1:14062 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:29:33] INFO:     127.0.0.1:14028 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:29:33] INFO:     127.0.0.1:14038 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:29:33 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 166, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-08-25 15:29:33 TP0] Prefill batch. #new-seq: 3, #new-token: 3, #cached-token: 498, token usage: 0.00, #running-req: 1, #queue-req: 0, 
[2025-08-25 15:29:33 TP0] Decode batch. #running-req: 4, #token: 287, token usage: 0.00, gen throughput (token/s): 594.56, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:29:34 TP0] Decode batch. #running-req: 4, #token: 447, token usage: 0.00, gen throughput (token/s): 919.97, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:29:34 TP0] Decode batch. #running-req: 4, #token: 607, token usage: 0.00, gen throughput (token/s): 902.13, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:29:34 TP0] Decode batch. #running-req: 4, #token: 767, token usage: 0.00, gen throughput (token/s): 900.77, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:29:34 TP0] Decode batch. #running-req: 4, #token: 927, token usage: 0.00, gen throughput (token/s): 890.87, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:29:34 TP0] Decode batch. #running-req: 4, #token: 1087, token usage: 0.00, gen throughput (token/s): 905.62, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:29:35 TP0] Decode batch. #running-req: 4, #token: 1247, token usage: 0.00, gen throughput (token/s): 896.75, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:29:35 TP0] Decode batch. #running-req: 4, #token: 1407, token usage: 0.00, gen throughput (token/s): 888.78, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:29:35 TP0] Decode batch. #running-req: 4, #token: 1567, token usage: 0.00, gen throughput (token/s): 832.45, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:29:35 TP0] Decode batch. #running-req: 4, #token: 1727, token usage: 0.00, gen throughput (token/s): 892.00, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:29:35 TP0] Decode batch. #running-req: 4, #token: 1887, token usage: 0.00, gen throughput (token/s): 884.57, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:29:35 TP0] Decode batch. #running-req: 4, #token: 2047, token usage: 0.00, gen throughput (token/s): 844.05, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:29:36] INFO:     127.0.0.1:14062 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:29:36] INFO:     127.0.0.1:14028 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:29:36] INFO:     127.0.0.1:14038 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:29:36] INFO:     127.0.0.1:14050 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:29:36 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 166, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-08-25 15:29:36 TP0] Prefill batch. #new-seq: 3, #new-token: 3, #cached-token: 498, token usage: 0.00, #running-req: 1, #queue-req: 0, 
[2025-08-25 15:29:36 TP0] Decode batch. #running-req: 4, #token: 207, token usage: 0.00, gen throughput (token/s): 585.36, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:29:36 TP0] Decode batch. #running-req: 4, #token: 367, token usage: 0.00, gen throughput (token/s): 896.13, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:29:36 TP0] Decode batch. #running-req: 4, #token: 527, token usage: 0.00, gen throughput (token/s): 889.20, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:29:36 TP0] Decode batch. #running-req: 4, #token: 687, token usage: 0.00, gen throughput (token/s): 888.25, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:29:36 TP0] Decode batch. #running-req: 4, #token: 847, token usage: 0.00, gen throughput (token/s): 878.96, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:29:37 TP0] Decode batch. #running-req: 4, #token: 1007, token usage: 0.00, gen throughput (token/s): 901.25, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:29:37 TP0] Decode batch. #running-req: 4, #token: 1167, token usage: 0.00, gen throughput (token/s): 884.34, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:29:37 TP0] Decode batch. #running-req: 4, #token: 1327, token usage: 0.00, gen throughput (token/s): 877.45, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:29:37 TP0] Decode batch. #running-req: 4, #token: 1487, token usage: 0.00, gen throughput (token/s): 886.59, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:29:37 TP0] Decode batch. #running-req: 4, #token: 1647, token usage: 0.00, gen throughput (token/s): 897.31, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:29:38 TP0] Decode batch. #running-req: 4, #token: 1807, token usage: 0.00, gen throughput (token/s): 891.97, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:29:38 TP0] Decode batch. #running-req: 4, #token: 1967, token usage: 0.00, gen throughput (token/s): 898.31, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:29:38 TP0] Decode batch. #running-req: 4, #token: 2127, token usage: 0.00, gen throughput (token/s): 905.98, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:29:38] INFO:     127.0.0.1:14062 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:29:38] INFO:     127.0.0.1:14028 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:29:38] INFO:     127.0.0.1:14038 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:29:38] INFO:     127.0.0.1:14050 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:29:38 TP0] Prefill batch. #new-seq: 1, #new-token: 614, #cached-token: 42, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-08-25 15:29:38 TP0] Prefill batch. #new-seq: 3, #new-token: 1842, #cached-token: 126, token usage: 0.02, #running-req: 1, #queue-req: 0, 
[2025-08-25 15:29:39] INFO:     127.0.0.1:45406 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 15:29:39] INFO:     127.0.0.1:45408 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 15:29:39] INFO:     127.0.0.1:45410 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 15:29:39] INFO:     127.0.0.1:45422 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 15:29:39 TP0] Prefill batch. #new-seq: 1, #new-token: 500, #cached-token: 156, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-08-25 15:29:39 TP0] Prefill batch. #new-seq: 3, #new-token: 1500, #cached-token: 468, token usage: 0.02, #running-req: 1, #queue-req: 0, 
[2025-08-25 15:29:39] INFO:     127.0.0.1:45406 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 15:29:40] INFO:     127.0.0.1:45422 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 15:29:40] INFO:     127.0.0.1:45408 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 15:29:40] INFO:     127.0.0.1:45410 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 15:29:40 TP0] Prefill batch. #new-seq: 1, #new-token: 500, #cached-token: 156, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-08-25 15:29:40 TP0] Prefill batch. #new-seq: 3, #new-token: 1500, #cached-token: 468, token usage: 0.02, #running-req: 1, #queue-req: 0, 
[2025-08-25 15:29:40] INFO:     127.0.0.1:45406 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 15:29:40 TP0] Prefill batch. #new-seq: 1, #new-token: 500, #cached-token: 156, token usage: 0.00, #running-req: 3, #queue-req: 0, 
[2025-08-25 15:29:40] INFO:     127.0.0.1:45422 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 15:29:40] INFO:     127.0.0.1:45408 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 15:29:40] INFO:     127.0.0.1:45410 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 15:29:40 TP0] Prefill batch. #new-seq: 3, #new-token: 1500, #cached-token: 468, token usage: 0.02, #running-req: 4, #queue-req: 0, 
[2025-08-25 15:29:40] INFO:     127.0.0.1:45406 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 15:29:41 TP0] Prefill batch. #new-seq: 1, #new-token: 621, #cached-token: 44, token usage: 0.00, #running-req: 3, #queue-req: 0, 
[2025-08-25 15:29:41] INFO:     127.0.0.1:45422 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 15:29:41] INFO:     127.0.0.1:45408 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 15:29:41] INFO:     127.0.0.1:45410 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 15:29:41 TP0] Prefill batch. #new-seq: 2, #new-token: 1242, #cached-token: 88, token usage: 0.02, #running-req: 4, #queue-req: 0, 
[2025-08-25 15:29:43 TP0] Decode batch. #running-req: 3, #token: 1763, token usage: 0.04, gen throughput (token/s): 8.22, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:29:45 TP0] Decode batch. #running-req: 3, #token: 1883, token usage: 0.05, gen throughput (token/s): 66.68, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:29:47 TP0] Decode batch. #running-req: 3, #token: 2003, token usage: 0.05, gen throughput (token/s): 66.31, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:29:48] INFO:     127.0.0.1:45406 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:29:48] INFO:     127.0.0.1:45422 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:29:48] INFO:     127.0.0.1:45408 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:29:48 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 109, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-08-25 15:29:48 TP0] Prefill batch. #new-seq: 3, #new-token: 3, #cached-token: 327, token usage: 0.00, #running-req: 1, #queue-req: 0, 
[2025-08-25 15:29:49 TP0] Decode batch. #running-req: 4, #token: 230, token usage: 0.00, gen throughput (token/s): 15.07, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:29:49 TP0] Decode batch. #running-req: 4, #token: 390, token usage: 0.00, gen throughput (token/s): 871.64, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:29:49 TP0] Decode batch. #running-req: 4, #token: 550, token usage: 0.00, gen throughput (token/s): 883.98, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:29:49 TP0] Decode batch. #running-req: 4, #token: 710, token usage: 0.00, gen throughput (token/s): 879.73, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:29:49 TP0] Decode batch. #running-req: 4, #token: 870, token usage: 0.00, gen throughput (token/s): 877.32, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:29:49 TP0] Decode batch. #running-req: 4, #token: 1030, token usage: 0.00, gen throughput (token/s): 881.34, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:29:50 TP0] Decode batch. #running-req: 4, #token: 1190, token usage: 0.00, gen throughput (token/s): 876.28, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:29:50 TP0] Decode batch. #running-req: 4, #token: 1350, token usage: 0.00, gen throughput (token/s): 862.66, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:29:50 TP0] Decode batch. #running-req: 4, #token: 1510, token usage: 0.00, gen throughput (token/s): 874.26, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:29:50 TP0] Decode batch. #running-req: 4, #token: 1670, token usage: 0.00, gen throughput (token/s): 862.63, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:29:50 TP0] Decode batch. #running-req: 4, #token: 1830, token usage: 0.00, gen throughput (token/s): 859.09, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:29:51 TP0] Decode batch. #running-req: 4, #token: 1990, token usage: 0.00, gen throughput (token/s): 874.97, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:29:51] INFO:     127.0.0.1:51600 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:29:51] INFO:     127.0.0.1:51608 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:29:51] INFO:     127.0.0.1:51620 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:29:51] INFO:     127.0.0.1:51636 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:29:51 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 109, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-08-25 15:29:51 TP0] Prefill batch. #new-seq: 3, #new-token: 3, #cached-token: 327, token usage: 0.00, #running-req: 1, #queue-req: 0, 
[2025-08-25 15:29:51 TP0] Decode batch. #running-req: 4, #token: 150, token usage: 0.00, gen throughput (token/s): 599.63, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:29:51 TP0] Decode batch. #running-req: 4, #token: 310, token usage: 0.00, gen throughput (token/s): 877.63, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:29:51 TP0] Decode batch. #running-req: 4, #token: 470, token usage: 0.00, gen throughput (token/s): 878.18, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:29:51 TP0] Decode batch. #running-req: 4, #token: 630, token usage: 0.00, gen throughput (token/s): 860.24, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:29:52 TP0] Decode batch. #running-req: 4, #token: 790, token usage: 0.00, gen throughput (token/s): 874.20, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:29:52 TP0] Decode batch. #running-req: 4, #token: 950, token usage: 0.00, gen throughput (token/s): 870.31, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:29:52 TP0] Decode batch. #running-req: 4, #token: 1110, token usage: 0.00, gen throughput (token/s): 884.06, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:29:52 TP0] Decode batch. #running-req: 4, #token: 1270, token usage: 0.00, gen throughput (token/s): 872.09, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:29:52 TP0] Decode batch. #running-req: 4, #token: 1430, token usage: 0.00, gen throughput (token/s): 891.10, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:29:52 TP0] Decode batch. #running-req: 4, #token: 1590, token usage: 0.00, gen throughput (token/s): 874.63, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:29:53 TP0] Decode batch. #running-req: 4, #token: 1750, token usage: 0.00, gen throughput (token/s): 887.24, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:29:53 TP0] Decode batch. #running-req: 4, #token: 1910, token usage: 0.00, gen throughput (token/s): 872.76, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:29:53 TP0] Decode batch. #running-req: 4, #token: 2070, token usage: 0.00, gen throughput (token/s): 874.47, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:29:53] INFO:     127.0.0.1:51636 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:29:53] INFO:     127.0.0.1:51600 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:29:53] INFO:     127.0.0.1:51608 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:29:53] INFO:     127.0.0.1:51620 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:29:53 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 109, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-08-25 15:29:53 TP0] Prefill batch. #new-seq: 3, #new-token: 3, #cached-token: 327, token usage: 0.00, #running-req: 1, #queue-req: 0, 
[2025-08-25 15:29:53 TP0] Decode batch. #running-req: 4, #token: 230, token usage: 0.00, gen throughput (token/s): 601.64, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:29:53 TP0] Decode batch. #running-req: 4, #token: 390, token usage: 0.00, gen throughput (token/s): 878.31, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:29:54 TP0] Decode batch. #running-req: 4, #token: 550, token usage: 0.00, gen throughput (token/s): 886.27, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:29:54 TP0] Decode batch. #running-req: 4, #token: 710, token usage: 0.00, gen throughput (token/s): 848.00, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:29:54 TP0] Decode batch. #running-req: 4, #token: 870, token usage: 0.00, gen throughput (token/s): 887.72, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:29:54 TP0] Decode batch. #running-req: 4, #token: 1030, token usage: 0.00, gen throughput (token/s): 837.77, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:29:54 TP0] Decode batch. #running-req: 4, #token: 1190, token usage: 0.00, gen throughput (token/s): 851.53, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:29:55 TP0] Decode batch. #running-req: 4, #token: 1350, token usage: 0.00, gen throughput (token/s): 854.91, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:29:55 TP0] Decode batch. #running-req: 4, #token: 1510, token usage: 0.00, gen throughput (token/s): 868.22, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:29:55 TP0] Decode batch. #running-req: 4, #token: 1670, token usage: 0.00, gen throughput (token/s): 874.24, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:29:55 TP0] Decode batch. #running-req: 4, #token: 1830, token usage: 0.00, gen throughput (token/s): 890.77, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:29:55 TP0] Decode batch. #running-req: 4, #token: 1990, token usage: 0.00, gen throughput (token/s): 870.62, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:29:55] INFO:     127.0.0.1:51636 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:29:55] INFO:     127.0.0.1:51600 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:29:55] INFO:     127.0.0.1:51608 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:29:55] INFO:     127.0.0.1:51620 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:29:55 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 109, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-08-25 15:29:55 TP0] Prefill batch. #new-seq: 3, #new-token: 3, #cached-token: 327, token usage: 0.00, #running-req: 1, #queue-req: 0, 
[2025-08-25 15:29:56 TP0] Decode batch. #running-req: 4, #token: 150, token usage: 0.00, gen throughput (token/s): 599.84, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:29:56 TP0] Decode batch. #running-req: 4, #token: 310, token usage: 0.00, gen throughput (token/s): 891.10, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:29:56 TP0] Decode batch. #running-req: 4, #token: 470, token usage: 0.00, gen throughput (token/s): 914.86, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:29:56 TP0] Decode batch. #running-req: 4, #token: 630, token usage: 0.00, gen throughput (token/s): 916.17, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:29:56 TP0] Decode batch. #running-req: 4, #token: 790, token usage: 0.00, gen throughput (token/s): 918.53, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:29:56 TP0] Decode batch. #running-req: 4, #token: 950, token usage: 0.00, gen throughput (token/s): 908.51, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:29:57 TP0] Decode batch. #running-req: 4, #token: 1110, token usage: 0.00, gen throughput (token/s): 925.75, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:29:57 TP0] Decode batch. #running-req: 4, #token: 1270, token usage: 0.00, gen throughput (token/s): 893.76, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:29:57 TP0] Decode batch. #running-req: 4, #token: 1430, token usage: 0.00, gen throughput (token/s): 890.03, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:29:57 TP0] Decode batch. #running-req: 4, #token: 1590, token usage: 0.00, gen throughput (token/s): 871.98, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:29:57 TP0] Decode batch. #running-req: 4, #token: 1750, token usage: 0.00, gen throughput (token/s): 881.99, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:29:57 TP0] Decode batch. #running-req: 4, #token: 1910, token usage: 0.00, gen throughput (token/s): 869.44, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:29:58 TP0] Decode batch. #running-req: 4, #token: 2070, token usage: 0.00, gen throughput (token/s): 869.79, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:29:58] INFO:     127.0.0.1:51636 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:29:58] INFO:     127.0.0.1:51600 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:29:58] INFO:     127.0.0.1:51608 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:29:58] INFO:     127.0.0.1:51620 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:29:58 TP0] Prefill batch. #new-seq: 1, #new-token: 555, #cached-token: 44, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-08-25 15:29:58 TP0] Prefill batch. #new-seq: 3, #new-token: 1665, #cached-token: 132, token usage: 0.02, #running-req: 1, #queue-req: 0, 
[2025-08-25 15:29:59] INFO:     127.0.0.1:61930 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 15:29:59] INFO:     127.0.0.1:61932 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 15:29:59] INFO:     127.0.0.1:61940 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 15:29:59] INFO:     127.0.0.1:61950 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 15:29:59 TP0] Prefill batch. #new-seq: 1, #new-token: 500, #cached-token: 99, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-08-25 15:29:59 TP0] Prefill batch. #new-seq: 3, #new-token: 1500, #cached-token: 297, token usage: 0.02, #running-req: 1, #queue-req: 0, 
[2025-08-25 15:29:59] INFO:     127.0.0.1:61930 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 15:29:59 TP0] Prefill batch. #new-seq: 1, #new-token: 500, #cached-token: 99, token usage: 0.00, #running-req: 3, #queue-req: 0, 
[2025-08-25 15:29:59] INFO:     127.0.0.1:61950 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 15:29:59] INFO:     127.0.0.1:61932 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 15:29:59] INFO:     127.0.0.1:61940 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 15:29:59 TP0] Prefill batch. #new-seq: 3, #new-token: 1500, #cached-token: 297, token usage: 0.02, #running-req: 4, #queue-req: 0, 
[2025-08-25 15:29:59] INFO:     127.0.0.1:61930 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 15:30:00 TP0] Prefill batch. #new-seq: 1, #new-token: 500, #cached-token: 99, token usage: 0.00, #running-req: 3, #queue-req: 0, 
[2025-08-25 15:30:00] INFO:     127.0.0.1:61950 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 15:30:00] INFO:     127.0.0.1:61932 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 15:30:00] INFO:     127.0.0.1:61940 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 15:30:00 TP0] Decode batch. #running-req: 3, #token: 599, token usage: 0.02, gen throughput (token/s): 8.87, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:30:00 TP0] Prefill batch. #new-seq: 3, #new-token: 1500, #cached-token: 297, token usage: 0.02, #running-req: 4, #queue-req: 0, 
[2025-08-25 15:30:00] INFO:     127.0.0.1:61930 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 15:30:01] INFO:     127.0.0.1:61950 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 15:30:01] INFO:     127.0.0.1:61932 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 15:30:01] INFO:     127.0.0.1:61940 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 15:30:01 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 135, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-08-25 15:30:01 TP0] Prefill batch. #new-seq: 3, #new-token: 3, #cached-token: 405, token usage: 0.00, #running-req: 1, #queue-req: 0, 
[2025-08-25 15:30:01 TP0] Decode batch. #running-req: 4, #token: 256, token usage: 0.00, gen throughput (token/s): 48.86, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:30:01 TP0] Decode batch. #running-req: 4, #token: 416, token usage: 0.00, gen throughput (token/s): 881.76, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:30:01 TP0] Decode batch. #running-req: 4, #token: 576, token usage: 0.00, gen throughput (token/s): 861.72, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:30:02 TP0] Decode batch. #running-req: 4, #token: 736, token usage: 0.00, gen throughput (token/s): 888.74, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:30:02 TP0] Decode batch. #running-req: 4, #token: 896, token usage: 0.00, gen throughput (token/s): 876.79, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:30:02 TP0] Decode batch. #running-req: 4, #token: 1056, token usage: 0.00, gen throughput (token/s): 886.70, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:30:02 TP0] Decode batch. #running-req: 4, #token: 1216, token usage: 0.00, gen throughput (token/s): 879.83, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:30:02 TP0] Decode batch. #running-req: 4, #token: 1376, token usage: 0.00, gen throughput (token/s): 883.40, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:30:02 TP0] Decode batch. #running-req: 4, #token: 1536, token usage: 0.00, gen throughput (token/s): 859.56, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:30:03 TP0] Decode batch. #running-req: 4, #token: 1696, token usage: 0.00, gen throughput (token/s): 903.03, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:30:03 TP0] Decode batch. #running-req: 4, #token: 1856, token usage: 0.00, gen throughput (token/s): 870.93, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:30:03 TP0] Decode batch. #running-req: 4, #token: 2016, token usage: 0.00, gen throughput (token/s): 877.89, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:30:03] INFO:     127.0.0.1:51636 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:30:03] INFO:     127.0.0.1:51600 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:30:03] INFO:     127.0.0.1:51608 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:30:03] INFO:     127.0.0.1:51620 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:30:03 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 135, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-08-25 15:30:03 TP0] Prefill batch. #new-seq: 3, #new-token: 3, #cached-token: 405, token usage: 0.00, #running-req: 1, #queue-req: 0, 
[2025-08-25 15:30:03 TP0] Decode batch. #running-req: 4, #token: 176, token usage: 0.00, gen throughput (token/s): 603.62, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:30:03 TP0] Decode batch. #running-req: 4, #token: 336, token usage: 0.00, gen throughput (token/s): 869.77, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:30:04 TP0] Decode batch. #running-req: 4, #token: 496, token usage: 0.00, gen throughput (token/s): 871.27, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:30:04 TP0] Decode batch. #running-req: 4, #token: 656, token usage: 0.00, gen throughput (token/s): 864.88, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:30:04 TP0] Decode batch. #running-req: 4, #token: 816, token usage: 0.00, gen throughput (token/s): 871.05, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:30:04 TP0] Decode batch. #running-req: 4, #token: 976, token usage: 0.00, gen throughput (token/s): 872.49, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:30:04 TP0] Decode batch. #running-req: 4, #token: 1136, token usage: 0.00, gen throughput (token/s): 874.25, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:30:05 TP0] Decode batch. #running-req: 4, #token: 1296, token usage: 0.00, gen throughput (token/s): 874.39, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:30:05 TP0] Decode batch. #running-req: 4, #token: 1456, token usage: 0.00, gen throughput (token/s): 909.03, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:30:05 TP0] Decode batch. #running-req: 4, #token: 1616, token usage: 0.00, gen throughput (token/s): 900.10, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:30:05 TP0] Decode batch. #running-req: 4, #token: 1776, token usage: 0.00, gen throughput (token/s): 850.28, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:30:05 TP0] Decode batch. #running-req: 4, #token: 1936, token usage: 0.00, gen throughput (token/s): 869.77, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:30:05 TP0] Decode batch. #running-req: 4, #token: 2096, token usage: 0.00, gen throughput (token/s): 911.42, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:30:05] INFO:     127.0.0.1:51636 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:30:05] INFO:     127.0.0.1:51600 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:30:05] INFO:     127.0.0.1:51608 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:30:05] INFO:     127.0.0.1:51620 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:30:05 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 135, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-08-25 15:30:06 TP0] Prefill batch. #new-seq: 3, #new-token: 3, #cached-token: 405, token usage: 0.00, #running-req: 1, #queue-req: 0, 
[2025-08-25 15:30:06 TP0] Decode batch. #running-req: 4, #token: 256, token usage: 0.00, gen throughput (token/s): 603.72, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:30:06 TP0] Decode batch. #running-req: 4, #token: 416, token usage: 0.00, gen throughput (token/s): 884.00, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:30:06 TP0] Decode batch. #running-req: 4, #token: 576, token usage: 0.00, gen throughput (token/s): 856.23, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:30:06 TP0] Decode batch. #running-req: 4, #token: 736, token usage: 0.00, gen throughput (token/s): 902.32, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:30:06 TP0] Decode batch. #running-req: 4, #token: 896, token usage: 0.00, gen throughput (token/s): 871.53, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:30:07 TP0] Decode batch. #running-req: 4, #token: 1056, token usage: 0.00, gen throughput (token/s): 875.91, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:30:07 TP0] Decode batch. #running-req: 4, #token: 1216, token usage: 0.00, gen throughput (token/s): 853.53, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:30:07 TP0] Decode batch. #running-req: 4, #token: 1376, token usage: 0.00, gen throughput (token/s): 878.56, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:30:07 TP0] Decode batch. #running-req: 4, #token: 1536, token usage: 0.00, gen throughput (token/s): 865.10, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:30:07 TP0] Decode batch. #running-req: 4, #token: 1696, token usage: 0.00, gen throughput (token/s): 875.82, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:30:08 TP0] Decode batch. #running-req: 4, #token: 1856, token usage: 0.00, gen throughput (token/s): 847.12, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:30:08 TP0] Decode batch. #running-req: 4, #token: 2016, token usage: 0.00, gen throughput (token/s): 873.45, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:30:08] INFO:     127.0.0.1:51636 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:30:08] INFO:     127.0.0.1:51600 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:30:08] INFO:     127.0.0.1:51608 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:30:08] INFO:     127.0.0.1:51620 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:30:08 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 135, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-08-25 15:30:08 TP0] Prefill batch. #new-seq: 3, #new-token: 3, #cached-token: 405, token usage: 0.00, #running-req: 1, #queue-req: 0, 
[2025-08-25 15:30:08 TP0] Decode batch. #running-req: 4, #token: 176, token usage: 0.00, gen throughput (token/s): 599.44, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:30:08 TP0] Decode batch. #running-req: 4, #token: 336, token usage: 0.00, gen throughput (token/s): 866.65, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:30:08 TP0] Decode batch. #running-req: 4, #token: 496, token usage: 0.00, gen throughput (token/s): 879.80, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:30:09 TP0] Decode batch. #running-req: 4, #token: 656, token usage: 0.00, gen throughput (token/s): 865.94, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:30:09 TP0] Decode batch. #running-req: 4, #token: 816, token usage: 0.00, gen throughput (token/s): 881.17, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:30:09 TP0] Decode batch. #running-req: 4, #token: 976, token usage: 0.00, gen throughput (token/s): 891.37, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:30:09 TP0] Decode batch. #running-req: 4, #token: 1136, token usage: 0.00, gen throughput (token/s): 869.72, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:30:09 TP0] Decode batch. #running-req: 4, #token: 1296, token usage: 0.00, gen throughput (token/s): 874.46, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:30:09 TP0] Decode batch. #running-req: 4, #token: 1456, token usage: 0.00, gen throughput (token/s): 860.14, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:30:10 TP0] Decode batch. #running-req: 4, #token: 1616, token usage: 0.00, gen throughput (token/s): 848.33, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:30:10 TP0] Decode batch. #running-req: 4, #token: 1776, token usage: 0.00, gen throughput (token/s): 884.24, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:30:10 TP0] Decode batch. #running-req: 4, #token: 1936, token usage: 0.00, gen throughput (token/s): 868.46, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:30:10 TP0] Decode batch. #running-req: 4, #token: 2096, token usage: 0.00, gen throughput (token/s): 892.74, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:30:10] INFO:     127.0.0.1:51636 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:30:10] INFO:     127.0.0.1:51600 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:30:10] INFO:     127.0.0.1:51608 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:30:10] INFO:     127.0.0.1:51620 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:30:10 TP0] Prefill batch. #new-seq: 2, #new-token: 1166, #cached-token: 84, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-08-25 15:30:10 TP0] Prefill batch. #new-seq: 2, #new-token: 1166, #cached-token: 84, token usage: 0.03, #running-req: 2, #queue-req: 0, 
[2025-08-25 15:30:11] INFO:     127.0.0.1:46880 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 15:30:11] INFO:     127.0.0.1:46894 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 15:30:11] INFO:     127.0.0.1:46900 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 15:30:11] INFO:     127.0.0.1:46916 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 15:30:11 TP0] Prefill batch. #new-seq: 1, #new-token: 500, #cached-token: 125, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-08-25 15:30:11 TP0] Prefill batch. #new-seq: 1, #new-token: 500, #cached-token: 125, token usage: 0.02, #running-req: 1, #queue-req: 0, 
[2025-08-25 15:30:11 TP0] Prefill batch. #new-seq: 2, #new-token: 1000, #cached-token: 250, token usage: 0.02, #running-req: 2, #queue-req: 0, 
[2025-08-25 15:30:11] INFO:     127.0.0.1:46880 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 15:30:11] INFO:     127.0.0.1:46894 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 15:30:12 TP0] Prefill batch. #new-seq: 2, #new-token: 1000, #cached-token: 250, token usage: 0.00, #running-req: 2, #queue-req: 0, 
[2025-08-25 15:30:12] INFO:     127.0.0.1:46916 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 15:30:12] INFO:     127.0.0.1:46900 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 15:30:12 TP0] Prefill batch. #new-seq: 2, #new-token: 1000, #cached-token: 250, token usage: 0.03, #running-req: 4, #queue-req: 0, 
[2025-08-25 15:30:12] INFO:     127.0.0.1:46880 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 15:30:12] INFO:     127.0.0.1:46894 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 15:30:12 TP0] Prefill batch. #new-seq: 2, #new-token: 1000, #cached-token: 250, token usage: 0.00, #running-req: 2, #queue-req: 0, 
[2025-08-25 15:30:12] INFO:     127.0.0.1:46916 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 15:30:12] INFO:     127.0.0.1:46900 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 15:30:13 TP0] Prefill batch. #new-seq: 2, #new-token: 1000, #cached-token: 250, token usage: 0.03, #running-req: 4, #queue-req: 0, 
[2025-08-25 15:30:13] INFO:     127.0.0.1:46880 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 15:30:13] INFO:     127.0.0.1:46894 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 15:30:13] INFO:     127.0.0.1:46916 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 15:30:13] INFO:     127.0.0.1:46900 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 15:30:13 TP0] Prefill batch. #new-seq: 4, #new-token: 4, #cached-token: 536, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-08-25 15:30:13 TP0] Decode batch. #running-req: 4, #token: 255, token usage: 0.00, gen throughput (token/s): 49.85, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:30:14 TP0] Decode batch. #running-req: 4, #token: 415, token usage: 0.00, gen throughput (token/s): 894.58, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:30:14 TP0] Decode batch. #running-req: 4, #token: 575, token usage: 0.00, gen throughput (token/s): 864.59, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:30:14 TP0] Decode batch. #running-req: 4, #token: 735, token usage: 0.00, gen throughput (token/s): 866.37, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:30:14 TP0] Decode batch. #running-req: 4, #token: 895, token usage: 0.00, gen throughput (token/s): 881.12, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:30:14 TP0] Decode batch. #running-req: 4, #token: 1055, token usage: 0.00, gen throughput (token/s): 868.96, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:30:14 TP0] Decode batch. #running-req: 4, #token: 1215, token usage: 0.00, gen throughput (token/s): 887.05, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:30:15 TP0] Decode batch. #running-req: 4, #token: 1375, token usage: 0.00, gen throughput (token/s): 871.19, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:30:15 TP0] Decode batch. #running-req: 4, #token: 1535, token usage: 0.00, gen throughput (token/s): 881.68, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:30:15 TP0] Decode batch. #running-req: 4, #token: 1695, token usage: 0.00, gen throughput (token/s): 887.95, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:30:15 TP0] Decode batch. #running-req: 4, #token: 1855, token usage: 0.00, gen throughput (token/s): 917.15, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:30:15 TP0] Decode batch. #running-req: 4, #token: 2015, token usage: 0.00, gen throughput (token/s): 912.65, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:30:16] INFO:     127.0.0.1:51636 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:30:16] INFO:     127.0.0.1:51600 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:30:16] INFO:     127.0.0.1:51608 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:30:16] INFO:     127.0.0.1:51620 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:30:16 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 134, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-08-25 15:30:16 TP0] Prefill batch. #new-seq: 3, #new-token: 3, #cached-token: 402, token usage: 0.00, #running-req: 1, #queue-req: 0, 
[2025-08-25 15:30:16 TP0] Decode batch. #running-req: 4, #token: 175, token usage: 0.00, gen throughput (token/s): 608.66, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:30:16 TP0] Decode batch. #running-req: 4, #token: 335, token usage: 0.00, gen throughput (token/s): 876.30, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:30:16 TP0] Decode batch. #running-req: 4, #token: 495, token usage: 0.00, gen throughput (token/s): 876.59, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:30:16 TP0] Decode batch. #running-req: 4, #token: 655, token usage: 0.00, gen throughput (token/s): 868.13, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:30:16 TP0] Decode batch. #running-req: 4, #token: 815, token usage: 0.00, gen throughput (token/s): 878.26, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:30:17 TP0] Decode batch. #running-req: 4, #token: 975, token usage: 0.00, gen throughput (token/s): 864.30, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:30:17 TP0] Decode batch. #running-req: 4, #token: 1135, token usage: 0.00, gen throughput (token/s): 883.30, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:30:17 TP0] Decode batch. #running-req: 4, #token: 1295, token usage: 0.00, gen throughput (token/s): 854.00, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:30:17 TP0] Decode batch. #running-req: 4, #token: 1455, token usage: 0.00, gen throughput (token/s): 883.14, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:30:17 TP0] Decode batch. #running-req: 4, #token: 1615, token usage: 0.00, gen throughput (token/s): 864.03, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:30:17 TP0] Decode batch. #running-req: 4, #token: 1775, token usage: 0.00, gen throughput (token/s): 883.26, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:30:18 TP0] Decode batch. #running-req: 4, #token: 1935, token usage: 0.00, gen throughput (token/s): 890.20, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:30:18 TP0] Decode batch. #running-req: 4, #token: 2095, token usage: 0.00, gen throughput (token/s): 879.38, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:30:18] INFO:     127.0.0.1:51636 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:30:18] INFO:     127.0.0.1:51600 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:30:18] INFO:     127.0.0.1:51608 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:30:18] INFO:     127.0.0.1:51620 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:30:18 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 134, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-08-25 15:30:18 TP0] Prefill batch. #new-seq: 3, #new-token: 3, #cached-token: 402, token usage: 0.00, #running-req: 1, #queue-req: 0, 
[2025-08-25 15:30:18 TP0] Decode batch. #running-req: 4, #token: 255, token usage: 0.00, gen throughput (token/s): 610.29, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:30:18 TP0] Decode batch. #running-req: 4, #token: 415, token usage: 0.00, gen throughput (token/s): 912.21, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:30:18 TP0] Decode batch. #running-req: 4, #token: 575, token usage: 0.00, gen throughput (token/s): 896.35, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:30:19 TP0] Decode batch. #running-req: 4, #token: 735, token usage: 0.00, gen throughput (token/s): 867.81, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:30:19 TP0] Decode batch. #running-req: 4, #token: 895, token usage: 0.00, gen throughput (token/s): 872.73, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:30:19 TP0] Decode batch. #running-req: 4, #token: 1055, token usage: 0.00, gen throughput (token/s): 870.65, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:30:19 TP0] Decode batch. #running-req: 4, #token: 1215, token usage: 0.00, gen throughput (token/s): 871.62, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:30:19 TP0] Decode batch. #running-req: 4, #token: 1375, token usage: 0.00, gen throughput (token/s): 874.05, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:30:20 TP0] Decode batch. #running-req: 4, #token: 1535, token usage: 0.00, gen throughput (token/s): 860.66, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:30:20 TP0] Decode batch. #running-req: 4, #token: 1695, token usage: 0.00, gen throughput (token/s): 892.63, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:30:20 TP0] Decode batch. #running-req: 4, #token: 1855, token usage: 0.00, gen throughput (token/s): 901.51, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:30:20 TP0] Decode batch. #running-req: 4, #token: 2015, token usage: 0.00, gen throughput (token/s): 890.80, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:30:20] INFO:     127.0.0.1:51636 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:30:20] INFO:     127.0.0.1:51600 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:30:20] INFO:     127.0.0.1:51608 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:30:20] INFO:     127.0.0.1:51620 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:30:20 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 134, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-08-25 15:30:20 TP0] Prefill batch. #new-seq: 3, #new-token: 3, #cached-token: 402, token usage: 0.00, #running-req: 1, #queue-req: 0, 
[2025-08-25 15:30:20 TP0] Decode batch. #running-req: 4, #token: 175, token usage: 0.00, gen throughput (token/s): 607.40, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:30:21 TP0] Decode batch. #running-req: 4, #token: 335, token usage: 0.00, gen throughput (token/s): 890.41, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:30:21 TP0] Decode batch. #running-req: 4, #token: 495, token usage: 0.00, gen throughput (token/s): 854.38, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:30:21 TP0] Decode batch. #running-req: 4, #token: 655, token usage: 0.00, gen throughput (token/s): 903.78, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:30:21 TP0] Decode batch. #running-req: 4, #token: 815, token usage: 0.00, gen throughput (token/s): 909.40, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:30:21 TP0] Decode batch. #running-req: 4, #token: 975, token usage: 0.00, gen throughput (token/s): 910.20, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:30:21 TP0] Decode batch. #running-req: 4, #token: 1135, token usage: 0.00, gen throughput (token/s): 891.44, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:30:22 TP0] Decode batch. #running-req: 4, #token: 1295, token usage: 0.00, gen throughput (token/s): 882.02, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:30:22 TP0] Decode batch. #running-req: 4, #token: 1455, token usage: 0.00, gen throughput (token/s): 895.96, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:30:22 TP0] Decode batch. #running-req: 4, #token: 1615, token usage: 0.00, gen throughput (token/s): 867.99, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:30:22 TP0] Decode batch. #running-req: 4, #token: 1775, token usage: 0.00, gen throughput (token/s): 862.46, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:30:22 TP0] Decode batch. #running-req: 4, #token: 1935, token usage: 0.00, gen throughput (token/s): 869.43, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:30:23 TP0] Decode batch. #running-req: 4, #token: 2095, token usage: 0.00, gen throughput (token/s): 871.57, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:30:23] INFO:     127.0.0.1:51636 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:30:23] INFO:     127.0.0.1:51600 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:30:23] INFO:     127.0.0.1:51608 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:30:23] INFO:     127.0.0.1:51620 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:30:23 TP0] Prefill batch. #new-seq: 4, #new-token: 2328, #cached-token: 168, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-08-25 15:30:23] INFO:     127.0.0.1:4806 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 15:30:23] INFO:     127.0.0.1:4818 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 15:30:23] INFO:     127.0.0.1:4820 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 15:30:23] INFO:     127.0.0.1:4828 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 15:30:23 TP0] Prefill batch. #new-seq: 1, #new-token: 500, #cached-token: 124, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-08-25 15:30:23 TP0] Prefill batch. #new-seq: 3, #new-token: 1500, #cached-token: 372, token usage: 0.02, #running-req: 1, #queue-req: 0, 
[2025-08-25 15:30:24] INFO:     127.0.0.1:4828 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 15:30:24] INFO:     127.0.0.1:4806 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 15:30:24] INFO:     127.0.0.1:4818 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 15:30:24] INFO:     127.0.0.1:4820 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 15:30:24 TP0] Prefill batch. #new-seq: 1, #new-token: 500, #cached-token: 124, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-08-25 15:30:24 TP0] Prefill batch. #new-seq: 3, #new-token: 1500, #cached-token: 372, token usage: 0.00, #running-req: 1, #queue-req: 0, 
[2025-08-25 15:30:24] INFO:     127.0.0.1:4828 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 15:30:24 TP0] Prefill batch. #new-seq: 1, #new-token: 500, #cached-token: 124, token usage: 0.04, #running-req: 4, #queue-req: 0, 
[2025-08-25 15:30:25] INFO:     127.0.0.1:4806 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 15:30:25] INFO:     127.0.0.1:4818 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 15:30:25] INFO:     127.0.0.1:4820 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 15:30:25] INFO:     127.0.0.1:4828 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 15:30:25 TP0] Prefill batch. #new-seq: 3, #new-token: 1500, #cached-token: 372, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-08-25 15:30:26] INFO:     127.0.0.1:4806 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 15:30:26] INFO:     127.0.0.1:4828 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 15:30:26] INFO:     127.0.0.1:4818 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 15:30:26 TP0] Prefill batch. #new-seq: 4, #new-token: 4, #cached-token: 784, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-08-25 15:30:26 TP0] Decode batch. #running-req: 4, #token: 317, token usage: 0.00, gen throughput (token/s): 44.70, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:30:26 TP0] Decode batch. #running-req: 4, #token: 477, token usage: 0.00, gen throughput (token/s): 838.77, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:30:26 TP0] Decode batch. #running-req: 4, #token: 637, token usage: 0.00, gen throughput (token/s): 879.64, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:30:27 TP0] Decode batch. #running-req: 4, #token: 797, token usage: 0.00, gen throughput (token/s): 872.18, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:30:27 TP0] Decode batch. #running-req: 4, #token: 957, token usage: 0.00, gen throughput (token/s): 879.09, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:30:27 TP0] Decode batch. #running-req: 4, #token: 1117, token usage: 0.00, gen throughput (token/s): 883.95, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:30:27 TP0] Decode batch. #running-req: 4, #token: 1277, token usage: 0.00, gen throughput (token/s): 878.26, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:30:27 TP0] Decode batch. #running-req: 4, #token: 1437, token usage: 0.00, gen throughput (token/s): 875.72, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:30:28 TP0] Decode batch. #running-req: 4, #token: 1597, token usage: 0.00, gen throughput (token/s): 890.78, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:30:28 TP0] Decode batch. #running-req: 4, #token: 1757, token usage: 0.00, gen throughput (token/s): 883.25, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:30:28 TP0] Decode batch. #running-req: 4, #token: 1917, token usage: 0.00, gen throughput (token/s): 879.31, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:30:28 TP0] Decode batch. #running-req: 4, #token: 2077, token usage: 0.00, gen throughput (token/s): 860.99, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:30:28] INFO:     127.0.0.1:51636 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:30:28] INFO:     127.0.0.1:51600 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:30:28] INFO:     127.0.0.1:51608 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:30:28] INFO:     127.0.0.1:51620 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:30:28 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 196, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-08-25 15:30:28 TP0] Prefill batch. #new-seq: 3, #new-token: 3, #cached-token: 588, token usage: 0.00, #running-req: 1, #queue-req: 0, 
[2025-08-25 15:30:28 TP0] Decode batch. #running-req: 4, #token: 237, token usage: 0.00, gen throughput (token/s): 587.26, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:30:29 TP0] Decode batch. #running-req: 4, #token: 397, token usage: 0.00, gen throughput (token/s): 866.10, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:30:29 TP0] Decode batch. #running-req: 4, #token: 557, token usage: 0.00, gen throughput (token/s): 877.59, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:30:29 TP0] Decode batch. #running-req: 4, #token: 717, token usage: 0.00, gen throughput (token/s): 887.91, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:30:29 TP0] Decode batch. #running-req: 4, #token: 877, token usage: 0.00, gen throughput (token/s): 886.75, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:30:29 TP0] Decode batch. #running-req: 4, #token: 1037, token usage: 0.00, gen throughput (token/s): 873.65, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:30:29 TP0] Decode batch. #running-req: 4, #token: 1197, token usage: 0.00, gen throughput (token/s): 889.69, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:30:30 TP0] Decode batch. #running-req: 4, #token: 1357, token usage: 0.00, gen throughput (token/s): 886.56, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:30:30 TP0] Decode batch. #running-req: 4, #token: 1517, token usage: 0.00, gen throughput (token/s): 870.11, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:30:30 TP0] Decode batch. #running-req: 4, #token: 1677, token usage: 0.00, gen throughput (token/s): 884.25, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:30:30 TP0] Decode batch. #running-req: 4, #token: 1837, token usage: 0.00, gen throughput (token/s): 921.43, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:30:30 TP0] Decode batch. #running-req: 4, #token: 1997, token usage: 0.00, gen throughput (token/s): 937.06, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:30:31 TP0] Decode batch. #running-req: 4, #token: 2157, token usage: 0.00, gen throughput (token/s): 892.87, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:30:31] INFO:     127.0.0.1:51636 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:30:31] INFO:     127.0.0.1:51600 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:30:31] INFO:     127.0.0.1:51608 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:30:31] INFO:     127.0.0.1:51620 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:30:31 TP0] Prefill batch. #new-seq: 4, #new-token: 4, #cached-token: 784, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-08-25 15:30:31 TP0] Decode batch. #running-req: 4, #token: 317, token usage: 0.00, gen throughput (token/s): 708.67, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:30:31 TP0] Decode batch. #running-req: 4, #token: 477, token usage: 0.00, gen throughput (token/s): 890.99, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:30:31 TP0] Decode batch. #running-req: 4, #token: 637, token usage: 0.00, gen throughput (token/s): 906.32, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:30:31 TP0] Decode batch. #running-req: 4, #token: 797, token usage: 0.00, gen throughput (token/s): 876.93, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:30:31 TP0] Decode batch. #running-req: 4, #token: 957, token usage: 0.00, gen throughput (token/s): 894.69, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:30:32 TP0] Decode batch. #running-req: 4, #token: 1117, token usage: 0.00, gen throughput (token/s): 898.53, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:30:32 TP0] Decode batch. #running-req: 4, #token: 1277, token usage: 0.00, gen throughput (token/s): 915.67, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:30:32 TP0] Decode batch. #running-req: 4, #token: 1437, token usage: 0.00, gen throughput (token/s): 889.77, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:30:32 TP0] Decode batch. #running-req: 4, #token: 1597, token usage: 0.00, gen throughput (token/s): 843.99, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:30:32 TP0] Decode batch. #running-req: 4, #token: 1757, token usage: 0.00, gen throughput (token/s): 896.00, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:30:33 TP0] Decode batch. #running-req: 4, #token: 1917, token usage: 0.00, gen throughput (token/s): 886.57, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:30:33 TP0] Decode batch. #running-req: 4, #token: 2077, token usage: 0.00, gen throughput (token/s): 884.62, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:30:33] INFO:     127.0.0.1:51636 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:30:33] INFO:     127.0.0.1:51600 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:30:33] INFO:     127.0.0.1:51608 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:30:33] INFO:     127.0.0.1:51620 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:30:33 TP0] Prefill batch. #new-seq: 2, #new-token: 2, #cached-token: 392, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-08-25 15:30:33 TP0] Prefill batch. #new-seq: 2, #new-token: 2, #cached-token: 392, token usage: 0.00, #running-req: 2, #queue-req: 0, 
[2025-08-25 15:30:33 TP0] Decode batch. #running-req: 4, #token: 237, token usage: 0.00, gen throughput (token/s): 584.50, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:30:33 TP0] Decode batch. #running-req: 4, #token: 397, token usage: 0.00, gen throughput (token/s): 893.56, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:30:33 TP0] Decode batch. #running-req: 4, #token: 557, token usage: 0.00, gen throughput (token/s): 920.45, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:30:34 TP0] Decode batch. #running-req: 4, #token: 717, token usage: 0.00, gen throughput (token/s): 920.71, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:30:34 TP0] Decode batch. #running-req: 4, #token: 877, token usage: 0.00, gen throughput (token/s): 878.04, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:30:34 TP0] Decode batch. #running-req: 4, #token: 1037, token usage: 0.00, gen throughput (token/s): 875.43, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:30:34 TP0] Decode batch. #running-req: 4, #token: 1197, token usage: 0.00, gen throughput (token/s): 863.25, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:30:34 TP0] Decode batch. #running-req: 4, #token: 1357, token usage: 0.00, gen throughput (token/s): 886.88, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:30:34 TP0] Decode batch. #running-req: 4, #token: 1517, token usage: 0.00, gen throughput (token/s): 865.68, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:30:35 TP0] Decode batch. #running-req: 4, #token: 1677, token usage: 0.00, gen throughput (token/s): 864.25, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:30:35 TP0] Decode batch. #running-req: 4, #token: 1837, token usage: 0.00, gen throughput (token/s): 853.99, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:30:35 TP0] Decode batch. #running-req: 4, #token: 1997, token usage: 0.00, gen throughput (token/s): 866.93, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:30:35 TP0] Decode batch. #running-req: 4, #token: 2157, token usage: 0.00, gen throughput (token/s): 868.16, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:30:35] INFO:     127.0.0.1:51636 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:30:35] INFO:     127.0.0.1:51600 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:30:35] INFO:     127.0.0.1:51608 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:30:35] INFO:     127.0.0.1:51620 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:30:35 TP0] Prefill batch. #new-seq: 4, #new-token: 2572, #cached-token: 172, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-08-25 15:30:36] INFO:     127.0.0.1:59452 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 15:30:36] INFO:     127.0.0.1:59464 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 15:30:36] INFO:     127.0.0.1:59480 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 15:30:36] INFO:     127.0.0.1:59492 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 15:30:36 TP0] Prefill batch. #new-seq: 1, #new-token: 500, #cached-token: 186, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-08-25 15:30:36 TP0] Prefill batch. #new-seq: 3, #new-token: 1500, #cached-token: 558, token usage: 0.02, #running-req: 1, #queue-req: 0, 
[2025-08-25 15:30:37] INFO:     127.0.0.1:59492 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 15:30:37] INFO:     127.0.0.1:59452 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 15:30:37] INFO:     127.0.0.1:59464 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 15:30:37] INFO:     127.0.0.1:59480 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 15:30:37 TP0] Prefill batch. #new-seq: 1, #new-token: 500, #cached-token: 186, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-08-25 15:30:37 TP0] Prefill batch. #new-seq: 2, #new-token: 1000, #cached-token: 372, token usage: 0.02, #running-req: 1, #queue-req: 0, 
[2025-08-25 15:30:37 TP0] Prefill batch. #new-seq: 1, #new-token: 500, #cached-token: 186, token usage: 0.03, #running-req: 3, #queue-req: 0, 
[2025-08-25 15:30:37] INFO:     127.0.0.1:59492 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 15:30:37] INFO:     127.0.0.1:59452 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 15:30:37] INFO:     127.0.0.1:59464 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 15:30:38 TP0] Prefill batch. #new-seq: 3, #new-token: 1500, #cached-token: 558, token usage: 0.00, #running-req: 1, #queue-req: 0, 
[2025-08-25 15:30:38] INFO:     127.0.0.1:59480 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 15:30:38 TP0] Prefill batch. #new-seq: 1, #new-token: 500, #cached-token: 186, token usage: 0.04, #running-req: 4, #queue-req: 0, 
[2025-08-25 15:30:38] INFO:     127.0.0.1:59492 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 15:30:38] INFO:     127.0.0.1:59452 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 15:30:38] INFO:     127.0.0.1:59464 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 15:30:38 TP0] Prefill batch. #new-seq: 3, #new-token: 1950, #cached-token: 135, token usage: 0.00, #running-req: 1, #queue-req: 0, 
[2025-08-25 15:30:38] INFO:     127.0.0.1:59480 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 15:30:38 TP0] Prefill batch. #new-seq: 1, #new-token: 650, #cached-token: 45, token usage: 0.05, #running-req: 4, #queue-req: 0, 
[2025-08-25 15:30:40 TP0] Decode batch. #running-req: 4, #token: 2281, token usage: 0.06, gen throughput (token/s): 3.39, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:30:42 TP0] Decode batch. #running-req: 4, #token: 2441, token usage: 0.06, gen throughput (token/s): 88.16, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:30:44 TP0] Decode batch. #running-req: 4, #token: 2601, token usage: 0.07, gen throughput (token/s): 88.36, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:30:46 TP0] Decode batch. #running-req: 4, #token: 2761, token usage: 0.07, gen throughput (token/s): 88.12, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:30:46] INFO:     127.0.0.1:59492 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:30:46] INFO:     127.0.0.1:59452 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:30:46] INFO:     127.0.0.1:59464 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:30:46] INFO:     127.0.0.1:59480 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:30:46 TP0] Prefill batch. #new-seq: 4, #new-token: 1986, #cached-token: 794, token usage: 0.01, #running-req: 0, #queue-req: 0, 
[2025-08-25 15:30:48 TP0] Decode batch. #running-req: 4, #token: 2324, token usage: 0.06, gen throughput (token/s): 66.71, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:30:50 TP0] Decode batch. #running-req: 4, #token: 2484, token usage: 0.06, gen throughput (token/s): 88.32, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:30:52 TP0] Decode batch. #running-req: 4, #token: 2644, token usage: 0.07, gen throughput (token/s): 87.76, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:30:53] INFO:     127.0.0.1:59464 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:30:53] INFO:     127.0.0.1:59492 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:30:53] INFO:     127.0.0.1:59452 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:30:53] INFO:     127.0.0.1:59480 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:30:53 TP0] Prefill batch. #new-seq: 4, #new-token: 1952, #cached-token: 828, token usage: 0.01, #running-req: 0, #queue-req: 0, 
[2025-08-25 15:30:54 TP0] Decode batch. #running-req: 4, #token: 2198, token usage: 0.06, gen throughput (token/s): 66.37, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:30:56 TP0] Decode batch. #running-req: 4, #token: 2358, token usage: 0.06, gen throughput (token/s): 88.28, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:30:58 TP0] Decode batch. #running-req: 4, #token: 2518, token usage: 0.06, gen throughput (token/s): 88.22, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:31:00 TP0] Decode batch. #running-req: 4, #token: 2678, token usage: 0.07, gen throughput (token/s): 87.83, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:31:01] INFO:     127.0.0.1:59492 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:31:01] INFO:     127.0.0.1:59452 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:31:01] INFO:     127.0.0.1:59464 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:31:01] INFO:     127.0.0.1:59480 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:31:01 TP0] Prefill batch. #new-seq: 1, #new-token: 490, #cached-token: 205, token usage: 0.01, #running-req: 0, #queue-req: 0, 
[2025-08-25 15:31:02 TP0] Decode batch. #running-req: 1, #token: 712, token usage: 0.02, gen throughput (token/s): 56.93, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:31:03 TP0] Decode batch. #running-req: 1, #token: 752, token usage: 0.02, gen throughput (token/s): 22.70, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:31:05 TP0] Decode batch. #running-req: 1, #token: 792, token usage: 0.02, gen throughput (token/s): 22.61, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:31:07 TP0] Decode batch. #running-req: 1, #token: 832, token usage: 0.02, gen throughput (token/s): 22.67, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:31:08] INFO:     127.0.0.1:59464 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:31:08 TP0] Prefill batch. #new-seq: 4, #new-token: 4, #cached-token: 688, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-08-25 15:31:08 TP0] Decode batch. #running-req: 4, #token: 293, token usage: 0.00, gen throughput (token/s): 4.92, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:31:08 TP0] Decode batch. #running-req: 4, #token: 453, token usage: 0.00, gen throughput (token/s): 879.16, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:31:08 TP0] Decode batch. #running-req: 4, #token: 613, token usage: 0.00, gen throughput (token/s): 834.36, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:31:08 TP0] Decode batch. #running-req: 4, #token: 773, token usage: 0.00, gen throughput (token/s): 838.59, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:31:08 TP0] Decode batch. #running-req: 4, #token: 933, token usage: 0.00, gen throughput (token/s): 833.02, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:31:09 TP0] Decode batch. #running-req: 4, #token: 1093, token usage: 0.00, gen throughput (token/s): 883.24, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:31:09 TP0] Decode batch. #running-req: 4, #token: 1253, token usage: 0.00, gen throughput (token/s): 859.14, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:31:09 TP0] Decode batch. #running-req: 4, #token: 1413, token usage: 0.00, gen throughput (token/s): 872.25, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:31:09 TP0] Decode batch. #running-req: 4, #token: 1573, token usage: 0.00, gen throughput (token/s): 875.15, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:31:09 TP0] Decode batch. #running-req: 4, #token: 1733, token usage: 0.00, gen throughput (token/s): 825.30, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:31:10 TP0] Decode batch. #running-req: 4, #token: 1893, token usage: 0.00, gen throughput (token/s): 891.98, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:31:10 TP0] Decode batch. #running-req: 4, #token: 2053, token usage: 0.00, gen throughput (token/s): 896.53, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:31:10] INFO:     127.0.0.1:30760 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:31:10] INFO:     127.0.0.1:30766 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:31:10] INFO:     127.0.0.1:30772 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:31:10] INFO:     127.0.0.1:30774 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:31:10 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 172, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-08-25 15:31:10 TP0] Prefill batch. #new-seq: 3, #new-token: 3, #cached-token: 516, token usage: 0.00, #running-req: 1, #queue-req: 0, 
[2025-08-25 15:31:10 TP0] Decode batch. #running-req: 4, #token: 213, token usage: 0.00, gen throughput (token/s): 599.12, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:31:10 TP0] Decode batch. #running-req: 4, #token: 373, token usage: 0.00, gen throughput (token/s): 859.80, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:31:10 TP0] Decode batch. #running-req: 4, #token: 533, token usage: 0.00, gen throughput (token/s): 867.56, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:31:11 TP0] Decode batch. #running-req: 4, #token: 693, token usage: 0.00, gen throughput (token/s): 860.22, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:31:11 TP0] Decode batch. #running-req: 4, #token: 853, token usage: 0.00, gen throughput (token/s): 880.72, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:31:11 TP0] Decode batch. #running-req: 4, #token: 1013, token usage: 0.00, gen throughput (token/s): 878.13, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:31:11 TP0] Decode batch. #running-req: 4, #token: 1173, token usage: 0.00, gen throughput (token/s): 829.56, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:31:11 TP0] Decode batch. #running-req: 4, #token: 1333, token usage: 0.00, gen throughput (token/s): 856.88, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:31:12 TP0] Decode batch. #running-req: 4, #token: 1493, token usage: 0.00, gen throughput (token/s): 833.67, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:31:12 TP0] Decode batch. #running-req: 4, #token: 1653, token usage: 0.00, gen throughput (token/s): 889.98, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:31:12 TP0] Decode batch. #running-req: 4, #token: 1813, token usage: 0.00, gen throughput (token/s): 819.88, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:31:12 TP0] Decode batch. #running-req: 4, #token: 1973, token usage: 0.00, gen throughput (token/s): 868.85, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:31:12 TP0] Decode batch. #running-req: 4, #token: 2133, token usage: 0.00, gen throughput (token/s): 882.63, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:31:12] INFO:     127.0.0.1:30774 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:31:12] INFO:     127.0.0.1:30760 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:31:12] INFO:     127.0.0.1:30766 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:31:12] INFO:     127.0.0.1:30772 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:31:12 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 172, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-08-25 15:31:12 TP0] Prefill batch. #new-seq: 3, #new-token: 3, #cached-token: 516, token usage: 0.00, #running-req: 1, #queue-req: 0, 
[2025-08-25 15:31:13 TP0] Decode batch. #running-req: 4, #token: 293, token usage: 0.00, gen throughput (token/s): 597.62, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:31:13 TP0] Decode batch. #running-req: 4, #token: 453, token usage: 0.00, gen throughput (token/s): 869.83, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:31:13 TP0] Decode batch. #running-req: 4, #token: 613, token usage: 0.00, gen throughput (token/s): 829.62, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:31:13 TP0] Decode batch. #running-req: 4, #token: 773, token usage: 0.00, gen throughput (token/s): 854.77, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:31:13 TP0] Decode batch. #running-req: 4, #token: 933, token usage: 0.00, gen throughput (token/s): 869.85, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:31:13 TP0] Decode batch. #running-req: 4, #token: 1093, token usage: 0.00, gen throughput (token/s): 881.20, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:31:14 TP0] Decode batch. #running-req: 4, #token: 1253, token usage: 0.00, gen throughput (token/s): 883.58, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:31:14 TP0] Decode batch. #running-req: 4, #token: 1413, token usage: 0.00, gen throughput (token/s): 868.70, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:31:14 TP0] Decode batch. #running-req: 4, #token: 1573, token usage: 0.00, gen throughput (token/s): 865.12, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:31:14 TP0] Decode batch. #running-req: 4, #token: 1733, token usage: 0.00, gen throughput (token/s): 871.95, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:31:14 TP0] Decode batch. #running-req: 4, #token: 1893, token usage: 0.00, gen throughput (token/s): 846.51, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:31:15 TP0] Decode batch. #running-req: 4, #token: 2053, token usage: 0.00, gen throughput (token/s): 849.82, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:31:15] INFO:     127.0.0.1:30774 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:31:15] INFO:     127.0.0.1:30760 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:31:15] INFO:     127.0.0.1:30766 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:31:15] INFO:     127.0.0.1:30772 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:31:15 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 172, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-08-25 15:31:15 TP0] Prefill batch. #new-seq: 3, #new-token: 3, #cached-token: 516, token usage: 0.00, #running-req: 1, #queue-req: 0, 
[2025-08-25 15:31:15 TP0] Decode batch. #running-req: 4, #token: 213, token usage: 0.00, gen throughput (token/s): 597.36, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:31:15 TP0] Decode batch. #running-req: 4, #token: 373, token usage: 0.00, gen throughput (token/s): 878.66, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:31:15 TP0] Decode batch. #running-req: 4, #token: 533, token usage: 0.00, gen throughput (token/s): 886.81, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:31:15 TP0] Decode batch. #running-req: 4, #token: 693, token usage: 0.00, gen throughput (token/s): 887.13, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:31:16 TP0] Decode batch. #running-req: 4, #token: 853, token usage: 0.00, gen throughput (token/s): 883.68, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:31:16 TP0] Decode batch. #running-req: 4, #token: 1013, token usage: 0.00, gen throughput (token/s): 862.38, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:31:16 TP0] Decode batch. #running-req: 4, #token: 1173, token usage: 0.00, gen throughput (token/s): 884.76, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:31:16 TP0] Decode batch. #running-req: 4, #token: 1333, token usage: 0.00, gen throughput (token/s): 889.04, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:31:16 TP0] Decode batch. #running-req: 4, #token: 1493, token usage: 0.00, gen throughput (token/s): 884.90, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:31:16 TP0] Decode batch. #running-req: 4, #token: 1653, token usage: 0.00, gen throughput (token/s): 870.23, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:31:17 TP0] Decode batch. #running-req: 4, #token: 1813, token usage: 0.00, gen throughput (token/s): 866.71, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:31:17 TP0] Decode batch. #running-req: 4, #token: 1973, token usage: 0.00, gen throughput (token/s): 838.30, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:31:17 TP0] Decode batch. #running-req: 4, #token: 2133, token usage: 0.00, gen throughput (token/s): 873.47, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:31:17] INFO:     127.0.0.1:30774 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:31:17] INFO:     127.0.0.1:30760 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:31:17] INFO:     127.0.0.1:30766 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:31:17] INFO:     127.0.0.1:30772 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:31:17 TP0] Prefill batch. #new-seq: 1, #new-token: 620, #cached-token: 42, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-08-25 15:31:17 TP0] Prefill batch. #new-seq: 3, #new-token: 1860, #cached-token: 126, token usage: 0.02, #running-req: 1, #queue-req: 0, 
[2025-08-25 15:31:17] INFO:     127.0.0.1:19448 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 15:31:18 TP0] Prefill batch. #new-seq: 1, #new-token: 500, #cached-token: 162, token usage: 0.00, #running-req: 3, #queue-req: 0, 
[2025-08-25 15:31:18] INFO:     127.0.0.1:19464 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 15:31:18] INFO:     127.0.0.1:19480 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 15:31:18] INFO:     127.0.0.1:19496 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 15:31:18 TP0] Prefill batch. #new-seq: 3, #new-token: 1500, #cached-token: 486, token usage: 0.02, #running-req: 4, #queue-req: 0, 
[2025-08-25 15:31:18] INFO:     127.0.0.1:19448 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 15:31:19 TP0] Prefill batch. #new-seq: 1, #new-token: 500, #cached-token: 162, token usage: 0.00, #running-req: 3, #queue-req: 0, 
[2025-08-25 15:31:19] INFO:     127.0.0.1:19496 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 15:31:19] INFO:     127.0.0.1:19464 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 15:31:19] INFO:     127.0.0.1:19480 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 15:31:19 TP0] Prefill batch. #new-seq: 3, #new-token: 1500, #cached-token: 486, token usage: 0.02, #running-req: 4, #queue-req: 0, 
[2025-08-25 15:31:19] INFO:     127.0.0.1:19448 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 15:31:19 TP0] Prefill batch. #new-seq: 1, #new-token: 500, #cached-token: 162, token usage: 0.00, #running-req: 3, #queue-req: 0, 
[2025-08-25 15:31:19] INFO:     127.0.0.1:19496 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 15:31:19] INFO:     127.0.0.1:19464 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 15:31:19] INFO:     127.0.0.1:19480 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 15:31:20 TP0] Prefill batch. #new-seq: 3, #new-token: 1500, #cached-token: 486, token usage: 0.02, #running-req: 4, #queue-req: 0, 
[2025-08-25 15:31:20] INFO:     127.0.0.1:19448 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 15:31:20] INFO:     127.0.0.1:19496 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 15:31:20] INFO:     127.0.0.1:19464 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 15:31:20] INFO:     127.0.0.1:19480 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 15:31:20 TP0] Prefill batch. #new-seq: 4, #new-token: 4, #cached-token: 616, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-08-25 15:31:20 TP0] Decode batch. #running-req: 4, #token: 275, token usage: 0.00, gen throughput (token/s): 49.64, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:31:20 TP0] Decode batch. #running-req: 4, #token: 435, token usage: 0.00, gen throughput (token/s): 861.67, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:31:21 TP0] Decode batch. #running-req: 4, #token: 595, token usage: 0.00, gen throughput (token/s): 863.18, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:31:21 TP0] Decode batch. #running-req: 4, #token: 755, token usage: 0.00, gen throughput (token/s): 904.18, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:31:21 TP0] Decode batch. #running-req: 4, #token: 915, token usage: 0.00, gen throughput (token/s): 881.64, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:31:21 TP0] Decode batch. #running-req: 4, #token: 1075, token usage: 0.00, gen throughput (token/s): 889.34, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:31:21 TP0] Decode batch. #running-req: 4, #token: 1235, token usage: 0.00, gen throughput (token/s): 898.78, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:31:22 TP0] Decode batch. #running-req: 4, #token: 1395, token usage: 0.00, gen throughput (token/s): 903.40, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:31:22 TP0] Decode batch. #running-req: 4, #token: 1555, token usage: 0.00, gen throughput (token/s): 903.11, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:31:22 TP0] Decode batch. #running-req: 4, #token: 1715, token usage: 0.00, gen throughput (token/s): 899.49, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:31:22 TP0] Decode batch. #running-req: 4, #token: 1875, token usage: 0.00, gen throughput (token/s): 872.74, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:31:22 TP0] Decode batch. #running-req: 4, #token: 2035, token usage: 0.00, gen throughput (token/s): 858.89, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:31:22] INFO:     127.0.0.1:30774 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:31:22] INFO:     127.0.0.1:30760 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:31:22] INFO:     127.0.0.1:30766 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:31:22] INFO:     127.0.0.1:30772 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:31:22 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 154, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-08-25 15:31:22 TP0] Prefill batch. #new-seq: 3, #new-token: 3, #cached-token: 462, token usage: 0.00, #running-req: 1, #queue-req: 0, 
[2025-08-25 15:31:23 TP0] Decode batch. #running-req: 4, #token: 195, token usage: 0.00, gen throughput (token/s): 585.01, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:31:23 TP0] Decode batch. #running-req: 4, #token: 355, token usage: 0.00, gen throughput (token/s): 893.38, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:31:23 TP0] Decode batch. #running-req: 4, #token: 515, token usage: 0.00, gen throughput (token/s): 890.70, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:31:23 TP0] Decode batch. #running-req: 4, #token: 675, token usage: 0.00, gen throughput (token/s): 884.66, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:31:23 TP0] Decode batch. #running-req: 4, #token: 835, token usage: 0.00, gen throughput (token/s): 863.33, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:31:23 TP0] Decode batch. #running-req: 4, #token: 995, token usage: 0.00, gen throughput (token/s): 875.11, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:31:24 TP0] Decode batch. #running-req: 4, #token: 1155, token usage: 0.00, gen throughput (token/s): 866.33, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:31:24 TP0] Decode batch. #running-req: 4, #token: 1315, token usage: 0.00, gen throughput (token/s): 908.44, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:31:24 TP0] Decode batch. #running-req: 4, #token: 1475, token usage: 0.00, gen throughput (token/s): 867.47, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:31:24 TP0] Decode batch. #running-req: 4, #token: 1635, token usage: 0.00, gen throughput (token/s): 876.43, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:31:24 TP0] Decode batch. #running-req: 4, #token: 1795, token usage: 0.00, gen throughput (token/s): 870.51, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:31:25 TP0] Decode batch. #running-req: 4, #token: 1955, token usage: 0.00, gen throughput (token/s): 880.03, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:31:25 TP0] Decode batch. #running-req: 4, #token: 2115, token usage: 0.00, gen throughput (token/s): 870.60, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:31:25] INFO:     127.0.0.1:30774 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:31:25] INFO:     127.0.0.1:30760 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:31:25] INFO:     127.0.0.1:30766 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:31:25] INFO:     127.0.0.1:30772 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:31:25 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 154, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-08-25 15:31:25 TP0] Prefill batch. #new-seq: 3, #new-token: 3, #cached-token: 462, token usage: 0.00, #running-req: 1, #queue-req: 0, 
[2025-08-25 15:31:25 TP0] Decode batch. #running-req: 4, #token: 275, token usage: 0.00, gen throughput (token/s): 586.37, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:31:25 TP0] Decode batch. #running-req: 4, #token: 435, token usage: 0.00, gen throughput (token/s): 851.28, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:31:25 TP0] Decode batch. #running-req: 4, #token: 595, token usage: 0.00, gen throughput (token/s): 875.09, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:31:26 TP0] Decode batch. #running-req: 4, #token: 755, token usage: 0.00, gen throughput (token/s): 868.54, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:31:26 TP0] Decode batch. #running-req: 4, #token: 915, token usage: 0.00, gen throughput (token/s): 889.41, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:31:26 TP0] Decode batch. #running-req: 4, #token: 1075, token usage: 0.00, gen throughput (token/s): 875.73, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:31:26 TP0] Decode batch. #running-req: 4, #token: 1235, token usage: 0.00, gen throughput (token/s): 870.37, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:31:26 TP0] Decode batch. #running-req: 4, #token: 1395, token usage: 0.00, gen throughput (token/s): 869.68, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:31:26 TP0] Decode batch. #running-req: 4, #token: 1555, token usage: 0.00, gen throughput (token/s): 878.64, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:31:27 TP0] Decode batch. #running-req: 4, #token: 1715, token usage: 0.00, gen throughput (token/s): 878.36, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:31:27 TP0] Decode batch. #running-req: 4, #token: 1875, token usage: 0.00, gen throughput (token/s): 886.80, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:31:27 TP0] Decode batch. #running-req: 4, #token: 2035, token usage: 0.00, gen throughput (token/s): 856.68, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:31:27] INFO:     127.0.0.1:30774 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:31:27] INFO:     127.0.0.1:30760 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:31:27] INFO:     127.0.0.1:30766 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:31:27] INFO:     127.0.0.1:30772 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:31:27 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 154, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-08-25 15:31:27 TP0] Prefill batch. #new-seq: 3, #new-token: 3, #cached-token: 462, token usage: 0.00, #running-req: 1, #queue-req: 0, 
[2025-08-25 15:31:27 TP0] Decode batch. #running-req: 4, #token: 195, token usage: 0.00, gen throughput (token/s): 589.73, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:31:27 TP0] Decode batch. #running-req: 4, #token: 355, token usage: 0.00, gen throughput (token/s): 899.37, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:31:28 TP0] Decode batch. #running-req: 4, #token: 515, token usage: 0.00, gen throughput (token/s): 879.22, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:31:28 TP0] Decode batch. #running-req: 4, #token: 675, token usage: 0.00, gen throughput (token/s): 852.08, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:31:28 TP0] Decode batch. #running-req: 4, #token: 835, token usage: 0.00, gen throughput (token/s): 885.96, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:31:28 TP0] Decode batch. #running-req: 4, #token: 995, token usage: 0.00, gen throughput (token/s): 894.79, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:31:28 TP0] Decode batch. #running-req: 4, #token: 1155, token usage: 0.00, gen throughput (token/s): 877.73, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:31:29 TP0] Decode batch. #running-req: 4, #token: 1315, token usage: 0.00, gen throughput (token/s): 888.63, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:31:29 TP0] Decode batch. #running-req: 4, #token: 1475, token usage: 0.00, gen throughput (token/s): 876.03, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:31:29 TP0] Decode batch. #running-req: 4, #token: 1635, token usage: 0.00, gen throughput (token/s): 891.55, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:31:29 TP0] Decode batch. #running-req: 4, #token: 1795, token usage: 0.00, gen throughput (token/s): 862.25, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:31:29 TP0] Decode batch. #running-req: 4, #token: 1955, token usage: 0.00, gen throughput (token/s): 857.21, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:31:29 TP0] Decode batch. #running-req: 4, #token: 2115, token usage: 0.00, gen throughput (token/s): 880.32, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:31:30] INFO:     127.0.0.1:30774 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:31:30] INFO:     127.0.0.1:30760 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:31:30] INFO:     127.0.0.1:30766 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:31:30] INFO:     127.0.0.1:30772 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:31:30 TP0] Prefill batch. #new-seq: 4, #new-token: 2404, #cached-token: 172, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-08-25 15:31:30] INFO:     127.0.0.1:54088 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 15:31:30] INFO:     127.0.0.1:54090 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 15:31:30] INFO:     127.0.0.1:54100 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 15:31:30] INFO:     127.0.0.1:54104 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 15:31:30 TP0] Prefill batch. #new-seq: 1, #new-token: 500, #cached-token: 144, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-08-25 15:31:30 TP0] Prefill batch. #new-seq: 3, #new-token: 1500, #cached-token: 432, token usage: 0.02, #running-req: 1, #queue-req: 0, 
[2025-08-25 15:31:31] INFO:     127.0.0.1:54104 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 15:31:31] INFO:     127.0.0.1:54088 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 15:31:31] INFO:     127.0.0.1:54090 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 15:31:31] INFO:     127.0.0.1:54100 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 15:31:31 TP0] Prefill batch. #new-seq: 1, #new-token: 500, #cached-token: 144, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-08-25 15:31:31 TP0] Prefill batch. #new-seq: 3, #new-token: 1500, #cached-token: 432, token usage: 0.00, #running-req: 1, #queue-req: 0, 
[2025-08-25 15:31:31] INFO:     127.0.0.1:54104 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 15:31:31 TP0] Prefill batch. #new-seq: 1, #new-token: 500, #cached-token: 144, token usage: 0.04, #running-req: 4, #queue-req: 0, 
[2025-08-25 15:31:32] INFO:     127.0.0.1:54088 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 15:31:32] INFO:     127.0.0.1:54090 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 15:31:32] INFO:     127.0.0.1:54100 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 15:31:32 TP0] Prefill batch. #new-seq: 3, #new-token: 1500, #cached-token: 432, token usage: 0.00, #running-req: 1, #queue-req: 0, 
[2025-08-25 15:31:32] INFO:     127.0.0.1:54104 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 15:31:33] INFO:     127.0.0.1:54088 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 15:31:33] INFO:     127.0.0.1:54090 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 15:31:33] INFO:     127.0.0.1:54100 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 15:31:33 TP0] Prefill batch. #new-seq: 4, #new-token: 4, #cached-token: 1232, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-08-25 15:31:33 TP0] Decode batch. #running-req: 4, #token: 429, token usage: 0.00, gen throughput (token/s): 48.35, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:31:33 TP0] Decode batch. #running-req: 4, #token: 589, token usage: 0.00, gen throughput (token/s): 883.38, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:31:33 TP0] Decode batch. #running-req: 4, #token: 749, token usage: 0.00, gen throughput (token/s): 866.93, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:31:33 TP0] Decode batch. #running-req: 4, #token: 909, token usage: 0.00, gen throughput (token/s): 856.64, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:31:33 TP0] Decode batch. #running-req: 4, #token: 1069, token usage: 0.00, gen throughput (token/s): 894.94, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:31:34 TP0] Decode batch. #running-req: 4, #token: 1229, token usage: 0.00, gen throughput (token/s): 860.40, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:31:34 TP0] Decode batch. #running-req: 4, #token: 1389, token usage: 0.00, gen throughput (token/s): 847.24, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:31:34 TP0] Decode batch. #running-req: 4, #token: 1549, token usage: 0.00, gen throughput (token/s): 884.39, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:31:34 TP0] Decode batch. #running-req: 4, #token: 1709, token usage: 0.00, gen throughput (token/s): 859.98, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:31:34 TP0] Decode batch. #running-req: 4, #token: 1869, token usage: 0.00, gen throughput (token/s): 879.54, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:31:35 TP0] Decode batch. #running-req: 4, #token: 2029, token usage: 0.00, gen throughput (token/s): 890.38, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:31:35 TP0] Decode batch. #running-req: 4, #token: 2189, token usage: 0.00, gen throughput (token/s): 884.59, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:31:35] INFO:     127.0.0.1:30774 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:31:35] INFO:     127.0.0.1:30760 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:31:35] INFO:     127.0.0.1:30766 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:31:35] INFO:     127.0.0.1:30772 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:31:35 TP0] Prefill batch. #new-seq: 4, #new-token: 4, #cached-token: 1232, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-08-25 15:31:35 TP0] Decode batch. #running-req: 4, #token: 349, token usage: 0.00, gen throughput (token/s): 645.99, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:31:35 TP0] Decode batch. #running-req: 4, #token: 509, token usage: 0.00, gen throughput (token/s): 872.83, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:31:35 TP0] Decode batch. #running-req: 4, #token: 669, token usage: 0.00, gen throughput (token/s): 873.90, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:31:36 TP0] Decode batch. #running-req: 4, #token: 829, token usage: 0.00, gen throughput (token/s): 865.04, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:31:36 TP0] Decode batch. #running-req: 4, #token: 989, token usage: 0.00, gen throughput (token/s): 859.24, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:31:36 TP0] Decode batch. #running-req: 4, #token: 1149, token usage: 0.00, gen throughput (token/s): 870.05, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:31:36 TP0] Decode batch. #running-req: 4, #token: 1309, token usage: 0.00, gen throughput (token/s): 843.16, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:31:36 TP0] Decode batch. #running-req: 4, #token: 1469, token usage: 0.00, gen throughput (token/s): 889.46, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:31:36 TP0] Decode batch. #running-req: 4, #token: 1629, token usage: 0.00, gen throughput (token/s): 881.84, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:31:37 TP0] Decode batch. #running-req: 4, #token: 1789, token usage: 0.00, gen throughput (token/s): 888.52, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:31:37 TP0] Decode batch. #running-req: 4, #token: 1949, token usage: 0.00, gen throughput (token/s): 888.88, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:31:37 TP0] Decode batch. #running-req: 4, #token: 2109, token usage: 0.00, gen throughput (token/s): 897.66, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:31:37 TP0] Decode batch. #running-req: 4, #token: 2269, token usage: 0.00, gen throughput (token/s): 891.58, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:31:37] INFO:     127.0.0.1:30774 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:31:37] INFO:     127.0.0.1:30760 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:31:37] INFO:     127.0.0.1:30766 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:31:37] INFO:     127.0.0.1:30772 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:31:37 TP0] Prefill batch. #new-seq: 3, #new-token: 3, #cached-token: 924, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-08-25 15:31:37 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 308, token usage: 0.00, #running-req: 3, #queue-req: 0, 
[2025-08-25 15:31:37 TP0] Decode batch. #running-req: 4, #token: 429, token usage: 0.00, gen throughput (token/s): 607.35, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:31:38 TP0] Decode batch. #running-req: 4, #token: 589, token usage: 0.00, gen throughput (token/s): 868.93, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:31:38 TP0] Decode batch. #running-req: 4, #token: 749, token usage: 0.00, gen throughput (token/s): 874.31, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:31:38 TP0] Decode batch. #running-req: 4, #token: 909, token usage: 0.00, gen throughput (token/s): 820.00, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:31:38 TP0] Decode batch. #running-req: 4, #token: 1069, token usage: 0.00, gen throughput (token/s): 906.18, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:31:38 TP0] Decode batch. #running-req: 4, #token: 1229, token usage: 0.00, gen throughput (token/s): 863.06, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:31:39 TP0] Decode batch. #running-req: 4, #token: 1389, token usage: 0.00, gen throughput (token/s): 872.41, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:31:39 TP0] Decode batch. #running-req: 4, #token: 1549, token usage: 0.00, gen throughput (token/s): 882.00, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:31:39 TP0] Decode batch. #running-req: 4, #token: 1709, token usage: 0.00, gen throughput (token/s): 882.77, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:31:39 TP0] Decode batch. #running-req: 4, #token: 1869, token usage: 0.00, gen throughput (token/s): 877.40, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:31:39 TP0] Decode batch. #running-req: 4, #token: 2029, token usage: 0.00, gen throughput (token/s): 881.77, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:31:39 TP0] Decode batch. #running-req: 4, #token: 2189, token usage: 0.00, gen throughput (token/s): 878.16, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:31:40] INFO:     127.0.0.1:30774 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:31:40] INFO:     127.0.0.1:30760 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:31:40] INFO:     127.0.0.1:30766 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:31:40] INFO:     127.0.0.1:30772 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:31:40 TP0] Prefill batch. #new-seq: 3, #new-token: 3, #cached-token: 924, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-08-25 15:31:40 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 308, token usage: 0.00, #running-req: 3, #queue-req: 0, 
[2025-08-25 15:31:40 TP0] Decode batch. #running-req: 4, #token: 349, token usage: 0.00, gen throughput (token/s): 578.82, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:31:40 TP0] Decode batch. #running-req: 4, #token: 509, token usage: 0.00, gen throughput (token/s): 865.17, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:31:40 TP0] Decode batch. #running-req: 4, #token: 669, token usage: 0.00, gen throughput (token/s): 869.66, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:31:40 TP0] Decode batch. #running-req: 4, #token: 829, token usage: 0.00, gen throughput (token/s): 882.28, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:31:41 TP0] Decode batch. #running-req: 4, #token: 989, token usage: 0.00, gen throughput (token/s): 867.99, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:31:41 TP0] Decode batch. #running-req: 4, #token: 1149, token usage: 0.00, gen throughput (token/s): 871.19, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:31:41 TP0] Decode batch. #running-req: 4, #token: 1309, token usage: 0.00, gen throughput (token/s): 863.94, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:31:41 TP0] Decode batch. #running-req: 4, #token: 1469, token usage: 0.00, gen throughput (token/s): 881.13, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:31:41 TP0] Decode batch. #running-req: 4, #token: 1629, token usage: 0.00, gen throughput (token/s): 907.39, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:31:41 TP0] Decode batch. #running-req: 4, #token: 1789, token usage: 0.00, gen throughput (token/s): 893.19, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:31:42 TP0] Decode batch. #running-req: 4, #token: 1949, token usage: 0.00, gen throughput (token/s): 876.17, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:31:42 TP0] Decode batch. #running-req: 4, #token: 2109, token usage: 0.00, gen throughput (token/s): 862.89, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:31:42 TP0] Decode batch. #running-req: 4, #token: 2269, token usage: 0.00, gen throughput (token/s): 887.18, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:31:42] INFO:     127.0.0.1:30774 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:31:42] INFO:     127.0.0.1:30760 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:31:42] INFO:     127.0.0.1:30766 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:31:42] INFO:     127.0.0.1:30772 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:31:42 TP0] Prefill batch. #new-seq: 1, #new-token: 754, #cached-token: 44, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-08-25 15:31:42 TP0] Prefill batch. #new-seq: 3, #new-token: 2262, #cached-token: 132, token usage: 0.02, #running-req: 1, #queue-req: 0, 
[2025-08-25 15:31:43] INFO:     127.0.0.1:46528 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 15:31:43] INFO:     127.0.0.1:46544 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 15:31:43] INFO:     127.0.0.1:46550 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 15:31:43] INFO:     127.0.0.1:46564 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 15:31:43 TP0] Prefill batch. #new-seq: 1, #new-token: 500, #cached-token: 298, token usage: 0.01, #running-req: 0, #queue-req: 0, 
[2025-08-25 15:31:43 TP0] Prefill batch. #new-seq: 3, #new-token: 1500, #cached-token: 894, token usage: 0.01, #running-req: 1, #queue-req: 0, 
[2025-08-25 15:31:43] INFO:     127.0.0.1:46528 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 15:31:43 TP0] Prefill batch. #new-seq: 1, #new-token: 500, #cached-token: 298, token usage: 0.05, #running-req: 4, #queue-req: 0, 
[2025-08-25 15:31:44] INFO:     127.0.0.1:46564 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 15:31:44] INFO:     127.0.0.1:46544 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 15:31:44] INFO:     127.0.0.1:46550 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 15:31:44 TP0] Prefill batch. #new-seq: 3, #new-token: 1500, #cached-token: 894, token usage: 0.01, #running-req: 1, #queue-req: 0, 
[2025-08-25 15:31:44] INFO:     127.0.0.1:46528 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 15:31:44 TP0] Prefill batch. #new-seq: 1, #new-token: 500, #cached-token: 298, token usage: 0.05, #running-req: 4, #queue-req: 0, 
[2025-08-25 15:31:44] INFO:     127.0.0.1:46564 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 15:31:45] INFO:     127.0.0.1:46544 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 15:31:45] INFO:     127.0.0.1:46550 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 15:31:45 TP0] Prefill batch. #new-seq: 3, #new-token: 1500, #cached-token: 894, token usage: 0.01, #running-req: 1, #queue-req: 0, 
[2025-08-25 15:31:45] INFO:     127.0.0.1:46528 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 15:31:45 TP0] Prefill batch. #new-seq: 1, #new-token: 761, #cached-token: 46, token usage: 0.05, #running-req: 4, #queue-req: 0, 
[2025-08-25 15:31:45] INFO:     127.0.0.1:46564 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 15:31:45] INFO:     127.0.0.1:46544 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 15:31:45] INFO:     127.0.0.1:46550 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 15:31:45 TP0] Prefill batch. #new-seq: 3, #new-token: 1447, #cached-token: 974, token usage: 0.02, #running-req: 1, #queue-req: 0, 
[2025-08-25 15:31:46 TP0] Decode batch. #running-req: 4, #token: 2307, token usage: 0.06, gen throughput (token/s): 2.35, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:31:48 TP0] Decode batch. #running-req: 4, #token: 2467, token usage: 0.06, gen throughput (token/s): 88.39, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:31:50 TP0] Decode batch. #running-req: 4, #token: 2627, token usage: 0.07, gen throughput (token/s): 88.15, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:31:52 TP0] Decode batch. #running-req: 4, #token: 2787, token usage: 0.07, gen throughput (token/s): 88.04, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:31:53] INFO:     127.0.0.1:46528 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:31:53] INFO:     127.0.0.1:46564 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:31:53] INFO:     127.0.0.1:46544 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:31:53] INFO:     127.0.0.1:46550 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:31:53 TP0] Prefill batch. #new-seq: 1, #new-token: 492, #cached-token: 315, token usage: 0.01, #running-req: 3, #queue-req: 0, 
[2025-08-25 15:31:53 TP0] Prefill batch. #new-seq: 3, #new-token: 1452, #cached-token: 969, token usage: 0.02, #running-req: 4, #queue-req: 0, 
[2025-08-25 15:31:54 TP0] Decode batch. #running-req: 4, #token: 2363, token usage: 0.06, gen throughput (token/s): 65.24, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:31:56 TP0] Decode batch. #running-req: 4, #token: 2523, token usage: 0.06, gen throughput (token/s): 88.04, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:31:58 TP0] Decode batch. #running-req: 4, #token: 2683, token usage: 0.07, gen throughput (token/s): 88.07, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:32:00 TP0] Decode batch. #running-req: 4, #token: 2843, token usage: 0.07, gen throughput (token/s): 88.29, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:32:00] INFO:     127.0.0.1:46528 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:32:00] INFO:     127.0.0.1:46564 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:32:00] INFO:     127.0.0.1:46544 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:32:00] INFO:     127.0.0.1:46550 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:32:00 TP0] Prefill batch. #new-seq: 4, #new-token: 1951, #cached-token: 1277, token usage: 0.01, #running-req: 0, #queue-req: 0, 
[2025-08-25 15:32:02 TP0] Decode batch. #running-req: 4, #token: 2424, token usage: 0.06, gen throughput (token/s): 66.24, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:32:04 TP0] Decode batch. #running-req: 4, #token: 2584, token usage: 0.06, gen throughput (token/s): 87.97, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:32:06 TP0] Decode batch. #running-req: 4, #token: 2744, token usage: 0.07, gen throughput (token/s): 87.98, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:32:08] INFO:     127.0.0.1:46564 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:32:08] INFO:     127.0.0.1:46528 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:32:08] INFO:     127.0.0.1:46544 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:32:08] INFO:     127.0.0.1:46550 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:32:08 TP0] Prefill batch. #new-seq: 1, #new-token: 475, #cached-token: 332, token usage: 0.01, #running-req: 0, #queue-req: 0, 
[2025-08-25 15:32:08 TP0] Decode batch. #running-req: 1, #token: 810, token usage: 0.02, gen throughput (token/s): 77.78, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:32:10 TP0] Decode batch. #running-req: 1, #token: 850, token usage: 0.02, gen throughput (token/s): 22.67, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:32:11 TP0] Decode batch. #running-req: 1, #token: 890, token usage: 0.02, gen throughput (token/s): 22.60, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:32:13 TP0] Decode batch. #running-req: 1, #token: 930, token usage: 0.02, gen throughput (token/s): 22.59, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:32:14] INFO:     127.0.0.1:46564 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:32:14 TP0] Prefill batch. #new-seq: 2, #new-token: 2, #cached-token: 504, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-08-25 15:32:14 TP0] Prefill batch. #new-seq: 2, #new-token: 2, #cached-token: 504, token usage: 0.00, #running-req: 2, #queue-req: 0, 
[2025-08-25 15:32:15 TP0] Decode batch. #running-req: 4, #token: 373, token usage: 0.00, gen throughput (token/s): 4.91, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:32:15 TP0] Decode batch. #running-req: 4, #token: 533, token usage: 0.00, gen throughput (token/s): 884.81, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:32:15 TP0] Decode batch. #running-req: 4, #token: 693, token usage: 0.00, gen throughput (token/s): 888.38, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:32:15 TP0] Decode batch. #running-req: 4, #token: 853, token usage: 0.00, gen throughput (token/s): 896.50, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:32:15 TP0] Decode batch. #running-req: 4, #token: 1013, token usage: 0.00, gen throughput (token/s): 873.53, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:32:15 TP0] Decode batch. #running-req: 4, #token: 1173, token usage: 0.00, gen throughput (token/s): 879.12, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:32:16 TP0] Decode batch. #running-req: 4, #token: 1333, token usage: 0.00, gen throughput (token/s): 893.29, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:32:16 TP0] Decode batch. #running-req: 4, #token: 1493, token usage: 0.00, gen throughput (token/s): 864.14, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:32:16 TP0] Decode batch. #running-req: 4, #token: 1653, token usage: 0.00, gen throughput (token/s): 886.10, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:32:16 TP0] Decode batch. #running-req: 4, #token: 1813, token usage: 0.00, gen throughput (token/s): 903.81, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:32:16 TP0] Decode batch. #running-req: 4, #token: 1973, token usage: 0.00, gen throughput (token/s): 912.65, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:32:17 TP0] Decode batch. #running-req: 4, #token: 2133, token usage: 0.00, gen throughput (token/s): 903.09, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:32:17] INFO:     127.0.0.1:13290 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:32:17] INFO:     127.0.0.1:13288 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:32:17] INFO:     127.0.0.1:13306 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:32:17] INFO:     127.0.0.1:13314 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:32:17 TP0] Prefill batch. #new-seq: 4, #new-token: 4, #cached-token: 1008, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-08-25 15:32:17 TP0] Decode batch. #running-req: 4, #token: 293, token usage: 0.00, gen throughput (token/s): 657.81, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:32:17 TP0] Decode batch. #running-req: 4, #token: 453, token usage: 0.00, gen throughput (token/s): 885.20, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:32:17 TP0] Decode batch. #running-req: 4, #token: 613, token usage: 0.00, gen throughput (token/s): 876.98, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:32:17 TP0] Decode batch. #running-req: 4, #token: 773, token usage: 0.00, gen throughput (token/s): 873.34, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:32:18 TP0] Decode batch. #running-req: 4, #token: 933, token usage: 0.00, gen throughput (token/s): 863.89, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:32:18 TP0] Decode batch. #running-req: 4, #token: 1093, token usage: 0.00, gen throughput (token/s): 890.36, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:32:18 TP0] Decode batch. #running-req: 4, #token: 1253, token usage: 0.00, gen throughput (token/s): 881.52, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:32:18 TP0] Decode batch. #running-req: 4, #token: 1413, token usage: 0.00, gen throughput (token/s): 877.38, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:32:18 TP0] Decode batch. #running-req: 4, #token: 1573, token usage: 0.00, gen throughput (token/s): 887.70, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:32:18 TP0] Decode batch. #running-req: 4, #token: 1733, token usage: 0.00, gen throughput (token/s): 872.77, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:32:19 TP0] Decode batch. #running-req: 4, #token: 1893, token usage: 0.00, gen throughput (token/s): 878.49, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:32:19 TP0] Decode batch. #running-req: 4, #token: 2053, token usage: 0.00, gen throughput (token/s): 898.94, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:32:19 TP0] Decode batch. #running-req: 4, #token: 2213, token usage: 0.00, gen throughput (token/s): 880.34, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:32:19] INFO:     127.0.0.1:13314 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:32:19] INFO:     127.0.0.1:13288 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:32:19] INFO:     127.0.0.1:13290 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:32:19] INFO:     127.0.0.1:13306 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:32:19 TP0] Prefill batch. #new-seq: 4, #new-token: 4, #cached-token: 1008, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-08-25 15:32:19 TP0] Decode batch. #running-req: 4, #token: 373, token usage: 0.00, gen throughput (token/s): 698.54, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:32:19 TP0] Decode batch. #running-req: 4, #token: 533, token usage: 0.00, gen throughput (token/s): 892.05, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:32:20 TP0] Decode batch. #running-req: 4, #token: 693, token usage: 0.00, gen throughput (token/s): 871.74, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:32:20 TP0] Decode batch. #running-req: 4, #token: 853, token usage: 0.00, gen throughput (token/s): 874.50, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:32:20 TP0] Decode batch. #running-req: 4, #token: 1013, token usage: 0.00, gen throughput (token/s): 884.99, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:32:20 TP0] Decode batch. #running-req: 4, #token: 1173, token usage: 0.00, gen throughput (token/s): 878.91, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:32:20 TP0] Decode batch. #running-req: 4, #token: 1333, token usage: 0.00, gen throughput (token/s): 904.82, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:32:20 TP0] Decode batch. #running-req: 4, #token: 1493, token usage: 0.00, gen throughput (token/s): 879.07, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:32:21 TP0] Decode batch. #running-req: 4, #token: 1653, token usage: 0.00, gen throughput (token/s): 870.38, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:32:21 TP0] Decode batch. #running-req: 4, #token: 1813, token usage: 0.00, gen throughput (token/s): 880.62, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:32:21 TP0] Decode batch. #running-req: 4, #token: 1973, token usage: 0.00, gen throughput (token/s): 864.15, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:32:21 TP0] Decode batch. #running-req: 4, #token: 2133, token usage: 0.00, gen throughput (token/s): 863.78, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:32:21] INFO:     127.0.0.1:13314 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:32:21] INFO:     127.0.0.1:13288 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:32:21] INFO:     127.0.0.1:13290 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:32:21] INFO:     127.0.0.1:13306 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:32:21 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 252, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-08-25 15:32:21 TP0] Prefill batch. #new-seq: 3, #new-token: 3, #cached-token: 756, token usage: 0.00, #running-req: 1, #queue-req: 0, 
[2025-08-25 15:32:21 TP0] Decode batch. #running-req: 4, #token: 293, token usage: 0.00, gen throughput (token/s): 588.24, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:32:22 TP0] Decode batch. #running-req: 4, #token: 453, token usage: 0.00, gen throughput (token/s): 874.95, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:32:22 TP0] Decode batch. #running-req: 4, #token: 613, token usage: 0.00, gen throughput (token/s): 889.60, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:32:22 TP0] Decode batch. #running-req: 4, #token: 773, token usage: 0.00, gen throughput (token/s): 880.09, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:32:22 TP0] Decode batch. #running-req: 4, #token: 933, token usage: 0.00, gen throughput (token/s): 883.56, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:32:22 TP0] Decode batch. #running-req: 4, #token: 1093, token usage: 0.00, gen throughput (token/s): 883.39, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:32:23 TP0] Decode batch. #running-req: 4, #token: 1253, token usage: 0.00, gen throughput (token/s): 882.22, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:32:23 TP0] Decode batch. #running-req: 4, #token: 1413, token usage: 0.00, gen throughput (token/s): 863.33, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:32:23 TP0] Decode batch. #running-req: 4, #token: 1573, token usage: 0.00, gen throughput (token/s): 873.13, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:32:23 TP0] Decode batch. #running-req: 4, #token: 1733, token usage: 0.00, gen throughput (token/s): 856.69, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:32:23 TP0] Decode batch. #running-req: 4, #token: 1893, token usage: 0.00, gen throughput (token/s): 829.50, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:32:23 TP0] Decode batch. #running-req: 4, #token: 2053, token usage: 0.00, gen throughput (token/s): 851.76, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:32:24 TP0] Decode batch. #running-req: 4, #token: 2213, token usage: 0.00, gen throughput (token/s): 877.88, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:32:24] INFO:     127.0.0.1:13314 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:32:24] INFO:     127.0.0.1:13288 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:32:24] INFO:     127.0.0.1:13290 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:32:24] INFO:     127.0.0.1:13306 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:32:24 TP0] Prefill batch. #new-seq: 4, #new-token: 2800, #cached-token: 168, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-08-25 15:32:25] INFO:     127.0.0.1:11848 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 15:32:25] INFO:     127.0.0.1:11854 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 15:32:25] INFO:     127.0.0.1:11864 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 15:32:25] INFO:     127.0.0.1:11866 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 15:32:25 TP0] Prefill batch. #new-seq: 4, #new-token: 2000, #cached-token: 968, token usage: 0.01, #running-req: 0, #queue-req: 0, 
[2025-08-25 15:32:25] INFO:     127.0.0.1:11866 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 15:32:25] INFO:     127.0.0.1:11848 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 15:32:25] INFO:     127.0.0.1:11854 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 15:32:25] INFO:     127.0.0.1:11864 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 15:32:25 TP0] Prefill batch. #new-seq: 1, #new-token: 500, #cached-token: 242, token usage: 0.01, #running-req: 0, #queue-req: 0, 
[2025-08-25 15:32:26 TP0] Prefill batch. #new-seq: 3, #new-token: 1500, #cached-token: 726, token usage: 0.02, #running-req: 1, #queue-req: 0, 
[2025-08-25 15:32:26] INFO:     127.0.0.1:11866 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 15:32:26 TP0] Prefill batch. #new-seq: 1, #new-token: 500, #cached-token: 242, token usage: 0.01, #running-req: 3, #queue-req: 0, 
[2025-08-25 15:32:26] INFO:     127.0.0.1:11848 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 15:32:26] INFO:     127.0.0.1:11854 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 15:32:26] INFO:     127.0.0.1:11864 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 15:32:26 TP0] Prefill batch. #new-seq: 3, #new-token: 1500, #cached-token: 726, token usage: 0.02, #running-req: 4, #queue-req: 0, 
[2025-08-25 15:32:26] INFO:     127.0.0.1:11866 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 15:32:27 TP0] Prefill batch. #new-seq: 1, #new-token: 707, #cached-token: 44, token usage: 0.00, #running-req: 3, #queue-req: 0, 
[2025-08-25 15:32:27] INFO:     127.0.0.1:11848 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 15:32:27] INFO:     127.0.0.1:11854 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 15:32:27] INFO:     127.0.0.1:11864 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 15:32:27 TP0] Prefill batch. #new-seq: 1, #new-token: 707, #cached-token: 44, token usage: 0.02, #running-req: 4, #queue-req: 0, 
[2025-08-25 15:32:28 TP0] Decode batch. #running-req: 2, #token: 1248, token usage: 0.03, gen throughput (token/s): 3.97, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:32:30 TP0] Decode batch. #running-req: 2, #token: 1328, token usage: 0.03, gen throughput (token/s): 44.85, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:32:31 TP0] Decode batch. #running-req: 2, #token: 1408, token usage: 0.04, gen throughput (token/s): 44.94, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:32:33 TP0] Decode batch. #running-req: 2, #token: 1488, token usage: 0.04, gen throughput (token/s): 44.93, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:32:34] INFO:     127.0.0.1:11866 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:32:34] INFO:     127.0.0.1:11848 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:32:34 TP0] Prefill batch. #new-seq: 3, #new-token: 3, #cached-token: 489, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-08-25 15:32:34 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 163, token usage: 0.00, #running-req: 3, #queue-req: 0, 
[2025-08-25 15:32:34 TP0] Decode batch. #running-req: 4, #token: 284, token usage: 0.00, gen throughput (token/s): 15.10, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:32:34 TP0] Decode batch. #running-req: 4, #token: 444, token usage: 0.00, gen throughput (token/s): 883.34, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:32:35 TP0] Decode batch. #running-req: 4, #token: 604, token usage: 0.00, gen throughput (token/s): 876.29, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:32:35 TP0] Decode batch. #running-req: 4, #token: 764, token usage: 0.00, gen throughput (token/s): 864.41, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:32:35 TP0] Decode batch. #running-req: 4, #token: 924, token usage: 0.00, gen throughput (token/s): 892.81, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:32:35 TP0] Decode batch. #running-req: 4, #token: 1084, token usage: 0.00, gen throughput (token/s): 904.54, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:32:35 TP0] Decode batch. #running-req: 4, #token: 1244, token usage: 0.00, gen throughput (token/s): 923.64, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:32:36 TP0] Decode batch. #running-req: 4, #token: 1404, token usage: 0.00, gen throughput (token/s): 899.34, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:32:36 TP0] Decode batch. #running-req: 4, #token: 1564, token usage: 0.00, gen throughput (token/s): 904.03, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:32:36 TP0] Decode batch. #running-req: 4, #token: 1724, token usage: 0.00, gen throughput (token/s): 914.47, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:32:36 TP0] Decode batch. #running-req: 4, #token: 1884, token usage: 0.00, gen throughput (token/s): 907.11, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:32:36 TP0] Decode batch. #running-req: 4, #token: 2044, token usage: 0.00, gen throughput (token/s): 896.90, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:32:36] INFO:     127.0.0.1:30776 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:32:36] INFO:     127.0.0.1:30782 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:32:36] INFO:     127.0.0.1:30786 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:32:36] INFO:     127.0.0.1:30796 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:32:36 TP0] Prefill batch. #new-seq: 3, #new-token: 3, #cached-token: 489, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-08-25 15:32:36 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 163, token usage: 0.00, #running-req: 3, #queue-req: 0, 
[2025-08-25 15:32:36 TP0] Decode batch. #running-req: 4, #token: 204, token usage: 0.00, gen throughput (token/s): 599.36, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:32:37 TP0] Decode batch. #running-req: 4, #token: 364, token usage: 0.00, gen throughput (token/s): 879.27, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:32:37 TP0] Decode batch. #running-req: 4, #token: 524, token usage: 0.00, gen throughput (token/s): 875.09, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:32:37 TP0] Decode batch. #running-req: 4, #token: 684, token usage: 0.00, gen throughput (token/s): 862.44, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:32:37 TP0] Decode batch. #running-req: 4, #token: 844, token usage: 0.00, gen throughput (token/s): 885.56, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:32:37 TP0] Decode batch. #running-req: 4, #token: 1004, token usage: 0.00, gen throughput (token/s): 863.77, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:32:38 TP0] Decode batch. #running-req: 4, #token: 1164, token usage: 0.00, gen throughput (token/s): 889.95, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:32:38 TP0] Decode batch. #running-req: 4, #token: 1324, token usage: 0.00, gen throughput (token/s): 869.01, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:32:38 TP0] Decode batch. #running-req: 4, #token: 1484, token usage: 0.00, gen throughput (token/s): 878.08, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:32:38 TP0] Decode batch. #running-req: 4, #token: 1644, token usage: 0.00, gen throughput (token/s): 852.13, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:32:38 TP0] Decode batch. #running-req: 4, #token: 1804, token usage: 0.00, gen throughput (token/s): 862.99, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:32:39 TP0] Decode batch. #running-req: 4, #token: 1964, token usage: 0.00, gen throughput (token/s): 851.48, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:32:39 TP0] Decode batch. #running-req: 4, #token: 2124, token usage: 0.00, gen throughput (token/s): 885.59, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:32:39] INFO:     127.0.0.1:30796 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:32:39] INFO:     127.0.0.1:30776 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:32:39] INFO:     127.0.0.1:30782 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:32:39] INFO:     127.0.0.1:30786 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:32:39 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 163, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-08-25 15:32:39 TP0] Prefill batch. #new-seq: 3, #new-token: 3, #cached-token: 489, token usage: 0.00, #running-req: 1, #queue-req: 0, 
[2025-08-25 15:32:39 TP0] Decode batch. #running-req: 4, #token: 284, token usage: 0.00, gen throughput (token/s): 599.47, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:32:39 TP0] Decode batch. #running-req: 4, #token: 444, token usage: 0.00, gen throughput (token/s): 909.31, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:32:39 TP0] Decode batch. #running-req: 4, #token: 604, token usage: 0.00, gen throughput (token/s): 892.25, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:32:39 TP0] Decode batch. #running-req: 4, #token: 764, token usage: 0.00, gen throughput (token/s): 922.10, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:32:40 TP0] Decode batch. #running-req: 4, #token: 924, token usage: 0.00, gen throughput (token/s): 926.83, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:32:40 TP0] Decode batch. #running-req: 4, #token: 1084, token usage: 0.00, gen throughput (token/s): 923.14, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:32:40 TP0] Decode batch. #running-req: 4, #token: 1244, token usage: 0.00, gen throughput (token/s): 920.23, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:32:40 TP0] Decode batch. #running-req: 4, #token: 1404, token usage: 0.00, gen throughput (token/s): 919.49, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:32:40 TP0] Decode batch. #running-req: 4, #token: 1564, token usage: 0.00, gen throughput (token/s): 916.59, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:32:41 TP0] Decode batch. #running-req: 4, #token: 1724, token usage: 0.00, gen throughput (token/s): 922.26, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:32:41 TP0] Decode batch. #running-req: 4, #token: 1884, token usage: 0.00, gen throughput (token/s): 949.03, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:32:41 TP0] Decode batch. #running-req: 4, #token: 2044, token usage: 0.00, gen throughput (token/s): 920.59, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:32:41] INFO:     127.0.0.1:30796 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:32:41] INFO:     127.0.0.1:30776 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:32:41] INFO:     127.0.0.1:30782 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:32:41] INFO:     127.0.0.1:30786 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:32:41 TP0] Prefill batch. #new-seq: 2, #new-token: 2, #cached-token: 326, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-08-25 15:32:41 TP0] Prefill batch. #new-seq: 2, #new-token: 2, #cached-token: 326, token usage: 0.00, #running-req: 2, #queue-req: 0, 
[2025-08-25 15:32:41 TP0] Decode batch. #running-req: 4, #token: 204, token usage: 0.00, gen throughput (token/s): 609.47, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:32:41 TP0] Decode batch. #running-req: 4, #token: 364, token usage: 0.00, gen throughput (token/s): 872.79, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:32:42 TP0] Decode batch. #running-req: 4, #token: 524, token usage: 0.00, gen throughput (token/s): 849.03, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:32:42 TP0] Decode batch. #running-req: 4, #token: 684, token usage: 0.00, gen throughput (token/s): 886.34, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:32:42 TP0] Decode batch. #running-req: 4, #token: 844, token usage: 0.00, gen throughput (token/s): 883.66, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:32:42 TP0] Decode batch. #running-req: 4, #token: 1004, token usage: 0.00, gen throughput (token/s): 880.74, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:32:42 TP0] Decode batch. #running-req: 4, #token: 1164, token usage: 0.00, gen throughput (token/s): 873.35, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:32:42 TP0] Decode batch. #running-req: 4, #token: 1324, token usage: 0.00, gen throughput (token/s): 869.86, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:32:43 TP0] Decode batch. #running-req: 4, #token: 1484, token usage: 0.00, gen throughput (token/s): 903.80, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:32:43 TP0] Decode batch. #running-req: 4, #token: 1644, token usage: 0.00, gen throughput (token/s): 909.88, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:32:43 TP0] Decode batch. #running-req: 4, #token: 1804, token usage: 0.00, gen throughput (token/s): 916.17, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:32:43 TP0] Decode batch. #running-req: 4, #token: 1964, token usage: 0.00, gen throughput (token/s): 914.74, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:32:43 TP0] Decode batch. #running-req: 4, #token: 2124, token usage: 0.00, gen throughput (token/s): 949.50, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:32:43] INFO:     127.0.0.1:30796 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:32:43] INFO:     127.0.0.1:30776 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:32:43] INFO:     127.0.0.1:30782 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:32:43] INFO:     127.0.0.1:30786 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:32:43 TP0] Prefill batch. #new-seq: 1, #new-token: 610, #cached-token: 43, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-08-25 15:32:43 TP0] Prefill batch. #new-seq: 3, #new-token: 1830, #cached-token: 129, token usage: 0.02, #running-req: 1, #queue-req: 0, 
[2025-08-25 15:32:44] INFO:     127.0.0.1:63086 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 15:32:44] INFO:     127.0.0.1:63088 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 15:32:44] INFO:     127.0.0.1:63090 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 15:32:44] INFO:     127.0.0.1:63092 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 15:32:44 TP0] Prefill batch. #new-seq: 1, #new-token: 500, #cached-token: 153, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-08-25 15:32:44 TP0] Prefill batch. #new-seq: 1, #new-token: 500, #cached-token: 153, token usage: 0.02, #running-req: 1, #queue-req: 0, 
[2025-08-25 15:32:44 TP0] Prefill batch. #new-seq: 2, #new-token: 1000, #cached-token: 306, token usage: 0.02, #running-req: 2, #queue-req: 0, 
[2025-08-25 15:32:44] INFO:     127.0.0.1:63086 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 15:32:45 TP0] Prefill batch. #new-seq: 1, #new-token: 500, #cached-token: 153, token usage: 0.03, #running-req: 4, #queue-req: 0, 
[2025-08-25 15:32:45] INFO:     127.0.0.1:63092 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 15:32:45 TP0] Prefill batch. #new-seq: 1, #new-token: 500, #cached-token: 153, token usage: 0.02, #running-req: 5, #queue-req: 0, 
[2025-08-25 15:32:45] INFO:     127.0.0.1:63088 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 15:32:45] INFO:     127.0.0.1:63090 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 15:32:45 TP0] Prefill batch. #new-seq: 2, #new-token: 1000, #cached-token: 306, token usage: 0.02, #running-req: 6, #queue-req: 0, 
[2025-08-25 15:32:45] INFO:     127.0.0.1:63086 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 15:32:46 TP0] Prefill batch. #new-seq: 1, #new-token: 500, #cached-token: 153, token usage: 0.03, #running-req: 8, #queue-req: 0, 
[2025-08-25 15:32:46] INFO:     127.0.0.1:63092 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 15:32:46 TP0] Prefill batch. #new-seq: 1, #new-token: 500, #cached-token: 153, token usage: 0.02, #running-req: 9, #queue-req: 0, 
[2025-08-25 15:32:46] INFO:     127.0.0.1:63088 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 15:32:46] INFO:     127.0.0.1:63090 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 15:32:46 TP0] Prefill batch. #new-seq: 2, #new-token: 1000, #cached-token: 306, token usage: 0.02, #running-req: 10, #queue-req: 0, 
[2025-08-25 15:32:46] INFO:     127.0.0.1:63086 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 15:32:46 TP0] Prefill batch. #new-seq: 1, #new-token: 617, #cached-token: 45, token usage: 0.03, #running-req: 12, #queue-req: 0, 
[2025-08-25 15:32:46] INFO:     127.0.0.1:63092 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 15:32:46 TP0] Prefill batch. #new-seq: 1, #new-token: 617, #cached-token: 45, token usage: 0.02, #running-req: 13, #queue-req: 0, 
[2025-08-25 15:32:46] INFO:     127.0.0.1:63088 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 15:32:46] INFO:     127.0.0.1:63090 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 15:32:46 TP0] Prefill batch. #new-seq: 1, #new-token: 496, #cached-token: 166, token usage: 0.03, #running-req: 14, #queue-req: 0, 
[2025-08-25 15:32:48 TP0] Decode batch. #running-req: 3, #token: 1702, token usage: 0.04, gen throughput (token/s): 6.77, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:32:49 TP0] Decode batch. #running-req: 3, #token: 1822, token usage: 0.05, gen throughput (token/s): 66.61, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:32:51 TP0] Decode batch. #running-req: 3, #token: 1942, token usage: 0.05, gen throughput (token/s): 66.43, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:32:53 TP0] Decode batch. #running-req: 3, #token: 2062, token usage: 0.05, gen throughput (token/s): 66.21, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:32:54] INFO:     127.0.0.1:63086 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:32:54] INFO:     127.0.0.1:63092 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:32:54] INFO:     127.0.0.1:63090 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:32:54 TP0] Prefill batch. #new-seq: 4, #new-token: 4, #cached-token: 528, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-08-25 15:32:54 TP0] Decode batch. #running-req: 4, #token: 253, token usage: 0.00, gen throughput (token/s): 15.33, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:32:54 TP0] Decode batch. #running-req: 4, #token: 413, token usage: 0.00, gen throughput (token/s): 897.08, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:32:54 TP0] Decode batch. #running-req: 4, #token: 573, token usage: 0.00, gen throughput (token/s): 858.72, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:32:54 TP0] Decode batch. #running-req: 4, #token: 733, token usage: 0.00, gen throughput (token/s): 907.97, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:32:54 TP0] Decode batch. #running-req: 4, #token: 893, token usage: 0.00, gen throughput (token/s): 910.31, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:32:55 TP0] Decode batch. #running-req: 4, #token: 1053, token usage: 0.00, gen throughput (token/s): 899.46, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:32:55 TP0] Decode batch. #running-req: 4, #token: 1213, token usage: 0.00, gen throughput (token/s): 915.77, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:32:55 TP0] Decode batch. #running-req: 4, #token: 1373, token usage: 0.00, gen throughput (token/s): 906.36, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:32:55 TP0] Decode batch. #running-req: 4, #token: 1533, token usage: 0.00, gen throughput (token/s): 908.22, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:32:55 TP0] Decode batch. #running-req: 4, #token: 1693, token usage: 0.00, gen throughput (token/s): 918.83, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:32:56 TP0] Decode batch. #running-req: 4, #token: 1853, token usage: 0.00, gen throughput (token/s): 892.38, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:32:56 TP0] Decode batch. #running-req: 4, #token: 2013, token usage: 0.00, gen throughput (token/s): 904.41, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:32:56] INFO:     127.0.0.1:46736 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:32:56] INFO:     127.0.0.1:46744 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:32:56] INFO:     127.0.0.1:46760 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:32:56] INFO:     127.0.0.1:46768 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:32:56 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 132, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-08-25 15:32:56 TP0] Prefill batch. #new-seq: 3, #new-token: 3, #cached-token: 396, token usage: 0.00, #running-req: 1, #queue-req: 0, 
[2025-08-25 15:32:56 TP0] Decode batch. #running-req: 4, #token: 173, token usage: 0.00, gen throughput (token/s): 582.93, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:32:56 TP0] Decode batch. #running-req: 4, #token: 333, token usage: 0.00, gen throughput (token/s): 869.38, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:32:56 TP0] Decode batch. #running-req: 4, #token: 493, token usage: 0.00, gen throughput (token/s): 839.52, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:32:57 TP0] Decode batch. #running-req: 4, #token: 653, token usage: 0.00, gen throughput (token/s): 873.83, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:32:57 TP0] Decode batch. #running-req: 4, #token: 813, token usage: 0.00, gen throughput (token/s): 885.93, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:32:57 TP0] Decode batch. #running-req: 4, #token: 973, token usage: 0.00, gen throughput (token/s): 883.78, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:32:57 TP0] Decode batch. #running-req: 4, #token: 1133, token usage: 0.00, gen throughput (token/s): 870.61, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:32:57 TP0] Decode batch. #running-req: 4, #token: 1293, token usage: 0.00, gen throughput (token/s): 866.17, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:32:57 TP0] Decode batch. #running-req: 4, #token: 1453, token usage: 0.00, gen throughput (token/s): 891.07, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:32:58 TP0] Decode batch. #running-req: 4, #token: 1613, token usage: 0.00, gen throughput (token/s): 839.41, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:32:58 TP0] Decode batch. #running-req: 4, #token: 1773, token usage: 0.00, gen throughput (token/s): 854.92, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:32:58 TP0] Decode batch. #running-req: 4, #token: 1933, token usage: 0.00, gen throughput (token/s): 850.92, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:32:58 TP0] Decode batch. #running-req: 4, #token: 2093, token usage: 0.00, gen throughput (token/s): 904.19, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:32:58] INFO:     127.0.0.1:46768 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:32:58] INFO:     127.0.0.1:46736 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:32:58] INFO:     127.0.0.1:46744 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:32:58] INFO:     127.0.0.1:46760 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:32:58 TP0] Prefill batch. #new-seq: 4, #new-token: 4, #cached-token: 528, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-08-25 15:32:58 TP0] Decode batch. #running-req: 4, #token: 253, token usage: 0.00, gen throughput (token/s): 667.45, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:32:59 TP0] Decode batch. #running-req: 4, #token: 413, token usage: 0.00, gen throughput (token/s): 875.24, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:32:59 TP0] Decode batch. #running-req: 4, #token: 573, token usage: 0.00, gen throughput (token/s): 840.98, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:32:59 TP0] Decode batch. #running-req: 4, #token: 733, token usage: 0.00, gen throughput (token/s): 843.84, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:32:59 TP0] Decode batch. #running-req: 4, #token: 893, token usage: 0.00, gen throughput (token/s): 884.67, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:32:59 TP0] Decode batch. #running-req: 4, #token: 1053, token usage: 0.00, gen throughput (token/s): 855.95, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:33:00 TP0] Decode batch. #running-req: 4, #token: 1213, token usage: 0.00, gen throughput (token/s): 885.88, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:33:00 TP0] Decode batch. #running-req: 4, #token: 1373, token usage: 0.00, gen throughput (token/s): 880.10, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:33:00 TP0] Decode batch. #running-req: 4, #token: 1533, token usage: 0.00, gen throughput (token/s): 872.41, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:33:00 TP0] Decode batch. #running-req: 4, #token: 1693, token usage: 0.00, gen throughput (token/s): 875.25, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:33:00 TP0] Decode batch. #running-req: 4, #token: 1853, token usage: 0.00, gen throughput (token/s): 885.03, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:33:00 TP0] Decode batch. #running-req: 4, #token: 2013, token usage: 0.00, gen throughput (token/s): 890.78, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:33:01] INFO:     127.0.0.1:46768 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:33:01] INFO:     127.0.0.1:46736 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:33:01] INFO:     127.0.0.1:46744 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:33:01] INFO:     127.0.0.1:46760 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:33:01 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 132, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-08-25 15:33:01 TP0] Prefill batch. #new-seq: 3, #new-token: 3, #cached-token: 396, token usage: 0.00, #running-req: 1, #queue-req: 0, 
[2025-08-25 15:33:01 TP0] Decode batch. #running-req: 4, #token: 173, token usage: 0.00, gen throughput (token/s): 596.26, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:33:01 TP0] Decode batch. #running-req: 4, #token: 333, token usage: 0.00, gen throughput (token/s): 882.11, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:33:01 TP0] Decode batch. #running-req: 4, #token: 493, token usage: 0.00, gen throughput (token/s): 862.61, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:33:01 TP0] Decode batch. #running-req: 4, #token: 653, token usage: 0.00, gen throughput (token/s): 911.67, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:33:01 TP0] Decode batch. #running-req: 4, #token: 813, token usage: 0.00, gen throughput (token/s): 902.78, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:33:02 TP0] Decode batch. #running-req: 4, #token: 973, token usage: 0.00, gen throughput (token/s): 904.25, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:33:02 TP0] Decode batch. #running-req: 4, #token: 1133, token usage: 0.00, gen throughput (token/s): 909.99, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:33:02 TP0] Decode batch. #running-req: 4, #token: 1293, token usage: 0.00, gen throughput (token/s): 914.45, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:33:02 TP0] Decode batch. #running-req: 4, #token: 1453, token usage: 0.00, gen throughput (token/s): 916.47, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:33:02 TP0] Decode batch. #running-req: 4, #token: 1613, token usage: 0.00, gen throughput (token/s): 909.57, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:33:02 TP0] Decode batch. #running-req: 4, #token: 1773, token usage: 0.00, gen throughput (token/s): 917.91, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:33:03 TP0] Decode batch. #running-req: 4, #token: 1933, token usage: 0.00, gen throughput (token/s): 924.03, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:33:03 TP0] Decode batch. #running-req: 4, #token: 2093, token usage: 0.00, gen throughput (token/s): 904.73, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:33:03] INFO:     127.0.0.1:46768 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:33:03] INFO:     127.0.0.1:46736 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:33:03] INFO:     127.0.0.1:46744 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:33:03] INFO:     127.0.0.1:46760 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:33:03 TP0] Prefill batch. #new-seq: 1, #new-token: 580, #cached-token: 42, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-08-25 15:33:03 TP0] Prefill batch. #new-seq: 3, #new-token: 1740, #cached-token: 126, token usage: 0.02, #running-req: 1, #queue-req: 0, 
[2025-08-25 15:33:04] INFO:     127.0.0.1:17598 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 15:33:04] INFO:     127.0.0.1:17608 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 15:33:04] INFO:     127.0.0.1:17614 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 15:33:04 TP0] Prefill batch. #new-seq: 1, #new-token: 500, #cached-token: 122, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-08-25 15:33:04] INFO:     127.0.0.1:17616 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 15:33:04 TP0] Prefill batch. #new-seq: 3, #new-token: 1500, #cached-token: 366, token usage: 0.00, #running-req: 1, #queue-req: 0, 
[2025-08-25 15:33:04] INFO:     127.0.0.1:17598 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 15:33:04 TP0] Prefill batch. #new-seq: 1, #new-token: 500, #cached-token: 122, token usage: 0.04, #running-req: 4, #queue-req: 0, 
[2025-08-25 15:33:05] INFO:     127.0.0.1:17616 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 15:33:05] INFO:     127.0.0.1:17608 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 15:33:05] INFO:     127.0.0.1:17614 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 15:33:05 TP0] Prefill batch. #new-seq: 3, #new-token: 1500, #cached-token: 366, token usage: 0.00, #running-req: 1, #queue-req: 0, 
[2025-08-25 15:33:05] INFO:     127.0.0.1:17598 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 15:33:06 TP0] Prefill batch. #new-seq: 1, #new-token: 500, #cached-token: 122, token usage: 0.04, #running-req: 4, #queue-req: 0, 
[2025-08-25 15:33:06] INFO:     127.0.0.1:17616 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 15:33:06] INFO:     127.0.0.1:17608 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 15:33:06] INFO:     127.0.0.1:17614 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 15:33:06 TP0] Prefill batch. #new-seq: 3, #new-token: 1500, #cached-token: 366, token usage: 0.00, #running-req: 1, #queue-req: 0, 
[2025-08-25 15:33:06] INFO:     127.0.0.1:17598 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 15:33:06 TP0] Prefill batch. #new-seq: 1, #new-token: 587, #cached-token: 44, token usage: 0.04, #running-req: 4, #queue-req: 0, 
[2025-08-25 15:33:07] INFO:     127.0.0.1:17616 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 15:33:07] INFO:     127.0.0.1:17608 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 15:33:07] INFO:     127.0.0.1:17614 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 15:33:07 TP0] Prefill batch. #new-seq: 3, #new-token: 1467, #cached-token: 426, token usage: 0.02, #running-req: 1, #queue-req: 0, 
[2025-08-25 15:33:08 TP0] Decode batch. #running-req: 4, #token: 2149, token usage: 0.05, gen throughput (token/s): 6.15, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:33:10 TP0] Decode batch. #running-req: 4, #token: 2309, token usage: 0.06, gen throughput (token/s): 88.54, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:33:12 TP0] Decode batch. #running-req: 4, #token: 2469, token usage: 0.06, gen throughput (token/s): 88.42, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:33:13 TP0] Decode batch. #running-req: 4, #token: 2629, token usage: 0.07, gen throughput (token/s): 88.21, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:33:14] INFO:     127.0.0.1:17598 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:33:14 TP0] Prefill batch. #new-seq: 1, #new-token: 491, #cached-token: 140, token usage: 0.05, #running-req: 3, #queue-req: 0, 
[2025-08-25 15:33:14] INFO:     127.0.0.1:17616 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:33:14] INFO:     127.0.0.1:17608 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:33:14] INFO:     127.0.0.1:17614 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:33:15 TP0] Prefill batch. #new-seq: 3, #new-token: 1484, #cached-token: 409, token usage: 0.02, #running-req: 1, #queue-req: 0, 
[2025-08-25 15:33:16 TP0] Decode batch. #running-req: 4, #token: 2184, token usage: 0.05, gen throughput (token/s): 64.20, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:33:18 TP0] Decode batch. #running-req: 4, #token: 2344, token usage: 0.06, gen throughput (token/s): 88.37, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:33:19 TP0] Decode batch. #running-req: 4, #token: 2504, token usage: 0.06, gen throughput (token/s): 88.29, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:33:21] INFO:     127.0.0.1:17598 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:33:21 TP0] Prefill batch. #new-seq: 1, #new-token: 496, #cached-token: 135, token usage: 0.05, #running-req: 3, #queue-req: 0, 
[2025-08-25 15:33:21 TP0] Decode batch. #running-req: 4, #token: 2518, token usage: 0.06, gen throughput (token/s): 80.43, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:33:22] INFO:     127.0.0.1:17616 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:33:22] INFO:     127.0.0.1:17608 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:33:22] INFO:     127.0.0.1:17614 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:33:22 TP0] Prefill batch. #new-seq: 3, #new-token: 1439, #cached-token: 454, token usage: 0.02, #running-req: 1, #queue-req: 0, 
[2025-08-25 15:33:24 TP0] Decode batch. #running-req: 4, #token: 2246, token usage: 0.06, gen throughput (token/s): 69.12, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:33:25 TP0] Decode batch. #running-req: 4, #token: 2406, token usage: 0.06, gen throughput (token/s): 88.35, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:33:27 TP0] Decode batch. #running-req: 4, #token: 2566, token usage: 0.06, gen throughput (token/s): 88.36, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:33:29] INFO:     127.0.0.1:17598 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:33:29 TP0] Prefill batch. #new-seq: 1, #new-token: 488, #cached-token: 143, token usage: 0.05, #running-req: 3, #queue-req: 0, 
[2025-08-25 15:33:29 TP0] Decode batch. #running-req: 4, #token: 2575, token usage: 0.06, gen throughput (token/s): 80.65, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:33:29] INFO:     127.0.0.1:17616 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:33:29] INFO:     127.0.0.1:17608 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:33:29] INFO:     127.0.0.1:17614 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:33:29 TP0] Prefill batch. #new-seq: 3, #new-token: 1464, #cached-token: 429, token usage: 0.02, #running-req: 1, #queue-req: 0, 
[2025-08-25 15:33:32 TP0] Decode batch. #running-req: 4, #token: 2273, token usage: 0.06, gen throughput (token/s): 69.14, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:33:33 TP0] Decode batch. #running-req: 4, #token: 2433, token usage: 0.06, gen throughput (token/s): 88.45, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:33:35 TP0] Decode batch. #running-req: 4, #token: 2593, token usage: 0.07, gen throughput (token/s): 88.17, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:33:36] INFO:     127.0.0.1:17598 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:33:37] INFO:     127.0.0.1:17616 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:33:37] INFO:     127.0.0.1:17608 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:33:37] INFO:     127.0.0.1:17614 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:33:37 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 180, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-08-25 15:33:37 TP0] Prefill batch. #new-seq: 3, #new-token: 3, #cached-token: 540, token usage: 0.00, #running-req: 1, #queue-req: 0, 
[2025-08-25 15:33:37 TP0] Decode batch. #running-req: 4, #token: 301, token usage: 0.00, gen throughput (token/s): 4.69, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:33:37 TP0] Decode batch. #running-req: 4, #token: 461, token usage: 0.00, gen throughput (token/s): 887.11, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:33:37 TP0] Decode batch. #running-req: 4, #token: 621, token usage: 0.00, gen throughput (token/s): 892.32, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:33:37 TP0] Decode batch. #running-req: 4, #token: 781, token usage: 0.00, gen throughput (token/s): 888.99, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:33:38 TP0] Decode batch. #running-req: 4, #token: 941, token usage: 0.00, gen throughput (token/s): 885.41, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:33:38 TP0] Decode batch. #running-req: 4, #token: 1101, token usage: 0.00, gen throughput (token/s): 887.27, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:33:38 TP0] Decode batch. #running-req: 4, #token: 1261, token usage: 0.00, gen throughput (token/s): 892.22, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:33:38 TP0] Decode batch. #running-req: 4, #token: 1421, token usage: 0.00, gen throughput (token/s): 892.92, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:33:38 TP0] Decode batch. #running-req: 4, #token: 1581, token usage: 0.00, gen throughput (token/s): 896.31, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:33:39 TP0] Decode batch. #running-req: 4, #token: 1741, token usage: 0.00, gen throughput (token/s): 906.99, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:33:39 TP0] Decode batch. #running-req: 4, #token: 1901, token usage: 0.00, gen throughput (token/s): 875.21, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:33:39 TP0] Decode batch. #running-req: 4, #token: 2061, token usage: 0.00, gen throughput (token/s): 892.90, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:33:39] INFO:     127.0.0.1:12882 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:33:39] INFO:     127.0.0.1:12884 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:33:39] INFO:     127.0.0.1:12896 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:33:39] INFO:     127.0.0.1:12900 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:33:39 TP0] Prefill batch. #new-seq: 4, #new-token: 4, #cached-token: 720, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-08-25 15:33:39 TP0] Decode batch. #running-req: 4, #token: 221, token usage: 0.00, gen throughput (token/s): 668.01, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:33:39 TP0] Decode batch. #running-req: 4, #token: 381, token usage: 0.00, gen throughput (token/s): 891.09, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:33:39 TP0] Decode batch. #running-req: 4, #token: 541, token usage: 0.00, gen throughput (token/s): 917.73, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:33:40 TP0] Decode batch. #running-req: 4, #token: 701, token usage: 0.00, gen throughput (token/s): 873.64, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:33:40 TP0] Decode batch. #running-req: 4, #token: 861, token usage: 0.00, gen throughput (token/s): 905.18, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:33:40 TP0] Decode batch. #running-req: 4, #token: 1021, token usage: 0.00, gen throughput (token/s): 912.64, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:33:40 TP0] Decode batch. #running-req: 4, #token: 1181, token usage: 0.00, gen throughput (token/s): 906.47, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:33:40 TP0] Decode batch. #running-req: 4, #token: 1341, token usage: 0.00, gen throughput (token/s): 897.83, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:33:41 TP0] Decode batch. #running-req: 4, #token: 1501, token usage: 0.00, gen throughput (token/s): 931.55, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:33:41 TP0] Decode batch. #running-req: 4, #token: 1661, token usage: 0.00, gen throughput (token/s): 869.57, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:33:41 TP0] Decode batch. #running-req: 4, #token: 1821, token usage: 0.00, gen throughput (token/s): 931.80, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:33:41 TP0] Decode batch. #running-req: 4, #token: 1981, token usage: 0.00, gen throughput (token/s): 877.34, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:33:41 TP0] Decode batch. #running-req: 4, #token: 2141, token usage: 0.00, gen throughput (token/s): 921.86, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:33:41] INFO:     127.0.0.1:12900 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:33:41] INFO:     127.0.0.1:12882 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:33:41] INFO:     127.0.0.1:12884 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:33:41] INFO:     127.0.0.1:12896 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:33:41 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 180, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-08-25 15:33:41 TP0] Prefill batch. #new-seq: 3, #new-token: 3, #cached-token: 540, token usage: 0.00, #running-req: 1, #queue-req: 0, 
[2025-08-25 15:33:42 TP0] Decode batch. #running-req: 4, #token: 301, token usage: 0.00, gen throughput (token/s): 611.39, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:33:42 TP0] Decode batch. #running-req: 4, #token: 461, token usage: 0.00, gen throughput (token/s): 913.19, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:33:42 TP0] Decode batch. #running-req: 4, #token: 621, token usage: 0.00, gen throughput (token/s): 926.49, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:33:42 TP0] Decode batch. #running-req: 4, #token: 781, token usage: 0.00, gen throughput (token/s): 913.30, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:33:42 TP0] Decode batch. #running-req: 4, #token: 941, token usage: 0.00, gen throughput (token/s): 906.75, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:33:42 TP0] Decode batch. #running-req: 4, #token: 1101, token usage: 0.00, gen throughput (token/s): 863.10, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:33:43 TP0] Decode batch. #running-req: 4, #token: 1261, token usage: 0.00, gen throughput (token/s): 881.43, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:33:43 TP0] Decode batch. #running-req: 4, #token: 1421, token usage: 0.00, gen throughput (token/s): 851.66, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:33:43 TP0] Decode batch. #running-req: 4, #token: 1581, token usage: 0.00, gen throughput (token/s): 879.85, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:33:43 TP0] Decode batch. #running-req: 4, #token: 1741, token usage: 0.00, gen throughput (token/s): 871.16, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:33:43 TP0] Decode batch. #running-req: 4, #token: 1901, token usage: 0.00, gen throughput (token/s): 879.32, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:33:44 TP0] Decode batch. #running-req: 4, #token: 2061, token usage: 0.00, gen throughput (token/s): 890.46, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:33:44] INFO:     127.0.0.1:12900 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:33:44] INFO:     127.0.0.1:12882 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:33:44] INFO:     127.0.0.1:12884 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:33:44] INFO:     127.0.0.1:12896 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:33:44 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 180, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-08-25 15:33:44 TP0] Prefill batch. #new-seq: 3, #new-token: 3, #cached-token: 540, token usage: 0.00, #running-req: 1, #queue-req: 0, 
[2025-08-25 15:33:44 TP0] Decode batch. #running-req: 4, #token: 221, token usage: 0.00, gen throughput (token/s): 592.94, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:33:44 TP0] Decode batch. #running-req: 4, #token: 381, token usage: 0.00, gen throughput (token/s): 861.82, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:33:44 TP0] Decode batch. #running-req: 4, #token: 541, token usage: 0.00, gen throughput (token/s): 867.80, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:33:44 TP0] Decode batch. #running-req: 4, #token: 701, token usage: 0.00, gen throughput (token/s): 879.13, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:33:45 TP0] Decode batch. #running-req: 4, #token: 861, token usage: 0.00, gen throughput (token/s): 910.51, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:33:45 TP0] Decode batch. #running-req: 4, #token: 1021, token usage: 0.00, gen throughput (token/s): 906.48, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:33:45 TP0] Decode batch. #running-req: 4, #token: 1181, token usage: 0.00, gen throughput (token/s): 908.22, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:33:45 TP0] Decode batch. #running-req: 4, #token: 1341, token usage: 0.00, gen throughput (token/s): 897.38, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:33:45 TP0] Decode batch. #running-req: 4, #token: 1501, token usage: 0.00, gen throughput (token/s): 902.35, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:33:45 TP0] Decode batch. #running-req: 4, #token: 1661, token usage: 0.00, gen throughput (token/s): 898.51, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:33:46 TP0] Decode batch. #running-req: 4, #token: 1821, token usage: 0.00, gen throughput (token/s): 898.95, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:33:46 TP0] Decode batch. #running-req: 4, #token: 1981, token usage: 0.00, gen throughput (token/s): 895.96, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:33:46 TP0] Decode batch. #running-req: 4, #token: 2141, token usage: 0.00, gen throughput (token/s): 891.48, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:33:46] INFO:     127.0.0.1:12900 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:33:46] INFO:     127.0.0.1:12882 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:33:46] INFO:     127.0.0.1:12884 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:33:46] INFO:     127.0.0.1:12896 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:33:46 TP0] Prefill batch. #new-seq: 1, #new-token: 628, #cached-token: 42, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-08-25 15:33:46 TP0] Prefill batch. #new-seq: 3, #new-token: 1884, #cached-token: 126, token usage: 0.02, #running-req: 1, #queue-req: 0, 
[2025-08-25 15:33:47] INFO:     127.0.0.1:22862 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 15:33:47] INFO:     127.0.0.1:22876 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 15:33:47] INFO:     127.0.0.1:22886 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 15:33:47] INFO:     127.0.0.1:22900 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 15:33:47 TP0] Prefill batch. #new-seq: 1, #new-token: 500, #cached-token: 170, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-08-25 15:33:47 TP0] Prefill batch. #new-seq: 2, #new-token: 1000, #cached-token: 340, token usage: 0.02, #running-req: 1, #queue-req: 0, 
[2025-08-25 15:33:47 TP0] Prefill batch. #new-seq: 1, #new-token: 500, #cached-token: 170, token usage: 0.03, #running-req: 3, #queue-req: 0, 
[2025-08-25 15:33:47] INFO:     127.0.0.1:22862 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 15:33:47] INFO:     127.0.0.1:22900 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 15:33:47] INFO:     127.0.0.1:22876 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 15:33:48 TP0] Prefill batch. #new-seq: 3, #new-token: 1500, #cached-token: 510, token usage: 0.00, #running-req: 1, #queue-req: 0, 
[2025-08-25 15:33:48] INFO:     127.0.0.1:22886 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 15:33:48 TP0] Prefill batch. #new-seq: 1, #new-token: 500, #cached-token: 170, token usage: 0.04, #running-req: 4, #queue-req: 0, 
[2025-08-25 15:33:48] INFO:     127.0.0.1:22862 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 15:33:48] INFO:     127.0.0.1:22876 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 15:33:48] INFO:     127.0.0.1:22900 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 15:33:48 TP0] Prefill batch. #new-seq: 3, #new-token: 1500, #cached-token: 510, token usage: 0.00, #running-req: 1, #queue-req: 0, 
[2025-08-25 15:33:48] INFO:     127.0.0.1:22886 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 15:33:49 TP0] Prefill batch. #new-seq: 1, #new-token: 500, #cached-token: 170, token usage: 0.04, #running-req: 4, #queue-req: 0, 
[2025-08-25 15:33:49] INFO:     127.0.0.1:22900 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 15:33:49] INFO:     127.0.0.1:22862 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 15:33:49] INFO:     127.0.0.1:22876 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 15:33:49 TP0] Prefill batch. #new-seq: 3, #new-token: 1905, #cached-token: 132, token usage: 0.00, #running-req: 1, #queue-req: 0, 
[2025-08-25 15:33:49] INFO:     127.0.0.1:22886 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 15:33:49 TP0] Prefill batch. #new-seq: 1, #new-token: 635, #cached-token: 44, token usage: 0.05, #running-req: 4, #queue-req: 0, 
[2025-08-25 15:33:50 TP0] Decode batch. #running-req: 4, #token: 2114, token usage: 0.05, gen throughput (token/s): 9.19, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:33:52 TP0] Decode batch. #running-req: 4, #token: 2274, token usage: 0.06, gen throughput (token/s): 88.47, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:33:53 TP0] Decode batch. #running-req: 4, #token: 2434, token usage: 0.06, gen throughput (token/s): 88.41, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:33:55 TP0] Decode batch. #running-req: 4, #token: 2594, token usage: 0.07, gen throughput (token/s): 88.23, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:33:57] INFO:     127.0.0.1:22900 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:33:57] INFO:     127.0.0.1:22862 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:33:57] INFO:     127.0.0.1:22876 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:33:57] INFO:     127.0.0.1:22886 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:33:57 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 129, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-08-25 15:33:57 TP0] Prefill batch. #new-seq: 3, #new-token: 3, #cached-token: 387, token usage: 0.00, #running-req: 1, #queue-req: 0, 
[2025-08-25 15:33:57 TP0] Decode batch. #running-req: 4, #token: 250, token usage: 0.00, gen throughput (token/s): 14.72, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:33:57 TP0] Decode batch. #running-req: 4, #token: 410, token usage: 0.00, gen throughput (token/s): 881.03, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:33:57 TP0] Decode batch. #running-req: 4, #token: 570, token usage: 0.00, gen throughput (token/s): 879.37, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:33:57 TP0] Decode batch. #running-req: 4, #token: 730, token usage: 0.00, gen throughput (token/s): 880.33, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:33:58 TP0] Decode batch. #running-req: 4, #token: 890, token usage: 0.00, gen throughput (token/s): 869.88, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:33:58 TP0] Decode batch. #running-req: 4, #token: 1050, token usage: 0.00, gen throughput (token/s): 883.76, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:33:58 TP0] Decode batch. #running-req: 4, #token: 1210, token usage: 0.00, gen throughput (token/s): 881.56, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:33:58 TP0] Decode batch. #running-req: 4, #token: 1370, token usage: 0.00, gen throughput (token/s): 856.30, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:33:58 TP0] Decode batch. #running-req: 4, #token: 1530, token usage: 0.00, gen throughput (token/s): 879.46, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:33:58 TP0] Decode batch. #running-req: 4, #token: 1690, token usage: 0.00, gen throughput (token/s): 875.06, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:33:59 TP0] Decode batch. #running-req: 4, #token: 1850, token usage: 0.00, gen throughput (token/s): 919.88, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:33:59 TP0] Decode batch. #running-req: 4, #token: 2010, token usage: 0.00, gen throughput (token/s): 915.92, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:33:59] INFO:     127.0.0.1:43482 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:33:59] INFO:     127.0.0.1:43490 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:33:59] INFO:     127.0.0.1:43504 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:33:59] INFO:     127.0.0.1:43512 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:33:59 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 129, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-08-25 15:33:59 TP0] Prefill batch. #new-seq: 3, #new-token: 3, #cached-token: 387, token usage: 0.00, #running-req: 1, #queue-req: 0, 
[2025-08-25 15:33:59 TP0] Decode batch. #running-req: 4, #token: 170, token usage: 0.00, gen throughput (token/s): 619.88, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:33:59 TP0] Decode batch. #running-req: 4, #token: 330, token usage: 0.00, gen throughput (token/s): 882.66, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:33:59 TP0] Decode batch. #running-req: 4, #token: 490, token usage: 0.00, gen throughput (token/s): 892.38, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:34:00 TP0] Decode batch. #running-req: 4, #token: 650, token usage: 0.00, gen throughput (token/s): 875.60, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:34:00 TP0] Decode batch. #running-req: 4, #token: 810, token usage: 0.00, gen throughput (token/s): 882.68, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:34:00 TP0] Decode batch. #running-req: 4, #token: 970, token usage: 0.00, gen throughput (token/s): 877.56, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:34:00 TP0] Decode batch. #running-req: 4, #token: 1130, token usage: 0.00, gen throughput (token/s): 884.93, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:34:00 TP0] Decode batch. #running-req: 4, #token: 1290, token usage: 0.00, gen throughput (token/s): 869.72, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:34:00 TP0] Decode batch. #running-req: 4, #token: 1450, token usage: 0.00, gen throughput (token/s): 884.91, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:34:01 TP0] Decode batch. #running-req: 4, #token: 1610, token usage: 0.00, gen throughput (token/s): 864.44, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:34:01 TP0] Decode batch. #running-req: 4, #token: 1770, token usage: 0.00, gen throughput (token/s): 879.34, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:34:01 TP0] Decode batch. #running-req: 4, #token: 1930, token usage: 0.00, gen throughput (token/s): 874.45, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:34:01 TP0] Decode batch. #running-req: 4, #token: 2090, token usage: 0.00, gen throughput (token/s): 882.76, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:34:01] INFO:     127.0.0.1:43512 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:34:01] INFO:     127.0.0.1:43482 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:34:01] INFO:     127.0.0.1:43490 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:34:01] INFO:     127.0.0.1:43504 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:34:01 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 129, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-08-25 15:34:01 TP0] Prefill batch. #new-seq: 3, #new-token: 3, #cached-token: 387, token usage: 0.00, #running-req: 1, #queue-req: 0, 
[2025-08-25 15:34:01 TP0] Decode batch. #running-req: 4, #token: 250, token usage: 0.00, gen throughput (token/s): 607.99, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:34:02 TP0] Decode batch. #running-req: 4, #token: 410, token usage: 0.00, gen throughput (token/s): 901.41, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:34:02 TP0] Decode batch. #running-req: 4, #token: 570, token usage: 0.00, gen throughput (token/s): 915.44, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:34:02 TP0] Decode batch. #running-req: 4, #token: 730, token usage: 0.00, gen throughput (token/s): 912.80, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:34:02 TP0] Decode batch. #running-req: 4, #token: 890, token usage: 0.00, gen throughput (token/s): 911.30, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:34:02 TP0] Decode batch. #running-req: 4, #token: 1050, token usage: 0.00, gen throughput (token/s): 906.54, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:34:03 TP0] Decode batch. #running-req: 4, #token: 1210, token usage: 0.00, gen throughput (token/s): 906.47, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:34:03 TP0] Decode batch. #running-req: 4, #token: 1370, token usage: 0.00, gen throughput (token/s): 895.65, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:34:03 TP0] Decode batch. #running-req: 4, #token: 1530, token usage: 0.00, gen throughput (token/s): 907.82, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:34:03 TP0] Decode batch. #running-req: 4, #token: 1690, token usage: 0.00, gen throughput (token/s): 907.09, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:34:03 TP0] Decode batch. #running-req: 4, #token: 1850, token usage: 0.00, gen throughput (token/s): 894.24, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:34:03 TP0] Decode batch. #running-req: 4, #token: 2010, token usage: 0.00, gen throughput (token/s): 879.13, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:34:04] INFO:     127.0.0.1:43512 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:34:04] INFO:     127.0.0.1:43482 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:34:04] INFO:     127.0.0.1:43490 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:34:04] INFO:     127.0.0.1:43504 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:34:04 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 129, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-08-25 15:34:04 TP0] Prefill batch. #new-seq: 3, #new-token: 3, #cached-token: 387, token usage: 0.00, #running-req: 1, #queue-req: 0, 
[2025-08-25 15:34:04 TP0] Decode batch. #running-req: 4, #token: 170, token usage: 0.00, gen throughput (token/s): 610.94, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:34:04 TP0] Decode batch. #running-req: 4, #token: 330, token usage: 0.00, gen throughput (token/s): 874.41, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:34:04 TP0] Decode batch. #running-req: 4, #token: 490, token usage: 0.00, gen throughput (token/s): 873.61, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:34:04 TP0] Decode batch. #running-req: 4, #token: 650, token usage: 0.00, gen throughput (token/s): 875.39, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:34:04 TP0] Decode batch. #running-req: 4, #token: 810, token usage: 0.00, gen throughput (token/s): 876.51, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:34:05 TP0] Decode batch. #running-req: 4, #token: 970, token usage: 0.00, gen throughput (token/s): 873.45, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:34:05 TP0] Decode batch. #running-req: 4, #token: 1130, token usage: 0.00, gen throughput (token/s): 863.21, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:34:05 TP0] Decode batch. #running-req: 4, #token: 1290, token usage: 0.00, gen throughput (token/s): 880.04, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:34:05 TP0] Decode batch. #running-req: 4, #token: 1450, token usage: 0.00, gen throughput (token/s): 885.46, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:34:05 TP0] Decode batch. #running-req: 4, #token: 1610, token usage: 0.00, gen throughput (token/s): 871.60, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:34:06 TP0] Decode batch. #running-req: 4, #token: 1770, token usage: 0.00, gen throughput (token/s): 876.33, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:34:06 TP0] Decode batch. #running-req: 4, #token: 1930, token usage: 0.00, gen throughput (token/s): 819.72, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:34:06 TP0] Decode batch. #running-req: 4, #token: 2090, token usage: 0.00, gen throughput (token/s): 859.70, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:34:06] INFO:     127.0.0.1:43512 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:34:06] INFO:     127.0.0.1:43482 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:34:06] INFO:     127.0.0.1:43490 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:34:06] INFO:     127.0.0.1:43504 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:34:06 TP0] Prefill batch. #new-seq: 4, #new-token: 2300, #cached-token: 176, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-08-25 15:34:07] INFO:     127.0.0.1:40786 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 15:34:07] INFO:     127.0.0.1:40788 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 15:34:07] INFO:     127.0.0.1:40798 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 15:34:07] INFO:     127.0.0.1:40806 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 15:34:07 TP0] Prefill batch. #new-seq: 1, #new-token: 500, #cached-token: 119, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-08-25 15:34:07 TP0] Prefill batch. #new-seq: 3, #new-token: 1500, #cached-token: 357, token usage: 0.02, #running-req: 1, #queue-req: 0, 
[2025-08-25 15:34:07] INFO:     127.0.0.1:40786 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 15:34:07 TP0] Prefill batch. #new-seq: 1, #new-token: 500, #cached-token: 119, token usage: 0.00, #running-req: 3, #queue-req: 0, 
[2025-08-25 15:34:07] INFO:     127.0.0.1:40806 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 15:34:07] INFO:     127.0.0.1:40788 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 15:34:08] INFO:     127.0.0.1:40798 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 15:34:08 TP0] Prefill batch. #new-seq: 3, #new-token: 1500, #cached-token: 357, token usage: 0.02, #running-req: 4, #queue-req: 0, 
[2025-08-25 15:34:08] INFO:     127.0.0.1:40786 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 15:34:08 TP0] Prefill batch. #new-seq: 1, #new-token: 500, #cached-token: 119, token usage: 0.00, #running-req: 3, #queue-req: 0, 
[2025-08-25 15:34:08] INFO:     127.0.0.1:40806 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 15:34:08] INFO:     127.0.0.1:40788 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 15:34:08] INFO:     127.0.0.1:40798 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 15:34:08 TP0] Prefill batch. #new-seq: 3, #new-token: 1500, #cached-token: 357, token usage: 0.02, #running-req: 4, #queue-req: 0, 
[2025-08-25 15:34:08] INFO:     127.0.0.1:40786 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 15:34:09 TP0] Prefill batch. #new-seq: 1, #new-token: 582, #cached-token: 46, token usage: 0.00, #running-req: 3, #queue-req: 0, 
[2025-08-25 15:34:09] INFO:     127.0.0.1:40806 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 15:34:09] INFO:     127.0.0.1:40788 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 15:34:09] INFO:     127.0.0.1:40798 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 15:34:09 TP0] Prefill batch. #new-seq: 3, #new-token: 1746, #cached-token: 138, token usage: 0.02, #running-req: 4, #queue-req: 0, 
[2025-08-25 15:34:10 TP0] Decode batch. #running-req: 4, #token: 2148, token usage: 0.05, gen throughput (token/s): 10.66, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:34:12 TP0] Decode batch. #running-req: 4, #token: 2308, token usage: 0.06, gen throughput (token/s): 88.39, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:34:14 TP0] Decode batch. #running-req: 4, #token: 2468, token usage: 0.06, gen throughput (token/s): 88.17, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:34:15 TP0] Decode batch. #running-req: 4, #token: 2628, token usage: 0.07, gen throughput (token/s): 88.31, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:34:16] INFO:     127.0.0.1:40786 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:34:16] INFO:     127.0.0.1:40806 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:34:16] INFO:     127.0.0.1:40788 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:34:16] INFO:     127.0.0.1:40798 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:37:41 TP0] Prefill batch. #new-seq: 4, #new-token: 4, #cached-token: 328, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-08-25 15:37:41 TP0] Decode batch. #running-req: 4, #token: 203, token usage: 0.00, gen throughput (token/s): 0.74, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:37:41 TP0] Decode batch. #running-req: 4, #token: 363, token usage: 0.00, gen throughput (token/s): 863.71, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:37:42 TP0] Decode batch. #running-req: 4, #token: 523, token usage: 0.00, gen throughput (token/s): 874.67, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:37:42 TP0] Decode batch. #running-req: 4, #token: 683, token usage: 0.00, gen throughput (token/s): 854.10, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:37:42 TP0] Decode batch. #running-req: 4, #token: 843, token usage: 0.00, gen throughput (token/s): 868.03, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:37:42 TP0] Decode batch. #running-req: 4, #token: 1003, token usage: 0.00, gen throughput (token/s): 872.28, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:37:42 TP0] Decode batch. #running-req: 4, #token: 1163, token usage: 0.00, gen throughput (token/s): 884.28, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:37:43 TP0] Decode batch. #running-req: 4, #token: 1323, token usage: 0.00, gen throughput (token/s): 881.52, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:37:43 TP0] Decode batch. #running-req: 4, #token: 1483, token usage: 0.00, gen throughput (token/s): 862.75, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:37:43 TP0] Decode batch. #running-req: 4, #token: 1643, token usage: 0.00, gen throughput (token/s): 910.27, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:37:43 TP0] Decode batch. #running-req: 4, #token: 1803, token usage: 0.00, gen throughput (token/s): 868.94, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:37:43 TP0] Decode batch. #running-req: 4, #token: 1963, token usage: 0.00, gen throughput (token/s): 890.25, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:37:43 TP0] Decode batch. #running-req: 4, #token: 2123, token usage: 0.00, gen throughput (token/s): 862.38, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:37:44 TP0] Decode batch. #running-req: 4, #token: 2283, token usage: 0.00, gen throughput (token/s): 853.61, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:37:44 TP0] Decode batch. #running-req: 4, #token: 2443, token usage: 0.00, gen throughput (token/s): 872.42, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:37:44 TP0] Decode batch. #running-req: 4, #token: 2603, token usage: 0.00, gen throughput (token/s): 841.54, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:37:44 TP0] Decode batch. #running-req: 4, #token: 2763, token usage: 0.00, gen throughput (token/s): 840.09, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:37:44 TP0] Decode batch. #running-req: 4, #token: 2923, token usage: 0.00, gen throughput (token/s): 858.88, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:37:45 TP0] Decode batch. #running-req: 4, #token: 3083, token usage: 0.00, gen throughput (token/s): 856.07, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:37:45 TP0] Decode batch. #running-req: 4, #token: 3243, token usage: 0.00, gen throughput (token/s): 884.70, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:37:45 TP0] Decode batch. #running-req: 4, #token: 3403, token usage: 0.00, gen throughput (token/s): 863.29, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:37:45 TP0] Decode batch. #running-req: 4, #token: 3563, token usage: 0.00, gen throughput (token/s): 883.89, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:37:45 TP0] Decode batch. #running-req: 4, #token: 3723, token usage: 0.00, gen throughput (token/s): 891.39, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:37:46 TP0] Decode batch. #running-req: 4, #token: 3883, token usage: 0.00, gen throughput (token/s): 841.34, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:37:46 TP0] Decode batch. #running-req: 4, #token: 4043, token usage: 0.00, gen throughput (token/s): 881.79, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:37:46] INFO:     127.0.0.1:9336 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:37:46] INFO:     127.0.0.1:9342 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:37:46] INFO:     127.0.0.1:9354 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:37:46] INFO:     127.0.0.1:9366 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:37:46 TP0] Prefill batch. #new-seq: 4, #new-token: 4, #cached-token: 328, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-08-25 15:37:46 TP0] Decode batch. #running-req: 4, #token: 203, token usage: 0.00, gen throughput (token/s): 659.32, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:37:46 TP0] Decode batch. #running-req: 4, #token: 363, token usage: 0.00, gen throughput (token/s): 891.78, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:37:46 TP0] Decode batch. #running-req: 4, #token: 523, token usage: 0.00, gen throughput (token/s): 886.83, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:37:47 TP0] Decode batch. #running-req: 4, #token: 683, token usage: 0.00, gen throughput (token/s): 879.83, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:37:47 TP0] Decode batch. #running-req: 4, #token: 843, token usage: 0.00, gen throughput (token/s): 877.48, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:37:47 TP0] Decode batch. #running-req: 4, #token: 1003, token usage: 0.00, gen throughput (token/s): 875.77, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:37:47 TP0] Decode batch. #running-req: 4, #token: 1163, token usage: 0.00, gen throughput (token/s): 868.28, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:37:47 TP0] Decode batch. #running-req: 4, #token: 1323, token usage: 0.00, gen throughput (token/s): 876.41, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:37:47 TP0] Decode batch. #running-req: 4, #token: 1483, token usage: 0.00, gen throughput (token/s): 872.77, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:37:48 TP0] Decode batch. #running-req: 4, #token: 1643, token usage: 0.00, gen throughput (token/s): 880.01, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:37:48 TP0] Decode batch. #running-req: 4, #token: 1803, token usage: 0.00, gen throughput (token/s): 878.65, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:37:48 TP0] Decode batch. #running-req: 4, #token: 1963, token usage: 0.00, gen throughput (token/s): 887.33, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:37:48 TP0] Decode batch. #running-req: 4, #token: 2123, token usage: 0.00, gen throughput (token/s): 877.15, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:37:48 TP0] Decode batch. #running-req: 4, #token: 2283, token usage: 0.00, gen throughput (token/s): 876.41, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:37:49 TP0] Decode batch. #running-req: 4, #token: 2443, token usage: 0.00, gen throughput (token/s): 886.07, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:37:49 TP0] Decode batch. #running-req: 4, #token: 2603, token usage: 0.00, gen throughput (token/s): 863.46, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:37:49 TP0] Decode batch. #running-req: 4, #token: 2763, token usage: 0.00, gen throughput (token/s): 886.54, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:37:49 TP0] Decode batch. #running-req: 4, #token: 2923, token usage: 0.00, gen throughput (token/s): 877.46, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:37:49 TP0] Decode batch. #running-req: 4, #token: 3083, token usage: 0.00, gen throughput (token/s): 886.52, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:37:49 TP0] Decode batch. #running-req: 4, #token: 3243, token usage: 0.00, gen throughput (token/s): 881.36, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:37:50 TP0] Decode batch. #running-req: 4, #token: 3403, token usage: 0.00, gen throughput (token/s): 885.92, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:37:50 TP0] Decode batch. #running-req: 4, #token: 3563, token usage: 0.00, gen throughput (token/s): 854.42, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:37:50 TP0] Decode batch. #running-req: 4, #token: 3723, token usage: 0.00, gen throughput (token/s): 874.92, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:37:50 TP0] Decode batch. #running-req: 4, #token: 3883, token usage: 0.00, gen throughput (token/s): 861.23, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:37:50 TP0] Decode batch. #running-req: 4, #token: 4043, token usage: 0.00, gen throughput (token/s): 896.76, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:37:50] INFO:     127.0.0.1:9336 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:37:50] INFO:     127.0.0.1:9342 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:37:50] INFO:     127.0.0.1:9354 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:37:50] INFO:     127.0.0.1:9366 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:37:50 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 82, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-08-25 15:37:50 TP0] Prefill batch. #new-seq: 3, #new-token: 3, #cached-token: 246, token usage: 0.00, #running-req: 1, #queue-req: 0, 
[2025-08-25 15:37:51 TP0] Decode batch. #running-req: 4, #token: 203, token usage: 0.00, gen throughput (token/s): 573.50, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:37:51 TP0] Decode batch. #running-req: 4, #token: 363, token usage: 0.00, gen throughput (token/s): 895.23, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:37:51 TP0] Decode batch. #running-req: 4, #token: 523, token usage: 0.00, gen throughput (token/s): 882.40, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:37:51 TP0] Decode batch. #running-req: 4, #token: 683, token usage: 0.00, gen throughput (token/s): 873.61, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:37:51 TP0] Decode batch. #running-req: 4, #token: 843, token usage: 0.00, gen throughput (token/s): 920.71, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:37:52 TP0] Decode batch. #running-req: 4, #token: 1003, token usage: 0.00, gen throughput (token/s): 853.61, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:37:52 TP0] Decode batch. #running-req: 4, #token: 1163, token usage: 0.00, gen throughput (token/s): 849.79, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:37:52 TP0] Decode batch. #running-req: 4, #token: 1323, token usage: 0.00, gen throughput (token/s): 848.86, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:37:52 TP0] Decode batch. #running-req: 4, #token: 1483, token usage: 0.00, gen throughput (token/s): 863.32, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:37:52 TP0] Decode batch. #running-req: 4, #token: 1643, token usage: 0.00, gen throughput (token/s): 866.20, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:37:52 TP0] Decode batch. #running-req: 4, #token: 1803, token usage: 0.00, gen throughput (token/s): 833.08, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:37:53 TP0] Decode batch. #running-req: 4, #token: 1963, token usage: 0.00, gen throughput (token/s): 850.37, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:37:53 TP0] Decode batch. #running-req: 4, #token: 2123, token usage: 0.00, gen throughput (token/s): 849.50, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:37:53 TP0] Decode batch. #running-req: 4, #token: 2283, token usage: 0.00, gen throughput (token/s): 852.54, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:37:53 TP0] Decode batch. #running-req: 4, #token: 2443, token usage: 0.00, gen throughput (token/s): 887.87, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:37:53 TP0] Decode batch. #running-req: 4, #token: 2603, token usage: 0.00, gen throughput (token/s): 845.90, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:37:54 TP0] Decode batch. #running-req: 4, #token: 2763, token usage: 0.00, gen throughput (token/s): 857.73, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:37:54 TP0] Decode batch. #running-req: 4, #token: 2923, token usage: 0.00, gen throughput (token/s): 831.66, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:37:54 TP0] Decode batch. #running-req: 4, #token: 3083, token usage: 0.00, gen throughput (token/s): 867.28, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:37:54 TP0] Decode batch. #running-req: 4, #token: 3243, token usage: 0.00, gen throughput (token/s): 867.96, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:37:54 TP0] Decode batch. #running-req: 4, #token: 3403, token usage: 0.00, gen throughput (token/s): 864.91, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:37:54 TP0] Decode batch. #running-req: 4, #token: 3563, token usage: 0.00, gen throughput (token/s): 902.28, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:37:55 TP0] Decode batch. #running-req: 4, #token: 3723, token usage: 0.00, gen throughput (token/s): 889.36, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:37:55 TP0] Decode batch. #running-req: 4, #token: 3883, token usage: 0.00, gen throughput (token/s): 898.53, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:37:55 TP0] Decode batch. #running-req: 4, #token: 4043, token usage: 0.00, gen throughput (token/s): 894.53, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:37:55] INFO:     127.0.0.1:9336 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:37:55] INFO:     127.0.0.1:9342 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:37:55] INFO:     127.0.0.1:9354 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:37:55] INFO:     127.0.0.1:9366 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:37:55 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 82, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-08-25 15:37:55 TP0] Prefill batch. #new-seq: 3, #new-token: 3, #cached-token: 246, token usage: 0.00, #running-req: 1, #queue-req: 0, 
[2025-08-25 15:37:55 TP0] Decode batch. #running-req: 4, #token: 203, token usage: 0.00, gen throughput (token/s): 605.84, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:37:55 TP0] Decode batch. #running-req: 4, #token: 363, token usage: 0.00, gen throughput (token/s): 867.67, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:37:56 TP0] Decode batch. #running-req: 4, #token: 523, token usage: 0.00, gen throughput (token/s): 882.93, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:37:56 TP0] Decode batch. #running-req: 4, #token: 683, token usage: 0.00, gen throughput (token/s): 895.99, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:37:56 TP0] Decode batch. #running-req: 4, #token: 843, token usage: 0.00, gen throughput (token/s): 884.80, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:37:56 TP0] Decode batch. #running-req: 4, #token: 1003, token usage: 0.00, gen throughput (token/s): 898.49, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:37:56 TP0] Decode batch. #running-req: 4, #token: 1163, token usage: 0.00, gen throughput (token/s): 899.64, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:37:57 TP0] Decode batch. #running-req: 4, #token: 1323, token usage: 0.00, gen throughput (token/s): 892.42, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:37:57 TP0] Decode batch. #running-req: 4, #token: 1483, token usage: 0.00, gen throughput (token/s): 884.83, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:37:57 TP0] Decode batch. #running-req: 4, #token: 1643, token usage: 0.00, gen throughput (token/s): 894.10, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:37:57 TP0] Decode batch. #running-req: 4, #token: 1803, token usage: 0.00, gen throughput (token/s): 888.14, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:37:57 TP0] Decode batch. #running-req: 4, #token: 1963, token usage: 0.00, gen throughput (token/s): 907.63, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:37:57 TP0] Decode batch. #running-req: 4, #token: 2123, token usage: 0.00, gen throughput (token/s): 903.93, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:37:58 TP0] Decode batch. #running-req: 4, #token: 2283, token usage: 0.00, gen throughput (token/s): 928.70, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:37:58 TP0] Decode batch. #running-req: 4, #token: 2443, token usage: 0.00, gen throughput (token/s): 935.11, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:37:58 TP0] Decode batch. #running-req: 4, #token: 2603, token usage: 0.00, gen throughput (token/s): 933.11, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:37:58 TP0] Decode batch. #running-req: 4, #token: 2763, token usage: 0.00, gen throughput (token/s): 913.84, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:37:58 TP0] Decode batch. #running-req: 4, #token: 2923, token usage: 0.00, gen throughput (token/s): 910.16, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:37:58 TP0] Decode batch. #running-req: 4, #token: 3083, token usage: 0.00, gen throughput (token/s): 917.10, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:37:59 TP0] Decode batch. #running-req: 4, #token: 3243, token usage: 0.00, gen throughput (token/s): 911.94, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:37:59 TP0] Decode batch. #running-req: 4, #token: 3403, token usage: 0.00, gen throughput (token/s): 930.62, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:37:59 TP0] Decode batch. #running-req: 4, #token: 3563, token usage: 0.00, gen throughput (token/s): 925.33, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:37:59 TP0] Decode batch. #running-req: 4, #token: 3723, token usage: 0.00, gen throughput (token/s): 927.81, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:37:59 TP0] Decode batch. #running-req: 4, #token: 3883, token usage: 0.00, gen throughput (token/s): 931.47, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:38:00 TP0] Decode batch. #running-req: 4, #token: 4043, token usage: 0.00, gen throughput (token/s): 917.86, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:38:00] INFO:     127.0.0.1:9336 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:38:00] INFO:     127.0.0.1:9342 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:38:00] INFO:     127.0.0.1:9354 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:38:00] INFO:     127.0.0.1:9366 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:38:00 TP0] Prefill batch. #new-seq: 1, #new-token: 1030, #cached-token: 42, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-08-25 15:38:00 TP0] Prefill batch. #new-seq: 3, #new-token: 3090, #cached-token: 126, token usage: 0.03, #running-req: 1, #queue-req: 0, 
[2025-08-25 15:38:01] INFO:     127.0.0.1:20218 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 15:38:01] INFO:     127.0.0.1:20224 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 15:38:01] INFO:     127.0.0.1:20232 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 15:38:01] INFO:     127.0.0.1:20244 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 15:38:01 TP0] Prefill batch. #new-seq: 2, #new-token: 2000, #cached-token: 144, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-08-25 15:38:01 TP0] Prefill batch. #new-seq: 2, #new-token: 2000, #cached-token: 144, token usage: 0.05, #running-req: 2, #queue-req: 0, 
[2025-08-25 15:38:02] INFO:     127.0.0.1:20218 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 15:38:02] INFO:     127.0.0.1:20224 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 15:38:02 TP0] Prefill batch. #new-seq: 1, #new-token: 1000, #cached-token: 72, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-08-25 15:38:02] INFO:     127.0.0.1:20232 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 15:38:02] INFO:     127.0.0.1:20244 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 15:38:03 TP0] Prefill batch. #new-seq: 3, #new-token: 3000, #cached-token: 216, token usage: 0.00, #running-req: 1, #queue-req: 0, 
[2025-08-25 15:38:03] INFO:     127.0.0.1:20218 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 15:38:04 TP0] Prefill batch. #new-seq: 1, #new-token: 1000, #cached-token: 72, token usage: 0.00, #running-req: 3, #queue-req: 0, 
[2025-08-25 15:38:04] INFO:     127.0.0.1:20224 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 15:38:04] INFO:     127.0.0.1:20232 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 15:38:04] INFO:     127.0.0.1:20244 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 15:38:04 TP0] Prefill batch. #new-seq: 3, #new-token: 3000, #cached-token: 216, token usage: 0.03, #running-req: 4, #queue-req: 0, 
[2025-08-25 15:38:04] INFO:     127.0.0.1:20218 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 15:38:05] INFO:     127.0.0.1:20224 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 15:38:05] INFO:     127.0.0.1:20232 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 15:38:05] INFO:     127.0.0.1:20244 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 15:38:05 TP0] Prefill batch. #new-seq: 4, #new-token: 4, #cached-token: 844, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-08-25 15:38:05 TP0] Decode batch. #running-req: 4, #token: 332, token usage: 0.00, gen throughput (token/s): 27.39, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:38:06 TP0] Decode batch. #running-req: 4, #token: 492, token usage: 0.00, gen throughput (token/s): 870.91, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:38:06 TP0] Decode batch. #running-req: 4, #token: 652, token usage: 0.00, gen throughput (token/s): 876.09, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:38:06 TP0] Decode batch. #running-req: 4, #token: 812, token usage: 0.00, gen throughput (token/s): 869.22, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:38:06 TP0] Decode batch. #running-req: 4, #token: 972, token usage: 0.00, gen throughput (token/s): 876.38, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:38:06 TP0] Decode batch. #running-req: 4, #token: 1132, token usage: 0.00, gen throughput (token/s): 864.70, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:38:06 TP0] Decode batch. #running-req: 4, #token: 1292, token usage: 0.00, gen throughput (token/s): 880.94, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:38:07 TP0] Decode batch. #running-req: 4, #token: 1452, token usage: 0.00, gen throughput (token/s): 886.48, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:38:07 TP0] Decode batch. #running-req: 4, #token: 1612, token usage: 0.00, gen throughput (token/s): 865.94, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:38:07 TP0] Decode batch. #running-req: 4, #token: 1772, token usage: 0.00, gen throughput (token/s): 876.38, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:38:07 TP0] Decode batch. #running-req: 4, #token: 1932, token usage: 0.00, gen throughput (token/s): 872.30, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:38:07 TP0] Decode batch. #running-req: 4, #token: 2092, token usage: 0.00, gen throughput (token/s): 877.61, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:38:08 TP0] Decode batch. #running-req: 4, #token: 2252, token usage: 0.00, gen throughput (token/s): 886.96, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:38:08 TP0] Decode batch. #running-req: 4, #token: 2412, token usage: 0.00, gen throughput (token/s): 858.01, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:38:08 TP0] Decode batch. #running-req: 4, #token: 2572, token usage: 0.00, gen throughput (token/s): 907.10, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:38:08 TP0] Decode batch. #running-req: 4, #token: 2732, token usage: 0.00, gen throughput (token/s): 886.64, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:38:08 TP0] Decode batch. #running-req: 4, #token: 2892, token usage: 0.00, gen throughput (token/s): 846.71, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:38:08 TP0] Decode batch. #running-req: 4, #token: 3052, token usage: 0.00, gen throughput (token/s): 842.97, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:38:09 TP0] Decode batch. #running-req: 4, #token: 3212, token usage: 0.00, gen throughput (token/s): 850.60, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:38:09 TP0] Decode batch. #running-req: 4, #token: 3372, token usage: 0.00, gen throughput (token/s): 879.95, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:38:09 TP0] Decode batch. #running-req: 4, #token: 3532, token usage: 0.00, gen throughput (token/s): 857.77, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:38:09 TP0] Decode batch. #running-req: 4, #token: 3692, token usage: 0.00, gen throughput (token/s): 846.49, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:38:09 TP0] Decode batch. #running-req: 4, #token: 3852, token usage: 0.00, gen throughput (token/s): 847.66, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:38:10 TP0] Decode batch. #running-req: 4, #token: 4012, token usage: 0.00, gen throughput (token/s): 826.17, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:38:10 TP0] Decode batch. #running-req: 4, #token: 4172, token usage: 0.00, gen throughput (token/s): 895.64, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:38:10] INFO:     127.0.0.1:33770 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:38:10] INFO:     127.0.0.1:33772 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:38:10] INFO:     127.0.0.1:33784 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:38:10] INFO:     127.0.0.1:33798 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:38:10 TP0] Prefill batch. #new-seq: 4, #new-token: 4, #cached-token: 844, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-08-25 15:38:10 TP0] Decode batch. #running-req: 4, #token: 332, token usage: 0.00, gen throughput (token/s): 654.61, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:38:10 TP0] Decode batch. #running-req: 4, #token: 492, token usage: 0.00, gen throughput (token/s): 875.66, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:38:10 TP0] Decode batch. #running-req: 4, #token: 652, token usage: 0.00, gen throughput (token/s): 893.76, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:38:11 TP0] Decode batch. #running-req: 4, #token: 812, token usage: 0.00, gen throughput (token/s): 912.21, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:38:11 TP0] Decode batch. #running-req: 4, #token: 972, token usage: 0.00, gen throughput (token/s): 920.96, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:38:11 TP0] Decode batch. #running-req: 4, #token: 1132, token usage: 0.00, gen throughput (token/s): 888.97, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:38:11 TP0] Decode batch. #running-req: 4, #token: 1292, token usage: 0.00, gen throughput (token/s): 908.73, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:38:11 TP0] Decode batch. #running-req: 4, #token: 1452, token usage: 0.00, gen throughput (token/s): 906.22, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:38:11 TP0] Decode batch. #running-req: 4, #token: 1612, token usage: 0.00, gen throughput (token/s): 901.66, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:38:12 TP0] Decode batch. #running-req: 4, #token: 1772, token usage: 0.00, gen throughput (token/s): 921.20, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:38:12 TP0] Decode batch. #running-req: 4, #token: 1932, token usage: 0.00, gen throughput (token/s): 918.74, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:38:12 TP0] Decode batch. #running-req: 4, #token: 2092, token usage: 0.00, gen throughput (token/s): 899.01, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:38:12 TP0] Decode batch. #running-req: 4, #token: 2252, token usage: 0.00, gen throughput (token/s): 913.96, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:38:12 TP0] Decode batch. #running-req: 4, #token: 2412, token usage: 0.00, gen throughput (token/s): 912.22, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:38:13 TP0] Decode batch. #running-req: 4, #token: 2572, token usage: 0.00, gen throughput (token/s): 905.98, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:38:13 TP0] Decode batch. #running-req: 4, #token: 2732, token usage: 0.00, gen throughput (token/s): 917.34, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:38:13 TP0] Decode batch. #running-req: 4, #token: 2892, token usage: 0.00, gen throughput (token/s): 907.32, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:38:13 TP0] Decode batch. #running-req: 4, #token: 3052, token usage: 0.00, gen throughput (token/s): 902.56, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:38:13 TP0] Decode batch. #running-req: 4, #token: 3212, token usage: 0.00, gen throughput (token/s): 870.05, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:38:13 TP0] Decode batch. #running-req: 4, #token: 3372, token usage: 0.00, gen throughput (token/s): 863.76, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:38:14 TP0] Decode batch. #running-req: 4, #token: 3532, token usage: 0.00, gen throughput (token/s): 872.61, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:38:14 TP0] Decode batch. #running-req: 4, #token: 3692, token usage: 0.00, gen throughput (token/s): 864.79, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:38:14 TP0] Decode batch. #running-req: 4, #token: 3852, token usage: 0.00, gen throughput (token/s): 878.02, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:38:14 TP0] Decode batch. #running-req: 4, #token: 4012, token usage: 0.00, gen throughput (token/s): 861.30, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:38:14 TP0] Decode batch. #running-req: 4, #token: 4172, token usage: 0.00, gen throughput (token/s): 853.02, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:38:14] INFO:     127.0.0.1:33798 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:38:14] INFO:     127.0.0.1:33770 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:38:14] INFO:     127.0.0.1:33772 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:38:14] INFO:     127.0.0.1:33784 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:38:14 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 211, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-08-25 15:38:14 TP0] Prefill batch. #new-seq: 3, #new-token: 3, #cached-token: 633, token usage: 0.00, #running-req: 1, #queue-req: 0, 
[2025-08-25 15:38:15 TP0] Decode batch. #running-req: 4, #token: 332, token usage: 0.00, gen throughput (token/s): 567.88, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:38:15 TP0] Decode batch. #running-req: 4, #token: 492, token usage: 0.00, gen throughput (token/s): 878.76, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:38:15 TP0] Decode batch. #running-req: 4, #token: 652, token usage: 0.00, gen throughput (token/s): 869.75, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:38:15 TP0] Decode batch. #running-req: 4, #token: 812, token usage: 0.00, gen throughput (token/s): 862.11, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:38:15 TP0] Decode batch. #running-req: 4, #token: 972, token usage: 0.00, gen throughput (token/s): 865.08, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:38:16 TP0] Decode batch. #running-req: 4, #token: 1132, token usage: 0.00, gen throughput (token/s): 866.18, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:38:16 TP0] Decode batch. #running-req: 4, #token: 1292, token usage: 0.00, gen throughput (token/s): 854.51, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:38:16 TP0] Decode batch. #running-req: 4, #token: 1452, token usage: 0.00, gen throughput (token/s): 845.16, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:38:16 TP0] Decode batch. #running-req: 4, #token: 1612, token usage: 0.00, gen throughput (token/s): 845.27, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:38:16 TP0] Decode batch. #running-req: 4, #token: 1772, token usage: 0.00, gen throughput (token/s): 858.34, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:38:16 TP0] Decode batch. #running-req: 4, #token: 1932, token usage: 0.00, gen throughput (token/s): 831.33, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:38:17 TP0] Decode batch. #running-req: 4, #token: 2092, token usage: 0.00, gen throughput (token/s): 847.93, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:38:17 TP0] Decode batch. #running-req: 4, #token: 2252, token usage: 0.00, gen throughput (token/s): 844.14, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:38:17 TP0] Decode batch. #running-req: 4, #token: 2412, token usage: 0.00, gen throughput (token/s): 856.40, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:38:17 TP0] Decode batch. #running-req: 4, #token: 2572, token usage: 0.00, gen throughput (token/s): 879.61, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:38:17 TP0] Decode batch. #running-req: 4, #token: 2732, token usage: 0.00, gen throughput (token/s): 845.43, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:38:18 TP0] Decode batch. #running-req: 4, #token: 2892, token usage: 0.00, gen throughput (token/s): 856.35, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:38:18 TP0] Decode batch. #running-req: 4, #token: 3052, token usage: 0.00, gen throughput (token/s): 859.85, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:38:18 TP0] Decode batch. #running-req: 4, #token: 3212, token usage: 0.00, gen throughput (token/s): 863.99, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:38:18 TP0] Decode batch. #running-req: 4, #token: 3372, token usage: 0.00, gen throughput (token/s): 869.46, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:38:18 TP0] Decode batch. #running-req: 4, #token: 3532, token usage: 0.00, gen throughput (token/s): 874.60, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:38:19 TP0] Decode batch. #running-req: 4, #token: 3692, token usage: 0.00, gen throughput (token/s): 882.14, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:38:19 TP0] Decode batch. #running-req: 4, #token: 3852, token usage: 0.00, gen throughput (token/s): 882.71, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:38:19 TP0] Decode batch. #running-req: 4, #token: 4012, token usage: 0.00, gen throughput (token/s): 875.33, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:38:19 TP0] Decode batch. #running-req: 4, #token: 4172, token usage: 0.00, gen throughput (token/s): 838.75, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:38:19] INFO:     127.0.0.1:33798 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:38:19] INFO:     127.0.0.1:33770 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:38:19] INFO:     127.0.0.1:33772 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:38:19] INFO:     127.0.0.1:33784 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:38:19 TP0] Prefill batch. #new-seq: 4, #new-token: 4, #cached-token: 844, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-08-25 15:38:19 TP0] Decode batch. #running-req: 4, #token: 332, token usage: 0.00, gen throughput (token/s): 651.39, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:38:20 TP0] Decode batch. #running-req: 4, #token: 492, token usage: 0.00, gen throughput (token/s): 875.95, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:38:20 TP0] Decode batch. #running-req: 4, #token: 652, token usage: 0.00, gen throughput (token/s): 909.41, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:38:20 TP0] Decode batch. #running-req: 4, #token: 812, token usage: 0.00, gen throughput (token/s): 906.80, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:38:20 TP0] Decode batch. #running-req: 4, #token: 972, token usage: 0.00, gen throughput (token/s): 905.50, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:38:20 TP0] Decode batch. #running-req: 4, #token: 1132, token usage: 0.00, gen throughput (token/s): 895.24, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:38:20 TP0] Decode batch. #running-req: 4, #token: 1292, token usage: 0.00, gen throughput (token/s): 912.94, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:38:21 TP0] Decode batch. #running-req: 4, #token: 1452, token usage: 0.00, gen throughput (token/s): 922.91, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:38:21 TP0] Decode batch. #running-req: 4, #token: 1612, token usage: 0.00, gen throughput (token/s): 900.06, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:38:21 TP0] Decode batch. #running-req: 4, #token: 1772, token usage: 0.00, gen throughput (token/s): 921.35, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:38:21 TP0] Decode batch. #running-req: 4, #token: 1932, token usage: 0.00, gen throughput (token/s): 903.77, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:38:21 TP0] Decode batch. #running-req: 4, #token: 2092, token usage: 0.00, gen throughput (token/s): 913.72, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:38:21 TP0] Decode batch. #running-req: 4, #token: 2252, token usage: 0.00, gen throughput (token/s): 898.67, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:38:22 TP0] Decode batch. #running-req: 4, #token: 2412, token usage: 0.00, gen throughput (token/s): 918.25, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:38:22 TP0] Decode batch. #running-req: 4, #token: 2572, token usage: 0.00, gen throughput (token/s): 929.40, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:38:22 TP0] Decode batch. #running-req: 4, #token: 2732, token usage: 0.00, gen throughput (token/s): 906.52, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:38:22 TP0] Decode batch. #running-req: 4, #token: 2892, token usage: 0.00, gen throughput (token/s): 903.81, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:38:22 TP0] Decode batch. #running-req: 4, #token: 3052, token usage: 0.00, gen throughput (token/s): 893.76, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:38:23 TP0] Decode batch. #running-req: 4, #token: 3212, token usage: 0.00, gen throughput (token/s): 860.61, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:38:23 TP0] Decode batch. #running-req: 4, #token: 3372, token usage: 0.00, gen throughput (token/s): 900.54, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:38:23 TP0] Decode batch. #running-req: 4, #token: 3532, token usage: 0.00, gen throughput (token/s): 846.33, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:38:23 TP0] Decode batch. #running-req: 4, #token: 3692, token usage: 0.00, gen throughput (token/s): 846.50, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:38:23 TP0] Decode batch. #running-req: 4, #token: 3852, token usage: 0.00, gen throughput (token/s): 850.08, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:38:23 TP0] Decode batch. #running-req: 4, #token: 4012, token usage: 0.00, gen throughput (token/s): 867.84, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:38:24 TP0] Decode batch. #running-req: 4, #token: 4172, token usage: 0.00, gen throughput (token/s): 867.44, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:38:24] INFO:     127.0.0.1:33798 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:38:24] INFO:     127.0.0.1:33770 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:38:24] INFO:     127.0.0.1:33772 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:38:24] INFO:     127.0.0.1:33784 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:38:24 TP0] Prefill batch. #new-seq: 1, #new-token: 1159, #cached-token: 42, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-08-25 15:38:24 TP0] Prefill batch. #new-seq: 2, #new-token: 2318, #cached-token: 84, token usage: 0.03, #running-req: 1, #queue-req: 0, 
[2025-08-25 15:38:25 TP0] Prefill batch. #new-seq: 1, #new-token: 1000, #cached-token: 201, token usage: 0.06, #running-req: 3, #queue-req: 0, 
[2025-08-25 15:38:25] INFO:     127.0.0.1:55852 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 15:38:25] INFO:     127.0.0.1:55862 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 15:38:25] INFO:     127.0.0.1:55872 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 15:38:25 TP0] Prefill batch. #new-seq: 3, #new-token: 3000, #cached-token: 603, token usage: 0.01, #running-req: 1, #queue-req: 0, 
[2025-08-25 15:38:25] INFO:     127.0.0.1:55874 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 15:38:26 TP0] Prefill batch. #new-seq: 1, #new-token: 1000, #cached-token: 201, token usage: 0.08, #running-req: 4, #queue-req: 0, 
[2025-08-25 15:38:26] INFO:     127.0.0.1:55852 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 15:38:26] INFO:     127.0.0.1:55862 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 15:38:26] INFO:     127.0.0.1:55872 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 15:38:26 TP0] Prefill batch. #new-seq: 3, #new-token: 3000, #cached-token: 603, token usage: 0.01, #running-req: 1, #queue-req: 0, 
[2025-08-25 15:38:26] INFO:     127.0.0.1:55874 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 15:38:27 TP0] Prefill batch. #new-seq: 1, #new-token: 1000, #cached-token: 201, token usage: 0.08, #running-req: 4, #queue-req: 0, 
[2025-08-25 15:38:27] INFO:     127.0.0.1:55852 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 15:38:28] INFO:     127.0.0.1:55862 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 15:38:28] INFO:     127.0.0.1:55872 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 15:38:28 TP0] Prefill batch. #new-seq: 3, #new-token: 3000, #cached-token: 603, token usage: 0.01, #running-req: 1, #queue-req: 0, 
[2025-08-25 15:38:28] INFO:     127.0.0.1:55874 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 15:38:29 TP0] Prefill batch. #new-seq: 1, #new-token: 1000, #cached-token: 201, token usage: 0.08, #running-req: 4, #queue-req: 0, 
[2025-08-25 15:38:29] INFO:     127.0.0.1:55852 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 15:38:29] INFO:     127.0.0.1:55862 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 15:38:29] INFO:     127.0.0.1:55872 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 15:38:29 TP0] Prefill batch. #new-seq: 2, #new-token: 2332, #cached-token: 88, token usage: 0.00, #running-req: 1, #queue-req: 0, 
[2025-08-25 15:38:29] INFO:     127.0.0.1:55874 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 15:38:29 TP0] Prefill batch. #new-seq: 1, #new-token: 1166, #cached-token: 44, token usage: 0.06, #running-req: 3, #queue-req: 0, 
[2025-08-25 15:38:31 TP0] Decode batch. #running-req: 3, #token: 3218, token usage: 0.08, gen throughput (token/s): 0.52, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:38:32 TP0] Decode batch. #running-req: 3, #token: 3338, token usage: 0.08, gen throughput (token/s): 65.95, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:38:34 TP0] Decode batch. #running-req: 3, #token: 3458, token usage: 0.09, gen throughput (token/s): 66.06, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:38:36 TP0] Decode batch. #running-req: 3, #token: 3578, token usage: 0.09, gen throughput (token/s): 65.68, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:38:37] INFO:     127.0.0.1:55852 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:38:37] INFO:     127.0.0.1:55862 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:38:37] INFO:     127.0.0.1:55874 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:38:37 TP0] Prefill batch. #new-seq: 3, #new-token: 3, #cached-token: 498, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-08-25 15:38:37 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 166, token usage: 0.00, #running-req: 3, #queue-req: 0, 
[2025-08-25 15:38:37 TP0] Decode batch. #running-req: 4, #token: 287, token usage: 0.00, gen throughput (token/s): 11.75, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:38:37 TP0] Decode batch. #running-req: 4, #token: 447, token usage: 0.00, gen throughput (token/s): 891.55, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:38:38 TP0] Decode batch. #running-req: 4, #token: 607, token usage: 0.00, gen throughput (token/s): 878.55, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:38:38 TP0] Decode batch. #running-req: 4, #token: 767, token usage: 0.00, gen throughput (token/s): 874.76, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:38:38 TP0] Decode batch. #running-req: 4, #token: 927, token usage: 0.00, gen throughput (token/s): 890.51, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:38:38 TP0] Decode batch. #running-req: 4, #token: 1087, token usage: 0.00, gen throughput (token/s): 883.46, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:38:38 TP0] Decode batch. #running-req: 4, #token: 1247, token usage: 0.00, gen throughput (token/s): 889.20, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:38:39 TP0] Decode batch. #running-req: 4, #token: 1407, token usage: 0.00, gen throughput (token/s): 871.72, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:38:39 TP0] Decode batch. #running-req: 4, #token: 1567, token usage: 0.00, gen throughput (token/s): 882.46, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:38:39 TP0] Decode batch. #running-req: 4, #token: 1727, token usage: 0.00, gen throughput (token/s): 877.17, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:38:39 TP0] Decode batch. #running-req: 4, #token: 1887, token usage: 0.00, gen throughput (token/s): 872.16, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:38:39 TP0] Decode batch. #running-req: 4, #token: 2047, token usage: 0.00, gen throughput (token/s): 881.75, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:38:39 TP0] Decode batch. #running-req: 4, #token: 2207, token usage: 0.00, gen throughput (token/s): 882.65, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:38:40 TP0] Decode batch. #running-req: 4, #token: 2367, token usage: 0.00, gen throughput (token/s): 876.07, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:38:40 TP0] Decode batch. #running-req: 4, #token: 2527, token usage: 0.00, gen throughput (token/s): 905.92, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:38:40 TP0] Decode batch. #running-req: 4, #token: 2687, token usage: 0.00, gen throughput (token/s): 901.90, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:38:40 TP0] Decode batch. #running-req: 4, #token: 2847, token usage: 0.00, gen throughput (token/s): 904.91, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:38:40 TP0] Decode batch. #running-req: 4, #token: 3007, token usage: 0.00, gen throughput (token/s): 901.19, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:38:40 TP0] Decode batch. #running-req: 4, #token: 3167, token usage: 0.00, gen throughput (token/s): 876.80, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:38:41 TP0] Decode batch. #running-req: 4, #token: 3327, token usage: 0.00, gen throughput (token/s): 889.14, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:38:41 TP0] Decode batch. #running-req: 4, #token: 3487, token usage: 0.00, gen throughput (token/s): 895.13, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:38:41 TP0] Decode batch. #running-req: 4, #token: 3647, token usage: 0.00, gen throughput (token/s): 876.56, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:38:41 TP0] Decode batch. #running-req: 4, #token: 3807, token usage: 0.00, gen throughput (token/s): 875.55, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:38:41 TP0] Decode batch. #running-req: 4, #token: 3967, token usage: 0.00, gen throughput (token/s): 847.93, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:38:42 TP0] Decode batch. #running-req: 4, #token: 4127, token usage: 0.00, gen throughput (token/s): 904.91, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:38:42] INFO:     127.0.0.1:41232 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:38:42] INFO:     127.0.0.1:41238 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:38:42] INFO:     127.0.0.1:41248 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:38:42] INFO:     127.0.0.1:41264 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:38:42 TP0] Prefill batch. #new-seq: 4, #new-token: 4, #cached-token: 664, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-08-25 15:38:42 TP0] Decode batch. #running-req: 4, #token: 287, token usage: 0.00, gen throughput (token/s): 618.96, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:38:42 TP0] Decode batch. #running-req: 4, #token: 447, token usage: 0.00, gen throughput (token/s): 880.84, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:38:42 TP0] Decode batch. #running-req: 4, #token: 607, token usage: 0.00, gen throughput (token/s): 862.88, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:38:42 TP0] Decode batch. #running-req: 4, #token: 767, token usage: 0.00, gen throughput (token/s): 852.88, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:38:43 TP0] Decode batch. #running-req: 4, #token: 927, token usage: 0.00, gen throughput (token/s): 916.73, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:38:43 TP0] Decode batch. #running-req: 4, #token: 1087, token usage: 0.00, gen throughput (token/s): 870.92, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:38:43 TP0] Decode batch. #running-req: 4, #token: 1247, token usage: 0.00, gen throughput (token/s): 874.05, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:38:43 TP0] Decode batch. #running-req: 4, #token: 1407, token usage: 0.00, gen throughput (token/s): 868.89, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:38:43 TP0] Decode batch. #running-req: 4, #token: 1567, token usage: 0.00, gen throughput (token/s): 852.86, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:38:43 TP0] Decode batch. #running-req: 4, #token: 1727, token usage: 0.00, gen throughput (token/s): 885.81, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:38:44 TP0] Decode batch. #running-req: 4, #token: 1887, token usage: 0.00, gen throughput (token/s): 855.08, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:38:44 TP0] Decode batch. #running-req: 4, #token: 2047, token usage: 0.00, gen throughput (token/s): 846.54, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:38:44 TP0] Decode batch. #running-req: 4, #token: 2207, token usage: 0.00, gen throughput (token/s): 874.57, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:38:44 TP0] Decode batch. #running-req: 4, #token: 2367, token usage: 0.00, gen throughput (token/s): 849.32, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:38:44 TP0] Decode batch. #running-req: 4, #token: 2527, token usage: 0.00, gen throughput (token/s): 901.84, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:38:45 TP0] Decode batch. #running-req: 4, #token: 2687, token usage: 0.00, gen throughput (token/s): 876.10, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:38:45 TP0] Decode batch. #running-req: 4, #token: 2847, token usage: 0.00, gen throughput (token/s): 871.54, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:38:45 TP0] Decode batch. #running-req: 4, #token: 3007, token usage: 0.00, gen throughput (token/s): 855.40, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:38:45 TP0] Decode batch. #running-req: 4, #token: 3167, token usage: 0.00, gen throughput (token/s): 868.76, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:38:45 TP0] Decode batch. #running-req: 4, #token: 3327, token usage: 0.00, gen throughput (token/s): 903.13, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:38:46 TP0] Decode batch. #running-req: 4, #token: 3487, token usage: 0.00, gen throughput (token/s): 918.12, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:38:46 TP0] Decode batch. #running-req: 4, #token: 3647, token usage: 0.00, gen throughput (token/s): 911.92, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:38:46 TP0] Decode batch. #running-req: 4, #token: 3807, token usage: 0.00, gen throughput (token/s): 831.42, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:38:46 TP0] Decode batch. #running-req: 4, #token: 3967, token usage: 0.00, gen throughput (token/s): 869.89, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:38:46 TP0] Decode batch. #running-req: 4, #token: 4127, token usage: 0.00, gen throughput (token/s): 924.50, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:38:46] INFO:     127.0.0.1:41264 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:38:46] INFO:     127.0.0.1:41232 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:38:46] INFO:     127.0.0.1:41238 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:38:46] INFO:     127.0.0.1:41248 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:38:46 TP0] Prefill batch. #new-seq: 4, #new-token: 4, #cached-token: 664, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-08-25 15:38:46 TP0] Decode batch. #running-req: 4, #token: 287, token usage: 0.00, gen throughput (token/s): 662.12, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:38:47 TP0] Decode batch. #running-req: 4, #token: 447, token usage: 0.00, gen throughput (token/s): 895.44, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:38:47 TP0] Decode batch. #running-req: 4, #token: 607, token usage: 0.00, gen throughput (token/s): 886.09, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:38:47 TP0] Decode batch. #running-req: 4, #token: 767, token usage: 0.00, gen throughput (token/s): 855.93, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:38:47 TP0] Decode batch. #running-req: 4, #token: 927, token usage: 0.00, gen throughput (token/s): 898.88, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:38:47 TP0] Decode batch. #running-req: 4, #token: 1087, token usage: 0.00, gen throughput (token/s): 888.35, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:38:48 TP0] Decode batch. #running-req: 4, #token: 1247, token usage: 0.00, gen throughput (token/s): 938.19, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:38:48 TP0] Decode batch. #running-req: 4, #token: 1407, token usage: 0.00, gen throughput (token/s): 932.72, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:38:48 TP0] Decode batch. #running-req: 4, #token: 1567, token usage: 0.00, gen throughput (token/s): 920.03, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:38:48 TP0] Decode batch. #running-req: 4, #token: 1727, token usage: 0.00, gen throughput (token/s): 920.83, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:38:48 TP0] Decode batch. #running-req: 4, #token: 1887, token usage: 0.00, gen throughput (token/s): 919.00, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:38:48 TP0] Decode batch. #running-req: 4, #token: 2047, token usage: 0.00, gen throughput (token/s): 920.06, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:38:49 TP0] Decode batch. #running-req: 4, #token: 2207, token usage: 0.00, gen throughput (token/s): 853.97, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:38:49 TP0] Decode batch. #running-req: 4, #token: 2367, token usage: 0.00, gen throughput (token/s): 837.61, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:38:49 TP0] Decode batch. #running-req: 4, #token: 2527, token usage: 0.00, gen throughput (token/s): 860.83, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:38:49 TP0] Decode batch. #running-req: 4, #token: 2687, token usage: 0.00, gen throughput (token/s): 864.94, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:38:49 TP0] Decode batch. #running-req: 4, #token: 2847, token usage: 0.00, gen throughput (token/s): 860.57, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:38:50 TP0] Decode batch. #running-req: 4, #token: 3007, token usage: 0.00, gen throughput (token/s): 848.95, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:38:50 TP0] Decode batch. #running-req: 4, #token: 3167, token usage: 0.00, gen throughput (token/s): 845.59, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:38:50 TP0] Decode batch. #running-req: 4, #token: 3327, token usage: 0.00, gen throughput (token/s): 895.06, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:38:50 TP0] Decode batch. #running-req: 4, #token: 3487, token usage: 0.00, gen throughput (token/s): 862.39, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:38:50 TP0] Decode batch. #running-req: 4, #token: 3647, token usage: 0.00, gen throughput (token/s): 848.46, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:38:50 TP0] Decode batch. #running-req: 4, #token: 3807, token usage: 0.00, gen throughput (token/s): 856.26, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:38:51 TP0] Decode batch. #running-req: 4, #token: 3967, token usage: 0.00, gen throughput (token/s): 836.14, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:38:51 TP0] Decode batch. #running-req: 4, #token: 4127, token usage: 0.00, gen throughput (token/s): 864.96, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:38:51] INFO:     127.0.0.1:41264 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:38:51] INFO:     127.0.0.1:41232 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:38:51] INFO:     127.0.0.1:41238 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:38:51] INFO:     127.0.0.1:41248 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:38:51 TP0] Prefill batch. #new-seq: 2, #new-token: 2, #cached-token: 332, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-08-25 15:38:51 TP0] Prefill batch. #new-seq: 2, #new-token: 2, #cached-token: 332, token usage: 0.00, #running-req: 2, #queue-req: 0, 
[2025-08-25 15:38:51 TP0] Decode batch. #running-req: 4, #token: 287, token usage: 0.00, gen throughput (token/s): 577.70, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:38:51 TP0] Decode batch. #running-req: 4, #token: 447, token usage: 0.00, gen throughput (token/s): 862.87, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:38:51 TP0] Decode batch. #running-req: 4, #token: 607, token usage: 0.00, gen throughput (token/s): 847.93, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:38:52 TP0] Decode batch. #running-req: 4, #token: 767, token usage: 0.00, gen throughput (token/s): 838.78, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:38:52 TP0] Decode batch. #running-req: 4, #token: 927, token usage: 0.00, gen throughput (token/s): 883.31, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:38:52 TP0] Decode batch. #running-req: 4, #token: 1087, token usage: 0.00, gen throughput (token/s): 887.45, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:38:52 TP0] Decode batch. #running-req: 4, #token: 1247, token usage: 0.00, gen throughput (token/s): 859.69, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:38:52 TP0] Decode batch. #running-req: 4, #token: 1407, token usage: 0.00, gen throughput (token/s): 871.91, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:38:53 TP0] Decode batch. #running-req: 4, #token: 1567, token usage: 0.00, gen throughput (token/s): 854.93, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:38:53 TP0] Decode batch. #running-req: 4, #token: 1727, token usage: 0.00, gen throughput (token/s): 905.96, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:38:53 TP0] Decode batch. #running-req: 4, #token: 1887, token usage: 0.00, gen throughput (token/s): 856.05, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:38:53 TP0] Decode batch. #running-req: 4, #token: 2047, token usage: 0.00, gen throughput (token/s): 877.85, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:38:53 TP0] Decode batch. #running-req: 4, #token: 2207, token usage: 0.00, gen throughput (token/s): 888.01, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:38:54 TP0] Decode batch. #running-req: 4, #token: 2367, token usage: 0.00, gen throughput (token/s): 885.14, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:38:54 TP0] Decode batch. #running-req: 4, #token: 2527, token usage: 0.00, gen throughput (token/s): 864.75, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:38:54 TP0] Decode batch. #running-req: 4, #token: 2687, token usage: 0.00, gen throughput (token/s): 857.15, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:38:54 TP0] Decode batch. #running-req: 4, #token: 2847, token usage: 0.00, gen throughput (token/s): 857.82, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:38:54 TP0] Decode batch. #running-req: 4, #token: 3007, token usage: 0.00, gen throughput (token/s): 867.76, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:38:54 TP0] Decode batch. #running-req: 4, #token: 3167, token usage: 0.00, gen throughput (token/s): 840.12, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:38:55 TP0] Decode batch. #running-req: 4, #token: 3327, token usage: 0.00, gen throughput (token/s): 885.64, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:38:55 TP0] Decode batch. #running-req: 4, #token: 3487, token usage: 0.00, gen throughput (token/s): 865.44, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:38:55 TP0] Decode batch. #running-req: 4, #token: 3647, token usage: 0.00, gen throughput (token/s): 882.81, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:38:55 TP0] Decode batch. #running-req: 4, #token: 3807, token usage: 0.00, gen throughput (token/s): 875.81, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:38:55 TP0] Decode batch. #running-req: 4, #token: 3967, token usage: 0.00, gen throughput (token/s): 861.75, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:38:56 TP0] Decode batch. #running-req: 4, #token: 4127, token usage: 0.00, gen throughput (token/s): 902.48, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:38:56] INFO:     127.0.0.1:41264 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:38:56] INFO:     127.0.0.1:41232 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:38:56] INFO:     127.0.0.1:41238 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:38:56] INFO:     127.0.0.1:41248 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:38:56 TP0] Prefill batch. #new-seq: 1, #new-token: 1114, #cached-token: 42, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-08-25 15:38:56 TP0] Prefill batch. #new-seq: 2, #new-token: 2228, #cached-token: 84, token usage: 0.03, #running-req: 1, #queue-req: 0, 
[2025-08-25 15:38:57 TP0] Prefill batch. #new-seq: 1, #new-token: 1000, #cached-token: 156, token usage: 0.06, #running-req: 3, #queue-req: 0, 
[2025-08-25 15:38:57] INFO:     127.0.0.1:60976 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 15:38:57] INFO:     127.0.0.1:60992 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 15:38:57] INFO:     127.0.0.1:60994 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 15:38:57 TP0] Prefill batch. #new-seq: 1, #new-token: 1000, #cached-token: 156, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-08-25 15:38:57 TP0] Prefill batch. #new-seq: 1, #new-token: 1000, #cached-token: 156, token usage: 0.03, #running-req: 1, #queue-req: 0, 
[2025-08-25 15:38:57] INFO:     127.0.0.1:60998 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 15:38:58 TP0] Prefill batch. #new-seq: 2, #new-token: 2000, #cached-token: 312, token usage: 0.03, #running-req: 2, #queue-req: 0, 
[2025-08-25 15:38:58] INFO:     127.0.0.1:60976 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 15:38:58] INFO:     127.0.0.1:60992 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 15:38:59 TP0] Prefill batch. #new-seq: 2, #new-token: 2000, #cached-token: 312, token usage: 0.00, #running-req: 2, #queue-req: 0, 
[2025-08-25 15:38:59] INFO:     127.0.0.1:60994 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 15:38:59] INFO:     127.0.0.1:60998 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 15:38:59 TP0] Prefill batch. #new-seq: 2, #new-token: 2000, #cached-token: 312, token usage: 0.05, #running-req: 4, #queue-req: 0, 
[2025-08-25 15:38:59] INFO:     127.0.0.1:60976 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 15:38:59] INFO:     127.0.0.1:60992 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 15:39:00 TP0] Prefill batch. #new-seq: 2, #new-token: 2000, #cached-token: 312, token usage: 0.00, #running-req: 2, #queue-req: 0, 
[2025-08-25 15:39:00] INFO:     127.0.0.1:60994 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 15:39:00] INFO:     127.0.0.1:60998 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 15:39:01 TP0] Prefill batch. #new-seq: 2, #new-token: 2000, #cached-token: 312, token usage: 0.05, #running-req: 4, #queue-req: 0, 
[2025-08-25 15:39:01] INFO:     127.0.0.1:60976 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 15:39:01] INFO:     127.0.0.1:60992 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 15:39:02 TP0] Prefill batch. #new-seq: 1, #new-token: 1121, #cached-token: 44, token usage: 0.00, #running-req: 2, #queue-req: 0, 
[2025-08-25 15:39:02] INFO:     127.0.0.1:60994 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 15:39:02] INFO:     127.0.0.1:60998 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 15:39:02 TP0] Prefill batch. #new-seq: 1, #new-token: 1121, #cached-token: 44, token usage: 0.03, #running-req: 3, #queue-req: 0, 
[2025-08-25 15:39:03 TP0] Decode batch. #running-req: 2, #token: 2187, token usage: 0.05, gen throughput (token/s): 3.75, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:39:05 TP0] Decode batch. #running-req: 2, #token: 2267, token usage: 0.06, gen throughput (token/s): 44.71, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:39:07 TP0] Decode batch. #running-req: 2, #token: 2347, token usage: 0.06, gen throughput (token/s): 44.64, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:39:08 TP0] Decode batch. #running-req: 2, #token: 2427, token usage: 0.06, gen throughput (token/s): 44.74, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:39:09] INFO:     127.0.0.1:60976 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:39:09] INFO:     127.0.0.1:60992 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:39:09 TP0] Prefill batch. #new-seq: 4, #new-token: 4, #cached-token: 436, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-08-25 15:39:09 TP0] Decode batch. #running-req: 4, #token: 230, token usage: 0.00, gen throughput (token/s): 11.68, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:39:09 TP0] Decode batch. #running-req: 4, #token: 390, token usage: 0.00, gen throughput (token/s): 908.99, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:39:10 TP0] Decode batch. #running-req: 4, #token: 550, token usage: 0.00, gen throughput (token/s): 879.57, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:39:10 TP0] Decode batch. #running-req: 4, #token: 710, token usage: 0.00, gen throughput (token/s): 892.12, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:39:10 TP0] Decode batch. #running-req: 4, #token: 870, token usage: 0.00, gen throughput (token/s): 901.91, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:39:10 TP0] Decode batch. #running-req: 4, #token: 1030, token usage: 0.00, gen throughput (token/s): 890.39, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:39:10 TP0] Decode batch. #running-req: 4, #token: 1190, token usage: 0.00, gen throughput (token/s): 921.43, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:39:10 TP0] Decode batch. #running-req: 4, #token: 1350, token usage: 0.00, gen throughput (token/s): 871.37, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:39:11 TP0] Decode batch. #running-req: 4, #token: 1510, token usage: 0.00, gen throughput (token/s): 855.62, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:39:11 TP0] Decode batch. #running-req: 4, #token: 1670, token usage: 0.00, gen throughput (token/s): 872.62, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:39:11 TP0] Decode batch. #running-req: 4, #token: 1830, token usage: 0.00, gen throughput (token/s): 857.93, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:39:11 TP0] Decode batch. #running-req: 4, #token: 1990, token usage: 0.00, gen throughput (token/s): 884.19, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:39:11 TP0] Decode batch. #running-req: 4, #token: 2150, token usage: 0.00, gen throughput (token/s): 875.54, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:39:12 TP0] Decode batch. #running-req: 4, #token: 2310, token usage: 0.00, gen throughput (token/s): 868.97, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:39:12 TP0] Decode batch. #running-req: 4, #token: 2470, token usage: 0.00, gen throughput (token/s): 890.34, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:39:12 TP0] Decode batch. #running-req: 4, #token: 2630, token usage: 0.00, gen throughput (token/s): 870.55, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:39:12 TP0] Decode batch. #running-req: 4, #token: 2790, token usage: 0.00, gen throughput (token/s): 854.93, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:39:12 TP0] Decode batch. #running-req: 4, #token: 2950, token usage: 0.00, gen throughput (token/s): 868.86, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:39:13 TP0] Decode batch. #running-req: 4, #token: 3110, token usage: 0.00, gen throughput (token/s): 843.52, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:39:13 TP0] Decode batch. #running-req: 4, #token: 3270, token usage: 0.00, gen throughput (token/s): 898.31, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:39:13 TP0] Decode batch. #running-req: 4, #token: 3430, token usage: 0.00, gen throughput (token/s): 841.19, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:39:13 TP0] Decode batch. #running-req: 4, #token: 3590, token usage: 0.00, gen throughput (token/s): 852.75, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:39:13 TP0] Decode batch. #running-req: 4, #token: 3750, token usage: 0.00, gen throughput (token/s): 813.47, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:39:13 TP0] Decode batch. #running-req: 4, #token: 3910, token usage: 0.00, gen throughput (token/s): 850.68, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:39:14 TP0] Decode batch. #running-req: 4, #token: 4070, token usage: 0.00, gen throughput (token/s): 872.41, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:39:14] INFO:     127.0.0.1:64650 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:39:14] INFO:     127.0.0.1:64652 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:39:14] INFO:     127.0.0.1:64656 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:39:14] INFO:     127.0.0.1:64666 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:39:14 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 109, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-08-25 15:39:14 TP0] Prefill batch. #new-seq: 3, #new-token: 3, #cached-token: 327, token usage: 0.00, #running-req: 1, #queue-req: 0, 
[2025-08-25 15:39:14 TP0] Decode batch. #running-req: 4, #token: 230, token usage: 0.00, gen throughput (token/s): 584.67, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:39:14 TP0] Decode batch. #running-req: 4, #token: 390, token usage: 0.00, gen throughput (token/s): 861.34, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:39:14 TP0] Decode batch. #running-req: 4, #token: 550, token usage: 0.00, gen throughput (token/s): 870.86, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:39:14 TP0] Decode batch. #running-req: 4, #token: 710, token usage: 0.00, gen throughput (token/s): 871.41, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:39:15 TP0] Decode batch. #running-req: 4, #token: 870, token usage: 0.00, gen throughput (token/s): 867.11, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:39:15 TP0] Decode batch. #running-req: 4, #token: 1030, token usage: 0.00, gen throughput (token/s): 853.71, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:39:15 TP0] Decode batch. #running-req: 4, #token: 1190, token usage: 0.00, gen throughput (token/s): 860.19, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:39:15 TP0] Decode batch. #running-req: 4, #token: 1350, token usage: 0.00, gen throughput (token/s): 856.83, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:39:15 TP0] Decode batch. #running-req: 4, #token: 1510, token usage: 0.00, gen throughput (token/s): 878.67, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:39:16 TP0] Decode batch. #running-req: 4, #token: 1670, token usage: 0.00, gen throughput (token/s): 870.08, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:39:16 TP0] Decode batch. #running-req: 4, #token: 1830, token usage: 0.00, gen throughput (token/s): 837.06, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:39:16 TP0] Decode batch. #running-req: 4, #token: 1990, token usage: 0.00, gen throughput (token/s): 850.44, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:39:16 TP0] Decode batch. #running-req: 4, #token: 2150, token usage: 0.00, gen throughput (token/s): 871.02, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:39:16 TP0] Decode batch. #running-req: 4, #token: 2310, token usage: 0.00, gen throughput (token/s): 860.88, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:39:17 TP0] Decode batch. #running-req: 4, #token: 2470, token usage: 0.00, gen throughput (token/s): 922.79, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:39:17 TP0] Decode batch. #running-req: 4, #token: 2630, token usage: 0.00, gen throughput (token/s): 861.21, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:39:17 TP0] Decode batch. #running-req: 4, #token: 2790, token usage: 0.00, gen throughput (token/s): 882.79, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:39:17 TP0] Decode batch. #running-req: 4, #token: 2950, token usage: 0.00, gen throughput (token/s): 831.03, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:39:17 TP0] Decode batch. #running-req: 4, #token: 3110, token usage: 0.00, gen throughput (token/s): 851.97, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:39:17 TP0] Decode batch. #running-req: 4, #token: 3270, token usage: 0.00, gen throughput (token/s): 884.99, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:39:18 TP0] Decode batch. #running-req: 4, #token: 3430, token usage: 0.00, gen throughput (token/s): 848.58, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:39:18 TP0] Decode batch. #running-req: 4, #token: 3590, token usage: 0.00, gen throughput (token/s): 857.23, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:39:18 TP0] Decode batch. #running-req: 4, #token: 3750, token usage: 0.00, gen throughput (token/s): 840.01, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:39:18 TP0] Decode batch. #running-req: 4, #token: 3910, token usage: 0.00, gen throughput (token/s): 877.82, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:39:18 TP0] Decode batch. #running-req: 4, #token: 4070, token usage: 0.00, gen throughput (token/s): 874.68, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:39:18] INFO:     127.0.0.1:64666 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:39:18] INFO:     127.0.0.1:64650 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:39:18] INFO:     127.0.0.1:64652 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:39:18] INFO:     127.0.0.1:64656 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:39:18 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 109, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-08-25 15:39:18 TP0] Prefill batch. #new-seq: 3, #new-token: 3, #cached-token: 327, token usage: 0.00, #running-req: 1, #queue-req: 0, 
[2025-08-25 15:39:19 TP0] Decode batch. #running-req: 4, #token: 230, token usage: 0.00, gen throughput (token/s): 597.52, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:39:19 TP0] Decode batch. #running-req: 4, #token: 390, token usage: 0.00, gen throughput (token/s): 868.03, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:39:19 TP0] Decode batch. #running-req: 4, #token: 550, token usage: 0.00, gen throughput (token/s): 886.96, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:39:19 TP0] Decode batch. #running-req: 4, #token: 710, token usage: 0.00, gen throughput (token/s): 852.56, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:39:19 TP0] Decode batch. #running-req: 4, #token: 870, token usage: 0.00, gen throughput (token/s): 887.85, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:39:20 TP0] Decode batch. #running-req: 4, #token: 1030, token usage: 0.00, gen throughput (token/s): 873.24, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:39:20 TP0] Decode batch. #running-req: 4, #token: 1190, token usage: 0.00, gen throughput (token/s): 820.25, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:39:20 TP0] Decode batch. #running-req: 4, #token: 1350, token usage: 0.00, gen throughput (token/s): 847.53, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:39:20 TP0] Decode batch. #running-req: 4, #token: 1510, token usage: 0.00, gen throughput (token/s): 861.26, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:39:20 TP0] Decode batch. #running-req: 4, #token: 1670, token usage: 0.00, gen throughput (token/s): 903.83, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:39:20 TP0] Decode batch. #running-req: 4, #token: 1830, token usage: 0.00, gen throughput (token/s): 861.37, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:39:21 TP0] Decode batch. #running-req: 4, #token: 1990, token usage: 0.00, gen throughput (token/s): 876.81, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:39:21 TP0] Decode batch. #running-req: 4, #token: 2150, token usage: 0.00, gen throughput (token/s): 896.92, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:39:21 TP0] Decode batch. #running-req: 4, #token: 2310, token usage: 0.00, gen throughput (token/s): 854.63, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:39:21 TP0] Decode batch. #running-req: 4, #token: 2470, token usage: 0.00, gen throughput (token/s): 889.58, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:39:21 TP0] Decode batch. #running-req: 4, #token: 2630, token usage: 0.00, gen throughput (token/s): 853.93, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:39:22 TP0] Decode batch. #running-req: 4, #token: 2790, token usage: 0.00, gen throughput (token/s): 839.36, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:39:22 TP0] Decode batch. #running-req: 4, #token: 2950, token usage: 0.00, gen throughput (token/s): 859.72, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:39:22 TP0] Decode batch. #running-req: 4, #token: 3110, token usage: 0.00, gen throughput (token/s): 858.96, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:39:22 TP0] Decode batch. #running-req: 4, #token: 3270, token usage: 0.00, gen throughput (token/s): 861.70, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:39:22 TP0] Decode batch. #running-req: 4, #token: 3430, token usage: 0.00, gen throughput (token/s): 879.44, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:39:23 TP0] Decode batch. #running-req: 4, #token: 3590, token usage: 0.00, gen throughput (token/s): 871.97, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:39:23 TP0] Decode batch. #running-req: 4, #token: 3750, token usage: 0.00, gen throughput (token/s): 875.46, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:39:23 TP0] Decode batch. #running-req: 4, #token: 3910, token usage: 0.00, gen throughput (token/s): 833.26, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:39:23 TP0] Decode batch. #running-req: 4, #token: 4070, token usage: 0.00, gen throughput (token/s): 839.45, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:39:23] INFO:     127.0.0.1:64666 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:39:23] INFO:     127.0.0.1:64650 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:39:23] INFO:     127.0.0.1:64652 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:39:23] INFO:     127.0.0.1:64656 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:39:23 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 109, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-08-25 15:39:23 TP0] Prefill batch. #new-seq: 3, #new-token: 3, #cached-token: 327, token usage: 0.00, #running-req: 1, #queue-req: 0, 
[2025-08-25 15:39:23 TP0] Decode batch. #running-req: 4, #token: 230, token usage: 0.00, gen throughput (token/s): 603.02, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:39:24 TP0] Decode batch. #running-req: 4, #token: 390, token usage: 0.00, gen throughput (token/s): 874.64, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:39:24 TP0] Decode batch. #running-req: 4, #token: 550, token usage: 0.00, gen throughput (token/s): 867.74, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:39:24 TP0] Decode batch. #running-req: 4, #token: 710, token usage: 0.00, gen throughput (token/s): 887.18, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:39:24 TP0] Decode batch. #running-req: 4, #token: 870, token usage: 0.00, gen throughput (token/s): 871.33, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:39:24 TP0] Decode batch. #running-req: 4, #token: 1030, token usage: 0.00, gen throughput (token/s): 890.56, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:39:24 TP0] Decode batch. #running-req: 4, #token: 1190, token usage: 0.00, gen throughput (token/s): 866.86, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:39:25 TP0] Decode batch. #running-req: 4, #token: 1350, token usage: 0.00, gen throughput (token/s): 852.81, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:39:25 TP0] Decode batch. #running-req: 4, #token: 1510, token usage: 0.00, gen throughput (token/s): 852.55, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:39:25 TP0] Decode batch. #running-req: 4, #token: 1670, token usage: 0.00, gen throughput (token/s): 878.56, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:39:25 TP0] Decode batch. #running-req: 4, #token: 1830, token usage: 0.00, gen throughput (token/s): 846.27, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:39:25 TP0] Decode batch. #running-req: 4, #token: 1990, token usage: 0.00, gen throughput (token/s): 852.22, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:39:26 TP0] Decode batch. #running-req: 4, #token: 2150, token usage: 0.00, gen throughput (token/s): 886.69, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:39:26 TP0] Decode batch. #running-req: 4, #token: 2310, token usage: 0.00, gen throughput (token/s): 861.53, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:39:26 TP0] Decode batch. #running-req: 4, #token: 2470, token usage: 0.00, gen throughput (token/s): 922.69, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:39:26 TP0] Decode batch. #running-req: 4, #token: 2630, token usage: 0.00, gen throughput (token/s): 874.56, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:39:26 TP0] Decode batch. #running-req: 4, #token: 2790, token usage: 0.00, gen throughput (token/s): 884.55, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:39:26 TP0] Decode batch. #running-req: 4, #token: 2950, token usage: 0.00, gen throughput (token/s): 889.14, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:39:27 TP0] Decode batch. #running-req: 4, #token: 3110, token usage: 0.00, gen throughput (token/s): 849.95, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:39:27 TP0] Decode batch. #running-req: 4, #token: 3270, token usage: 0.00, gen throughput (token/s): 878.44, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:39:27 TP0] Decode batch. #running-req: 4, #token: 3430, token usage: 0.00, gen throughput (token/s): 885.86, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:39:27 TP0] Decode batch. #running-req: 4, #token: 3590, token usage: 0.00, gen throughput (token/s): 861.24, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:39:27 TP0] Decode batch. #running-req: 4, #token: 3750, token usage: 0.00, gen throughput (token/s): 843.03, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:39:28 TP0] Decode batch. #running-req: 4, #token: 3910, token usage: 0.00, gen throughput (token/s): 827.40, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:39:28 TP0] Decode batch. #running-req: 4, #token: 4070, token usage: 0.00, gen throughput (token/s): 892.51, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:39:28] INFO:     127.0.0.1:64666 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:39:28] INFO:     127.0.0.1:64650 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:39:28] INFO:     127.0.0.1:64652 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:39:28] INFO:     127.0.0.1:64656 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:39:28 TP0] Prefill batch. #new-seq: 3, #new-token: 3165, #cached-token: 132, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-08-25 15:39:28 TP0] Prefill batch. #new-seq: 1, #new-token: 1055, #cached-token: 44, token usage: 0.08, #running-req: 3, #queue-req: 0, 
[2025-08-25 15:39:29] INFO:     127.0.0.1:28592 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 15:39:29] INFO:     127.0.0.1:28594 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 15:39:29] INFO:     127.0.0.1:28600 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 15:39:29 TP0] Prefill batch. #new-seq: 1, #new-token: 1000, #cached-token: 99, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-08-25 15:39:29 TP0] Prefill batch. #new-seq: 1, #new-token: 1000, #cached-token: 99, token usage: 0.03, #running-req: 1, #queue-req: 0, 
[2025-08-25 15:39:29] INFO:     127.0.0.1:28612 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 15:39:30 TP0] Prefill batch. #new-seq: 2, #new-token: 2000, #cached-token: 198, token usage: 0.03, #running-req: 2, #queue-req: 0, 
[2025-08-25 15:39:30] INFO:     127.0.0.1:28592 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 15:39:30] INFO:     127.0.0.1:28594 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 15:39:31 TP0] Prefill batch. #new-seq: 2, #new-token: 2000, #cached-token: 198, token usage: 0.00, #running-req: 2, #queue-req: 0, 
[2025-08-25 15:39:31] INFO:     127.0.0.1:28600 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 15:39:31] INFO:     127.0.0.1:28612 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 15:39:31 TP0] Prefill batch. #new-seq: 2, #new-token: 2000, #cached-token: 198, token usage: 0.05, #running-req: 4, #queue-req: 0, 
[2025-08-25 15:39:31] INFO:     127.0.0.1:28592 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 15:39:31] INFO:     127.0.0.1:28594 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 15:39:32 TP0] Prefill batch. #new-seq: 2, #new-token: 2000, #cached-token: 198, token usage: 0.00, #running-req: 2, #queue-req: 0, 
[2025-08-25 15:39:32] INFO:     127.0.0.1:28600 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 15:39:32] INFO:     127.0.0.1:28612 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 15:39:33 TP0] Prefill batch. #new-seq: 2, #new-token: 2000, #cached-token: 198, token usage: 0.05, #running-req: 4, #queue-req: 0, 
[2025-08-25 15:39:33] INFO:     127.0.0.1:28592 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 15:39:33] INFO:     127.0.0.1:28594 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 15:39:33] INFO:     127.0.0.1:28600 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 15:39:33] INFO:     127.0.0.1:28612 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 15:39:33 TP0] Prefill batch. #new-seq: 3, #new-token: 3, #cached-token: 405, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-08-25 15:39:33 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 135, token usage: 0.00, #running-req: 3, #queue-req: 0, 
[2025-08-25 15:39:33 TP0] Decode batch. #running-req: 4, #token: 256, token usage: 0.00, gen throughput (token/s): 28.05, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:39:34 TP0] Decode batch. #running-req: 4, #token: 416, token usage: 0.00, gen throughput (token/s): 867.64, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:39:34 TP0] Decode batch. #running-req: 4, #token: 576, token usage: 0.00, gen throughput (token/s): 861.31, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:39:34 TP0] Decode batch. #running-req: 4, #token: 736, token usage: 0.00, gen throughput (token/s): 849.86, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:39:34 TP0] Decode batch. #running-req: 4, #token: 896, token usage: 0.00, gen throughput (token/s): 884.48, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:39:34 TP0] Decode batch. #running-req: 4, #token: 1056, token usage: 0.00, gen throughput (token/s): 847.03, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:39:35 TP0] Decode batch. #running-req: 4, #token: 1216, token usage: 0.00, gen throughput (token/s): 870.86, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:39:35 TP0] Decode batch. #running-req: 4, #token: 1376, token usage: 0.00, gen throughput (token/s): 874.76, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:39:35 TP0] Decode batch. #running-req: 4, #token: 1536, token usage: 0.00, gen throughput (token/s): 873.51, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:39:35 TP0] Decode batch. #running-req: 4, #token: 1696, token usage: 0.00, gen throughput (token/s): 870.16, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:39:35 TP0] Decode batch. #running-req: 4, #token: 1856, token usage: 0.00, gen throughput (token/s): 875.78, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:39:35 TP0] Decode batch. #running-req: 4, #token: 2016, token usage: 0.00, gen throughput (token/s): 872.90, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:39:36 TP0] Decode batch. #running-req: 4, #token: 2176, token usage: 0.00, gen throughput (token/s): 863.53, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:39:36 TP0] Decode batch. #running-req: 4, #token: 2336, token usage: 0.00, gen throughput (token/s): 843.74, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:39:36 TP0] Decode batch. #running-req: 4, #token: 2496, token usage: 0.00, gen throughput (token/s): 927.52, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:39:36 TP0] Decode batch. #running-req: 4, #token: 2656, token usage: 0.00, gen throughput (token/s): 910.99, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:39:36 TP0] Decode batch. #running-req: 4, #token: 2816, token usage: 0.00, gen throughput (token/s): 906.87, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:39:37 TP0] Decode batch. #running-req: 4, #token: 2976, token usage: 0.00, gen throughput (token/s): 913.78, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:39:37 TP0] Decode batch. #running-req: 4, #token: 3136, token usage: 0.00, gen throughput (token/s): 894.70, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:39:37 TP0] Decode batch. #running-req: 4, #token: 3296, token usage: 0.00, gen throughput (token/s): 881.70, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:39:37 TP0] Decode batch. #running-req: 4, #token: 3456, token usage: 0.00, gen throughput (token/s): 891.23, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:39:37 TP0] Decode batch. #running-req: 4, #token: 3616, token usage: 0.00, gen throughput (token/s): 912.90, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:39:37 TP0] Decode batch. #running-req: 4, #token: 3776, token usage: 0.00, gen throughput (token/s): 903.73, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:39:38 TP0] Decode batch. #running-req: 4, #token: 3936, token usage: 0.00, gen throughput (token/s): 913.29, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:39:38 TP0] Decode batch. #running-req: 4, #token: 4096, token usage: 0.00, gen throughput (token/s): 922.30, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:39:38] INFO:     127.0.0.1:26628 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:39:38] INFO:     127.0.0.1:26632 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:39:38] INFO:     127.0.0.1:26642 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:39:38] INFO:     127.0.0.1:26658 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:39:38 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 135, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-08-25 15:39:38 TP0] Prefill batch. #new-seq: 3, #new-token: 3, #cached-token: 405, token usage: 0.00, #running-req: 1, #queue-req: 0, 
[2025-08-25 15:39:38 TP0] Decode batch. #running-req: 4, #token: 256, token usage: 0.00, gen throughput (token/s): 578.43, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:39:38 TP0] Decode batch. #running-req: 4, #token: 416, token usage: 0.00, gen throughput (token/s): 883.58, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:39:38 TP0] Decode batch. #running-req: 4, #token: 576, token usage: 0.00, gen throughput (token/s): 887.18, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:39:39 TP0] Decode batch. #running-req: 4, #token: 736, token usage: 0.00, gen throughput (token/s): 870.55, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:39:39 TP0] Decode batch. #running-req: 4, #token: 896, token usage: 0.00, gen throughput (token/s): 881.61, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:39:39 TP0] Decode batch. #running-req: 4, #token: 1056, token usage: 0.00, gen throughput (token/s): 883.50, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:39:39 TP0] Decode batch. #running-req: 4, #token: 1216, token usage: 0.00, gen throughput (token/s): 875.88, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:39:39 TP0] Decode batch. #running-req: 4, #token: 1376, token usage: 0.00, gen throughput (token/s): 838.73, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:39:40 TP0] Decode batch. #running-req: 4, #token: 1536, token usage: 0.00, gen throughput (token/s): 839.25, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:39:40 TP0] Decode batch. #running-req: 4, #token: 1696, token usage: 0.00, gen throughput (token/s): 864.43, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:39:40 TP0] Decode batch. #running-req: 4, #token: 1856, token usage: 0.00, gen throughput (token/s): 841.25, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:39:40 TP0] Decode batch. #running-req: 4, #token: 2016, token usage: 0.00, gen throughput (token/s): 850.56, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:39:40 TP0] Decode batch. #running-req: 4, #token: 2176, token usage: 0.00, gen throughput (token/s): 869.67, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:39:40 TP0] Decode batch. #running-req: 4, #token: 2336, token usage: 0.00, gen throughput (token/s): 867.78, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:39:41 TP0] Decode batch. #running-req: 4, #token: 2496, token usage: 0.00, gen throughput (token/s): 881.21, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:39:41 TP0] Decode batch. #running-req: 4, #token: 2656, token usage: 0.00, gen throughput (token/s): 870.06, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:39:41 TP0] Decode batch. #running-req: 4, #token: 2816, token usage: 0.00, gen throughput (token/s): 877.80, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:39:41 TP0] Decode batch. #running-req: 4, #token: 2976, token usage: 0.00, gen throughput (token/s): 864.13, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:39:41 TP0] Decode batch. #running-req: 4, #token: 3136, token usage: 0.00, gen throughput (token/s): 866.61, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:39:42 TP0] Decode batch. #running-req: 4, #token: 3296, token usage: 0.00, gen throughput (token/s): 893.36, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:39:42 TP0] Decode batch. #running-req: 4, #token: 3456, token usage: 0.00, gen throughput (token/s): 866.85, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:39:42 TP0] Decode batch. #running-req: 4, #token: 3616, token usage: 0.00, gen throughput (token/s): 864.19, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:39:42 TP0] Decode batch. #running-req: 4, #token: 3776, token usage: 0.00, gen throughput (token/s): 873.30, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:39:42 TP0] Decode batch. #running-req: 4, #token: 3936, token usage: 0.00, gen throughput (token/s): 858.46, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:39:42 TP0] Decode batch. #running-req: 4, #token: 4096, token usage: 0.00, gen throughput (token/s): 870.63, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:39:43] INFO:     127.0.0.1:26658 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:39:43] INFO:     127.0.0.1:26628 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:39:43] INFO:     127.0.0.1:26632 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:39:43] INFO:     127.0.0.1:26642 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:39:43 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 135, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-08-25 15:39:43 TP0] Prefill batch. #new-seq: 3, #new-token: 3, #cached-token: 405, token usage: 0.00, #running-req: 1, #queue-req: 0, 
[2025-08-25 15:39:43 TP0] Decode batch. #running-req: 4, #token: 256, token usage: 0.00, gen throughput (token/s): 588.21, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:39:43 TP0] Decode batch. #running-req: 4, #token: 416, token usage: 0.00, gen throughput (token/s): 881.99, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:39:43 TP0] Decode batch. #running-req: 4, #token: 576, token usage: 0.00, gen throughput (token/s): 888.27, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:39:43 TP0] Decode batch. #running-req: 4, #token: 736, token usage: 0.00, gen throughput (token/s): 883.74, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:39:43 TP0] Decode batch. #running-req: 4, #token: 896, token usage: 0.00, gen throughput (token/s): 882.02, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:39:44 TP0] Decode batch. #running-req: 4, #token: 1056, token usage: 0.00, gen throughput (token/s): 864.47, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:39:44 TP0] Decode batch. #running-req: 4, #token: 1216, token usage: 0.00, gen throughput (token/s): 869.04, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:39:44 TP0] Decode batch. #running-req: 4, #token: 1376, token usage: 0.00, gen throughput (token/s): 851.34, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:39:44 TP0] Decode batch. #running-req: 4, #token: 1536, token usage: 0.00, gen throughput (token/s): 882.56, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:39:44 TP0] Decode batch. #running-req: 4, #token: 1696, token usage: 0.00, gen throughput (token/s): 858.42, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:39:45 TP0] Decode batch. #running-req: 4, #token: 1856, token usage: 0.00, gen throughput (token/s): 882.36, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:39:45 TP0] Decode batch. #running-req: 4, #token: 2016, token usage: 0.00, gen throughput (token/s): 849.80, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:39:45 TP0] Decode batch. #running-req: 4, #token: 2176, token usage: 0.00, gen throughput (token/s): 886.23, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:39:45 TP0] Decode batch. #running-req: 4, #token: 2336, token usage: 0.00, gen throughput (token/s): 848.97, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:39:45 TP0] Decode batch. #running-req: 4, #token: 2496, token usage: 0.00, gen throughput (token/s): 893.71, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:39:46 TP0] Decode batch. #running-req: 4, #token: 2656, token usage: 0.00, gen throughput (token/s): 866.57, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:39:46 TP0] Decode batch. #running-req: 4, #token: 2816, token usage: 0.00, gen throughput (token/s): 857.66, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:39:46 TP0] Decode batch. #running-req: 4, #token: 2976, token usage: 0.00, gen throughput (token/s): 888.83, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:39:46 TP0] Decode batch. #running-req: 4, #token: 3136, token usage: 0.00, gen throughput (token/s): 878.58, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:39:46 TP0] Decode batch. #running-req: 4, #token: 3296, token usage: 0.00, gen throughput (token/s): 875.24, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:39:46 TP0] Decode batch. #running-req: 4, #token: 3456, token usage: 0.00, gen throughput (token/s): 889.84, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:39:47 TP0] Decode batch. #running-req: 4, #token: 3616, token usage: 0.00, gen throughput (token/s): 881.05, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:39:47 TP0] Decode batch. #running-req: 4, #token: 3776, token usage: 0.00, gen throughput (token/s): 902.06, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:39:47 TP0] Decode batch. #running-req: 4, #token: 3936, token usage: 0.00, gen throughput (token/s): 889.83, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:39:47 TP0] Decode batch. #running-req: 4, #token: 4096, token usage: 0.00, gen throughput (token/s): 870.90, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:39:47] INFO:     127.0.0.1:26658 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:39:47] INFO:     127.0.0.1:26628 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:39:47] INFO:     127.0.0.1:26632 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:39:47] INFO:     127.0.0.1:26642 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:39:47 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 135, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-08-25 15:39:47 TP0] Prefill batch. #new-seq: 3, #new-token: 3, #cached-token: 405, token usage: 0.00, #running-req: 1, #queue-req: 0, 
[2025-08-25 15:39:47 TP0] Decode batch. #running-req: 4, #token: 256, token usage: 0.00, gen throughput (token/s): 596.97, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:39:48 TP0] Decode batch. #running-req: 4, #token: 416, token usage: 0.00, gen throughput (token/s): 923.74, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:39:48 TP0] Decode batch. #running-req: 4, #token: 576, token usage: 0.00, gen throughput (token/s): 938.70, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:39:48 TP0] Decode batch. #running-req: 4, #token: 736, token usage: 0.00, gen throughput (token/s): 924.18, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:39:48 TP0] Decode batch. #running-req: 4, #token: 896, token usage: 0.00, gen throughput (token/s): 924.78, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:39:48 TP0] Decode batch. #running-req: 4, #token: 1056, token usage: 0.00, gen throughput (token/s): 906.43, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:39:48 TP0] Decode batch. #running-req: 4, #token: 1216, token usage: 0.00, gen throughput (token/s): 917.06, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:39:49 TP0] Decode batch. #running-req: 4, #token: 1376, token usage: 0.00, gen throughput (token/s): 898.00, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:39:49 TP0] Decode batch. #running-req: 4, #token: 1536, token usage: 0.00, gen throughput (token/s): 888.72, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:39:49 TP0] Decode batch. #running-req: 4, #token: 1696, token usage: 0.00, gen throughput (token/s): 895.50, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:39:49 TP0] Decode batch. #running-req: 4, #token: 1856, token usage: 0.00, gen throughput (token/s): 861.09, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:39:49 TP0] Decode batch. #running-req: 4, #token: 2016, token usage: 0.00, gen throughput (token/s): 831.13, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:39:50 TP0] Decode batch. #running-req: 4, #token: 2176, token usage: 0.00, gen throughput (token/s): 889.18, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:39:50 TP0] Decode batch. #running-req: 4, #token: 2336, token usage: 0.00, gen throughput (token/s): 849.07, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:39:50 TP0] Decode batch. #running-req: 4, #token: 2496, token usage: 0.00, gen throughput (token/s): 875.88, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:39:50 TP0] Decode batch. #running-req: 4, #token: 2656, token usage: 0.00, gen throughput (token/s): 873.34, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:39:50 TP0] Decode batch. #running-req: 4, #token: 2816, token usage: 0.00, gen throughput (token/s): 863.18, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:39:50 TP0] Decode batch. #running-req: 4, #token: 2976, token usage: 0.00, gen throughput (token/s): 864.59, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:39:51 TP0] Decode batch. #running-req: 4, #token: 3136, token usage: 0.00, gen throughput (token/s): 864.29, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:39:51 TP0] Decode batch. #running-req: 4, #token: 3296, token usage: 0.00, gen throughput (token/s): 860.45, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:39:51 TP0] Decode batch. #running-req: 4, #token: 3456, token usage: 0.00, gen throughput (token/s): 862.44, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:39:51 TP0] Decode batch. #running-req: 4, #token: 3616, token usage: 0.00, gen throughput (token/s): 852.40, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:39:51 TP0] Decode batch. #running-req: 4, #token: 3776, token usage: 0.00, gen throughput (token/s): 844.72, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:39:52 TP0] Decode batch. #running-req: 4, #token: 3936, token usage: 0.00, gen throughput (token/s): 829.38, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:39:52 TP0] Decode batch. #running-req: 4, #token: 4096, token usage: 0.00, gen throughput (token/s): 891.18, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:39:52] INFO:     127.0.0.1:26658 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:39:52] INFO:     127.0.0.1:26628 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:39:52] INFO:     127.0.0.1:26632 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:39:52] INFO:     127.0.0.1:26642 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:39:52 TP0] Prefill batch. #new-seq: 1, #new-token: 1083, #cached-token: 42, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-08-25 15:39:52 TP0] Prefill batch. #new-seq: 3, #new-token: 3249, #cached-token: 126, token usage: 0.03, #running-req: 1, #queue-req: 0, 
[2025-08-25 15:39:53] INFO:     127.0.0.1:30294 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 15:39:53] INFO:     127.0.0.1:30300 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 15:39:53] INFO:     127.0.0.1:30310 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 15:39:53] INFO:     127.0.0.1:30326 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 15:39:53 TP0] Prefill batch. #new-seq: 1, #new-token: 1000, #cached-token: 125, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-08-25 15:39:53 TP0] Prefill batch. #new-seq: 3, #new-token: 3000, #cached-token: 375, token usage: 0.03, #running-req: 1, #queue-req: 0, 
[2025-08-25 15:39:55] INFO:     127.0.0.1:30294 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 15:39:55 TP0] Prefill batch. #new-seq: 1, #new-token: 1000, #cached-token: 125, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-08-25 15:39:55] INFO:     127.0.0.1:30300 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 15:39:55] INFO:     127.0.0.1:30310 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 15:39:55] INFO:     127.0.0.1:30326 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 15:39:55 TP0] Prefill batch. #new-seq: 3, #new-token: 3000, #cached-token: 375, token usage: 0.00, #running-req: 1, #queue-req: 0, 
[2025-08-25 15:39:55] INFO:     127.0.0.1:30294 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 15:39:56 TP0] Prefill batch. #new-seq: 1, #new-token: 1000, #cached-token: 125, token usage: 0.00, #running-req: 3, #queue-req: 0, 
[2025-08-25 15:39:56] INFO:     127.0.0.1:30300 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 15:39:56] INFO:     127.0.0.1:30310 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 15:39:56] INFO:     127.0.0.1:30326 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 15:39:56 TP0] Prefill batch. #new-seq: 3, #new-token: 3000, #cached-token: 375, token usage: 0.03, #running-req: 4, #queue-req: 0, 
[2025-08-25 15:39:56] INFO:     127.0.0.1:30294 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 15:39:57] INFO:     127.0.0.1:30300 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 15:39:57] INFO:     127.0.0.1:30310 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 15:39:57] INFO:     127.0.0.1:30326 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 15:39:57 TP0] Prefill batch. #new-seq: 3, #new-token: 3, #cached-token: 402, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-08-25 15:39:58 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 134, token usage: 0.00, #running-req: 3, #queue-req: 0, 
[2025-08-25 15:39:58 TP0] Decode batch. #running-req: 4, #token: 255, token usage: 0.00, gen throughput (token/s): 27.13, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:39:58 TP0] Decode batch. #running-req: 4, #token: 415, token usage: 0.00, gen throughput (token/s): 869.67, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:39:58 TP0] Decode batch. #running-req: 4, #token: 575, token usage: 0.00, gen throughput (token/s): 883.47, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:39:58 TP0] Decode batch. #running-req: 4, #token: 735, token usage: 0.00, gen throughput (token/s): 887.64, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:39:58 TP0] Decode batch. #running-req: 4, #token: 895, token usage: 0.00, gen throughput (token/s): 880.63, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:39:59 TP0] Decode batch. #running-req: 4, #token: 1055, token usage: 0.00, gen throughput (token/s): 849.19, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:39:59 TP0] Decode batch. #running-req: 4, #token: 1215, token usage: 0.00, gen throughput (token/s): 855.81, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:39:59 TP0] Decode batch. #running-req: 4, #token: 1375, token usage: 0.00, gen throughput (token/s): 887.01, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:39:59 TP0] Decode batch. #running-req: 4, #token: 1535, token usage: 0.00, gen throughput (token/s): 859.75, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:39:59 TP0] Decode batch. #running-req: 4, #token: 1695, token usage: 0.00, gen throughput (token/s): 857.95, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:40:00 TP0] Decode batch. #running-req: 4, #token: 1855, token usage: 0.00, gen throughput (token/s): 847.44, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:40:00 TP0] Decode batch. #running-req: 4, #token: 2015, token usage: 0.00, gen throughput (token/s): 852.13, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:40:00 TP0] Decode batch. #running-req: 4, #token: 2175, token usage: 0.00, gen throughput (token/s): 866.81, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:40:00 TP0] Decode batch. #running-req: 4, #token: 2335, token usage: 0.00, gen throughput (token/s): 841.98, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:40:00 TP0] Decode batch. #running-req: 4, #token: 2495, token usage: 0.00, gen throughput (token/s): 871.61, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:40:00 TP0] Decode batch. #running-req: 4, #token: 2655, token usage: 0.00, gen throughput (token/s): 867.95, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:40:01 TP0] Decode batch. #running-req: 4, #token: 2815, token usage: 0.00, gen throughput (token/s): 882.83, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:40:01 TP0] Decode batch. #running-req: 4, #token: 2975, token usage: 0.00, gen throughput (token/s): 872.03, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:40:01 TP0] Decode batch. #running-req: 4, #token: 3135, token usage: 0.00, gen throughput (token/s): 858.97, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:40:01 TP0] Decode batch. #running-req: 4, #token: 3295, token usage: 0.00, gen throughput (token/s): 884.79, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:40:01 TP0] Decode batch. #running-req: 4, #token: 3455, token usage: 0.00, gen throughput (token/s): 841.15, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:40:02 TP0] Decode batch. #running-req: 4, #token: 3615, token usage: 0.00, gen throughput (token/s): 847.39, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:40:02 TP0] Decode batch. #running-req: 4, #token: 3775, token usage: 0.00, gen throughput (token/s): 849.55, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:40:02 TP0] Decode batch. #running-req: 4, #token: 3935, token usage: 0.00, gen throughput (token/s): 826.46, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:40:02 TP0] Decode batch. #running-req: 4, #token: 4095, token usage: 0.00, gen throughput (token/s): 892.36, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:40:02] INFO:     127.0.0.1:53328 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:40:02] INFO:     127.0.0.1:53332 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:40:02] INFO:     127.0.0.1:53334 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:40:02] INFO:     127.0.0.1:53342 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:40:02 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 134, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-08-25 15:40:02 TP0] Prefill batch. #new-seq: 3, #new-token: 3, #cached-token: 402, token usage: 0.00, #running-req: 1, #queue-req: 0, 
[2025-08-25 15:40:02 TP0] Decode batch. #running-req: 4, #token: 255, token usage: 0.00, gen throughput (token/s): 557.06, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:40:03 TP0] Decode batch. #running-req: 4, #token: 415, token usage: 0.00, gen throughput (token/s): 864.08, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:40:03 TP0] Decode batch. #running-req: 4, #token: 575, token usage: 0.00, gen throughput (token/s): 859.22, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:40:03 TP0] Decode batch. #running-req: 4, #token: 735, token usage: 0.00, gen throughput (token/s): 887.94, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:40:03 TP0] Decode batch. #running-req: 4, #token: 895, token usage: 0.00, gen throughput (token/s): 881.23, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:40:03 TP0] Decode batch. #running-req: 4, #token: 1055, token usage: 0.00, gen throughput (token/s): 849.65, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:40:04 TP0] Decode batch. #running-req: 4, #token: 1215, token usage: 0.00, gen throughput (token/s): 908.94, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:40:04 TP0] Decode batch. #running-req: 4, #token: 1375, token usage: 0.00, gen throughput (token/s): 905.58, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:40:04 TP0] Decode batch. #running-req: 4, #token: 1535, token usage: 0.00, gen throughput (token/s): 902.83, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:40:04 TP0] Decode batch. #running-req: 4, #token: 1695, token usage: 0.00, gen throughput (token/s): 888.04, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:40:04 TP0] Decode batch. #running-req: 4, #token: 1855, token usage: 0.00, gen throughput (token/s): 900.95, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:40:04 TP0] Decode batch. #running-req: 4, #token: 2015, token usage: 0.00, gen throughput (token/s): 903.09, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:40:05 TP0] Decode batch. #running-req: 4, #token: 2175, token usage: 0.00, gen throughput (token/s): 927.75, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:40:05 TP0] Decode batch. #running-req: 4, #token: 2335, token usage: 0.00, gen throughput (token/s): 931.96, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:40:05 TP0] Decode batch. #running-req: 4, #token: 2495, token usage: 0.00, gen throughput (token/s): 926.16, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:40:05 TP0] Decode batch. #running-req: 4, #token: 2655, token usage: 0.00, gen throughput (token/s): 933.70, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:40:05 TP0] Decode batch. #running-req: 4, #token: 2815, token usage: 0.00, gen throughput (token/s): 933.60, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:40:05 TP0] Decode batch. #running-req: 4, #token: 2975, token usage: 0.00, gen throughput (token/s): 915.88, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:40:06 TP0] Decode batch. #running-req: 4, #token: 3135, token usage: 0.00, gen throughput (token/s): 922.63, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:40:06 TP0] Decode batch. #running-req: 4, #token: 3295, token usage: 0.00, gen throughput (token/s): 928.45, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:40:06 TP0] Decode batch. #running-req: 4, #token: 3455, token usage: 0.00, gen throughput (token/s): 934.40, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:40:06 TP0] Decode batch. #running-req: 4, #token: 3615, token usage: 0.00, gen throughput (token/s): 901.96, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:40:06 TP0] Decode batch. #running-req: 4, #token: 3775, token usage: 0.00, gen throughput (token/s): 919.18, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:40:06 TP0] Decode batch. #running-req: 4, #token: 3935, token usage: 0.00, gen throughput (token/s): 898.34, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:40:07 TP0] Decode batch. #running-req: 4, #token: 4095, token usage: 0.00, gen throughput (token/s): 917.42, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:40:07] INFO:     127.0.0.1:53342 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:40:07] INFO:     127.0.0.1:53328 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:40:07] INFO:     127.0.0.1:53332 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:40:07] INFO:     127.0.0.1:53334 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:40:07 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 134, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-08-25 15:40:07 TP0] Prefill batch. #new-seq: 3, #new-token: 3, #cached-token: 402, token usage: 0.00, #running-req: 1, #queue-req: 0, 
[2025-08-25 15:40:07 TP0] Decode batch. #running-req: 4, #token: 255, token usage: 0.00, gen throughput (token/s): 605.34, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:40:07 TP0] Decode batch. #running-req: 4, #token: 415, token usage: 0.00, gen throughput (token/s): 854.47, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:40:07 TP0] Decode batch. #running-req: 4, #token: 575, token usage: 0.00, gen throughput (token/s): 902.45, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:40:07 TP0] Decode batch. #running-req: 4, #token: 735, token usage: 0.00, gen throughput (token/s): 911.45, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:40:08 TP0] Decode batch. #running-req: 4, #token: 895, token usage: 0.00, gen throughput (token/s): 906.24, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:40:08 TP0] Decode batch. #running-req: 4, #token: 1055, token usage: 0.00, gen throughput (token/s): 888.15, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:40:08 TP0] Decode batch. #running-req: 4, #token: 1215, token usage: 0.00, gen throughput (token/s): 900.62, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:40:08 TP0] Decode batch. #running-req: 4, #token: 1375, token usage: 0.00, gen throughput (token/s): 880.02, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:40:08 TP0] Decode batch. #running-req: 4, #token: 1535, token usage: 0.00, gen throughput (token/s): 870.74, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:40:09 TP0] Decode batch. #running-req: 4, #token: 1695, token usage: 0.00, gen throughput (token/s): 890.46, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:40:09 TP0] Decode batch. #running-req: 4, #token: 1855, token usage: 0.00, gen throughput (token/s): 853.57, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:40:09 TP0] Decode batch. #running-req: 4, #token: 2015, token usage: 0.00, gen throughput (token/s): 875.29, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:40:09 TP0] Decode batch. #running-req: 4, #token: 2175, token usage: 0.00, gen throughput (token/s): 881.88, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:40:09 TP0] Decode batch. #running-req: 4, #token: 2335, token usage: 0.00, gen throughput (token/s): 876.91, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:40:09 TP0] Decode batch. #running-req: 4, #token: 2495, token usage: 0.00, gen throughput (token/s): 873.93, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:40:10 TP0] Decode batch. #running-req: 4, #token: 2655, token usage: 0.00, gen throughput (token/s): 850.61, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:40:10 TP0] Decode batch. #running-req: 4, #token: 2815, token usage: 0.00, gen throughput (token/s): 878.76, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:40:10 TP0] Decode batch. #running-req: 4, #token: 2975, token usage: 0.00, gen throughput (token/s): 864.64, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:40:10 TP0] Decode batch. #running-req: 4, #token: 3135, token usage: 0.00, gen throughput (token/s): 881.92, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:40:10 TP0] Decode batch. #running-req: 4, #token: 3295, token usage: 0.00, gen throughput (token/s): 881.73, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:40:11 TP0] Decode batch. #running-req: 4, #token: 3455, token usage: 0.00, gen throughput (token/s): 861.72, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:40:11 TP0] Decode batch. #running-req: 4, #token: 3615, token usage: 0.00, gen throughput (token/s): 892.05, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:40:11 TP0] Decode batch. #running-req: 4, #token: 3775, token usage: 0.00, gen throughput (token/s): 873.72, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:40:11 TP0] Decode batch. #running-req: 4, #token: 3935, token usage: 0.00, gen throughput (token/s): 869.06, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:40:11 TP0] Decode batch. #running-req: 4, #token: 4095, token usage: 0.00, gen throughput (token/s): 884.09, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:40:11] INFO:     127.0.0.1:53342 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:40:11] INFO:     127.0.0.1:53328 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:40:11] INFO:     127.0.0.1:53332 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:40:11] INFO:     127.0.0.1:53334 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:40:11 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 134, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-08-25 15:40:11 TP0] Prefill batch. #new-seq: 3, #new-token: 3, #cached-token: 402, token usage: 0.00, #running-req: 1, #queue-req: 0, 
[2025-08-25 15:40:12 TP0] Decode batch. #running-req: 4, #token: 255, token usage: 0.00, gen throughput (token/s): 611.83, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:40:12 TP0] Decode batch. #running-req: 4, #token: 415, token usage: 0.00, gen throughput (token/s): 898.02, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:40:12 TP0] Decode batch. #running-req: 4, #token: 575, token usage: 0.00, gen throughput (token/s): 878.90, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:40:12 TP0] Decode batch. #running-req: 4, #token: 735, token usage: 0.00, gen throughput (token/s): 910.23, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:40:12 TP0] Decode batch. #running-req: 4, #token: 895, token usage: 0.00, gen throughput (token/s): 908.83, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:40:12 TP0] Decode batch. #running-req: 4, #token: 1055, token usage: 0.00, gen throughput (token/s): 916.36, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:40:13 TP0] Decode batch. #running-req: 4, #token: 1215, token usage: 0.00, gen throughput (token/s): 918.94, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:40:13 TP0] Decode batch. #running-req: 4, #token: 1375, token usage: 0.00, gen throughput (token/s): 907.59, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:40:13 TP0] Decode batch. #running-req: 4, #token: 1535, token usage: 0.00, gen throughput (token/s): 911.63, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:40:13 TP0] Decode batch. #running-req: 4, #token: 1695, token usage: 0.00, gen throughput (token/s): 902.05, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:40:13 TP0] Decode batch. #running-req: 4, #token: 1855, token usage: 0.00, gen throughput (token/s): 899.80, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:40:14 TP0] Decode batch. #running-req: 4, #token: 2015, token usage: 0.00, gen throughput (token/s): 850.62, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:40:14 TP0] Decode batch. #running-req: 4, #token: 2175, token usage: 0.00, gen throughput (token/s): 862.56, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:40:14 TP0] Decode batch. #running-req: 4, #token: 2335, token usage: 0.00, gen throughput (token/s): 853.99, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:40:14 TP0] Decode batch. #running-req: 4, #token: 2495, token usage: 0.00, gen throughput (token/s): 870.53, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:40:14 TP0] Decode batch. #running-req: 4, #token: 2655, token usage: 0.00, gen throughput (token/s): 881.22, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:40:14 TP0] Decode batch. #running-req: 4, #token: 2815, token usage: 0.00, gen throughput (token/s): 838.02, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:40:15 TP0] Decode batch. #running-req: 4, #token: 2975, token usage: 0.00, gen throughput (token/s): 866.65, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:40:15 TP0] Decode batch. #running-req: 4, #token: 3135, token usage: 0.00, gen throughput (token/s): 881.77, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:40:15 TP0] Decode batch. #running-req: 4, #token: 3295, token usage: 0.00, gen throughput (token/s): 866.61, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:40:15 TP0] Decode batch. #running-req: 4, #token: 3455, token usage: 0.00, gen throughput (token/s): 862.83, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:40:15 TP0] Decode batch. #running-req: 4, #token: 3615, token usage: 0.00, gen throughput (token/s): 873.16, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:40:16 TP0] Decode batch. #running-req: 4, #token: 3775, token usage: 0.00, gen throughput (token/s): 861.88, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:40:16 TP0] Decode batch. #running-req: 4, #token: 3935, token usage: 0.00, gen throughput (token/s): 859.14, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:40:16 TP0] Decode batch. #running-req: 4, #token: 4095, token usage: 0.00, gen throughput (token/s): 873.18, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:40:16] INFO:     127.0.0.1:53342 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:40:16] INFO:     127.0.0.1:53328 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:40:16] INFO:     127.0.0.1:53332 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:40:16] INFO:     127.0.0.1:53334 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:40:16 TP0] Prefill batch. #new-seq: 1, #new-token: 1082, #cached-token: 42, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-08-25 15:40:16 TP0] Prefill batch. #new-seq: 3, #new-token: 3246, #cached-token: 126, token usage: 0.03, #running-req: 1, #queue-req: 0, 
[2025-08-25 15:40:17] INFO:     127.0.0.1:18188 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 15:40:18 TP0] Prefill batch. #new-seq: 1, #new-token: 1000, #cached-token: 124, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-08-25 15:40:18] INFO:     127.0.0.1:18200 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 15:40:18] INFO:     127.0.0.1:18216 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 15:40:18] INFO:     127.0.0.1:18232 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 15:40:18 TP0] Prefill batch. #new-seq: 3, #new-token: 3000, #cached-token: 372, token usage: 0.00, #running-req: 1, #queue-req: 0, 
[2025-08-25 15:40:18] INFO:     127.0.0.1:18188 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 15:40:19 TP0] Prefill batch. #new-seq: 1, #new-token: 1000, #cached-token: 124, token usage: 0.00, #running-req: 3, #queue-req: 0, 
[2025-08-25 15:40:19] INFO:     127.0.0.1:18200 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 15:40:19] INFO:     127.0.0.1:18216 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 15:40:19] INFO:     127.0.0.1:18232 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 15:40:20 TP0] Prefill batch. #new-seq: 3, #new-token: 3000, #cached-token: 372, token usage: 0.03, #running-req: 4, #queue-req: 0, 
[2025-08-25 15:40:20] INFO:     127.0.0.1:18188 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 15:40:21 TP0] Prefill batch. #new-seq: 1, #new-token: 1000, #cached-token: 124, token usage: 0.00, #running-req: 3, #queue-req: 0, 
[2025-08-25 15:40:21] INFO:     127.0.0.1:18200 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 15:40:21] INFO:     127.0.0.1:18216 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 15:40:21] INFO:     127.0.0.1:18232 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 15:40:21 TP0] Prefill batch. #new-seq: 3, #new-token: 3000, #cached-token: 372, token usage: 0.03, #running-req: 4, #queue-req: 0, 
[2025-08-25 15:40:21] INFO:     127.0.0.1:18188 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 15:40:22] INFO:     127.0.0.1:18200 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 15:40:22] INFO:     127.0.0.1:18216 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 15:40:22] INFO:     127.0.0.1:18232 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 15:40:22 TP0] Prefill batch. #new-seq: 4, #new-token: 4, #cached-token: 784, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-08-25 15:40:22 TP0] Decode batch. #running-req: 4, #token: 317, token usage: 0.00, gen throughput (token/s): 25.35, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:40:22 TP0] Decode batch. #running-req: 4, #token: 477, token usage: 0.00, gen throughput (token/s): 880.31, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:40:23 TP0] Decode batch. #running-req: 4, #token: 637, token usage: 0.00, gen throughput (token/s): 885.83, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:40:23 TP0] Decode batch. #running-req: 4, #token: 797, token usage: 0.00, gen throughput (token/s): 853.32, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:40:23 TP0] Decode batch. #running-req: 4, #token: 957, token usage: 0.00, gen throughput (token/s): 872.04, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:40:23 TP0] Decode batch. #running-req: 4, #token: 1117, token usage: 0.00, gen throughput (token/s): 875.43, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:40:23 TP0] Decode batch. #running-req: 4, #token: 1277, token usage: 0.00, gen throughput (token/s): 872.78, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:40:24 TP0] Decode batch. #running-req: 4, #token: 1437, token usage: 0.00, gen throughput (token/s): 870.97, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:40:24 TP0] Decode batch. #running-req: 4, #token: 1597, token usage: 0.00, gen throughput (token/s): 870.40, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:40:24 TP0] Decode batch. #running-req: 4, #token: 1757, token usage: 0.00, gen throughput (token/s): 892.07, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:40:24 TP0] Decode batch. #running-req: 4, #token: 1917, token usage: 0.00, gen throughput (token/s): 825.56, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:40:24 TP0] Decode batch. #running-req: 4, #token: 2077, token usage: 0.00, gen throughput (token/s): 849.64, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:40:24 TP0] Decode batch. #running-req: 4, #token: 2237, token usage: 0.00, gen throughput (token/s): 851.85, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:40:25 TP0] Decode batch. #running-req: 4, #token: 2397, token usage: 0.00, gen throughput (token/s): 847.10, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:40:25 TP0] Decode batch. #running-req: 4, #token: 2557, token usage: 0.00, gen throughput (token/s): 855.70, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:40:25 TP0] Decode batch. #running-req: 4, #token: 2717, token usage: 0.00, gen throughput (token/s): 850.52, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:40:25 TP0] Decode batch. #running-req: 4, #token: 2877, token usage: 0.00, gen throughput (token/s): 829.96, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:40:25 TP0] Decode batch. #running-req: 4, #token: 3037, token usage: 0.00, gen throughput (token/s): 851.80, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:40:26 TP0] Decode batch. #running-req: 4, #token: 3197, token usage: 0.00, gen throughput (token/s): 880.91, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:40:26 TP0] Decode batch. #running-req: 4, #token: 3357, token usage: 0.00, gen throughput (token/s): 900.49, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:40:26 TP0] Decode batch. #running-req: 4, #token: 3517, token usage: 0.00, gen throughput (token/s): 881.47, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:40:26 TP0] Decode batch. #running-req: 4, #token: 3677, token usage: 0.00, gen throughput (token/s): 888.78, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:40:26 TP0] Decode batch. #running-req: 4, #token: 3837, token usage: 0.00, gen throughput (token/s): 879.04, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:40:26 TP0] Decode batch. #running-req: 4, #token: 3997, token usage: 0.00, gen throughput (token/s): 873.69, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:40:27 TP0] Decode batch. #running-req: 4, #token: 4157, token usage: 0.00, gen throughput (token/s): 880.21, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:40:27] INFO:     127.0.0.1:7126 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:40:27] INFO:     127.0.0.1:7130 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:40:27] INFO:     127.0.0.1:7132 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:40:27] INFO:     127.0.0.1:7142 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:40:27 TP0] Prefill batch. #new-seq: 3, #new-token: 3, #cached-token: 588, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-08-25 15:40:27 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 196, token usage: 0.00, #running-req: 3, #queue-req: 0, 
[2025-08-25 15:40:27 TP0] Decode batch. #running-req: 4, #token: 317, token usage: 0.00, gen throughput (token/s): 576.44, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:40:27 TP0] Decode batch. #running-req: 4, #token: 477, token usage: 0.00, gen throughput (token/s): 899.14, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:40:27 TP0] Decode batch. #running-req: 4, #token: 637, token usage: 0.00, gen throughput (token/s): 888.01, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:40:27 TP0] Decode batch. #running-req: 4, #token: 797, token usage: 0.00, gen throughput (token/s): 885.66, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:40:28 TP0] Decode batch. #running-req: 4, #token: 957, token usage: 0.00, gen throughput (token/s): 900.39, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:40:28 TP0] Decode batch. #running-req: 4, #token: 1117, token usage: 0.00, gen throughput (token/s): 888.09, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:40:28 TP0] Decode batch. #running-req: 4, #token: 1277, token usage: 0.00, gen throughput (token/s): 906.55, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:40:28 TP0] Decode batch. #running-req: 4, #token: 1437, token usage: 0.00, gen throughput (token/s): 896.70, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:40:28 TP0] Decode batch. #running-req: 4, #token: 1597, token usage: 0.00, gen throughput (token/s): 884.84, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:40:29 TP0] Decode batch. #running-req: 4, #token: 1757, token usage: 0.00, gen throughput (token/s): 885.26, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:40:29 TP0] Decode batch. #running-req: 4, #token: 1917, token usage: 0.00, gen throughput (token/s): 889.50, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:40:29 TP0] Decode batch. #running-req: 4, #token: 2077, token usage: 0.00, gen throughput (token/s): 900.91, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:40:29 TP0] Decode batch. #running-req: 4, #token: 2237, token usage: 0.00, gen throughput (token/s): 881.50, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:40:29 TP0] Decode batch. #running-req: 4, #token: 2397, token usage: 0.00, gen throughput (token/s): 889.41, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:40:29 TP0] Decode batch. #running-req: 4, #token: 2557, token usage: 0.00, gen throughput (token/s): 889.56, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:40:30 TP0] Decode batch. #running-req: 4, #token: 2717, token usage: 0.00, gen throughput (token/s): 869.69, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:40:30 TP0] Decode batch. #running-req: 4, #token: 2877, token usage: 0.00, gen throughput (token/s): 839.14, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:40:30 TP0] Decode batch. #running-req: 4, #token: 3037, token usage: 0.00, gen throughput (token/s): 843.72, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:40:30 TP0] Decode batch. #running-req: 4, #token: 3197, token usage: 0.00, gen throughput (token/s): 850.24, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:40:30 TP0] Decode batch. #running-req: 4, #token: 3357, token usage: 0.00, gen throughput (token/s): 853.02, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:40:31 TP0] Decode batch. #running-req: 4, #token: 3517, token usage: 0.00, gen throughput (token/s): 857.41, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:40:31 TP0] Decode batch. #running-req: 4, #token: 3677, token usage: 0.00, gen throughput (token/s): 848.41, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:40:31 TP0] Decode batch. #running-req: 4, #token: 3837, token usage: 0.00, gen throughput (token/s): 854.07, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:40:31 TP0] Decode batch. #running-req: 4, #token: 3997, token usage: 0.00, gen throughput (token/s): 855.08, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:40:31 TP0] Decode batch. #running-req: 4, #token: 4157, token usage: 0.00, gen throughput (token/s): 854.02, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:40:31] INFO:     127.0.0.1:7142 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:40:31] INFO:     127.0.0.1:7126 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:40:31] INFO:     127.0.0.1:7130 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:40:31] INFO:     127.0.0.1:7132 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:40:31 TP0] Prefill batch. #new-seq: 4, #new-token: 4, #cached-token: 784, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-08-25 15:40:32 TP0] Decode batch. #running-req: 4, #token: 317, token usage: 0.00, gen throughput (token/s): 666.36, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:40:32 TP0] Decode batch. #running-req: 4, #token: 477, token usage: 0.00, gen throughput (token/s): 878.75, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:40:32 TP0] Decode batch. #running-req: 4, #token: 637, token usage: 0.00, gen throughput (token/s): 852.42, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:40:32 TP0] Decode batch. #running-req: 4, #token: 797, token usage: 0.00, gen throughput (token/s): 853.40, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:40:32 TP0] Decode batch. #running-req: 4, #token: 957, token usage: 0.00, gen throughput (token/s): 887.54, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:40:32 TP0] Decode batch. #running-req: 4, #token: 1117, token usage: 0.00, gen throughput (token/s): 857.59, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:40:33 TP0] Decode batch. #running-req: 4, #token: 1277, token usage: 0.00, gen throughput (token/s): 841.08, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:40:33 TP0] Decode batch. #running-req: 4, #token: 1437, token usage: 0.00, gen throughput (token/s): 890.95, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:40:33 TP0] Decode batch. #running-req: 4, #token: 1597, token usage: 0.00, gen throughput (token/s): 899.17, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:40:33 TP0] Decode batch. #running-req: 4, #token: 1757, token usage: 0.00, gen throughput (token/s): 893.19, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:40:33 TP0] Decode batch. #running-req: 4, #token: 1917, token usage: 0.00, gen throughput (token/s): 890.32, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:40:34 TP0] Decode batch. #running-req: 4, #token: 2077, token usage: 0.00, gen throughput (token/s): 895.14, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:40:34 TP0] Decode batch. #running-req: 4, #token: 2237, token usage: 0.00, gen throughput (token/s): 882.49, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:40:34 TP0] Decode batch. #running-req: 4, #token: 2397, token usage: 0.00, gen throughput (token/s): 897.26, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:40:34 TP0] Decode batch. #running-req: 4, #token: 2557, token usage: 0.00, gen throughput (token/s): 908.25, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:40:34 TP0] Decode batch. #running-req: 4, #token: 2717, token usage: 0.00, gen throughput (token/s): 869.79, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:40:34 TP0] Decode batch. #running-req: 4, #token: 2877, token usage: 0.00, gen throughput (token/s): 884.19, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:40:35 TP0] Decode batch. #running-req: 4, #token: 3037, token usage: 0.00, gen throughput (token/s): 901.21, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:40:35 TP0] Decode batch. #running-req: 4, #token: 3197, token usage: 0.00, gen throughput (token/s): 893.15, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:40:35 TP0] Decode batch. #running-req: 4, #token: 3357, token usage: 0.00, gen throughput (token/s): 876.95, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:40:35 TP0] Decode batch. #running-req: 4, #token: 3517, token usage: 0.00, gen throughput (token/s): 870.35, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:40:35 TP0] Decode batch. #running-req: 4, #token: 3677, token usage: 0.00, gen throughput (token/s): 864.32, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:40:36 TP0] Decode batch. #running-req: 4, #token: 3837, token usage: 0.00, gen throughput (token/s): 872.71, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:40:36 TP0] Decode batch. #running-req: 4, #token: 3997, token usage: 0.00, gen throughput (token/s): 855.10, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:40:36 TP0] Decode batch. #running-req: 4, #token: 4157, token usage: 0.00, gen throughput (token/s): 866.42, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:40:36] INFO:     127.0.0.1:7142 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:40:36] INFO:     127.0.0.1:7126 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:40:36] INFO:     127.0.0.1:7130 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:40:36] INFO:     127.0.0.1:7132 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:40:36 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 196, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-08-25 15:40:36 TP0] Prefill batch. #new-seq: 3, #new-token: 3, #cached-token: 588, token usage: 0.00, #running-req: 1, #queue-req: 0, 
[2025-08-25 15:40:36 TP0] Decode batch. #running-req: 4, #token: 317, token usage: 0.00, gen throughput (token/s): 581.95, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:40:36 TP0] Decode batch. #running-req: 4, #token: 477, token usage: 0.00, gen throughput (token/s): 914.53, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:40:37 TP0] Decode batch. #running-req: 4, #token: 637, token usage: 0.00, gen throughput (token/s): 906.00, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:40:37 TP0] Decode batch. #running-req: 4, #token: 797, token usage: 0.00, gen throughput (token/s): 883.92, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:40:37 TP0] Decode batch. #running-req: 4, #token: 957, token usage: 0.00, gen throughput (token/s): 921.64, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:40:37 TP0] Decode batch. #running-req: 4, #token: 1117, token usage: 0.00, gen throughput (token/s): 908.53, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:40:37 TP0] Decode batch. #running-req: 4, #token: 1277, token usage: 0.00, gen throughput (token/s): 919.16, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:40:37 TP0] Decode batch. #running-req: 4, #token: 1437, token usage: 0.00, gen throughput (token/s): 905.46, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:40:38 TP0] Decode batch. #running-req: 4, #token: 1597, token usage: 0.00, gen throughput (token/s): 915.17, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:40:38 TP0] Decode batch. #running-req: 4, #token: 1757, token usage: 0.00, gen throughput (token/s): 910.44, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:40:38 TP0] Decode batch. #running-req: 4, #token: 1917, token usage: 0.00, gen throughput (token/s): 906.06, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:40:38 TP0] Decode batch. #running-req: 4, #token: 2077, token usage: 0.00, gen throughput (token/s): 876.70, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:40:38 TP0] Decode batch. #running-req: 4, #token: 2237, token usage: 0.00, gen throughput (token/s): 870.32, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:40:39 TP0] Decode batch. #running-req: 4, #token: 2397, token usage: 0.00, gen throughput (token/s): 881.59, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:40:39 TP0] Decode batch. #running-req: 4, #token: 2557, token usage: 0.00, gen throughput (token/s): 911.63, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:40:39 TP0] Decode batch. #running-req: 4, #token: 2717, token usage: 0.00, gen throughput (token/s): 913.59, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:40:39 TP0] Decode batch. #running-req: 4, #token: 2877, token usage: 0.00, gen throughput (token/s): 913.83, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:40:39 TP0] Decode batch. #running-req: 4, #token: 3037, token usage: 0.00, gen throughput (token/s): 905.64, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:40:39 TP0] Decode batch. #running-req: 4, #token: 3197, token usage: 0.00, gen throughput (token/s): 915.01, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:40:40 TP0] Decode batch. #running-req: 4, #token: 3357, token usage: 0.00, gen throughput (token/s): 912.72, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:40:40 TP0] Decode batch. #running-req: 4, #token: 3517, token usage: 0.00, gen throughput (token/s): 916.22, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:40:40 TP0] Decode batch. #running-req: 4, #token: 3677, token usage: 0.00, gen throughput (token/s): 911.17, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:40:40 TP0] Decode batch. #running-req: 4, #token: 3837, token usage: 0.00, gen throughput (token/s): 914.76, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:40:40 TP0] Decode batch. #running-req: 4, #token: 3997, token usage: 0.00, gen throughput (token/s): 892.35, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:40:40 TP0] Decode batch. #running-req: 4, #token: 4157, token usage: 0.00, gen throughput (token/s): 910.24, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:40:41] INFO:     127.0.0.1:7142 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:40:41] INFO:     127.0.0.1:7126 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:40:41] INFO:     127.0.0.1:7130 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:40:41] INFO:     127.0.0.1:7132 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:40:41 TP0] Prefill batch. #new-seq: 1, #new-token: 1144, #cached-token: 42, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-08-25 15:40:41 TP0] Prefill batch. #new-seq: 3, #new-token: 3432, #cached-token: 126, token usage: 0.03, #running-req: 1, #queue-req: 0, 
[2025-08-25 15:40:42] INFO:     127.0.0.1:33488 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 15:40:42] INFO:     127.0.0.1:33490 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 15:40:42] INFO:     127.0.0.1:33498 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 15:40:42] INFO:     127.0.0.1:33514 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 15:40:42 TP0] Prefill batch. #new-seq: 1, #new-token: 1000, #cached-token: 186, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-08-25 15:40:42 TP0] Prefill batch. #new-seq: 2, #new-token: 2000, #cached-token: 372, token usage: 0.03, #running-req: 1, #queue-req: 0, 
[2025-08-25 15:40:43 TP0] Prefill batch. #new-seq: 1, #new-token: 1000, #cached-token: 186, token usage: 0.05, #running-req: 3, #queue-req: 0, 
[2025-08-25 15:40:43] INFO:     127.0.0.1:33488 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 15:40:43] INFO:     127.0.0.1:33490 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 15:40:43] INFO:     127.0.0.1:33498 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 15:40:43 TP0] Prefill batch. #new-seq: 3, #new-token: 3000, #cached-token: 558, token usage: 0.00, #running-req: 1, #queue-req: 0, 
[2025-08-25 15:40:43] INFO:     127.0.0.1:33514 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 15:40:44 TP0] Prefill batch. #new-seq: 1, #new-token: 1000, #cached-token: 186, token usage: 0.08, #running-req: 4, #queue-req: 0, 
[2025-08-25 15:40:44] INFO:     127.0.0.1:33488 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 15:40:44] INFO:     127.0.0.1:33490 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 15:40:44] INFO:     127.0.0.1:33498 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 15:40:45 TP0] Prefill batch. #new-seq: 3, #new-token: 3000, #cached-token: 558, token usage: 0.00, #running-req: 1, #queue-req: 0, 
[2025-08-25 15:40:45] INFO:     127.0.0.1:33514 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 15:40:46 TP0] Prefill batch. #new-seq: 1, #new-token: 1000, #cached-token: 186, token usage: 0.08, #running-req: 4, #queue-req: 0, 
[2025-08-25 15:40:46] INFO:     127.0.0.1:33488 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 15:40:46] INFO:     127.0.0.1:33490 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 15:40:46] INFO:     127.0.0.1:33498 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 15:40:46 TP0] Prefill batch. #new-seq: 3, #new-token: 3585, #cached-token: 0, token usage: 0.00, #running-req: 1, #queue-req: 0, 
[2025-08-25 15:40:46] INFO:     127.0.0.1:33514 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 15:40:46 TP0] Prefill batch. #new-seq: 1, #new-token: 1195, #cached-token: 0, token usage: 0.09, #running-req: 4, #queue-req: 0, 
[2025-08-25 15:40:48 TP0] Decode batch. #running-req: 4, #token: 4207, token usage: 0.11, gen throughput (token/s): 0.95, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:40:50 TP0] Decode batch. #running-req: 4, #token: 4367, token usage: 0.11, gen throughput (token/s): 87.72, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:40:52 TP0] Decode batch. #running-req: 4, #token: 4527, token usage: 0.11, gen throughput (token/s): 87.62, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:40:54 TP0] Decode batch. #running-req: 4, #token: 4687, token usage: 0.12, gen throughput (token/s): 87.20, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:40:55] INFO:     127.0.0.1:33488 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:40:55] INFO:     127.0.0.1:33490 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:40:55] INFO:     127.0.0.1:33498 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:40:55] INFO:     127.0.0.1:33514 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:40:55 TP0] Prefill batch. #new-seq: 3, #new-token: 2978, #cached-token: 607, token usage: 0.01, #running-req: 0, #queue-req: 0, 
[2025-08-25 15:40:55 TP0] Prefill batch. #new-seq: 1, #new-token: 991, #cached-token: 204, token usage: 0.08, #running-req: 3, #queue-req: 0, 
[2025-08-25 15:40:57 TP0] Decode batch. #running-req: 4, #token: 4236, token usage: 0.11, gen throughput (token/s): 52.75, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:40:59 TP0] Decode batch. #running-req: 4, #token: 4396, token usage: 0.11, gen throughput (token/s): 87.37, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:41:00 TP0] Decode batch. #running-req: 4, #token: 4556, token usage: 0.11, gen throughput (token/s): 87.16, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:41:02 TP0] Decode batch. #running-req: 4, #token: 4716, token usage: 0.12, gen throughput (token/s): 87.17, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:41:03] INFO:     127.0.0.1:33514 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:41:03] INFO:     127.0.0.1:33488 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:41:03] INFO:     127.0.0.1:33490 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:41:03] INFO:     127.0.0.1:33498 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:41:03 TP0] Prefill batch. #new-seq: 2, #new-token: 1987, #cached-token: 403, token usage: 0.01, #running-req: 0, #queue-req: 0, 
[2025-08-25 15:41:03 TP0] Prefill batch. #new-seq: 2, #new-token: 1982, #cached-token: 408, token usage: 0.06, #running-req: 2, #queue-req: 0, 
[2025-08-25 15:41:05 TP0] Decode batch. #running-req: 4, #token: 4295, token usage: 0.11, gen throughput (token/s): 53.12, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:41:07 TP0] Decode batch. #running-req: 4, #token: 4455, token usage: 0.11, gen throughput (token/s): 87.41, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:41:09 TP0] Decode batch. #running-req: 4, #token: 4615, token usage: 0.12, gen throughput (token/s): 87.29, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:41:11 TP0] Decode batch. #running-req: 4, #token: 4775, token usage: 0.12, gen throughput (token/s): 87.38, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:41:11] INFO:     127.0.0.1:33514 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:41:11] INFO:     127.0.0.1:33488 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:41:11] INFO:     127.0.0.1:33490 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:41:11] INFO:     127.0.0.1:33498 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:41:11 TP0] Prefill batch. #new-seq: 2, #new-token: 1984, #cached-token: 406, token usage: 0.01, #running-req: 0, #queue-req: 0, 
[2025-08-25 15:41:13 TP0] Decode batch. #running-req: 2, #token: 2269, token usage: 0.06, gen throughput (token/s): 36.67, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:41:15 TP0] Decode batch. #running-req: 2, #token: 2349, token usage: 0.06, gen throughput (token/s): 44.53, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:41:17 TP0] Decode batch. #running-req: 2, #token: 2429, token usage: 0.06, gen throughput (token/s): 44.55, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:41:18] INFO:     127.0.0.1:33514 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:41:18] INFO:     127.0.0.1:33488 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:41:18 TP0] Prefill batch. #new-seq: 4, #new-token: 4, #cached-token: 688, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-08-25 15:41:18 TP0] Decode batch. #running-req: 4, #token: 293, token usage: 0.00, gen throughput (token/s): 4.22, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:41:19 TP0] Decode batch. #running-req: 4, #token: 453, token usage: 0.00, gen throughput (token/s): 869.05, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:41:19 TP0] Decode batch. #running-req: 4, #token: 613, token usage: 0.00, gen throughput (token/s): 870.58, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:41:19 TP0] Decode batch. #running-req: 4, #token: 773, token usage: 0.00, gen throughput (token/s): 872.61, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:41:19 TP0] Decode batch. #running-req: 4, #token: 933, token usage: 0.00, gen throughput (token/s): 887.56, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:41:19 TP0] Decode batch. #running-req: 4, #token: 1093, token usage: 0.00, gen throughput (token/s): 895.06, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:41:19 TP0] Decode batch. #running-req: 4, #token: 1253, token usage: 0.00, gen throughput (token/s): 889.61, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:41:20 TP0] Decode batch. #running-req: 4, #token: 1413, token usage: 0.00, gen throughput (token/s): 878.33, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:41:20 TP0] Decode batch. #running-req: 4, #token: 1573, token usage: 0.00, gen throughput (token/s): 883.02, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:41:20 TP0] Decode batch. #running-req: 4, #token: 1733, token usage: 0.00, gen throughput (token/s): 881.98, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:41:20 TP0] Decode batch. #running-req: 4, #token: 1893, token usage: 0.00, gen throughput (token/s): 877.48, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:41:20 TP0] Decode batch. #running-req: 4, #token: 2053, token usage: 0.00, gen throughput (token/s): 851.44, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:41:21 TP0] Decode batch. #running-req: 4, #token: 2213, token usage: 0.00, gen throughput (token/s): 880.85, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:41:21 TP0] Decode batch. #running-req: 4, #token: 2373, token usage: 0.00, gen throughput (token/s): 880.18, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:41:21 TP0] Decode batch. #running-req: 4, #token: 2533, token usage: 0.00, gen throughput (token/s): 884.76, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:41:21 TP0] Decode batch. #running-req: 4, #token: 2693, token usage: 0.00, gen throughput (token/s): 902.41, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:41:21 TP0] Decode batch. #running-req: 4, #token: 2853, token usage: 0.00, gen throughput (token/s): 911.85, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:41:21 TP0] Decode batch. #running-req: 4, #token: 3013, token usage: 0.00, gen throughput (token/s): 874.99, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:41:22 TP0] Decode batch. #running-req: 4, #token: 3173, token usage: 0.00, gen throughput (token/s): 939.69, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:41:22 TP0] Decode batch. #running-req: 4, #token: 3333, token usage: 0.00, gen throughput (token/s): 926.69, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:41:22 TP0] Decode batch. #running-req: 4, #token: 3493, token usage: 0.00, gen throughput (token/s): 926.16, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:41:22 TP0] Decode batch. #running-req: 4, #token: 3653, token usage: 0.00, gen throughput (token/s): 925.52, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:41:22 TP0] Decode batch. #running-req: 4, #token: 3813, token usage: 0.00, gen throughput (token/s): 910.24, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:41:22 TP0] Decode batch. #running-req: 4, #token: 3973, token usage: 0.00, gen throughput (token/s): 910.22, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:41:23 TP0] Decode batch. #running-req: 4, #token: 4133, token usage: 0.00, gen throughput (token/s): 931.15, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:41:23] INFO:     127.0.0.1:19716 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:41:23] INFO:     127.0.0.1:19718 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:41:23] INFO:     127.0.0.1:19724 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:41:23] INFO:     127.0.0.1:19726 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:41:23 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 172, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-08-25 15:41:23 TP0] Prefill batch. #new-seq: 3, #new-token: 3, #cached-token: 516, token usage: 0.00, #running-req: 1, #queue-req: 0, 
[2025-08-25 15:41:23 TP0] Decode batch. #running-req: 4, #token: 293, token usage: 0.00, gen throughput (token/s): 600.26, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:41:23 TP0] Decode batch. #running-req: 4, #token: 453, token usage: 0.00, gen throughput (token/s): 886.66, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:41:23 TP0] Decode batch. #running-req: 4, #token: 613, token usage: 0.00, gen throughput (token/s): 853.53, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:41:23 TP0] Decode batch. #running-req: 4, #token: 773, token usage: 0.00, gen throughput (token/s): 875.85, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:41:24 TP0] Decode batch. #running-req: 4, #token: 933, token usage: 0.00, gen throughput (token/s): 875.65, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:41:24 TP0] Decode batch. #running-req: 4, #token: 1093, token usage: 0.00, gen throughput (token/s): 858.30, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:41:24 TP0] Decode batch. #running-req: 4, #token: 1253, token usage: 0.00, gen throughput (token/s): 871.49, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:41:24 TP0] Decode batch. #running-req: 4, #token: 1413, token usage: 0.00, gen throughput (token/s): 877.44, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:41:24 TP0] Decode batch. #running-req: 4, #token: 1573, token usage: 0.00, gen throughput (token/s): 857.74, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:41:25 TP0] Decode batch. #running-req: 4, #token: 1733, token usage: 0.00, gen throughput (token/s): 887.52, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:41:25 TP0] Decode batch. #running-req: 4, #token: 1893, token usage: 0.00, gen throughput (token/s): 890.69, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:41:25 TP0] Decode batch. #running-req: 4, #token: 2053, token usage: 0.00, gen throughput (token/s): 874.34, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:41:25 TP0] Decode batch. #running-req: 4, #token: 2213, token usage: 0.00, gen throughput (token/s): 887.97, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:41:25 TP0] Decode batch. #running-req: 4, #token: 2373, token usage: 0.00, gen throughput (token/s): 883.58, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:41:25 TP0] Decode batch. #running-req: 4, #token: 2533, token usage: 0.00, gen throughput (token/s): 893.96, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:41:26 TP0] Decode batch. #running-req: 4, #token: 2693, token usage: 0.00, gen throughput (token/s): 885.69, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:41:26 TP0] Decode batch. #running-req: 4, #token: 2853, token usage: 0.00, gen throughput (token/s): 891.51, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:41:26 TP0] Decode batch. #running-req: 4, #token: 3013, token usage: 0.00, gen throughput (token/s): 904.63, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:41:26 TP0] Decode batch. #running-req: 4, #token: 3173, token usage: 0.00, gen throughput (token/s): 891.21, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:41:26 TP0] Decode batch. #running-req: 4, #token: 3333, token usage: 0.00, gen throughput (token/s): 899.90, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:41:27 TP0] Decode batch. #running-req: 4, #token: 3493, token usage: 0.00, gen throughput (token/s): 892.23, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:41:27 TP0] Decode batch. #running-req: 4, #token: 3653, token usage: 0.00, gen throughput (token/s): 883.02, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:41:27 TP0] Decode batch. #running-req: 4, #token: 3813, token usage: 0.00, gen throughput (token/s): 880.12, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:41:27 TP0] Decode batch. #running-req: 4, #token: 3973, token usage: 0.00, gen throughput (token/s): 878.59, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:41:27 TP0] Decode batch. #running-req: 4, #token: 4133, token usage: 0.00, gen throughput (token/s): 877.86, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:41:27] INFO:     127.0.0.1:19726 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:41:27] INFO:     127.0.0.1:19716 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:41:27] INFO:     127.0.0.1:19718 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:41:27] INFO:     127.0.0.1:19724 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:41:27 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 172, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-08-25 15:41:27 TP0] Prefill batch. #new-seq: 3, #new-token: 3, #cached-token: 516, token usage: 0.00, #running-req: 1, #queue-req: 0, 
[2025-08-25 15:41:28 TP0] Decode batch. #running-req: 4, #token: 293, token usage: 0.00, gen throughput (token/s): 594.62, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:41:28 TP0] Decode batch. #running-req: 4, #token: 453, token usage: 0.00, gen throughput (token/s): 901.62, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:41:28 TP0] Decode batch. #running-req: 4, #token: 613, token usage: 0.00, gen throughput (token/s): 907.28, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:41:28 TP0] Decode batch. #running-req: 4, #token: 773, token usage: 0.00, gen throughput (token/s): 906.94, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:41:28 TP0] Decode batch. #running-req: 4, #token: 933, token usage: 0.00, gen throughput (token/s): 920.01, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:41:28 TP0] Decode batch. #running-req: 4, #token: 1093, token usage: 0.00, gen throughput (token/s): 873.18, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:41:29 TP0] Decode batch. #running-req: 4, #token: 1253, token usage: 0.00, gen throughput (token/s): 913.21, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:41:29 TP0] Decode batch. #running-req: 4, #token: 1413, token usage: 0.00, gen throughput (token/s): 922.06, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:41:29 TP0] Decode batch. #running-req: 4, #token: 1573, token usage: 0.00, gen throughput (token/s): 907.82, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:41:29 TP0] Decode batch. #running-req: 4, #token: 1733, token usage: 0.00, gen throughput (token/s): 934.45, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:41:29 TP0] Decode batch. #running-req: 4, #token: 1893, token usage: 0.00, gen throughput (token/s): 924.50, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:41:29 TP0] Decode batch. #running-req: 4, #token: 2053, token usage: 0.00, gen throughput (token/s): 912.43, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:41:30 TP0] Decode batch. #running-req: 4, #token: 2213, token usage: 0.00, gen throughput (token/s): 918.04, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:41:30 TP0] Decode batch. #running-req: 4, #token: 2373, token usage: 0.00, gen throughput (token/s): 922.25, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:41:30 TP0] Decode batch. #running-req: 4, #token: 2533, token usage: 0.00, gen throughput (token/s): 922.34, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:41:30 TP0] Decode batch. #running-req: 4, #token: 2693, token usage: 0.00, gen throughput (token/s): 904.03, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:41:30 TP0] Decode batch. #running-req: 4, #token: 2853, token usage: 0.00, gen throughput (token/s): 920.99, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:41:31 TP0] Decode batch. #running-req: 4, #token: 3013, token usage: 0.00, gen throughput (token/s): 911.58, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:41:31 TP0] Decode batch. #running-req: 4, #token: 3173, token usage: 0.00, gen throughput (token/s): 899.49, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:41:31 TP0] Decode batch. #running-req: 4, #token: 3333, token usage: 0.00, gen throughput (token/s): 878.73, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:41:31 TP0] Decode batch. #running-req: 4, #token: 3493, token usage: 0.00, gen throughput (token/s): 881.01, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:41:31 TP0] Decode batch. #running-req: 4, #token: 3653, token usage: 0.00, gen throughput (token/s): 880.10, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:41:31 TP0] Decode batch. #running-req: 4, #token: 3813, token usage: 0.00, gen throughput (token/s): 879.95, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:41:32 TP0] Decode batch. #running-req: 4, #token: 3973, token usage: 0.00, gen throughput (token/s): 885.95, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:41:32 TP0] Decode batch. #running-req: 4, #token: 4133, token usage: 0.00, gen throughput (token/s): 862.41, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:41:32] INFO:     127.0.0.1:19726 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:41:32] INFO:     127.0.0.1:19716 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:41:32] INFO:     127.0.0.1:19718 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:41:32] INFO:     127.0.0.1:19724 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:41:32 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 172, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-08-25 15:41:32 TP0] Prefill batch. #new-seq: 3, #new-token: 3, #cached-token: 516, token usage: 0.00, #running-req: 1, #queue-req: 0, 
[2025-08-25 15:41:32 TP0] Decode batch. #running-req: 4, #token: 293, token usage: 0.00, gen throughput (token/s): 600.53, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:41:32 TP0] Decode batch. #running-req: 4, #token: 453, token usage: 0.00, gen throughput (token/s): 926.90, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:41:32 TP0] Decode batch. #running-req: 4, #token: 613, token usage: 0.00, gen throughput (token/s): 873.48, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:41:33 TP0] Decode batch. #running-req: 4, #token: 773, token usage: 0.00, gen throughput (token/s): 858.44, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:41:33 TP0] Decode batch. #running-req: 4, #token: 933, token usage: 0.00, gen throughput (token/s): 890.15, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:41:33 TP0] Decode batch. #running-req: 4, #token: 1093, token usage: 0.00, gen throughput (token/s): 864.37, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:41:33 TP0] Decode batch. #running-req: 4, #token: 1253, token usage: 0.00, gen throughput (token/s): 903.44, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:41:33 TP0] Decode batch. #running-req: 4, #token: 1413, token usage: 0.00, gen throughput (token/s): 903.52, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:41:34 TP0] Decode batch. #running-req: 4, #token: 1573, token usage: 0.00, gen throughput (token/s): 909.09, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:41:34 TP0] Decode batch. #running-req: 4, #token: 1733, token usage: 0.00, gen throughput (token/s): 894.63, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:41:34 TP0] Decode batch. #running-req: 4, #token: 1893, token usage: 0.00, gen throughput (token/s): 927.03, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:41:34 TP0] Decode batch. #running-req: 4, #token: 2053, token usage: 0.00, gen throughput (token/s): 895.76, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:41:34 TP0] Decode batch. #running-req: 4, #token: 2213, token usage: 0.00, gen throughput (token/s): 920.35, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:41:34 TP0] Decode batch. #running-req: 4, #token: 2373, token usage: 0.00, gen throughput (token/s): 896.68, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:41:35 TP0] Decode batch. #running-req: 4, #token: 2533, token usage: 0.00, gen throughput (token/s): 902.87, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:41:35 TP0] Decode batch. #running-req: 4, #token: 2693, token usage: 0.00, gen throughput (token/s): 902.70, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:41:35 TP0] Decode batch. #running-req: 4, #token: 2853, token usage: 0.00, gen throughput (token/s): 915.14, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:41:35 TP0] Decode batch. #running-req: 4, #token: 3013, token usage: 0.00, gen throughput (token/s): 892.17, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:41:35 TP0] Decode batch. #running-req: 4, #token: 3173, token usage: 0.00, gen throughput (token/s): 887.68, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:41:35 TP0] Decode batch. #running-req: 4, #token: 3333, token usage: 0.00, gen throughput (token/s): 889.03, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:41:36 TP0] Decode batch. #running-req: 4, #token: 3493, token usage: 0.00, gen throughput (token/s): 859.20, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:41:36 TP0] Decode batch. #running-req: 4, #token: 3653, token usage: 0.00, gen throughput (token/s): 843.91, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:41:36 TP0] Decode batch. #running-req: 4, #token: 3813, token usage: 0.00, gen throughput (token/s): 856.50, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:41:36 TP0] Decode batch. #running-req: 4, #token: 3973, token usage: 0.00, gen throughput (token/s): 846.03, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:41:36 TP0] Decode batch. #running-req: 4, #token: 4133, token usage: 0.00, gen throughput (token/s): 887.97, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:41:36] INFO:     127.0.0.1:19726 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:41:36] INFO:     127.0.0.1:19716 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:41:36] INFO:     127.0.0.1:19718 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:41:36] INFO:     127.0.0.1:19724 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:41:36 TP0] Prefill batch. #new-seq: 1, #new-token: 1120, #cached-token: 42, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-08-25 15:41:37 TP0] Prefill batch. #new-seq: 3, #new-token: 3360, #cached-token: 126, token usage: 0.03, #running-req: 1, #queue-req: 0, 
[2025-08-25 15:41:37] INFO:     127.0.0.1:22118 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 15:41:38 TP0] Prefill batch. #new-seq: 1, #new-token: 1000, #cached-token: 162, token usage: 0.00, #running-req: 3, #queue-req: 0, 
[2025-08-25 15:41:38] INFO:     127.0.0.1:22134 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 15:41:38] INFO:     127.0.0.1:22150 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 15:41:38] INFO:     127.0.0.1:22158 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 15:41:38 TP0] Prefill batch. #new-seq: 3, #new-token: 3000, #cached-token: 486, token usage: 0.03, #running-req: 4, #queue-req: 0, 
[2025-08-25 15:41:38] INFO:     127.0.0.1:22118 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 15:41:39 TP0] Prefill batch. #new-seq: 1, #new-token: 1000, #cached-token: 162, token usage: 0.00, #running-req: 3, #queue-req: 0, 
[2025-08-25 15:41:39] INFO:     127.0.0.1:22134 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 15:41:39] INFO:     127.0.0.1:22150 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 15:41:39] INFO:     127.0.0.1:22158 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 15:41:40 TP0] Prefill batch. #new-seq: 3, #new-token: 3000, #cached-token: 486, token usage: 0.03, #running-req: 4, #queue-req: 0, 
[2025-08-25 15:41:40] INFO:     127.0.0.1:22118 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 15:41:41 TP0] Prefill batch. #new-seq: 1, #new-token: 1000, #cached-token: 162, token usage: 0.00, #running-req: 3, #queue-req: 0, 
[2025-08-25 15:41:41] INFO:     127.0.0.1:22134 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 15:41:41] INFO:     127.0.0.1:22150 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 15:41:41] INFO:     127.0.0.1:22158 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 15:41:41 TP0] Prefill batch. #new-seq: 3, #new-token: 3000, #cached-token: 486, token usage: 0.03, #running-req: 4, #queue-req: 0, 
[2025-08-25 15:41:41] INFO:     127.0.0.1:22118 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 15:41:42] INFO:     127.0.0.1:22134 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 15:41:42] INFO:     127.0.0.1:22150 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 15:41:42] INFO:     127.0.0.1:22158 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 15:41:42 TP0] Prefill batch. #new-seq: 4, #new-token: 4, #cached-token: 616, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-08-25 15:41:42 TP0] Decode batch. #running-req: 4, #token: 275, token usage: 0.00, gen throughput (token/s): 27.58, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:41:42 TP0] Decode batch. #running-req: 4, #token: 435, token usage: 0.00, gen throughput (token/s): 878.99, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:41:43 TP0] Decode batch. #running-req: 4, #token: 595, token usage: 0.00, gen throughput (token/s): 896.17, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:41:43 TP0] Decode batch. #running-req: 4, #token: 755, token usage: 0.00, gen throughput (token/s): 891.96, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:41:43 TP0] Decode batch. #running-req: 4, #token: 915, token usage: 0.00, gen throughput (token/s): 906.47, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:41:43 TP0] Decode batch. #running-req: 4, #token: 1075, token usage: 0.00, gen throughput (token/s): 881.33, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:41:43 TP0] Decode batch. #running-req: 4, #token: 1235, token usage: 0.00, gen throughput (token/s): 869.27, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:41:43 TP0] Decode batch. #running-req: 4, #token: 1395, token usage: 0.00, gen throughput (token/s): 881.85, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:41:44 TP0] Decode batch. #running-req: 4, #token: 1555, token usage: 0.00, gen throughput (token/s): 904.86, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:41:44 TP0] Decode batch. #running-req: 4, #token: 1715, token usage: 0.00, gen throughput (token/s): 877.48, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:41:44 TP0] Decode batch. #running-req: 4, #token: 1875, token usage: 0.00, gen throughput (token/s): 871.67, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:41:44 TP0] Decode batch. #running-req: 4, #token: 2035, token usage: 0.00, gen throughput (token/s): 890.06, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:41:44 TP0] Decode batch. #running-req: 4, #token: 2195, token usage: 0.00, gen throughput (token/s): 876.53, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:41:45 TP0] Decode batch. #running-req: 4, #token: 2355, token usage: 0.00, gen throughput (token/s): 866.39, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:41:45 TP0] Decode batch. #running-req: 4, #token: 2515, token usage: 0.00, gen throughput (token/s): 869.43, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:41:45 TP0] Decode batch. #running-req: 4, #token: 2675, token usage: 0.00, gen throughput (token/s): 851.59, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:41:45 TP0] Decode batch. #running-req: 4, #token: 2835, token usage: 0.00, gen throughput (token/s): 847.39, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:41:45 TP0] Decode batch. #running-req: 4, #token: 2995, token usage: 0.00, gen throughput (token/s): 871.15, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:41:45 TP0] Decode batch. #running-req: 4, #token: 3155, token usage: 0.00, gen throughput (token/s): 899.64, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:41:46 TP0] Decode batch. #running-req: 4, #token: 3315, token usage: 0.00, gen throughput (token/s): 880.72, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:41:46 TP0] Decode batch. #running-req: 4, #token: 3475, token usage: 0.00, gen throughput (token/s): 878.18, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:41:46 TP0] Decode batch. #running-req: 4, #token: 3635, token usage: 0.00, gen throughput (token/s): 880.24, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:41:46 TP0] Decode batch. #running-req: 4, #token: 3795, token usage: 0.00, gen throughput (token/s): 876.34, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:41:46 TP0] Decode batch. #running-req: 4, #token: 3955, token usage: 0.00, gen throughput (token/s): 881.46, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:41:47 TP0] Decode batch. #running-req: 4, #token: 4115, token usage: 0.00, gen throughput (token/s): 883.88, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:41:47] INFO:     127.0.0.1:23866 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:41:47] INFO:     127.0.0.1:23872 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:41:47] INFO:     127.0.0.1:23888 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:41:47] INFO:     127.0.0.1:23904 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:41:47 TP0] Prefill batch. #new-seq: 4, #new-token: 4, #cached-token: 616, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-08-25 15:41:47 TP0] Decode batch. #running-req: 4, #token: 275, token usage: 0.00, gen throughput (token/s): 640.60, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:41:47 TP0] Decode batch. #running-req: 4, #token: 435, token usage: 0.00, gen throughput (token/s): 873.62, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:41:47 TP0] Decode batch. #running-req: 4, #token: 595, token usage: 0.00, gen throughput (token/s): 874.30, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:41:47 TP0] Decode batch. #running-req: 4, #token: 755, token usage: 0.00, gen throughput (token/s): 879.03, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:41:48 TP0] Decode batch. #running-req: 4, #token: 915, token usage: 0.00, gen throughput (token/s): 877.70, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:41:48 TP0] Decode batch. #running-req: 4, #token: 1075, token usage: 0.00, gen throughput (token/s): 889.49, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:41:48 TP0] Decode batch. #running-req: 4, #token: 1235, token usage: 0.00, gen throughput (token/s): 891.61, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:41:48 TP0] Decode batch. #running-req: 4, #token: 1395, token usage: 0.00, gen throughput (token/s): 852.82, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:41:48 TP0] Decode batch. #running-req: 4, #token: 1555, token usage: 0.00, gen throughput (token/s): 879.61, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:41:48 TP0] Decode batch. #running-req: 4, #token: 1715, token usage: 0.00, gen throughput (token/s): 897.26, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:41:49 TP0] Decode batch. #running-req: 4, #token: 1875, token usage: 0.00, gen throughput (token/s): 900.55, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:41:49 TP0] Decode batch. #running-req: 4, #token: 2035, token usage: 0.00, gen throughput (token/s): 891.67, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:41:49 TP0] Decode batch. #running-req: 4, #token: 2195, token usage: 0.00, gen throughput (token/s): 889.24, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:41:49 TP0] Decode batch. #running-req: 4, #token: 2355, token usage: 0.00, gen throughput (token/s): 891.07, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:41:49 TP0] Decode batch. #running-req: 4, #token: 2515, token usage: 0.00, gen throughput (token/s): 894.44, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:41:50 TP0] Decode batch. #running-req: 4, #token: 2675, token usage: 0.00, gen throughput (token/s): 904.23, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:41:50 TP0] Decode batch. #running-req: 4, #token: 2835, token usage: 0.00, gen throughput (token/s): 894.66, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:41:50 TP0] Decode batch. #running-req: 4, #token: 2995, token usage: 0.00, gen throughput (token/s): 890.72, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:41:50 TP0] Decode batch. #running-req: 4, #token: 3155, token usage: 0.00, gen throughput (token/s): 886.78, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:41:50 TP0] Decode batch. #running-req: 4, #token: 3315, token usage: 0.00, gen throughput (token/s): 914.91, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:41:50 TP0] Decode batch. #running-req: 4, #token: 3475, token usage: 0.00, gen throughput (token/s): 892.13, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:41:51 TP0] Decode batch. #running-req: 4, #token: 3635, token usage: 0.00, gen throughput (token/s): 888.14, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:41:51 TP0] Decode batch. #running-req: 4, #token: 3795, token usage: 0.00, gen throughput (token/s): 915.29, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:41:51 TP0] Decode batch. #running-req: 4, #token: 3955, token usage: 0.00, gen throughput (token/s): 863.45, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:41:51 TP0] Decode batch. #running-req: 4, #token: 4115, token usage: 0.00, gen throughput (token/s): 885.64, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:41:51] INFO:     127.0.0.1:23904 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:41:51] INFO:     127.0.0.1:23866 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:41:51] INFO:     127.0.0.1:23872 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:41:51] INFO:     127.0.0.1:23888 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:41:51 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 154, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-08-25 15:41:51 TP0] Prefill batch. #new-seq: 3, #new-token: 3, #cached-token: 462, token usage: 0.00, #running-req: 1, #queue-req: 0, 
[2025-08-25 15:41:51 TP0] Decode batch. #running-req: 4, #token: 275, token usage: 0.00, gen throughput (token/s): 591.00, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:41:52 TP0] Decode batch. #running-req: 4, #token: 435, token usage: 0.00, gen throughput (token/s): 871.93, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:41:52 TP0] Decode batch. #running-req: 4, #token: 595, token usage: 0.00, gen throughput (token/s): 872.65, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:41:52 TP0] Decode batch. #running-req: 4, #token: 755, token usage: 0.00, gen throughput (token/s): 861.30, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:41:52 TP0] Decode batch. #running-req: 4, #token: 915, token usage: 0.00, gen throughput (token/s): 860.05, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:41:52 TP0] Decode batch. #running-req: 4, #token: 1075, token usage: 0.00, gen throughput (token/s): 874.23, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:41:53 TP0] Decode batch. #running-req: 4, #token: 1235, token usage: 0.00, gen throughput (token/s): 862.88, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:41:53 TP0] Decode batch. #running-req: 4, #token: 1395, token usage: 0.00, gen throughput (token/s): 872.54, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:41:53 TP0] Decode batch. #running-req: 4, #token: 1555, token usage: 0.00, gen throughput (token/s): 859.57, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:41:53 TP0] Decode batch. #running-req: 4, #token: 1715, token usage: 0.00, gen throughput (token/s): 877.20, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:41:53 TP0] Decode batch. #running-req: 4, #token: 1875, token usage: 0.00, gen throughput (token/s): 846.70, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:41:53 TP0] Decode batch. #running-req: 4, #token: 2035, token usage: 0.00, gen throughput (token/s): 885.78, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:41:54 TP0] Decode batch. #running-req: 4, #token: 2195, token usage: 0.00, gen throughput (token/s): 882.71, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:41:54 TP0] Decode batch. #running-req: 4, #token: 2355, token usage: 0.00, gen throughput (token/s): 872.14, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:41:54 TP0] Decode batch. #running-req: 4, #token: 2515, token usage: 0.00, gen throughput (token/s): 870.19, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:41:54 TP0] Decode batch. #running-req: 4, #token: 2675, token usage: 0.00, gen throughput (token/s): 853.32, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:41:54 TP0] Decode batch. #running-req: 4, #token: 2835, token usage: 0.00, gen throughput (token/s): 856.26, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:41:55 TP0] Decode batch. #running-req: 4, #token: 2995, token usage: 0.00, gen throughput (token/s): 869.42, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:41:55 TP0] Decode batch. #running-req: 4, #token: 3155, token usage: 0.00, gen throughput (token/s): 819.70, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:41:55 TP0] Decode batch. #running-req: 4, #token: 3315, token usage: 0.00, gen throughput (token/s): 881.96, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:41:55 TP0] Decode batch. #running-req: 4, #token: 3475, token usage: 0.00, gen throughput (token/s): 892.04, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:41:55 TP0] Decode batch. #running-req: 4, #token: 3635, token usage: 0.00, gen throughput (token/s): 878.23, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:41:55 TP0] Decode batch. #running-req: 4, #token: 3795, token usage: 0.00, gen throughput (token/s): 876.39, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:41:56 TP0] Decode batch. #running-req: 4, #token: 3955, token usage: 0.00, gen throughput (token/s): 859.24, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:41:56 TP0] Decode batch. #running-req: 4, #token: 4115, token usage: 0.00, gen throughput (token/s): 859.50, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:41:56] INFO:     127.0.0.1:23904 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:41:56] INFO:     127.0.0.1:23866 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:41:56] INFO:     127.0.0.1:23872 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:41:56] INFO:     127.0.0.1:23888 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:41:56 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 154, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-08-25 15:41:56 TP0] Prefill batch. #new-seq: 3, #new-token: 3, #cached-token: 462, token usage: 0.00, #running-req: 1, #queue-req: 0, 
[2025-08-25 15:41:56 TP0] Decode batch. #running-req: 4, #token: 275, token usage: 0.00, gen throughput (token/s): 597.48, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:41:56 TP0] Decode batch. #running-req: 4, #token: 435, token usage: 0.00, gen throughput (token/s): 875.18, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:41:56 TP0] Decode batch. #running-req: 4, #token: 595, token usage: 0.00, gen throughput (token/s): 858.47, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:41:57 TP0] Decode batch. #running-req: 4, #token: 755, token usage: 0.00, gen throughput (token/s): 874.91, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:41:57 TP0] Decode batch. #running-req: 4, #token: 915, token usage: 0.00, gen throughput (token/s): 877.75, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:41:57 TP0] Decode batch. #running-req: 4, #token: 1075, token usage: 0.00, gen throughput (token/s): 880.68, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:41:57 TP0] Decode batch. #running-req: 4, #token: 1235, token usage: 0.00, gen throughput (token/s): 871.78, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:41:57 TP0] Decode batch. #running-req: 4, #token: 1395, token usage: 0.00, gen throughput (token/s): 874.44, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:41:58 TP0] Decode batch. #running-req: 4, #token: 1555, token usage: 0.00, gen throughput (token/s): 861.12, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:41:58 TP0] Decode batch. #running-req: 4, #token: 1715, token usage: 0.00, gen throughput (token/s): 910.16, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:41:58 TP0] Decode batch. #running-req: 4, #token: 1875, token usage: 0.00, gen throughput (token/s): 900.35, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:41:58 TP0] Decode batch. #running-req: 4, #token: 2035, token usage: 0.00, gen throughput (token/s): 889.15, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:41:58 TP0] Decode batch. #running-req: 4, #token: 2195, token usage: 0.00, gen throughput (token/s): 869.98, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:41:58 TP0] Decode batch. #running-req: 4, #token: 2355, token usage: 0.00, gen throughput (token/s): 891.18, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:41:59 TP0] Decode batch. #running-req: 4, #token: 2515, token usage: 0.00, gen throughput (token/s): 892.98, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:41:59 TP0] Decode batch. #running-req: 4, #token: 2675, token usage: 0.00, gen throughput (token/s): 904.07, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:41:59 TP0] Decode batch. #running-req: 4, #token: 2835, token usage: 0.00, gen throughput (token/s): 898.35, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:41:59 TP0] Decode batch. #running-req: 4, #token: 2995, token usage: 0.00, gen throughput (token/s): 894.54, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:41:59 TP0] Decode batch. #running-req: 4, #token: 3155, token usage: 0.00, gen throughput (token/s): 897.20, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:42:00 TP0] Decode batch. #running-req: 4, #token: 3315, token usage: 0.00, gen throughput (token/s): 915.10, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:42:00 TP0] Decode batch. #running-req: 4, #token: 3475, token usage: 0.00, gen throughput (token/s): 901.92, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:42:00 TP0] Decode batch. #running-req: 4, #token: 3635, token usage: 0.00, gen throughput (token/s): 908.23, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:42:00 TP0] Decode batch. #running-req: 4, #token: 3795, token usage: 0.00, gen throughput (token/s): 906.77, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:42:00 TP0] Decode batch. #running-req: 4, #token: 3955, token usage: 0.00, gen throughput (token/s): 879.98, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:42:00 TP0] Decode batch. #running-req: 4, #token: 4115, token usage: 0.00, gen throughput (token/s): 888.97, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:42:00] INFO:     127.0.0.1:23904 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:42:00] INFO:     127.0.0.1:23866 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:42:00] INFO:     127.0.0.1:23872 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:42:00] INFO:     127.0.0.1:23888 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:42:01 TP0] Prefill batch. #new-seq: 1, #new-token: 1101, #cached-token: 43, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-08-25 15:42:01 TP0] Prefill batch. #new-seq: 2, #new-token: 2202, #cached-token: 86, token usage: 0.03, #running-req: 1, #queue-req: 0, 
[2025-08-25 15:42:02 TP0] Prefill batch. #new-seq: 1, #new-token: 1000, #cached-token: 144, token usage: 0.06, #running-req: 3, #queue-req: 0, 
[2025-08-25 15:42:02] INFO:     127.0.0.1:43596 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 15:42:02] INFO:     127.0.0.1:43602 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 15:42:02] INFO:     127.0.0.1:43606 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 15:42:02 TP0] Prefill batch. #new-seq: 3, #new-token: 3000, #cached-token: 432, token usage: 0.00, #running-req: 1, #queue-req: 0, 
[2025-08-25 15:42:02] INFO:     127.0.0.1:43620 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 15:42:03 TP0] Prefill batch. #new-seq: 1, #new-token: 1000, #cached-token: 144, token usage: 0.08, #running-req: 4, #queue-req: 0, 
[2025-08-25 15:42:03 TP0] Decode batch. #running-req: 0, #token: 0, token usage: 0.00, gen throughput (token/s): 1.76, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:42:03] INFO:     127.0.0.1:43596 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 15:42:04] INFO:     127.0.0.1:43602 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 15:42:04] INFO:     127.0.0.1:43606 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 15:42:04 TP0] Prefill batch. #new-seq: 1, #new-token: 1000, #cached-token: 144, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-08-25 15:42:04 TP0] Prefill batch. #new-seq: 1, #new-token: 1000, #cached-token: 144, token usage: 0.03, #running-req: 1, #queue-req: 0, 
[2025-08-25 15:42:04] INFO:     127.0.0.1:43620 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 15:42:04 TP0] Prefill batch. #new-seq: 2, #new-token: 2000, #cached-token: 288, token usage: 0.03, #running-req: 2, #queue-req: 0, 
[2025-08-25 15:42:04] INFO:     127.0.0.1:43596 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 15:42:04] INFO:     127.0.0.1:43602 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 15:42:05 TP0] Prefill batch. #new-seq: 2, #new-token: 2000, #cached-token: 288, token usage: 0.00, #running-req: 2, #queue-req: 0, 
[2025-08-25 15:42:05] INFO:     127.0.0.1:43606 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 15:42:05] INFO:     127.0.0.1:43620 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 15:42:06 TP0] Prefill batch. #new-seq: 2, #new-token: 2000, #cached-token: 288, token usage: 0.05, #running-req: 4, #queue-req: 0, 
[2025-08-25 15:42:06] INFO:     127.0.0.1:43596 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 15:42:06] INFO:     127.0.0.1:43602 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 15:42:06] INFO:     127.0.0.1:43606 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 15:42:06] INFO:     127.0.0.1:43620 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 15:42:06 TP0] Prefill batch. #new-seq: 4, #new-token: 4, #cached-token: 1232, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-08-25 15:42:06 TP0] Decode batch. #running-req: 4, #token: 429, token usage: 0.00, gen throughput (token/s): 26.52, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:42:07 TP0] Decode batch. #running-req: 4, #token: 589, token usage: 0.00, gen throughput (token/s): 869.16, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:42:07 TP0] Decode batch. #running-req: 4, #token: 749, token usage: 0.00, gen throughput (token/s): 859.06, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:42:07 TP0] Decode batch. #running-req: 4, #token: 909, token usage: 0.00, gen throughput (token/s): 852.37, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:42:07 TP0] Decode batch. #running-req: 4, #token: 1069, token usage: 0.00, gen throughput (token/s): 892.78, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:42:07 TP0] Decode batch. #running-req: 4, #token: 1229, token usage: 0.00, gen throughput (token/s): 859.98, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:42:08 TP0] Decode batch. #running-req: 4, #token: 1389, token usage: 0.00, gen throughput (token/s): 868.52, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:42:08 TP0] Decode batch. #running-req: 4, #token: 1549, token usage: 0.00, gen throughput (token/s): 873.88, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:42:08 TP0] Decode batch. #running-req: 4, #token: 1709, token usage: 0.00, gen throughput (token/s): 859.21, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:42:08 TP0] Decode batch. #running-req: 4, #token: 1869, token usage: 0.00, gen throughput (token/s): 852.08, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:42:08 TP0] Decode batch. #running-req: 4, #token: 2029, token usage: 0.00, gen throughput (token/s): 847.63, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:42:09 TP0] Decode batch. #running-req: 4, #token: 2189, token usage: 0.00, gen throughput (token/s): 859.14, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:42:09 TP0] Decode batch. #running-req: 4, #token: 2349, token usage: 0.00, gen throughput (token/s): 856.81, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:42:09 TP0] Decode batch. #running-req: 4, #token: 2509, token usage: 0.00, gen throughput (token/s): 828.28, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:42:09 TP0] Decode batch. #running-req: 4, #token: 2669, token usage: 0.00, gen throughput (token/s): 883.04, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:42:09 TP0] Decode batch. #running-req: 4, #token: 2829, token usage: 0.00, gen throughput (token/s): 840.17, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:42:09 TP0] Decode batch. #running-req: 4, #token: 2989, token usage: 0.00, gen throughput (token/s): 881.74, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:42:10 TP0] Decode batch. #running-req: 4, #token: 3149, token usage: 0.00, gen throughput (token/s): 823.49, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:42:10 TP0] Decode batch. #running-req: 4, #token: 3309, token usage: 0.00, gen throughput (token/s): 857.98, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:42:10 TP0] Decode batch. #running-req: 4, #token: 3469, token usage: 0.00, gen throughput (token/s): 830.71, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:42:10 TP0] Decode batch. #running-req: 4, #token: 3629, token usage: 0.00, gen throughput (token/s): 858.93, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:42:10 TP0] Decode batch. #running-req: 4, #token: 3789, token usage: 0.00, gen throughput (token/s): 867.51, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:42:11 TP0] Decode batch. #running-req: 4, #token: 3949, token usage: 0.00, gen throughput (token/s): 843.41, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:42:11 TP0] Decode batch. #running-req: 4, #token: 4109, token usage: 0.00, gen throughput (token/s): 830.40, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:42:11 TP0] Decode batch. #running-req: 4, #token: 4269, token usage: 0.00, gen throughput (token/s): 825.11, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:42:11] INFO:     127.0.0.1:36332 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:42:11] INFO:     127.0.0.1:36334 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:42:11] INFO:     127.0.0.1:36340 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:42:11] INFO:     127.0.0.1:36348 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:42:11 TP0] Prefill batch. #new-seq: 4, #new-token: 4, #cached-token: 1232, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-08-25 15:42:11 TP0] Decode batch. #running-req: 4, #token: 429, token usage: 0.00, gen throughput (token/s): 598.84, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:42:11 TP0] Decode batch. #running-req: 4, #token: 589, token usage: 0.00, gen throughput (token/s): 867.49, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:42:12 TP0] Decode batch. #running-req: 4, #token: 749, token usage: 0.00, gen throughput (token/s): 849.83, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:42:12 TP0] Decode batch. #running-req: 4, #token: 909, token usage: 0.00, gen throughput (token/s): 876.05, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:42:12 TP0] Decode batch. #running-req: 4, #token: 1069, token usage: 0.00, gen throughput (token/s): 865.90, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:42:12 TP0] Decode batch. #running-req: 4, #token: 1229, token usage: 0.00, gen throughput (token/s): 850.43, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:42:12 TP0] Decode batch. #running-req: 4, #token: 1389, token usage: 0.00, gen throughput (token/s): 875.39, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:42:13 TP0] Decode batch. #running-req: 4, #token: 1549, token usage: 0.00, gen throughput (token/s): 853.31, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:42:13 TP0] Decode batch. #running-req: 4, #token: 1709, token usage: 0.00, gen throughput (token/s): 847.74, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:42:13 TP0] Decode batch. #running-req: 4, #token: 1869, token usage: 0.00, gen throughput (token/s): 885.60, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:42:13 TP0] Decode batch. #running-req: 4, #token: 2029, token usage: 0.00, gen throughput (token/s): 863.27, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:42:13 TP0] Decode batch. #running-req: 4, #token: 2189, token usage: 0.00, gen throughput (token/s): 829.38, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:42:13 TP0] Decode batch. #running-req: 4, #token: 2349, token usage: 0.00, gen throughput (token/s): 855.17, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:42:14 TP0] Decode batch. #running-req: 4, #token: 2509, token usage: 0.00, gen throughput (token/s): 853.15, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:42:14 TP0] Decode batch. #running-req: 4, #token: 2669, token usage: 0.00, gen throughput (token/s): 887.71, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:42:14 TP0] Decode batch. #running-req: 4, #token: 2829, token usage: 0.00, gen throughput (token/s): 854.27, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:42:14 TP0] Decode batch. #running-req: 4, #token: 2989, token usage: 0.00, gen throughput (token/s): 850.38, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:42:14 TP0] Decode batch. #running-req: 4, #token: 3149, token usage: 0.00, gen throughput (token/s): 852.42, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:42:15 TP0] Decode batch. #running-req: 4, #token: 3309, token usage: 0.00, gen throughput (token/s): 850.67, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:42:15 TP0] Decode batch. #running-req: 4, #token: 3469, token usage: 0.00, gen throughput (token/s): 899.59, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:42:15 TP0] Decode batch. #running-req: 4, #token: 3629, token usage: 0.00, gen throughput (token/s): 865.05, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:42:15 TP0] Decode batch. #running-req: 4, #token: 3789, token usage: 0.00, gen throughput (token/s): 874.74, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:42:15 TP0] Decode batch. #running-req: 4, #token: 3949, token usage: 0.00, gen throughput (token/s): 847.56, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:42:15 TP0] Decode batch. #running-req: 4, #token: 4109, token usage: 0.00, gen throughput (token/s): 875.98, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:42:16 TP0] Decode batch. #running-req: 4, #token: 4269, token usage: 0.00, gen throughput (token/s): 877.32, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:42:16] INFO:     127.0.0.1:36348 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:42:16] INFO:     127.0.0.1:36332 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:42:16] INFO:     127.0.0.1:36334 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:42:16] INFO:     127.0.0.1:36340 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:42:16 TP0] Prefill batch. #new-seq: 3, #new-token: 3, #cached-token: 924, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-08-25 15:42:16 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 308, token usage: 0.00, #running-req: 3, #queue-req: 0, 
[2025-08-25 15:42:16 TP0] Decode batch. #running-req: 4, #token: 429, token usage: 0.00, gen throughput (token/s): 577.66, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:42:16 TP0] Decode batch. #running-req: 4, #token: 589, token usage: 0.00, gen throughput (token/s): 894.53, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:42:16 TP0] Decode batch. #running-req: 4, #token: 749, token usage: 0.00, gen throughput (token/s): 885.19, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:42:16 TP0] Decode batch. #running-req: 4, #token: 909, token usage: 0.00, gen throughput (token/s): 905.13, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:42:17 TP0] Decode batch. #running-req: 4, #token: 1069, token usage: 0.00, gen throughput (token/s): 913.52, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:42:17 TP0] Decode batch. #running-req: 4, #token: 1229, token usage: 0.00, gen throughput (token/s): 911.06, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:42:17 TP0] Decode batch. #running-req: 4, #token: 1389, token usage: 0.00, gen throughput (token/s): 898.87, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:42:17 TP0] Decode batch. #running-req: 4, #token: 1549, token usage: 0.00, gen throughput (token/s): 904.67, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:42:17 TP0] Decode batch. #running-req: 4, #token: 1709, token usage: 0.00, gen throughput (token/s): 886.64, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:42:18 TP0] Decode batch. #running-req: 4, #token: 1869, token usage: 0.00, gen throughput (token/s): 870.44, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:42:18 TP0] Decode batch. #running-req: 4, #token: 2029, token usage: 0.00, gen throughput (token/s): 895.77, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:42:18 TP0] Decode batch. #running-req: 4, #token: 2189, token usage: 0.00, gen throughput (token/s): 891.73, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:42:18 TP0] Decode batch. #running-req: 4, #token: 2349, token usage: 0.00, gen throughput (token/s): 852.30, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:42:18 TP0] Decode batch. #running-req: 4, #token: 2509, token usage: 0.00, gen throughput (token/s): 909.18, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:42:18 TP0] Decode batch. #running-req: 4, #token: 2669, token usage: 0.00, gen throughput (token/s): 909.65, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:42:19 TP0] Decode batch. #running-req: 4, #token: 2829, token usage: 0.00, gen throughput (token/s): 901.71, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:42:19 TP0] Decode batch. #running-req: 4, #token: 2989, token usage: 0.00, gen throughput (token/s): 890.02, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:42:19 TP0] Decode batch. #running-req: 4, #token: 3149, token usage: 0.00, gen throughput (token/s): 908.05, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:42:19 TP0] Decode batch. #running-req: 4, #token: 3309, token usage: 0.00, gen throughput (token/s): 882.45, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:42:19 TP0] Decode batch. #running-req: 4, #token: 3469, token usage: 0.00, gen throughput (token/s): 902.23, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:42:20 TP0] Decode batch. #running-req: 4, #token: 3629, token usage: 0.00, gen throughput (token/s): 862.49, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:42:20 TP0] Decode batch. #running-req: 4, #token: 3789, token usage: 0.00, gen throughput (token/s): 869.43, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:42:20 TP0] Decode batch. #running-req: 4, #token: 3949, token usage: 0.00, gen throughput (token/s): 876.63, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:42:20 TP0] Decode batch. #running-req: 4, #token: 4109, token usage: 0.00, gen throughput (token/s): 873.48, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:42:20 TP0] Decode batch. #running-req: 4, #token: 4269, token usage: 0.00, gen throughput (token/s): 867.12, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:42:20] INFO:     127.0.0.1:36348 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:42:20] INFO:     127.0.0.1:36332 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:42:20] INFO:     127.0.0.1:36334 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:42:20] INFO:     127.0.0.1:36340 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:42:20 TP0] Prefill batch. #new-seq: 4, #new-token: 4, #cached-token: 1232, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-08-25 15:42:21 TP0] Decode batch. #running-req: 4, #token: 429, token usage: 0.00, gen throughput (token/s): 639.10, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:42:21 TP0] Decode batch. #running-req: 4, #token: 589, token usage: 0.00, gen throughput (token/s): 881.41, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:42:21 TP0] Decode batch. #running-req: 4, #token: 749, token usage: 0.00, gen throughput (token/s): 885.65, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:42:21 TP0] Decode batch. #running-req: 4, #token: 909, token usage: 0.00, gen throughput (token/s): 862.97, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:42:21 TP0] Decode batch. #running-req: 4, #token: 1069, token usage: 0.00, gen throughput (token/s): 847.82, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:42:21 TP0] Decode batch. #running-req: 4, #token: 1229, token usage: 0.00, gen throughput (token/s): 864.38, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:42:22 TP0] Decode batch. #running-req: 4, #token: 1389, token usage: 0.00, gen throughput (token/s): 874.48, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:42:22 TP0] Decode batch. #running-req: 4, #token: 1549, token usage: 0.00, gen throughput (token/s): 871.02, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:42:22 TP0] Decode batch. #running-req: 4, #token: 1709, token usage: 0.00, gen throughput (token/s): 855.51, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:42:22 TP0] Decode batch. #running-req: 4, #token: 1869, token usage: 0.00, gen throughput (token/s): 890.97, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:42:22 TP0] Decode batch. #running-req: 4, #token: 2029, token usage: 0.00, gen throughput (token/s): 874.20, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:42:23 TP0] Decode batch. #running-req: 4, #token: 2189, token usage: 0.00, gen throughput (token/s): 873.77, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:42:23 TP0] Decode batch. #running-req: 4, #token: 2349, token usage: 0.00, gen throughput (token/s): 876.19, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:42:23 TP0] Decode batch. #running-req: 4, #token: 2509, token usage: 0.00, gen throughput (token/s): 853.79, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:42:23 TP0] Decode batch. #running-req: 4, #token: 2669, token usage: 0.00, gen throughput (token/s): 890.93, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:42:23 TP0] Decode batch. #running-req: 4, #token: 2829, token usage: 0.00, gen throughput (token/s): 843.69, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:42:23 TP0] Decode batch. #running-req: 4, #token: 2989, token usage: 0.00, gen throughput (token/s): 846.59, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:42:24 TP0] Decode batch. #running-req: 4, #token: 3149, token usage: 0.00, gen throughput (token/s): 883.14, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:42:24 TP0] Decode batch. #running-req: 4, #token: 3309, token usage: 0.00, gen throughput (token/s): 878.95, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:42:24 TP0] Decode batch. #running-req: 4, #token: 3469, token usage: 0.00, gen throughput (token/s): 861.62, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:42:24 TP0] Decode batch. #running-req: 4, #token: 3629, token usage: 0.00, gen throughput (token/s): 866.93, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:42:24 TP0] Decode batch. #running-req: 4, #token: 3789, token usage: 0.00, gen throughput (token/s): 863.68, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:42:25 TP0] Decode batch. #running-req: 4, #token: 3949, token usage: 0.00, gen throughput (token/s): 873.37, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:42:25 TP0] Decode batch. #running-req: 4, #token: 4109, token usage: 0.00, gen throughput (token/s): 872.14, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:42:25 TP0] Decode batch. #running-req: 4, #token: 4269, token usage: 0.00, gen throughput (token/s): 891.41, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:42:25] INFO:     127.0.0.1:36348 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:42:25] INFO:     127.0.0.1:36332 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:42:25] INFO:     127.0.0.1:36334 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:42:25] INFO:     127.0.0.1:36340 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:42:25 TP0] Prefill batch. #new-seq: 3, #new-token: 3765, #cached-token: 129, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-08-25 15:42:25 TP0] Prefill batch. #new-seq: 1, #new-token: 1255, #cached-token: 43, token usage: 0.10, #running-req: 3, #queue-req: 0, 
[2025-08-25 15:42:27] INFO:     127.0.0.1:50390 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 15:42:27] INFO:     127.0.0.1:50402 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 15:42:27] INFO:     127.0.0.1:50414 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 15:42:27 TP0] Prefill batch. #new-seq: 1, #new-token: 1000, #cached-token: 298, token usage: 0.01, #running-req: 0, #queue-req: 0, 
[2025-08-25 15:42:27 TP0] Prefill batch. #new-seq: 1, #new-token: 1000, #cached-token: 298, token usage: 0.03, #running-req: 1, #queue-req: 0, 
[2025-08-25 15:42:27] INFO:     127.0.0.1:50418 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 15:42:27 TP0] Prefill batch. #new-seq: 2, #new-token: 2000, #cached-token: 596, token usage: 0.03, #running-req: 2, #queue-req: 0, 
[2025-08-25 15:42:27] INFO:     127.0.0.1:50390 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 15:42:27] INFO:     127.0.0.1:50402 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 15:42:28 TP0] Prefill batch. #new-seq: 2, #new-token: 2000, #cached-token: 596, token usage: 0.01, #running-req: 2, #queue-req: 0, 
[2025-08-25 15:42:28] INFO:     127.0.0.1:50414 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 15:42:28] INFO:     127.0.0.1:50418 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 15:42:29 TP0] Prefill batch. #new-seq: 2, #new-token: 2000, #cached-token: 596, token usage: 0.06, #running-req: 4, #queue-req: 0, 
[2025-08-25 15:42:29] INFO:     127.0.0.1:50390 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 15:42:29] INFO:     127.0.0.1:50402 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 15:42:29 TP0] Prefill batch. #new-seq: 2, #new-token: 2000, #cached-token: 596, token usage: 0.01, #running-req: 2, #queue-req: 0, 
[2025-08-25 15:42:29] INFO:     127.0.0.1:50414 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 15:42:29] INFO:     127.0.0.1:50418 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 15:42:30 TP0] Prefill batch. #new-seq: 2, #new-token: 2000, #cached-token: 596, token usage: 0.06, #running-req: 4, #queue-req: 0, 
[2025-08-25 15:42:30] INFO:     127.0.0.1:50390 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 15:42:30] INFO:     127.0.0.1:50402 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 15:42:31 TP0] Prefill batch. #new-seq: 2, #new-token: 2614, #cached-token: 0, token usage: 0.00, #running-req: 2, #queue-req: 0, 
[2025-08-25 15:42:31] INFO:     127.0.0.1:50414 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 15:42:31] INFO:     127.0.0.1:50418 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 15:42:31 TP0] Prefill batch. #new-seq: 2, #new-token: 2614, #cached-token: 0, token usage: 0.07, #running-req: 4, #queue-req: 0, 
[2025-08-25 15:42:34 TP0] Decode batch. #running-req: 4, #token: 4418, token usage: 0.11, gen throughput (token/s): 4.83, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:42:36 TP0] Decode batch. #running-req: 4, #token: 4578, token usage: 0.11, gen throughput (token/s): 87.43, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:42:37 TP0] Decode batch. #running-req: 4, #token: 4738, token usage: 0.12, gen throughput (token/s): 87.48, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:42:39] INFO:     127.0.0.1:50390 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:42:39] INFO:     127.0.0.1:50402 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:42:39] INFO:     127.0.0.1:50414 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:42:39] INFO:     127.0.0.1:50418 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:42:39 TP0] Prefill batch. #new-seq: 3, #new-token: 2930, #cached-token: 991, token usage: 0.01, #running-req: 0, #queue-req: 0, 
[2025-08-25 15:42:39 TP0] Prefill batch. #new-seq: 1, #new-token: 1000, #cached-token: 307, token usage: 0.08, #running-req: 3, #queue-req: 0, 
[2025-08-25 15:42:40 TP0] Decode batch. #running-req: 4, #token: 4290, token usage: 0.11, gen throughput (token/s): 52.90, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:42:42 TP0] Decode batch. #running-req: 4, #token: 4450, token usage: 0.11, gen throughput (token/s): 87.52, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:42:44 TP0] Decode batch. #running-req: 4, #token: 4610, token usage: 0.12, gen throughput (token/s): 87.47, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:42:46 TP0] Decode batch. #running-req: 4, #token: 4770, token usage: 0.12, gen throughput (token/s): 87.36, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:42:47] INFO:     127.0.0.1:50418 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:42:47] INFO:     127.0.0.1:50390 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:42:47] INFO:     127.0.0.1:50402 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:42:47] INFO:     127.0.0.1:50414 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:42:47 TP0] Prefill batch. #new-seq: 2, #new-token: 1975, #cached-token: 639, token usage: 0.01, #running-req: 0, #queue-req: 0, 
[2025-08-25 15:42:47 TP0] Prefill batch. #new-seq: 2, #new-token: 1970, #cached-token: 644, token usage: 0.06, #running-req: 2, #queue-req: 0, 
[2025-08-25 15:42:49 TP0] Decode batch. #running-req: 4, #token: 4356, token usage: 0.11, gen throughput (token/s): 52.85, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:42:51 TP0] Decode batch. #running-req: 4, #token: 4516, token usage: 0.11, gen throughput (token/s): 86.86, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:42:53 TP0] Decode batch. #running-req: 4, #token: 4676, token usage: 0.12, gen throughput (token/s): 87.08, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:42:54 TP0] Decode batch. #running-req: 4, #token: 4836, token usage: 0.12, gen throughput (token/s): 87.15, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:42:55] INFO:     127.0.0.1:50418 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:42:55] INFO:     127.0.0.1:50390 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:42:55] INFO:     127.0.0.1:50402 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:42:55] INFO:     127.0.0.1:50414 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:42:55 TP0] Prefill batch. #new-seq: 3, #new-token: 2978, #cached-token: 943, token usage: 0.01, #running-req: 0, #queue-req: 0, 
[2025-08-25 15:42:57 TP0] Decode batch. #running-req: 3, #token: 3376, token usage: 0.08, gen throughput (token/s): 49.65, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:42:59 TP0] Decode batch. #running-req: 3, #token: 3496, token usage: 0.09, gen throughput (token/s): 65.39, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:43:01 TP0] Decode batch. #running-req: 3, #token: 3616, token usage: 0.09, gen throughput (token/s): 65.66, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:43:03 TP0] Decode batch. #running-req: 3, #token: 3736, token usage: 0.09, gen throughput (token/s): 65.60, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:43:03] INFO:     127.0.0.1:50418 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:43:03] INFO:     127.0.0.1:50390 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:43:03] INFO:     127.0.0.1:50402 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:43:03 TP0] Prefill batch. #new-seq: 4, #new-token: 4, #cached-token: 1008, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-08-25 15:43:03 TP0] Decode batch. #running-req: 4, #token: 373, token usage: 0.00, gen throughput (token/s): 4.19, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:43:03 TP0] Decode batch. #running-req: 4, #token: 533, token usage: 0.00, gen throughput (token/s): 860.78, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:43:03 TP0] Decode batch. #running-req: 4, #token: 693, token usage: 0.00, gen throughput (token/s): 885.25, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:43:04 TP0] Decode batch. #running-req: 4, #token: 853, token usage: 0.00, gen throughput (token/s): 874.77, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:43:04 TP0] Decode batch. #running-req: 4, #token: 1013, token usage: 0.00, gen throughput (token/s): 892.49, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:43:04 TP0] Decode batch. #running-req: 4, #token: 1173, token usage: 0.00, gen throughput (token/s): 874.78, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:43:04 TP0] Decode batch. #running-req: 4, #token: 1333, token usage: 0.00, gen throughput (token/s): 847.10, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:43:04 TP0] Decode batch. #running-req: 4, #token: 1493, token usage: 0.00, gen throughput (token/s): 856.52, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:43:05 TP0] Decode batch. #running-req: 4, #token: 1653, token usage: 0.00, gen throughput (token/s): 873.18, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:43:05 TP0] Decode batch. #running-req: 4, #token: 1813, token usage: 0.00, gen throughput (token/s): 908.21, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:43:05 TP0] Decode batch. #running-req: 4, #token: 1973, token usage: 0.00, gen throughput (token/s): 895.11, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:43:05 TP0] Decode batch. #running-req: 4, #token: 2133, token usage: 0.00, gen throughput (token/s): 911.33, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:43:05 TP0] Decode batch. #running-req: 4, #token: 2293, token usage: 0.00, gen throughput (token/s): 887.73, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:43:05 TP0] Decode batch. #running-req: 4, #token: 2453, token usage: 0.00, gen throughput (token/s): 858.85, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:43:06 TP0] Decode batch. #running-req: 4, #token: 2613, token usage: 0.00, gen throughput (token/s): 886.02, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:43:06 TP0] Decode batch. #running-req: 4, #token: 2773, token usage: 0.00, gen throughput (token/s): 902.16, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:43:06 TP0] Decode batch. #running-req: 4, #token: 2933, token usage: 0.00, gen throughput (token/s): 855.37, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:43:06 TP0] Decode batch. #running-req: 4, #token: 3093, token usage: 0.00, gen throughput (token/s): 867.49, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:43:06 TP0] Decode batch. #running-req: 4, #token: 3253, token usage: 0.00, gen throughput (token/s): 862.82, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:43:07 TP0] Decode batch. #running-req: 4, #token: 3413, token usage: 0.00, gen throughput (token/s): 872.58, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:43:07 TP0] Decode batch. #running-req: 4, #token: 3573, token usage: 0.00, gen throughput (token/s): 874.17, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:43:07 TP0] Decode batch. #running-req: 4, #token: 3733, token usage: 0.00, gen throughput (token/s): 840.69, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:43:07 TP0] Decode batch. #running-req: 4, #token: 3893, token usage: 0.00, gen throughput (token/s): 878.16, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:43:07 TP0] Decode batch. #running-req: 4, #token: 4053, token usage: 0.00, gen throughput (token/s): 864.71, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:43:08 TP0] Decode batch. #running-req: 4, #token: 4213, token usage: 0.00, gen throughput (token/s): 872.21, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:43:08] INFO:     127.0.0.1:54958 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:43:08] INFO:     127.0.0.1:54960 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:43:08] INFO:     127.0.0.1:54966 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:43:08] INFO:     127.0.0.1:54982 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:43:08 TP0] Prefill batch. #new-seq: 3, #new-token: 3, #cached-token: 756, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-08-25 15:43:08 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 252, token usage: 0.00, #running-req: 3, #queue-req: 0, 
[2025-08-25 15:43:08 TP0] Decode batch. #running-req: 4, #token: 373, token usage: 0.00, gen throughput (token/s): 582.13, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:43:08 TP0] Decode batch. #running-req: 4, #token: 533, token usage: 0.00, gen throughput (token/s): 883.24, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:43:08 TP0] Decode batch. #running-req: 4, #token: 693, token usage: 0.00, gen throughput (token/s): 877.52, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:43:08 TP0] Decode batch. #running-req: 4, #token: 853, token usage: 0.00, gen throughput (token/s): 875.32, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:43:09 TP0] Decode batch. #running-req: 4, #token: 1013, token usage: 0.00, gen throughput (token/s): 882.83, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:43:09 TP0] Decode batch. #running-req: 4, #token: 1173, token usage: 0.00, gen throughput (token/s): 863.58, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:43:09 TP0] Decode batch. #running-req: 4, #token: 1333, token usage: 0.00, gen throughput (token/s): 872.39, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:43:09 TP0] Decode batch. #running-req: 4, #token: 1493, token usage: 0.00, gen throughput (token/s): 877.33, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:43:09 TP0] Decode batch. #running-req: 4, #token: 1653, token usage: 0.00, gen throughput (token/s): 884.69, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:43:09 TP0] Decode batch. #running-req: 4, #token: 1813, token usage: 0.00, gen throughput (token/s): 884.66, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:43:10 TP0] Decode batch. #running-req: 4, #token: 1973, token usage: 0.00, gen throughput (token/s): 890.97, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:43:10 TP0] Decode batch. #running-req: 4, #token: 2133, token usage: 0.00, gen throughput (token/s): 889.27, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:43:10 TP0] Decode batch. #running-req: 4, #token: 2293, token usage: 0.00, gen throughput (token/s): 879.55, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:43:10 TP0] Decode batch. #running-req: 4, #token: 2453, token usage: 0.00, gen throughput (token/s): 886.21, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:43:10 TP0] Decode batch. #running-req: 4, #token: 2613, token usage: 0.00, gen throughput (token/s): 880.15, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:43:11 TP0] Decode batch. #running-req: 4, #token: 2773, token usage: 0.00, gen throughput (token/s): 886.66, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:43:11 TP0] Decode batch. #running-req: 4, #token: 2933, token usage: 0.00, gen throughput (token/s): 877.20, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:43:11 TP0] Decode batch. #running-req: 4, #token: 3093, token usage: 0.00, gen throughput (token/s): 891.87, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:43:11 TP0] Decode batch. #running-req: 4, #token: 3253, token usage: 0.00, gen throughput (token/s): 880.25, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:43:11 TP0] Decode batch. #running-req: 4, #token: 3413, token usage: 0.00, gen throughput (token/s): 901.20, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:43:11 TP0] Decode batch. #running-req: 4, #token: 3573, token usage: 0.00, gen throughput (token/s): 876.70, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:43:12 TP0] Decode batch. #running-req: 4, #token: 3733, token usage: 0.00, gen throughput (token/s): 890.28, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:43:12 TP0] Decode batch. #running-req: 4, #token: 3893, token usage: 0.00, gen throughput (token/s): 878.32, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:43:12 TP0] Decode batch. #running-req: 4, #token: 4053, token usage: 0.00, gen throughput (token/s): 874.28, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:43:12 TP0] Decode batch. #running-req: 4, #token: 4213, token usage: 0.00, gen throughput (token/s): 892.72, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:43:12] INFO:     127.0.0.1:54982 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:43:12] INFO:     127.0.0.1:54958 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:43:12] INFO:     127.0.0.1:54960 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:43:12] INFO:     127.0.0.1:54966 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:43:12 TP0] Prefill batch. #new-seq: 4, #new-token: 4, #cached-token: 1008, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-08-25 15:43:12 TP0] Decode batch. #running-req: 4, #token: 373, token usage: 0.00, gen throughput (token/s): 652.64, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:43:13 TP0] Decode batch. #running-req: 4, #token: 533, token usage: 0.00, gen throughput (token/s): 888.83, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:43:13 TP0] Decode batch. #running-req: 4, #token: 693, token usage: 0.00, gen throughput (token/s): 893.13, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:43:13 TP0] Decode batch. #running-req: 4, #token: 853, token usage: 0.00, gen throughput (token/s): 890.29, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:43:13 TP0] Decode batch. #running-req: 4, #token: 1013, token usage: 0.00, gen throughput (token/s): 896.45, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:43:13 TP0] Decode batch. #running-req: 4, #token: 1173, token usage: 0.00, gen throughput (token/s): 876.37, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:43:13 TP0] Decode batch. #running-req: 4, #token: 1333, token usage: 0.00, gen throughput (token/s): 888.16, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:43:14 TP0] Decode batch. #running-req: 4, #token: 1493, token usage: 0.00, gen throughput (token/s): 860.95, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:43:14 TP0] Decode batch. #running-req: 4, #token: 1653, token usage: 0.00, gen throughput (token/s): 871.28, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:43:14 TP0] Decode batch. #running-req: 4, #token: 1813, token usage: 0.00, gen throughput (token/s): 877.35, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:43:14 TP0] Decode batch. #running-req: 4, #token: 1973, token usage: 0.00, gen throughput (token/s): 887.24, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:43:14 TP0] Decode batch. #running-req: 4, #token: 2133, token usage: 0.00, gen throughput (token/s): 860.20, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:43:15 TP0] Decode batch. #running-req: 4, #token: 2293, token usage: 0.00, gen throughput (token/s): 881.52, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:43:15 TP0] Decode batch. #running-req: 4, #token: 2453, token usage: 0.00, gen throughput (token/s): 909.16, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:43:15 TP0] Decode batch. #running-req: 4, #token: 2613, token usage: 0.00, gen throughput (token/s): 905.35, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:43:15 TP0] Decode batch. #running-req: 4, #token: 2773, token usage: 0.00, gen throughput (token/s): 894.95, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:43:15 TP0] Decode batch. #running-req: 4, #token: 2933, token usage: 0.00, gen throughput (token/s): 902.09, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:43:15 TP0] Decode batch. #running-req: 4, #token: 3093, token usage: 0.00, gen throughput (token/s): 895.96, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:43:16 TP0] Decode batch. #running-req: 4, #token: 3253, token usage: 0.00, gen throughput (token/s): 889.78, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:43:16 TP0] Decode batch. #running-req: 4, #token: 3413, token usage: 0.00, gen throughput (token/s): 896.21, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:43:16 TP0] Decode batch. #running-req: 4, #token: 3573, token usage: 0.00, gen throughput (token/s): 915.47, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:43:16 TP0] Decode batch. #running-req: 4, #token: 3733, token usage: 0.00, gen throughput (token/s): 908.54, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:43:16 TP0] Decode batch. #running-req: 4, #token: 3893, token usage: 0.00, gen throughput (token/s): 906.75, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:43:17 TP0] Decode batch. #running-req: 4, #token: 4053, token usage: 0.00, gen throughput (token/s): 893.28, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:43:17 TP0] Decode batch. #running-req: 4, #token: 4213, token usage: 0.00, gen throughput (token/s): 890.64, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:43:17] INFO:     127.0.0.1:54982 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:43:17] INFO:     127.0.0.1:54958 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:43:17] INFO:     127.0.0.1:54960 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:43:17] INFO:     127.0.0.1:54966 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:43:17 TP0] Prefill batch. #new-seq: 4, #new-token: 4, #cached-token: 1008, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-08-25 15:43:17 TP0] Decode batch. #running-req: 4, #token: 373, token usage: 0.00, gen throughput (token/s): 624.92, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:43:17 TP0] Decode batch. #running-req: 4, #token: 533, token usage: 0.00, gen throughput (token/s): 868.20, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:43:17 TP0] Decode batch. #running-req: 4, #token: 693, token usage: 0.00, gen throughput (token/s): 884.67, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:43:17 TP0] Decode batch. #running-req: 4, #token: 853, token usage: 0.00, gen throughput (token/s): 885.43, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:43:18 TP0] Decode batch. #running-req: 4, #token: 1013, token usage: 0.00, gen throughput (token/s): 898.74, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:43:18 TP0] Decode batch. #running-req: 4, #token: 1173, token usage: 0.00, gen throughput (token/s): 889.70, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:43:18 TP0] Decode batch. #running-req: 4, #token: 1333, token usage: 0.00, gen throughput (token/s): 866.05, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:43:18 TP0] Decode batch. #running-req: 4, #token: 1493, token usage: 0.00, gen throughput (token/s): 881.24, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:43:18 TP0] Decode batch. #running-req: 4, #token: 1653, token usage: 0.00, gen throughput (token/s): 850.71, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:43:19 TP0] Decode batch. #running-req: 4, #token: 1813, token usage: 0.00, gen throughput (token/s): 882.65, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:43:19 TP0] Decode batch. #running-req: 4, #token: 1973, token usage: 0.00, gen throughput (token/s): 883.18, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:43:19 TP0] Decode batch. #running-req: 4, #token: 2133, token usage: 0.00, gen throughput (token/s): 885.94, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:43:19 TP0] Decode batch. #running-req: 4, #token: 2293, token usage: 0.00, gen throughput (token/s): 900.94, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:43:19 TP0] Decode batch. #running-req: 4, #token: 2453, token usage: 0.00, gen throughput (token/s): 899.64, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:43:19 TP0] Decode batch. #running-req: 4, #token: 2613, token usage: 0.00, gen throughput (token/s): 887.14, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:43:20 TP0] Decode batch. #running-req: 4, #token: 2773, token usage: 0.00, gen throughput (token/s): 873.00, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:43:20 TP0] Decode batch. #running-req: 4, #token: 2933, token usage: 0.00, gen throughput (token/s): 880.01, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:43:20 TP0] Decode batch. #running-req: 4, #token: 3093, token usage: 0.00, gen throughput (token/s): 892.82, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:43:20 TP0] Decode batch. #running-req: 4, #token: 3253, token usage: 0.00, gen throughput (token/s): 888.41, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:43:20 TP0] Decode batch. #running-req: 4, #token: 3413, token usage: 0.00, gen throughput (token/s): 870.20, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:43:21 TP0] Decode batch. #running-req: 4, #token: 3573, token usage: 0.00, gen throughput (token/s): 879.19, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:43:21 TP0] Decode batch. #running-req: 4, #token: 3733, token usage: 0.00, gen throughput (token/s): 877.98, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:43:21 TP0] Decode batch. #running-req: 4, #token: 3893, token usage: 0.00, gen throughput (token/s): 884.27, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:43:21 TP0] Decode batch. #running-req: 4, #token: 4053, token usage: 0.00, gen throughput (token/s): 873.18, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:43:21 TP0] Decode batch. #running-req: 4, #token: 4213, token usage: 0.00, gen throughput (token/s): 884.93, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:43:21] INFO:     127.0.0.1:54982 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:43:21] INFO:     127.0.0.1:54958 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:43:21] INFO:     127.0.0.1:54960 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:43:21] INFO:     127.0.0.1:54966 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:43:21 TP0] Prefill batch. #new-seq: 1, #new-token: 1200, #cached-token: 42, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-08-25 15:43:21 TP0] Prefill batch. #new-seq: 3, #new-token: 3600, #cached-token: 126, token usage: 0.03, #running-req: 1, #queue-req: 0, 
[2025-08-25 15:43:22] INFO:     127.0.0.1:33216 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 15:43:23 TP0] Prefill batch. #new-seq: 1, #new-token: 1000, #cached-token: 242, token usage: 0.01, #running-req: 3, #queue-req: 0, 
[2025-08-25 15:43:23] INFO:     127.0.0.1:33226 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 15:43:23] INFO:     127.0.0.1:33240 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 15:43:23] INFO:     127.0.0.1:33242 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 15:43:23 TP0] Prefill batch. #new-seq: 3, #new-token: 3000, #cached-token: 726, token usage: 0.03, #running-req: 4, #queue-req: 0, 
[2025-08-25 15:43:23] INFO:     127.0.0.1:33216 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 15:43:25 TP0] Prefill batch. #new-seq: 1, #new-token: 1000, #cached-token: 242, token usage: 0.01, #running-req: 3, #queue-req: 0, 
[2025-08-25 15:43:25] INFO:     127.0.0.1:33226 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 15:43:25] INFO:     127.0.0.1:33240 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 15:43:25] INFO:     127.0.0.1:33242 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 15:43:25 TP0] Prefill batch. #new-seq: 3, #new-token: 3000, #cached-token: 726, token usage: 0.03, #running-req: 4, #queue-req: 0, 
[2025-08-25 15:43:25] INFO:     127.0.0.1:33216 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 15:43:26 TP0] Prefill batch. #new-seq: 1, #new-token: 1000, #cached-token: 242, token usage: 0.01, #running-req: 3, #queue-req: 0, 
[2025-08-25 15:43:26] INFO:     127.0.0.1:33226 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 15:43:26] INFO:     127.0.0.1:33240 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 15:43:26] INFO:     127.0.0.1:33242 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 15:43:26 TP0] Prefill batch. #new-seq: 3, #new-token: 3000, #cached-token: 726, token usage: 0.03, #running-req: 4, #queue-req: 0, 
[2025-08-25 15:43:26] INFO:     127.0.0.1:33216 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 15:43:27 TP0] Prefill batch. #new-seq: 1, #new-token: 1207, #cached-token: 44, token usage: 0.00, #running-req: 3, #queue-req: 0, 
[2025-08-25 15:43:27] INFO:     127.0.0.1:33226 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 15:43:27] INFO:     127.0.0.1:33240 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 15:43:28] INFO:     127.0.0.1:33242 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 15:43:28 TP0] Prefill batch. #new-seq: 3, #new-token: 2970, #cached-token: 783, token usage: 0.03, #running-req: 1, #queue-req: 0, 
[2025-08-25 15:43:30 TP0] Decode batch. #running-req: 4, #token: 4342, token usage: 0.11, gen throughput (token/s): 5.36, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:43:32 TP0] Decode batch. #running-req: 4, #token: 4502, token usage: 0.11, gen throughput (token/s): 87.54, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:43:34 TP0] Decode batch. #running-req: 4, #token: 4662, token usage: 0.12, gen throughput (token/s): 87.43, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:43:36] INFO:     127.0.0.1:33216 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:43:36] INFO:     127.0.0.1:33226 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:43:36] INFO:     127.0.0.1:33240 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:43:36] INFO:     127.0.0.1:33242 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:43:36 TP0] Decode batch. #running-req: 3, #token: 3, token usage: 0.00, gen throughput (token/s): 87.32, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:43:36 TP0] Prefill batch. #new-seq: 1, #new-token: 996, #cached-token: 255, token usage: 0.01, #running-req: 3, #queue-req: 0, 
[2025-08-25 15:43:38 TP0] Decode batch. #running-req: 1, #token: 1291, token usage: 0.03, gen throughput (token/s): 20.29, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:43:39 TP0] Decode batch. #running-req: 1, #token: 1331, token usage: 0.03, gen throughput (token/s): 22.65, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:43:41 TP0] Decode batch. #running-req: 1, #token: 1371, token usage: 0.03, gen throughput (token/s): 22.55, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:43:43] INFO:     127.0.0.1:33216 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:43:43 TP0] Prefill batch. #new-seq: 4, #new-token: 4, #cached-token: 652, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-08-25 15:43:43 TP0] Decode batch. #running-req: 4, #token: 284, token usage: 0.00, gen throughput (token/s): 7.47, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:43:43 TP0] Decode batch. #running-req: 4, #token: 444, token usage: 0.00, gen throughput (token/s): 883.30, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:43:43 TP0] Decode batch. #running-req: 4, #token: 604, token usage: 0.00, gen throughput (token/s): 894.51, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:43:43 TP0] Decode batch. #running-req: 4, #token: 764, token usage: 0.00, gen throughput (token/s): 875.02, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:43:43 TP0] Decode batch. #running-req: 4, #token: 924, token usage: 0.00, gen throughput (token/s): 882.32, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:43:44 TP0] Decode batch. #running-req: 4, #token: 1084, token usage: 0.00, gen throughput (token/s): 868.16, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:43:44 TP0] Decode batch. #running-req: 4, #token: 1244, token usage: 0.00, gen throughput (token/s): 879.86, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:43:44 TP0] Decode batch. #running-req: 4, #token: 1404, token usage: 0.00, gen throughput (token/s): 884.37, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:43:44 TP0] Decode batch. #running-req: 4, #token: 1564, token usage: 0.00, gen throughput (token/s): 876.88, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:43:44 TP0] Decode batch. #running-req: 4, #token: 1724, token usage: 0.00, gen throughput (token/s): 900.16, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:43:45 TP0] Decode batch. #running-req: 4, #token: 1884, token usage: 0.00, gen throughput (token/s): 889.79, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:43:45 TP0] Decode batch. #running-req: 4, #token: 2044, token usage: 0.00, gen throughput (token/s): 881.23, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:43:45 TP0] Decode batch. #running-req: 4, #token: 2204, token usage: 0.00, gen throughput (token/s): 849.67, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:43:45 TP0] Decode batch. #running-req: 4, #token: 2364, token usage: 0.00, gen throughput (token/s): 848.86, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:43:45 TP0] Decode batch. #running-req: 4, #token: 2524, token usage: 0.00, gen throughput (token/s): 875.49, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:43:45 TP0] Decode batch. #running-req: 4, #token: 2684, token usage: 0.00, gen throughput (token/s): 861.37, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:43:46 TP0] Decode batch. #running-req: 4, #token: 2844, token usage: 0.00, gen throughput (token/s): 844.83, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:43:46 TP0] Decode batch. #running-req: 4, #token: 3004, token usage: 0.00, gen throughput (token/s): 877.14, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:43:46 TP0] Decode batch. #running-req: 4, #token: 3164, token usage: 0.00, gen throughput (token/s): 878.74, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:43:46 TP0] Decode batch. #running-req: 4, #token: 3324, token usage: 0.00, gen throughput (token/s): 921.32, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:43:46 TP0] Decode batch. #running-req: 4, #token: 3484, token usage: 0.00, gen throughput (token/s): 909.08, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:43:47 TP0] Decode batch. #running-req: 4, #token: 3644, token usage: 0.00, gen throughput (token/s): 905.22, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:43:47 TP0] Decode batch. #running-req: 4, #token: 3804, token usage: 0.00, gen throughput (token/s): 898.33, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:43:47 TP0] Decode batch. #running-req: 4, #token: 3964, token usage: 0.00, gen throughput (token/s): 897.04, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:43:47 TP0] Decode batch. #running-req: 4, #token: 4124, token usage: 0.00, gen throughput (token/s): 888.77, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:43:47] INFO:     127.0.0.1:6156 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:43:47] INFO:     127.0.0.1:6164 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:43:47] INFO:     127.0.0.1:6168 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:43:47] INFO:     127.0.0.1:6174 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:43:47 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 163, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-08-25 15:43:47 TP0] Prefill batch. #new-seq: 3, #new-token: 3, #cached-token: 489, token usage: 0.00, #running-req: 1, #queue-req: 0, 
[2025-08-25 15:43:47 TP0] Decode batch. #running-req: 4, #token: 284, token usage: 0.00, gen throughput (token/s): 596.84, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:43:48 TP0] Decode batch. #running-req: 4, #token: 444, token usage: 0.00, gen throughput (token/s): 885.45, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:43:48 TP0] Decode batch. #running-req: 4, #token: 604, token usage: 0.00, gen throughput (token/s): 906.41, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:43:48 TP0] Decode batch. #running-req: 4, #token: 764, token usage: 0.00, gen throughput (token/s): 891.61, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:43:48 TP0] Decode batch. #running-req: 4, #token: 924, token usage: 0.00, gen throughput (token/s): 909.18, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:43:48 TP0] Decode batch. #running-req: 4, #token: 1084, token usage: 0.00, gen throughput (token/s): 888.99, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:43:48 TP0] Decode batch. #running-req: 4, #token: 1244, token usage: 0.00, gen throughput (token/s): 892.61, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:43:49 TP0] Decode batch. #running-req: 4, #token: 1404, token usage: 0.00, gen throughput (token/s): 912.13, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:43:49 TP0] Decode batch. #running-req: 4, #token: 1564, token usage: 0.00, gen throughput (token/s): 900.58, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:43:49 TP0] Decode batch. #running-req: 4, #token: 1724, token usage: 0.00, gen throughput (token/s): 905.67, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:43:49 TP0] Decode batch. #running-req: 4, #token: 1884, token usage: 0.00, gen throughput (token/s): 843.56, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:43:49 TP0] Decode batch. #running-req: 4, #token: 2044, token usage: 0.00, gen throughput (token/s): 850.04, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:43:50 TP0] Decode batch. #running-req: 4, #token: 2204, token usage: 0.00, gen throughput (token/s): 850.04, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:43:50 TP0] Decode batch. #running-req: 4, #token: 2364, token usage: 0.00, gen throughput (token/s): 862.67, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:43:50 TP0] Decode batch. #running-req: 4, #token: 2524, token usage: 0.00, gen throughput (token/s): 881.95, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:43:50 TP0] Decode batch. #running-req: 4, #token: 2684, token usage: 0.00, gen throughput (token/s): 874.72, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:43:50 TP0] Decode batch. #running-req: 4, #token: 2844, token usage: 0.00, gen throughput (token/s): 842.34, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:43:50 TP0] Decode batch. #running-req: 4, #token: 3004, token usage: 0.00, gen throughput (token/s): 903.22, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:43:51 TP0] Decode batch. #running-req: 4, #token: 3164, token usage: 0.00, gen throughput (token/s): 892.50, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:43:51 TP0] Decode batch. #running-req: 4, #token: 3324, token usage: 0.00, gen throughput (token/s): 923.20, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:43:51 TP0] Decode batch. #running-req: 4, #token: 3484, token usage: 0.00, gen throughput (token/s): 906.00, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:43:51 TP0] Decode batch. #running-req: 4, #token: 3644, token usage: 0.00, gen throughput (token/s): 902.74, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:43:51 TP0] Decode batch. #running-req: 4, #token: 3804, token usage: 0.00, gen throughput (token/s): 902.14, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:43:51 TP0] Decode batch. #running-req: 4, #token: 3964, token usage: 0.00, gen throughput (token/s): 900.66, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:43:52 TP0] Decode batch. #running-req: 4, #token: 4124, token usage: 0.00, gen throughput (token/s): 905.06, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:43:52] INFO:     127.0.0.1:6174 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:43:52] INFO:     127.0.0.1:6156 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:43:52] INFO:     127.0.0.1:6164 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:43:52] INFO:     127.0.0.1:6168 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:43:52 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 163, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-08-25 15:43:52 TP0] Prefill batch. #new-seq: 3, #new-token: 3, #cached-token: 489, token usage: 0.00, #running-req: 1, #queue-req: 0, 
[2025-08-25 15:43:52 TP0] Decode batch. #running-req: 4, #token: 284, token usage: 0.00, gen throughput (token/s): 592.24, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:43:52 TP0] Decode batch. #running-req: 4, #token: 444, token usage: 0.00, gen throughput (token/s): 911.68, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:43:52 TP0] Decode batch. #running-req: 4, #token: 604, token usage: 0.00, gen throughput (token/s): 899.54, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:43:52 TP0] Decode batch. #running-req: 4, #token: 764, token usage: 0.00, gen throughput (token/s): 889.11, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:43:53 TP0] Decode batch. #running-req: 4, #token: 924, token usage: 0.00, gen throughput (token/s): 910.33, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:43:53 TP0] Decode batch. #running-req: 4, #token: 1084, token usage: 0.00, gen throughput (token/s): 891.08, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:43:53 TP0] Decode batch. #running-req: 4, #token: 1244, token usage: 0.00, gen throughput (token/s): 914.09, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:43:53 TP0] Decode batch. #running-req: 4, #token: 1404, token usage: 0.00, gen throughput (token/s): 883.83, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:43:53 TP0] Decode batch. #running-req: 4, #token: 1564, token usage: 0.00, gen throughput (token/s): 903.68, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:43:54 TP0] Decode batch. #running-req: 4, #token: 1724, token usage: 0.00, gen throughput (token/s): 929.55, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:43:54 TP0] Decode batch. #running-req: 4, #token: 1884, token usage: 0.00, gen throughput (token/s): 897.66, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:43:54 TP0] Decode batch. #running-req: 4, #token: 2044, token usage: 0.00, gen throughput (token/s): 866.47, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:43:54 TP0] Decode batch. #running-req: 4, #token: 2204, token usage: 0.00, gen throughput (token/s): 846.85, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:43:54 TP0] Decode batch. #running-req: 4, #token: 2364, token usage: 0.00, gen throughput (token/s): 871.21, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:43:54 TP0] Decode batch. #running-req: 4, #token: 2524, token usage: 0.00, gen throughput (token/s): 864.87, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:43:55 TP0] Decode batch. #running-req: 4, #token: 2684, token usage: 0.00, gen throughput (token/s): 867.51, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:43:55 TP0] Decode batch. #running-req: 4, #token: 2844, token usage: 0.00, gen throughput (token/s): 876.50, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:43:55 TP0] Decode batch. #running-req: 4, #token: 3004, token usage: 0.00, gen throughput (token/s): 880.36, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:43:55 TP0] Decode batch. #running-req: 4, #token: 3164, token usage: 0.00, gen throughput (token/s): 849.01, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:43:55 TP0] Decode batch. #running-req: 4, #token: 3324, token usage: 0.00, gen throughput (token/s): 909.79, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:43:56 TP0] Decode batch. #running-req: 4, #token: 3484, token usage: 0.00, gen throughput (token/s): 865.35, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:43:56 TP0] Decode batch. #running-req: 4, #token: 3644, token usage: 0.00, gen throughput (token/s): 873.26, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:43:56 TP0] Decode batch. #running-req: 4, #token: 3804, token usage: 0.00, gen throughput (token/s): 847.66, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:43:56 TP0] Decode batch. #running-req: 4, #token: 3964, token usage: 0.00, gen throughput (token/s): 860.97, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:43:56 TP0] Decode batch. #running-req: 4, #token: 4124, token usage: 0.00, gen throughput (token/s): 873.88, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:43:56] INFO:     127.0.0.1:6174 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:43:56] INFO:     127.0.0.1:6156 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:43:56] INFO:     127.0.0.1:6164 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:43:56] INFO:     127.0.0.1:6168 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:43:56 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 163, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-08-25 15:43:56 TP0] Prefill batch. #new-seq: 3, #new-token: 3, #cached-token: 489, token usage: 0.00, #running-req: 1, #queue-req: 0, 
[2025-08-25 15:43:57 TP0] Decode batch. #running-req: 4, #token: 281, token usage: 0.00, gen throughput (token/s): 578.70, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:43:57 TP0] Decode batch. #running-req: 4, #token: 441, token usage: 0.00, gen throughput (token/s): 880.96, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:43:57 TP0] Decode batch. #running-req: 4, #token: 601, token usage: 0.00, gen throughput (token/s): 885.46, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:43:57 TP0] Decode batch. #running-req: 4, #token: 761, token usage: 0.00, gen throughput (token/s): 877.58, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:43:57 TP0] Decode batch. #running-req: 4, #token: 921, token usage: 0.00, gen throughput (token/s): 892.48, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:43:57 TP0] Decode batch. #running-req: 4, #token: 1081, token usage: 0.00, gen throughput (token/s): 884.59, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:43:58 TP0] Decode batch. #running-req: 4, #token: 1241, token usage: 0.00, gen throughput (token/s): 879.48, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:43:58 TP0] Decode batch. #running-req: 4, #token: 1401, token usage: 0.00, gen throughput (token/s): 869.56, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:43:58 TP0] Decode batch. #running-req: 4, #token: 1561, token usage: 0.00, gen throughput (token/s): 865.00, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:43:58 TP0] Decode batch. #running-req: 4, #token: 1721, token usage: 0.00, gen throughput (token/s): 863.57, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:43:58 TP0] Decode batch. #running-req: 4, #token: 1881, token usage: 0.00, gen throughput (token/s): 852.03, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:43:59 TP0] Decode batch. #running-req: 4, #token: 2041, token usage: 0.00, gen throughput (token/s): 825.00, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:43:59 TP0] Decode batch. #running-req: 4, #token: 2201, token usage: 0.00, gen throughput (token/s): 878.29, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:43:59 TP0] Decode batch. #running-req: 4, #token: 2361, token usage: 0.00, gen throughput (token/s): 872.27, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:43:59 TP0] Decode batch. #running-req: 4, #token: 2521, token usage: 0.00, gen throughput (token/s): 880.70, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:43:59 TP0] Decode batch. #running-req: 4, #token: 2681, token usage: 0.00, gen throughput (token/s): 864.95, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:44:00 TP0] Decode batch. #running-req: 4, #token: 2841, token usage: 0.00, gen throughput (token/s): 881.18, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:44:00 TP0] Decode batch. #running-req: 4, #token: 3001, token usage: 0.00, gen throughput (token/s): 873.48, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:44:00 TP0] Decode batch. #running-req: 4, #token: 3161, token usage: 0.00, gen throughput (token/s): 859.25, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:44:00 TP0] Decode batch. #running-req: 4, #token: 3321, token usage: 0.00, gen throughput (token/s): 880.42, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:44:00 TP0] Decode batch. #running-req: 4, #token: 3481, token usage: 0.00, gen throughput (token/s): 862.28, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:44:00 TP0] Decode batch. #running-req: 4, #token: 3641, token usage: 0.00, gen throughput (token/s): 874.12, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:44:01 TP0] Decode batch. #running-req: 4, #token: 3801, token usage: 0.00, gen throughput (token/s): 875.03, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:44:01 TP0] Decode batch. #running-req: 4, #token: 3961, token usage: 0.00, gen throughput (token/s): 889.01, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:44:01 TP0] Decode batch. #running-req: 4, #token: 4121, token usage: 0.00, gen throughput (token/s): 893.45, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:44:01] INFO:     127.0.0.1:6174 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:44:01] INFO:     127.0.0.1:6156 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:44:01] INFO:     127.0.0.1:6164 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:44:01] INFO:     127.0.0.1:6168 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:44:01 TP0] Prefill batch. #new-seq: 1, #new-token: 1110, #cached-token: 43, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-08-25 15:44:01 TP0] Prefill batch. #new-seq: 1, #new-token: 1110, #cached-token: 43, token usage: 0.03, #running-req: 1, #queue-req: 0, 
[2025-08-25 15:44:02 TP0] Prefill batch. #new-seq: 2, #new-token: 2000, #cached-token: 306, token usage: 0.03, #running-req: 2, #queue-req: 0, 
[2025-08-25 15:44:02] INFO:     127.0.0.1:12540 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 15:44:02] INFO:     127.0.0.1:12550 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 15:44:02 TP0] Prefill batch. #new-seq: 2, #new-token: 2000, #cached-token: 306, token usage: 0.00, #running-req: 2, #queue-req: 0, 
[2025-08-25 15:44:02] INFO:     127.0.0.1:12564 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 15:44:02] INFO:     127.0.0.1:12566 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 15:44:03 TP0] Prefill batch. #new-seq: 2, #new-token: 2000, #cached-token: 306, token usage: 0.05, #running-req: 4, #queue-req: 0, 
[2025-08-25 15:44:03] INFO:     127.0.0.1:12540 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 15:44:03] INFO:     127.0.0.1:12550 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 15:44:04 TP0] Prefill batch. #new-seq: 2, #new-token: 2000, #cached-token: 306, token usage: 0.00, #running-req: 2, #queue-req: 0, 
[2025-08-25 15:44:04] INFO:     127.0.0.1:12564 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 15:44:04] INFO:     127.0.0.1:12566 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 15:44:04 TP0] Prefill batch. #new-seq: 2, #new-token: 2000, #cached-token: 306, token usage: 0.05, #running-req: 4, #queue-req: 0, 
[2025-08-25 15:44:04] INFO:     127.0.0.1:12540 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 15:44:04] INFO:     127.0.0.1:12550 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 15:44:05 TP0] Prefill batch. #new-seq: 2, #new-token: 2000, #cached-token: 306, token usage: 0.00, #running-req: 2, #queue-req: 0, 
[2025-08-25 15:44:05] INFO:     127.0.0.1:12564 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 15:44:05] INFO:     127.0.0.1:12566 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 15:44:06 TP0] Prefill batch. #new-seq: 2, #new-token: 2000, #cached-token: 306, token usage: 0.05, #running-req: 4, #queue-req: 0, 
[2025-08-25 15:44:06] INFO:     127.0.0.1:12540 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 15:44:06] INFO:     127.0.0.1:12550 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 15:44:06] INFO:     127.0.0.1:12564 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 15:44:06] INFO:     127.0.0.1:12566 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 15:44:06 TP0] Prefill batch. #new-seq: 4, #new-token: 4, #cached-token: 528, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-08-25 15:44:07 TP0] Decode batch. #running-req: 4, #token: 249, token usage: 0.00, gen throughput (token/s): 28.35, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:44:07 TP0] Decode batch. #running-req: 4, #token: 409, token usage: 0.00, gen throughput (token/s): 876.25, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:44:07 TP0] Decode batch. #running-req: 4, #token: 569, token usage: 0.00, gen throughput (token/s): 883.68, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:44:07 TP0] Decode batch. #running-req: 4, #token: 729, token usage: 0.00, gen throughput (token/s): 877.26, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:44:07 TP0] Decode batch. #running-req: 4, #token: 889, token usage: 0.00, gen throughput (token/s): 874.03, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:44:07 TP0] Decode batch. #running-req: 4, #token: 1049, token usage: 0.00, gen throughput (token/s): 871.71, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:44:08 TP0] Decode batch. #running-req: 4, #token: 1209, token usage: 0.00, gen throughput (token/s): 867.57, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:44:08 TP0] Decode batch. #running-req: 4, #token: 1369, token usage: 0.00, gen throughput (token/s): 870.30, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:44:08 TP0] Decode batch. #running-req: 4, #token: 1529, token usage: 0.00, gen throughput (token/s): 878.52, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:44:08 TP0] Decode batch. #running-req: 4, #token: 1689, token usage: 0.00, gen throughput (token/s): 861.46, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:44:08 TP0] Decode batch. #running-req: 4, #token: 1849, token usage: 0.00, gen throughput (token/s): 854.56, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:44:09 TP0] Decode batch. #running-req: 4, #token: 2009, token usage: 0.00, gen throughput (token/s): 873.92, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:44:09 TP0] Decode batch. #running-req: 4, #token: 2169, token usage: 0.00, gen throughput (token/s): 870.97, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:44:09 TP0] Decode batch. #running-req: 4, #token: 2329, token usage: 0.00, gen throughput (token/s): 844.48, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:44:09 TP0] Decode batch. #running-req: 4, #token: 2489, token usage: 0.00, gen throughput (token/s): 855.02, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:44:09 TP0] Decode batch. #running-req: 4, #token: 2649, token usage: 0.00, gen throughput (token/s): 855.75, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:44:10 TP0] Decode batch. #running-req: 4, #token: 2809, token usage: 0.00, gen throughput (token/s): 882.55, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:44:10 TP0] Decode batch. #running-req: 4, #token: 2969, token usage: 0.00, gen throughput (token/s): 860.37, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:44:10 TP0] Decode batch. #running-req: 4, #token: 3129, token usage: 0.00, gen throughput (token/s): 874.39, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:44:10 TP0] Decode batch. #running-req: 4, #token: 3289, token usage: 0.00, gen throughput (token/s): 862.66, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:44:10 TP0] Decode batch. #running-req: 4, #token: 3449, token usage: 0.00, gen throughput (token/s): 860.77, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:44:10 TP0] Decode batch. #running-req: 4, #token: 3609, token usage: 0.00, gen throughput (token/s): 862.76, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:44:11 TP0] Decode batch. #running-req: 4, #token: 3769, token usage: 0.00, gen throughput (token/s): 868.00, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:44:11 TP0] Decode batch. #running-req: 4, #token: 3929, token usage: 0.00, gen throughput (token/s): 863.84, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:44:11 TP0] Decode batch. #running-req: 4, #token: 4089, token usage: 0.00, gen throughput (token/s): 844.22, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:44:11] INFO:     127.0.0.1:29394 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:44:11] INFO:     127.0.0.1:29396 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:44:11] INFO:     127.0.0.1:29410 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:44:11] INFO:     127.0.0.1:29414 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:44:11 TP0] Prefill batch. #new-seq: 4, #new-token: 4, #cached-token: 528, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-08-25 15:44:11 TP0] Decode batch. #running-req: 4, #token: 249, token usage: 0.00, gen throughput (token/s): 656.87, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:44:11 TP0] Decode batch. #running-req: 4, #token: 409, token usage: 0.00, gen throughput (token/s): 865.27, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:44:12 TP0] Decode batch. #running-req: 4, #token: 569, token usage: 0.00, gen throughput (token/s): 880.36, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:44:12 TP0] Decode batch. #running-req: 4, #token: 729, token usage: 0.00, gen throughput (token/s): 866.02, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:44:12 TP0] Decode batch. #running-req: 4, #token: 889, token usage: 0.00, gen throughput (token/s): 891.56, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:44:12 TP0] Decode batch. #running-req: 4, #token: 1049, token usage: 0.00, gen throughput (token/s): 875.98, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:44:12 TP0] Decode batch. #running-req: 4, #token: 1209, token usage: 0.00, gen throughput (token/s): 881.82, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:44:13 TP0] Decode batch. #running-req: 4, #token: 1369, token usage: 0.00, gen throughput (token/s): 887.30, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:44:13 TP0] Decode batch. #running-req: 4, #token: 1529, token usage: 0.00, gen throughput (token/s): 888.07, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:44:13 TP0] Decode batch. #running-req: 4, #token: 1689, token usage: 0.00, gen throughput (token/s): 896.09, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:44:13 TP0] Decode batch. #running-req: 4, #token: 1849, token usage: 0.00, gen throughput (token/s): 902.81, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:44:13 TP0] Decode batch. #running-req: 4, #token: 2009, token usage: 0.00, gen throughput (token/s): 913.53, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:44:13 TP0] Decode batch. #running-req: 4, #token: 2169, token usage: 0.00, gen throughput (token/s): 884.32, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:44:14 TP0] Decode batch. #running-req: 4, #token: 2329, token usage: 0.00, gen throughput (token/s): 887.99, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:44:14 TP0] Decode batch. #running-req: 4, #token: 2489, token usage: 0.00, gen throughput (token/s): 900.81, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:44:14 TP0] Decode batch. #running-req: 4, #token: 2649, token usage: 0.00, gen throughput (token/s): 900.33, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:44:14 TP0] Decode batch. #running-req: 4, #token: 2809, token usage: 0.00, gen throughput (token/s): 893.12, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:44:14 TP0] Decode batch. #running-req: 4, #token: 2969, token usage: 0.00, gen throughput (token/s): 901.79, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:44:14 TP0] Decode batch. #running-req: 4, #token: 3129, token usage: 0.00, gen throughput (token/s): 876.08, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:44:15 TP0] Decode batch. #running-req: 4, #token: 3289, token usage: 0.00, gen throughput (token/s): 869.07, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:44:15 TP0] Decode batch. #running-req: 4, #token: 3449, token usage: 0.00, gen throughput (token/s): 886.51, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:44:15 TP0] Decode batch. #running-req: 4, #token: 3609, token usage: 0.00, gen throughput (token/s): 874.58, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:44:15 TP0] Decode batch. #running-req: 4, #token: 3769, token usage: 0.00, gen throughput (token/s): 903.19, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:44:15 TP0] Decode batch. #running-req: 4, #token: 3929, token usage: 0.00, gen throughput (token/s): 891.97, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:44:16 TP0] Decode batch. #running-req: 4, #token: 4089, token usage: 0.00, gen throughput (token/s): 901.70, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:44:16] INFO:     127.0.0.1:29414 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:44:16] INFO:     127.0.0.1:29394 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:44:16] INFO:     127.0.0.1:29396 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:44:16] INFO:     127.0.0.1:29410 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:44:16 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 132, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-08-25 15:44:16 TP0] Prefill batch. #new-seq: 3, #new-token: 3, #cached-token: 396, token usage: 0.00, #running-req: 1, #queue-req: 0, 
[2025-08-25 15:44:16 TP0] Decode batch. #running-req: 4, #token: 249, token usage: 0.00, gen throughput (token/s): 603.07, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:44:16 TP0] Decode batch. #running-req: 4, #token: 409, token usage: 0.00, gen throughput (token/s): 885.76, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:44:16 TP0] Decode batch. #running-req: 4, #token: 569, token usage: 0.00, gen throughput (token/s): 889.12, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:44:16 TP0] Decode batch. #running-req: 4, #token: 729, token usage: 0.00, gen throughput (token/s): 875.06, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:44:17 TP0] Decode batch. #running-req: 4, #token: 889, token usage: 0.00, gen throughput (token/s): 878.19, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:44:17 TP0] Decode batch. #running-req: 4, #token: 1049, token usage: 0.00, gen throughput (token/s): 868.79, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:44:17 TP0] Decode batch. #running-req: 4, #token: 1209, token usage: 0.00, gen throughput (token/s): 870.88, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:44:17 TP0] Decode batch. #running-req: 4, #token: 1369, token usage: 0.00, gen throughput (token/s): 875.33, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:44:17 TP0] Decode batch. #running-req: 4, #token: 1529, token usage: 0.00, gen throughput (token/s): 867.30, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:44:17 TP0] Decode batch. #running-req: 4, #token: 1689, token usage: 0.00, gen throughput (token/s): 883.75, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:44:18 TP0] Decode batch. #running-req: 4, #token: 1849, token usage: 0.00, gen throughput (token/s): 884.66, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:44:18 TP0] Decode batch. #running-req: 4, #token: 2009, token usage: 0.00, gen throughput (token/s): 869.56, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:44:18 TP0] Decode batch. #running-req: 4, #token: 2169, token usage: 0.00, gen throughput (token/s): 882.34, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:44:18 TP0] Decode batch. #running-req: 4, #token: 2329, token usage: 0.00, gen throughput (token/s): 869.86, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:44:18 TP0] Decode batch. #running-req: 4, #token: 2489, token usage: 0.00, gen throughput (token/s): 872.08, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:44:19 TP0] Decode batch. #running-req: 4, #token: 2649, token usage: 0.00, gen throughput (token/s): 878.89, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:44:19 TP0] Decode batch. #running-req: 4, #token: 2809, token usage: 0.00, gen throughput (token/s): 882.46, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:44:19 TP0] Decode batch. #running-req: 4, #token: 2969, token usage: 0.00, gen throughput (token/s): 872.99, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:44:19 TP0] Decode batch. #running-req: 4, #token: 3129, token usage: 0.00, gen throughput (token/s): 875.98, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:44:19 TP0] Decode batch. #running-req: 4, #token: 3289, token usage: 0.00, gen throughput (token/s): 860.09, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:44:19 TP0] Decode batch. #running-req: 4, #token: 3449, token usage: 0.00, gen throughput (token/s): 879.30, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:44:20 TP0] Decode batch. #running-req: 4, #token: 3609, token usage: 0.00, gen throughput (token/s): 880.11, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:44:20 TP0] Decode batch. #running-req: 4, #token: 3769, token usage: 0.00, gen throughput (token/s): 850.64, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:44:20 TP0] Decode batch. #running-req: 4, #token: 3929, token usage: 0.00, gen throughput (token/s): 859.98, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:44:20 TP0] Decode batch. #running-req: 4, #token: 4089, token usage: 0.00, gen throughput (token/s): 867.40, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:44:20] INFO:     127.0.0.1:29414 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:44:20] INFO:     127.0.0.1:29394 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:44:20] INFO:     127.0.0.1:29396 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:44:20] INFO:     127.0.0.1:29410 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:44:20 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 132, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-08-25 15:44:20 TP0] Prefill batch. #new-seq: 3, #new-token: 3, #cached-token: 396, token usage: 0.00, #running-req: 1, #queue-req: 0, 
[2025-08-25 15:44:21 TP0] Decode batch. #running-req: 4, #token: 249, token usage: 0.00, gen throughput (token/s): 598.20, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:44:21 TP0] Decode batch. #running-req: 4, #token: 409, token usage: 0.00, gen throughput (token/s): 890.57, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:44:21 TP0] Decode batch. #running-req: 4, #token: 569, token usage: 0.00, gen throughput (token/s): 892.56, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:44:21 TP0] Decode batch. #running-req: 4, #token: 729, token usage: 0.00, gen throughput (token/s): 875.62, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:44:21 TP0] Decode batch. #running-req: 4, #token: 889, token usage: 0.00, gen throughput (token/s): 873.87, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:44:21 TP0] Decode batch. #running-req: 4, #token: 1049, token usage: 0.00, gen throughput (token/s): 885.06, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:44:22 TP0] Decode batch. #running-req: 4, #token: 1209, token usage: 0.00, gen throughput (token/s): 906.87, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:44:22 TP0] Decode batch. #running-req: 4, #token: 1369, token usage: 0.00, gen throughput (token/s): 872.18, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:44:22 TP0] Decode batch. #running-req: 4, #token: 1529, token usage: 0.00, gen throughput (token/s): 901.72, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:44:22 TP0] Decode batch. #running-req: 4, #token: 1689, token usage: 0.00, gen throughput (token/s): 859.74, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:44:22 TP0] Decode batch. #running-req: 4, #token: 1849, token usage: 0.00, gen throughput (token/s): 870.71, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:44:23 TP0] Decode batch. #running-req: 4, #token: 2009, token usage: 0.00, gen throughput (token/s): 852.51, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:44:23 TP0] Decode batch. #running-req: 4, #token: 2169, token usage: 0.00, gen throughput (token/s): 846.18, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:44:23 TP0] Decode batch. #running-req: 4, #token: 2329, token usage: 0.00, gen throughput (token/s): 881.46, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:44:23 TP0] Decode batch. #running-req: 4, #token: 2489, token usage: 0.00, gen throughput (token/s): 863.82, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:44:23 TP0] Decode batch. #running-req: 4, #token: 2649, token usage: 0.00, gen throughput (token/s): 871.50, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:44:23 TP0] Decode batch. #running-req: 4, #token: 2809, token usage: 0.00, gen throughput (token/s): 866.47, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:44:24 TP0] Decode batch. #running-req: 4, #token: 2969, token usage: 0.00, gen throughput (token/s): 847.84, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:44:24 TP0] Decode batch. #running-req: 4, #token: 3129, token usage: 0.00, gen throughput (token/s): 868.95, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:44:24 TP0] Decode batch. #running-req: 4, #token: 3289, token usage: 0.00, gen throughput (token/s): 870.67, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:44:24 TP0] Decode batch. #running-req: 4, #token: 3449, token usage: 0.00, gen throughput (token/s): 834.96, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:44:24 TP0] Decode batch. #running-req: 4, #token: 3609, token usage: 0.00, gen throughput (token/s): 862.69, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:44:25 TP0] Decode batch. #running-req: 4, #token: 3769, token usage: 0.00, gen throughput (token/s): 857.29, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:44:25 TP0] Decode batch. #running-req: 4, #token: 3929, token usage: 0.00, gen throughput (token/s): 871.08, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:44:25 TP0] Decode batch. #running-req: 4, #token: 4089, token usage: 0.00, gen throughput (token/s): 853.93, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:44:25] INFO:     127.0.0.1:29414 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:44:25] INFO:     127.0.0.1:29394 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:44:25] INFO:     127.0.0.1:29396 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:44:25] INFO:     127.0.0.1:29410 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:44:25 TP0] Prefill batch. #new-seq: 3, #new-token: 3240, #cached-token: 126, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-08-25 15:44:25 TP0] Prefill batch. #new-seq: 1, #new-token: 1080, #cached-token: 42, token usage: 0.08, #running-req: 3, #queue-req: 0, 
[2025-08-25 15:44:26] INFO:     127.0.0.1:16624 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 15:44:27] INFO:     127.0.0.1:16638 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 15:44:27] INFO:     127.0.0.1:16652 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 15:44:27 TP0] Prefill batch. #new-seq: 1, #new-token: 1000, #cached-token: 122, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-08-25 15:44:27] INFO:     127.0.0.1:16656 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 15:44:27 TP0] Prefill batch. #new-seq: 3, #new-token: 3000, #cached-token: 366, token usage: 0.00, #running-req: 1, #queue-req: 0, 
[2025-08-25 15:44:27] INFO:     127.0.0.1:16624 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 15:44:28 TP0] Prefill batch. #new-seq: 1, #new-token: 1000, #cached-token: 122, token usage: 0.00, #running-req: 3, #queue-req: 0, 
[2025-08-25 15:44:28] INFO:     127.0.0.1:16638 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 15:44:28] INFO:     127.0.0.1:16652 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 15:44:28] INFO:     127.0.0.1:16656 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 15:44:28 TP0] Prefill batch. #new-seq: 3, #new-token: 3000, #cached-token: 366, token usage: 0.03, #running-req: 4, #queue-req: 0, 
[2025-08-25 15:44:28] INFO:     127.0.0.1:16624 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 15:44:29 TP0] Prefill batch. #new-seq: 1, #new-token: 1000, #cached-token: 122, token usage: 0.00, #running-req: 3, #queue-req: 0, 
[2025-08-25 15:44:29] INFO:     127.0.0.1:16638 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 15:44:29] INFO:     127.0.0.1:16652 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 15:44:29] INFO:     127.0.0.1:16656 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 15:44:30 TP0] Prefill batch. #new-seq: 3, #new-token: 3000, #cached-token: 366, token usage: 0.03, #running-req: 4, #queue-req: 0, 
[2025-08-25 15:44:30] INFO:     127.0.0.1:16624 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 15:44:31 TP0] Prefill batch. #new-seq: 1, #new-token: 1087, #cached-token: 44, token usage: 0.00, #running-req: 3, #queue-req: 0, 
[2025-08-25 15:44:31] INFO:     127.0.0.1:16638 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 15:44:31] INFO:     127.0.0.1:16652 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 15:44:31] INFO:     127.0.0.1:16656 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 15:44:31 TP0] Decode batch. #running-req: 3, #token: 1131, token usage: 0.03, gen throughput (token/s): 1.01, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:44:31 TP0] Prefill batch. #new-seq: 3, #new-token: 2988, #cached-token: 405, token usage: 0.03, #running-req: 1, #queue-req: 0, 
[2025-08-25 15:44:34 TP0] Decode batch. #running-req: 4, #token: 4249, token usage: 0.11, gen throughput (token/s): 52.72, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:44:35 TP0] Decode batch. #running-req: 4, #token: 4409, token usage: 0.11, gen throughput (token/s): 87.47, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:44:37 TP0] Decode batch. #running-req: 4, #token: 4569, token usage: 0.11, gen throughput (token/s): 87.61, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:44:39] INFO:     127.0.0.1:16624 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:44:39] INFO:     127.0.0.1:16638 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:44:39] INFO:     127.0.0.1:16652 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:44:39] INFO:     127.0.0.1:16656 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:44:39 TP0] Prefill batch. #new-seq: 1, #new-token: 974, #cached-token: 157, token usage: 0.00, #running-req: 3, #queue-req: 0, 
[2025-08-25 15:44:39 TP0] Prefill batch. #new-seq: 3, #new-token: 2974, #cached-token: 419, token usage: 0.03, #running-req: 4, #queue-req: 0, 
[2025-08-25 15:44:40 TP0] Decode batch. #running-req: 4, #token: 4158, token usage: 0.10, gen throughput (token/s): 52.48, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:44:42 TP0] Decode batch. #running-req: 4, #token: 4318, token usage: 0.11, gen throughput (token/s): 87.30, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:44:44 TP0] Decode batch. #running-req: 4, #token: 4478, token usage: 0.11, gen throughput (token/s): 87.97, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:44:46 TP0] Decode batch. #running-req: 4, #token: 4638, token usage: 0.12, gen throughput (token/s): 87.67, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:44:47] INFO:     127.0.0.1:16624 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:44:47] INFO:     127.0.0.1:16656 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:44:47] INFO:     127.0.0.1:16638 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:44:47] INFO:     127.0.0.1:16652 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:44:47 TP0] Prefill batch. #new-seq: 3, #new-token: 2953, #cached-token: 440, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-08-25 15:44:48 TP0] Prefill batch. #new-seq: 1, #new-token: 996, #cached-token: 135, token usage: 0.08, #running-req: 3, #queue-req: 0, 
[2025-08-25 15:44:49 TP0] Decode batch. #running-req: 4, #token: 4190, token usage: 0.11, gen throughput (token/s): 52.39, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:44:51 TP0] Decode batch. #running-req: 4, #token: 4350, token usage: 0.11, gen throughput (token/s): 87.52, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:44:53 TP0] Decode batch. #running-req: 4, #token: 4510, token usage: 0.11, gen throughput (token/s): 87.23, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:44:54 TP0] Decode batch. #running-req: 4, #token: 4670, token usage: 0.12, gen throughput (token/s): 87.57, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:44:55] INFO:     127.0.0.1:16656 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:44:55] INFO:     127.0.0.1:16624 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:44:55] INFO:     127.0.0.1:16638 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:44:55 TP0] Prefill batch. #new-seq: 3, #new-token: 2937, #cached-token: 456, token usage: 0.00, #running-req: 1, #queue-req: 0, 
[2025-08-25 15:44:55] INFO:     127.0.0.1:16652 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:44:55 TP0] Prefill batch. #new-seq: 1, #new-token: 996, #cached-token: 135, token usage: 0.08, #running-req: 4, #queue-req: 0, 
[2025-08-25 15:44:57 TP0] Decode batch. #running-req: 4, #token: 4227, token usage: 0.11, gen throughput (token/s): 51.96, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:44:59 TP0] Decode batch. #running-req: 4, #token: 4387, token usage: 0.11, gen throughput (token/s): 87.49, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:45:01 TP0] Decode batch. #running-req: 4, #token: 4547, token usage: 0.11, gen throughput (token/s): 87.01, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:45:03 TP0] Decode batch. #running-req: 4, #token: 4707, token usage: 0.12, gen throughput (token/s): 87.31, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:45:03] INFO:     127.0.0.1:16656 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:45:03] INFO:     127.0.0.1:16624 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:45:03] INFO:     127.0.0.1:16638 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:45:03] INFO:     127.0.0.1:16652 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:45:03 TP0] Prefill batch. #new-seq: 4, #new-token: 4, #cached-token: 720, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-08-25 15:45:03 TP0] Decode batch. #running-req: 4, #token: 297, token usage: 0.00, gen throughput (token/s): 4.19, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:45:03 TP0] Decode batch. #running-req: 4, #token: 457, token usage: 0.00, gen throughput (token/s): 859.34, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:45:04 TP0] Decode batch. #running-req: 4, #token: 617, token usage: 0.00, gen throughput (token/s): 886.73, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:45:04 TP0] Decode batch. #running-req: 4, #token: 777, token usage: 0.00, gen throughput (token/s): 862.35, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:45:04 TP0] Decode batch. #running-req: 4, #token: 937, token usage: 0.00, gen throughput (token/s): 852.88, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:45:04 TP0] Decode batch. #running-req: 4, #token: 1097, token usage: 0.00, gen throughput (token/s): 880.37, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:45:04 TP0] Decode batch. #running-req: 4, #token: 1257, token usage: 0.00, gen throughput (token/s): 874.03, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:45:04 TP0] Decode batch. #running-req: 4, #token: 1417, token usage: 0.00, gen throughput (token/s): 880.65, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:45:05 TP0] Decode batch. #running-req: 4, #token: 1577, token usage: 0.00, gen throughput (token/s): 876.72, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:45:05 TP0] Decode batch. #running-req: 4, #token: 1737, token usage: 0.00, gen throughput (token/s): 875.85, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:45:05 TP0] Decode batch. #running-req: 4, #token: 1897, token usage: 0.00, gen throughput (token/s): 868.46, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:45:05 TP0] Decode batch. #running-req: 4, #token: 2057, token usage: 0.00, gen throughput (token/s): 882.98, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:45:05 TP0] Decode batch. #running-req: 4, #token: 2217, token usage: 0.00, gen throughput (token/s): 880.77, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:45:06 TP0] Decode batch. #running-req: 4, #token: 2377, token usage: 0.00, gen throughput (token/s): 874.42, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:45:06 TP0] Decode batch. #running-req: 4, #token: 2537, token usage: 0.00, gen throughput (token/s): 868.16, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:45:06 TP0] Decode batch. #running-req: 4, #token: 2697, token usage: 0.00, gen throughput (token/s): 854.61, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:45:06 TP0] Decode batch. #running-req: 4, #token: 2857, token usage: 0.00, gen throughput (token/s): 900.28, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:45:06 TP0] Decode batch. #running-req: 4, #token: 3017, token usage: 0.00, gen throughput (token/s): 895.36, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:45:06 TP0] Decode batch. #running-req: 4, #token: 3177, token usage: 0.00, gen throughput (token/s): 898.30, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:45:07 TP0] Decode batch. #running-req: 4, #token: 3337, token usage: 0.00, gen throughput (token/s): 904.20, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:45:07 TP0] Decode batch. #running-req: 4, #token: 3497, token usage: 0.00, gen throughput (token/s): 890.01, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:45:07 TP0] Decode batch. #running-req: 4, #token: 3657, token usage: 0.00, gen throughput (token/s): 903.12, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:45:07 TP0] Decode batch. #running-req: 4, #token: 3817, token usage: 0.00, gen throughput (token/s): 891.78, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:45:07 TP0] Decode batch. #running-req: 4, #token: 3977, token usage: 0.00, gen throughput (token/s): 879.07, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:45:08 TP0] Decode batch. #running-req: 4, #token: 4137, token usage: 0.00, gen throughput (token/s): 912.13, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:45:08] INFO:     127.0.0.1:51256 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:45:08] INFO:     127.0.0.1:51260 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:45:08] INFO:     127.0.0.1:51274 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:45:08] INFO:     127.0.0.1:51282 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:45:08 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 180, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-08-25 15:45:08 TP0] Prefill batch. #new-seq: 3, #new-token: 3, #cached-token: 540, token usage: 0.00, #running-req: 1, #queue-req: 0, 
[2025-08-25 15:45:08 TP0] Decode batch. #running-req: 4, #token: 297, token usage: 0.00, gen throughput (token/s): 597.66, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:45:08 TP0] Decode batch. #running-req: 4, #token: 457, token usage: 0.00, gen throughput (token/s): 880.13, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:45:08 TP0] Decode batch. #running-req: 4, #token: 617, token usage: 0.00, gen throughput (token/s): 874.65, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:45:08 TP0] Decode batch. #running-req: 4, #token: 777, token usage: 0.00, gen throughput (token/s): 827.14, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:45:09 TP0] Decode batch. #running-req: 4, #token: 937, token usage: 0.00, gen throughput (token/s): 902.19, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:45:09 TP0] Decode batch. #running-req: 4, #token: 1097, token usage: 0.00, gen throughput (token/s): 885.10, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:45:09 TP0] Decode batch. #running-req: 4, #token: 1257, token usage: 0.00, gen throughput (token/s): 884.06, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:45:09 TP0] Decode batch. #running-req: 4, #token: 1417, token usage: 0.00, gen throughput (token/s): 892.60, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:45:09 TP0] Decode batch. #running-req: 4, #token: 1577, token usage: 0.00, gen throughput (token/s): 879.32, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:45:09 TP0] Decode batch. #running-req: 4, #token: 1737, token usage: 0.00, gen throughput (token/s): 886.06, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:45:10 TP0] Decode batch. #running-req: 4, #token: 1897, token usage: 0.00, gen throughput (token/s): 908.87, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:45:10 TP0] Decode batch. #running-req: 4, #token: 2057, token usage: 0.00, gen throughput (token/s): 893.62, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:45:10 TP0] Decode batch. #running-req: 4, #token: 2217, token usage: 0.00, gen throughput (token/s): 922.48, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:45:10 TP0] Decode batch. #running-req: 4, #token: 2377, token usage: 0.00, gen throughput (token/s): 921.15, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:45:10 TP0] Decode batch. #running-req: 4, #token: 2537, token usage: 0.00, gen throughput (token/s): 846.13, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:45:10 TP0] Decode batch. #running-req: 4, #token: 2697, token usage: 0.00, gen throughput (token/s): 844.35, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:45:11 TP0] Decode batch. #running-req: 4, #token: 2857, token usage: 0.00, gen throughput (token/s): 846.50, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:45:11 TP0] Decode batch. #running-req: 4, #token: 3017, token usage: 0.00, gen throughput (token/s): 856.11, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:45:11 TP0] Decode batch. #running-req: 4, #token: 3177, token usage: 0.00, gen throughput (token/s): 879.01, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:45:11 TP0] Decode batch. #running-req: 4, #token: 3337, token usage: 0.00, gen throughput (token/s): 843.11, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:45:11 TP0] Decode batch. #running-req: 4, #token: 3497, token usage: 0.00, gen throughput (token/s): 838.53, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:45:12 TP0] Decode batch. #running-req: 4, #token: 3657, token usage: 0.00, gen throughput (token/s): 828.98, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:45:12 TP0] Decode batch. #running-req: 4, #token: 3817, token usage: 0.00, gen throughput (token/s): 860.23, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:45:12 TP0] Decode batch. #running-req: 4, #token: 3977, token usage: 0.00, gen throughput (token/s): 876.11, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:45:12 TP0] Decode batch. #running-req: 4, #token: 4137, token usage: 0.00, gen throughput (token/s): 872.96, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:45:12] INFO:     127.0.0.1:51282 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:45:12] INFO:     127.0.0.1:51256 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:45:12] INFO:     127.0.0.1:51260 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:45:12] INFO:     127.0.0.1:51274 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:45:12 TP0] Prefill batch. #new-seq: 4, #new-token: 4, #cached-token: 720, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-08-25 15:45:12 TP0] Decode batch. #running-req: 4, #token: 297, token usage: 0.00, gen throughput (token/s): 656.10, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:45:13 TP0] Decode batch. #running-req: 4, #token: 457, token usage: 0.00, gen throughput (token/s): 883.91, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:45:13 TP0] Decode batch. #running-req: 4, #token: 617, token usage: 0.00, gen throughput (token/s): 885.35, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:45:13 TP0] Decode batch. #running-req: 4, #token: 777, token usage: 0.00, gen throughput (token/s): 877.19, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:45:13 TP0] Decode batch. #running-req: 4, #token: 937, token usage: 0.00, gen throughput (token/s): 883.09, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:45:13 TP0] Decode batch. #running-req: 4, #token: 1097, token usage: 0.00, gen throughput (token/s): 856.16, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:45:14 TP0] Decode batch. #running-req: 4, #token: 1257, token usage: 0.00, gen throughput (token/s): 867.20, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:45:14 TP0] Decode batch. #running-req: 4, #token: 1417, token usage: 0.00, gen throughput (token/s): 882.55, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:45:14 TP0] Decode batch. #running-req: 4, #token: 1577, token usage: 0.00, gen throughput (token/s): 885.79, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:45:14 TP0] Decode batch. #running-req: 4, #token: 1737, token usage: 0.00, gen throughput (token/s): 884.30, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:45:14 TP0] Decode batch. #running-req: 4, #token: 1897, token usage: 0.00, gen throughput (token/s): 860.14, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:45:14 TP0] Decode batch. #running-req: 4, #token: 2057, token usage: 0.00, gen throughput (token/s): 865.11, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:45:15 TP0] Decode batch. #running-req: 4, #token: 2217, token usage: 0.00, gen throughput (token/s): 849.74, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:45:15 TP0] Decode batch. #running-req: 4, #token: 2377, token usage: 0.00, gen throughput (token/s): 867.50, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:45:15 TP0] Decode batch. #running-req: 4, #token: 2537, token usage: 0.00, gen throughput (token/s): 853.37, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:45:15 TP0] Decode batch. #running-req: 4, #token: 2697, token usage: 0.00, gen throughput (token/s): 880.58, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:45:15 TP0] Decode batch. #running-req: 4, #token: 2857, token usage: 0.00, gen throughput (token/s): 842.29, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:45:16 TP0] Decode batch. #running-req: 4, #token: 3017, token usage: 0.00, gen throughput (token/s): 883.92, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:45:16 TP0] Decode batch. #running-req: 4, #token: 3177, token usage: 0.00, gen throughput (token/s): 883.64, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:45:16 TP0] Decode batch. #running-req: 4, #token: 3337, token usage: 0.00, gen throughput (token/s): 883.49, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:45:16 TP0] Decode batch. #running-req: 4, #token: 3497, token usage: 0.00, gen throughput (token/s): 887.23, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:45:16 TP0] Decode batch. #running-req: 4, #token: 3657, token usage: 0.00, gen throughput (token/s): 873.14, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:45:16 TP0] Decode batch. #running-req: 4, #token: 3817, token usage: 0.00, gen throughput (token/s): 888.15, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:45:17 TP0] Decode batch. #running-req: 4, #token: 3977, token usage: 0.00, gen throughput (token/s): 875.29, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:45:17 TP0] Decode batch. #running-req: 4, #token: 4137, token usage: 0.00, gen throughput (token/s): 884.18, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:45:17] INFO:     127.0.0.1:51282 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:45:17] INFO:     127.0.0.1:51256 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:45:17] INFO:     127.0.0.1:51260 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:45:17] INFO:     127.0.0.1:51274 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:45:17 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 180, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-08-25 15:45:17 TP0] Prefill batch. #new-seq: 3, #new-token: 3, #cached-token: 540, token usage: 0.00, #running-req: 1, #queue-req: 0, 
[2025-08-25 15:45:17 TP0] Decode batch. #running-req: 4, #token: 297, token usage: 0.00, gen throughput (token/s): 593.34, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:45:17 TP0] Decode batch. #running-req: 4, #token: 457, token usage: 0.00, gen throughput (token/s): 880.53, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:45:17 TP0] Decode batch. #running-req: 4, #token: 617, token usage: 0.00, gen throughput (token/s): 893.94, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:45:18 TP0] Decode batch. #running-req: 4, #token: 777, token usage: 0.00, gen throughput (token/s): 893.95, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:45:18 TP0] Decode batch. #running-req: 4, #token: 937, token usage: 0.00, gen throughput (token/s): 907.77, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:45:18 TP0] Decode batch. #running-req: 4, #token: 1097, token usage: 0.00, gen throughput (token/s): 913.50, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:45:18 TP0] Decode batch. #running-req: 4, #token: 1257, token usage: 0.00, gen throughput (token/s): 894.07, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:45:18 TP0] Decode batch. #running-req: 4, #token: 1417, token usage: 0.00, gen throughput (token/s): 902.90, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:45:19 TP0] Decode batch. #running-req: 4, #token: 1577, token usage: 0.00, gen throughput (token/s): 926.75, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:45:19 TP0] Decode batch. #running-req: 4, #token: 1737, token usage: 0.00, gen throughput (token/s): 934.52, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:45:19 TP0] Decode batch. #running-req: 4, #token: 1897, token usage: 0.00, gen throughput (token/s): 919.36, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:45:19 TP0] Decode batch. #running-req: 4, #token: 2057, token usage: 0.00, gen throughput (token/s): 918.32, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:45:19 TP0] Decode batch. #running-req: 4, #token: 2217, token usage: 0.00, gen throughput (token/s): 938.03, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:45:19 TP0] Decode batch. #running-req: 4, #token: 2377, token usage: 0.00, gen throughput (token/s): 927.16, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:45:20 TP0] Decode batch. #running-req: 4, #token: 2537, token usage: 0.00, gen throughput (token/s): 945.02, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:45:20 TP0] Decode batch. #running-req: 4, #token: 2697, token usage: 0.00, gen throughput (token/s): 921.68, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:45:20 TP0] Decode batch. #running-req: 4, #token: 2857, token usage: 0.00, gen throughput (token/s): 955.36, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:45:20 TP0] Decode batch. #running-req: 4, #token: 3017, token usage: 0.00, gen throughput (token/s): 946.36, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:45:20 TP0] Decode batch. #running-req: 4, #token: 3177, token usage: 0.00, gen throughput (token/s): 900.13, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:45:20 TP0] Decode batch. #running-req: 4, #token: 3337, token usage: 0.00, gen throughput (token/s): 868.56, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:45:21 TP0] Decode batch. #running-req: 4, #token: 3497, token usage: 0.00, gen throughput (token/s): 860.24, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:45:21 TP0] Decode batch. #running-req: 4, #token: 3657, token usage: 0.00, gen throughput (token/s): 867.32, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:45:21 TP0] Decode batch. #running-req: 4, #token: 3817, token usage: 0.00, gen throughput (token/s): 859.35, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:45:21 TP0] Decode batch. #running-req: 4, #token: 3977, token usage: 0.00, gen throughput (token/s): 871.44, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:45:21 TP0] Decode batch. #running-req: 4, #token: 4137, token usage: 0.00, gen throughput (token/s): 863.80, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:45:21] INFO:     127.0.0.1:51282 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:45:21] INFO:     127.0.0.1:51256 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:45:21] INFO:     127.0.0.1:51260 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:45:21] INFO:     127.0.0.1:51274 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:45:21 TP0] Prefill batch. #new-seq: 1, #new-token: 1128, #cached-token: 42, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-08-25 15:45:21 TP0] Prefill batch. #new-seq: 3, #new-token: 3384, #cached-token: 126, token usage: 0.03, #running-req: 1, #queue-req: 0, 
[2025-08-25 15:45:23] INFO:     127.0.0.1:65000 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 15:45:23] INFO:     127.0.0.1:65014 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 15:45:23] INFO:     127.0.0.1:65024 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 15:45:23] INFO:     127.0.0.1:65038 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 15:45:23 TP0] Prefill batch. #new-seq: 1, #new-token: 1000, #cached-token: 170, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-08-25 15:45:23 TP0] Prefill batch. #new-seq: 3, #new-token: 3000, #cached-token: 510, token usage: 0.00, #running-req: 1, #queue-req: 0, 
[2025-08-25 15:45:23] INFO:     127.0.0.1:65000 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 15:45:24 TP0] Prefill batch. #new-seq: 1, #new-token: 1000, #cached-token: 170, token usage: 0.00, #running-req: 3, #queue-req: 0, 
[2025-08-25 15:45:24] INFO:     127.0.0.1:65014 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 15:45:24] INFO:     127.0.0.1:65024 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 15:45:24] INFO:     127.0.0.1:65038 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 15:45:25 TP0] Prefill batch. #new-seq: 3, #new-token: 3000, #cached-token: 510, token usage: 0.03, #running-req: 4, #queue-req: 0, 
[2025-08-25 15:45:25] INFO:     127.0.0.1:65000 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 15:45:26 TP0] Prefill batch. #new-seq: 1, #new-token: 1000, #cached-token: 170, token usage: 0.00, #running-req: 3, #queue-req: 0, 
[2025-08-25 15:45:26] INFO:     127.0.0.1:65014 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 15:45:26] INFO:     127.0.0.1:65024 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 15:45:26] INFO:     127.0.0.1:65038 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 15:45:26 TP0] Prefill batch. #new-seq: 3, #new-token: 3000, #cached-token: 510, token usage: 0.03, #running-req: 4, #queue-req: 0, 
[2025-08-25 15:45:26] INFO:     127.0.0.1:65000 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 15:45:27 TP0] Prefill batch. #new-seq: 1, #new-token: 1135, #cached-token: 44, token usage: 0.00, #running-req: 3, #queue-req: 0, 
[2025-08-25 15:45:27] INFO:     127.0.0.1:65014 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 15:45:27] INFO:     127.0.0.1:65038 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 15:45:27] INFO:     127.0.0.1:65024 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 15:45:27 TP0] Prefill batch. #new-seq: 1, #new-token: 1135, #cached-token: 44, token usage: 0.03, #running-req: 4, #queue-req: 0, 
[2025-08-25 15:45:29 TP0] Decode batch. #running-req: 2, #token: 2243, token usage: 0.06, gen throughput (token/s): 3.31, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:45:31 TP0] Decode batch. #running-req: 2, #token: 2323, token usage: 0.06, gen throughput (token/s): 44.70, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:45:33 TP0] Decode batch. #running-req: 2, #token: 2403, token usage: 0.06, gen throughput (token/s): 44.63, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:45:34] INFO:     127.0.0.1:65000 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:45:34] INFO:     127.0.0.1:65014 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:45:34 TP0] Prefill batch. #new-seq: 4, #new-token: 4, #cached-token: 516, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-08-25 15:45:35 TP0] Decode batch. #running-req: 4, #token: 246, token usage: 0.00, gen throughput (token/s): 12.10, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:45:35 TP0] Decode batch. #running-req: 4, #token: 406, token usage: 0.00, gen throughput (token/s): 875.23, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:45:35 TP0] Decode batch. #running-req: 4, #token: 566, token usage: 0.00, gen throughput (token/s): 882.37, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:45:35 TP0] Decode batch. #running-req: 4, #token: 726, token usage: 0.00, gen throughput (token/s): 880.05, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:45:35 TP0] Decode batch. #running-req: 4, #token: 886, token usage: 0.00, gen throughput (token/s): 900.75, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:45:35 TP0] Decode batch. #running-req: 4, #token: 1046, token usage: 0.00, gen throughput (token/s): 885.67, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:45:36 TP0] Decode batch. #running-req: 4, #token: 1206, token usage: 0.00, gen throughput (token/s): 894.35, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:45:36 TP0] Decode batch. #running-req: 4, #token: 1366, token usage: 0.00, gen throughput (token/s): 854.30, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:45:36 TP0] Decode batch. #running-req: 4, #token: 1526, token usage: 0.00, gen throughput (token/s): 883.27, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:45:36 TP0] Decode batch. #running-req: 4, #token: 1686, token usage: 0.00, gen throughput (token/s): 869.73, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:45:36 TP0] Decode batch. #running-req: 4, #token: 1846, token usage: 0.00, gen throughput (token/s): 854.47, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:45:37 TP0] Decode batch. #running-req: 4, #token: 2006, token usage: 0.00, gen throughput (token/s): 878.54, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:45:37 TP0] Decode batch. #running-req: 4, #token: 2166, token usage: 0.00, gen throughput (token/s): 852.75, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:45:37 TP0] Decode batch. #running-req: 4, #token: 2326, token usage: 0.00, gen throughput (token/s): 872.18, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:45:37 TP0] Decode batch. #running-req: 4, #token: 2486, token usage: 0.00, gen throughput (token/s): 853.93, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:45:37 TP0] Decode batch. #running-req: 4, #token: 2646, token usage: 0.00, gen throughput (token/s): 863.01, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:45:37 TP0] Decode batch. #running-req: 4, #token: 2806, token usage: 0.00, gen throughput (token/s): 836.72, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:45:38 TP0] Decode batch. #running-req: 4, #token: 2966, token usage: 0.00, gen throughput (token/s): 828.53, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:45:38 TP0] Decode batch. #running-req: 4, #token: 3126, token usage: 0.00, gen throughput (token/s): 878.75, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:45:38 TP0] Decode batch. #running-req: 4, #token: 3286, token usage: 0.00, gen throughput (token/s): 829.50, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:45:38 TP0] Decode batch. #running-req: 4, #token: 3446, token usage: 0.00, gen throughput (token/s): 855.07, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:45:38 TP0] Decode batch. #running-req: 4, #token: 3606, token usage: 0.00, gen throughput (token/s): 869.06, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:45:39 TP0] Decode batch. #running-req: 4, #token: 3766, token usage: 0.00, gen throughput (token/s): 870.28, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:45:39 TP0] Decode batch. #running-req: 4, #token: 3926, token usage: 0.00, gen throughput (token/s): 876.29, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:45:39 TP0] Decode batch. #running-req: 4, #token: 4086, token usage: 0.00, gen throughput (token/s): 860.35, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:45:39] INFO:     127.0.0.1:59418 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:45:39] INFO:     127.0.0.1:59402 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:45:39] INFO:     127.0.0.1:59430 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:45:39] INFO:     127.0.0.1:59446 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:45:39 TP0] Prefill batch. #new-seq: 4, #new-token: 4, #cached-token: 516, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-08-25 15:45:39 TP0] Decode batch. #running-req: 4, #token: 246, token usage: 0.00, gen throughput (token/s): 680.80, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:45:39 TP0] Decode batch. #running-req: 4, #token: 406, token usage: 0.00, gen throughput (token/s): 873.11, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:45:40 TP0] Decode batch. #running-req: 4, #token: 566, token usage: 0.00, gen throughput (token/s): 879.81, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:45:40 TP0] Decode batch. #running-req: 4, #token: 726, token usage: 0.00, gen throughput (token/s): 868.63, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:45:40 TP0] Decode batch. #running-req: 4, #token: 886, token usage: 0.00, gen throughput (token/s): 862.67, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:45:40 TP0] Decode batch. #running-req: 4, #token: 1046, token usage: 0.00, gen throughput (token/s): 871.18, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:45:40 TP0] Decode batch. #running-req: 4, #token: 1206, token usage: 0.00, gen throughput (token/s): 878.69, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:45:41 TP0] Decode batch. #running-req: 4, #token: 1366, token usage: 0.00, gen throughput (token/s): 877.73, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:45:41 TP0] Decode batch. #running-req: 4, #token: 1526, token usage: 0.00, gen throughput (token/s): 873.49, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:45:41 TP0] Decode batch. #running-req: 4, #token: 1686, token usage: 0.00, gen throughput (token/s): 874.62, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:45:41 TP0] Decode batch. #running-req: 4, #token: 1846, token usage: 0.00, gen throughput (token/s): 876.42, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:45:41 TP0] Decode batch. #running-req: 4, #token: 2006, token usage: 0.00, gen throughput (token/s): 867.33, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:45:41 TP0] Decode batch. #running-req: 4, #token: 2166, token usage: 0.00, gen throughput (token/s): 874.94, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:45:42 TP0] Decode batch. #running-req: 4, #token: 2326, token usage: 0.00, gen throughput (token/s): 879.89, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:45:42 TP0] Decode batch. #running-req: 4, #token: 2486, token usage: 0.00, gen throughput (token/s): 863.35, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:45:42 TP0] Decode batch. #running-req: 4, #token: 2646, token usage: 0.00, gen throughput (token/s): 863.30, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:45:42 TP0] Decode batch. #running-req: 4, #token: 2806, token usage: 0.00, gen throughput (token/s): 880.11, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:45:42 TP0] Decode batch. #running-req: 4, #token: 2966, token usage: 0.00, gen throughput (token/s): 858.91, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:45:43 TP0] Decode batch. #running-req: 4, #token: 3126, token usage: 0.00, gen throughput (token/s): 880.87, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:45:43 TP0] Decode batch. #running-req: 4, #token: 3286, token usage: 0.00, gen throughput (token/s): 868.98, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:45:43 TP0] Decode batch. #running-req: 4, #token: 3446, token usage: 0.00, gen throughput (token/s): 893.43, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:45:43 TP0] Decode batch. #running-req: 4, #token: 3606, token usage: 0.00, gen throughput (token/s): 875.21, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:45:43 TP0] Decode batch. #running-req: 4, #token: 3766, token usage: 0.00, gen throughput (token/s): 868.14, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:45:43 TP0] Decode batch. #running-req: 4, #token: 3926, token usage: 0.00, gen throughput (token/s): 828.48, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:45:44 TP0] Decode batch. #running-req: 4, #token: 4086, token usage: 0.00, gen throughput (token/s): 872.76, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:45:44] INFO:     127.0.0.1:59446 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:45:44] INFO:     127.0.0.1:59402 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:45:44] INFO:     127.0.0.1:59418 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:45:44] INFO:     127.0.0.1:59430 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:45:44 TP0] Prefill batch. #new-seq: 4, #new-token: 4, #cached-token: 516, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-08-25 15:45:44 TP0] Decode batch. #running-req: 4, #token: 246, token usage: 0.00, gen throughput (token/s): 667.50, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:45:44 TP0] Decode batch. #running-req: 4, #token: 406, token usage: 0.00, gen throughput (token/s): 841.64, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:45:44 TP0] Decode batch. #running-req: 4, #token: 566, token usage: 0.00, gen throughput (token/s): 881.64, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:45:44 TP0] Decode batch. #running-req: 4, #token: 726, token usage: 0.00, gen throughput (token/s): 859.86, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:45:45 TP0] Decode batch. #running-req: 4, #token: 886, token usage: 0.00, gen throughput (token/s): 870.20, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:45:45 TP0] Decode batch. #running-req: 4, #token: 1046, token usage: 0.00, gen throughput (token/s): 866.80, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:45:45 TP0] Decode batch. #running-req: 4, #token: 1206, token usage: 0.00, gen throughput (token/s): 838.05, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:45:45 TP0] Decode batch. #running-req: 4, #token: 1366, token usage: 0.00, gen throughput (token/s): 883.33, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:45:45 TP0] Decode batch. #running-req: 4, #token: 1526, token usage: 0.00, gen throughput (token/s): 892.24, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:45:46 TP0] Decode batch. #running-req: 4, #token: 1686, token usage: 0.00, gen throughput (token/s): 882.68, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:45:46 TP0] Decode batch. #running-req: 4, #token: 1846, token usage: 0.00, gen throughput (token/s): 890.97, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:45:46 TP0] Decode batch. #running-req: 4, #token: 2006, token usage: 0.00, gen throughput (token/s): 881.96, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:45:46 TP0] Decode batch. #running-req: 4, #token: 2166, token usage: 0.00, gen throughput (token/s): 861.83, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:45:46 TP0] Decode batch. #running-req: 4, #token: 2326, token usage: 0.00, gen throughput (token/s): 879.89, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:45:46 TP0] Decode batch. #running-req: 4, #token: 2486, token usage: 0.00, gen throughput (token/s): 886.58, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:45:47 TP0] Decode batch. #running-req: 4, #token: 2646, token usage: 0.00, gen throughput (token/s): 873.66, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:45:47 TP0] Decode batch. #running-req: 4, #token: 2806, token usage: 0.00, gen throughput (token/s): 870.38, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:45:47 TP0] Decode batch. #running-req: 4, #token: 2966, token usage: 0.00, gen throughput (token/s): 863.17, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:45:47 TP0] Decode batch. #running-req: 4, #token: 3126, token usage: 0.00, gen throughput (token/s): 856.99, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:45:47 TP0] Decode batch. #running-req: 4, #token: 3286, token usage: 0.00, gen throughput (token/s): 876.18, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:45:48 TP0] Decode batch. #running-req: 4, #token: 3446, token usage: 0.00, gen throughput (token/s): 877.14, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:45:48 TP0] Decode batch. #running-req: 4, #token: 3606, token usage: 0.00, gen throughput (token/s): 858.02, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:45:48 TP0] Decode batch. #running-req: 4, #token: 3766, token usage: 0.00, gen throughput (token/s): 863.20, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:45:48 TP0] Decode batch. #running-req: 4, #token: 3926, token usage: 0.00, gen throughput (token/s): 856.45, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:45:48 TP0] Decode batch. #running-req: 4, #token: 4086, token usage: 0.00, gen throughput (token/s): 864.86, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:45:48] INFO:     127.0.0.1:59446 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:45:48] INFO:     127.0.0.1:59402 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:45:48] INFO:     127.0.0.1:59418 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:45:48] INFO:     127.0.0.1:59430 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:45:48 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 129, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-08-25 15:45:48 TP0] Prefill batch. #new-seq: 3, #new-token: 3, #cached-token: 387, token usage: 0.00, #running-req: 1, #queue-req: 0, 
[2025-08-25 15:45:49 TP0] Decode batch. #running-req: 4, #token: 246, token usage: 0.00, gen throughput (token/s): 600.40, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:45:49 TP0] Decode batch. #running-req: 4, #token: 406, token usage: 0.00, gen throughput (token/s): 894.48, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:45:49 TP0] Decode batch. #running-req: 4, #token: 566, token usage: 0.00, gen throughput (token/s): 886.48, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:45:49 TP0] Decode batch. #running-req: 4, #token: 726, token usage: 0.00, gen throughput (token/s): 885.77, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:45:49 TP0] Decode batch. #running-req: 4, #token: 886, token usage: 0.00, gen throughput (token/s): 893.89, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:45:49 TP0] Decode batch. #running-req: 4, #token: 1046, token usage: 0.00, gen throughput (token/s): 871.66, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:45:50 TP0] Decode batch. #running-req: 4, #token: 1206, token usage: 0.00, gen throughput (token/s): 908.82, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:45:50 TP0] Decode batch. #running-req: 4, #token: 1366, token usage: 0.00, gen throughput (token/s): 916.10, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:45:50 TP0] Decode batch. #running-req: 4, #token: 1526, token usage: 0.00, gen throughput (token/s): 927.37, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:45:50 TP0] Decode batch. #running-req: 4, #token: 1686, token usage: 0.00, gen throughput (token/s): 919.76, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:45:50 TP0] Decode batch. #running-req: 4, #token: 1846, token usage: 0.00, gen throughput (token/s): 926.04, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:45:50 TP0] Decode batch. #running-req: 4, #token: 2006, token usage: 0.00, gen throughput (token/s): 895.63, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:45:51 TP0] Decode batch. #running-req: 4, #token: 2166, token usage: 0.00, gen throughput (token/s): 920.52, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:45:51 TP0] Decode batch. #running-req: 4, #token: 2326, token usage: 0.00, gen throughput (token/s): 916.09, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:45:51 TP0] Decode batch. #running-req: 4, #token: 2486, token usage: 0.00, gen throughput (token/s): 915.95, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:45:51 TP0] Decode batch. #running-req: 4, #token: 2646, token usage: 0.00, gen throughput (token/s): 914.51, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:45:51 TP0] Decode batch. #running-req: 4, #token: 2806, token usage: 0.00, gen throughput (token/s): 932.12, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:45:52 TP0] Decode batch. #running-req: 4, #token: 2966, token usage: 0.00, gen throughput (token/s): 904.52, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:45:52 TP0] Decode batch. #running-req: 4, #token: 3126, token usage: 0.00, gen throughput (token/s): 925.87, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:45:52 TP0] Decode batch. #running-req: 4, #token: 3286, token usage: 0.00, gen throughput (token/s): 889.43, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:45:52 TP0] Decode batch. #running-req: 4, #token: 3446, token usage: 0.00, gen throughput (token/s): 898.50, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:45:52 TP0] Decode batch. #running-req: 4, #token: 3606, token usage: 0.00, gen throughput (token/s): 910.73, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:45:52 TP0] Decode batch. #running-req: 4, #token: 3766, token usage: 0.00, gen throughput (token/s): 904.22, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:45:53 TP0] Decode batch. #running-req: 4, #token: 3926, token usage: 0.00, gen throughput (token/s): 918.94, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:45:53 TP0] Decode batch. #running-req: 4, #token: 4086, token usage: 0.00, gen throughput (token/s): 916.11, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:45:53] INFO:     127.0.0.1:59446 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:45:53] INFO:     127.0.0.1:59402 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:45:53] INFO:     127.0.0.1:59418 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:45:53] INFO:     127.0.0.1:59430 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:45:53 TP0] Prefill batch. #new-seq: 3, #new-token: 3225, #cached-token: 132, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-08-25 15:45:53 TP0] Prefill batch. #new-seq: 1, #new-token: 1075, #cached-token: 44, token usage: 0.08, #running-req: 3, #queue-req: 0, 
[2025-08-25 15:45:55] INFO:     127.0.0.1:53902 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 15:45:55] INFO:     127.0.0.1:53918 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 15:45:55] INFO:     127.0.0.1:53924 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 15:45:55 TP0] Prefill batch. #new-seq: 2, #new-token: 2000, #cached-token: 238, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-08-25 15:45:55] INFO:     127.0.0.1:53932 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 15:45:56 TP0] Prefill batch. #new-seq: 2, #new-token: 2000, #cached-token: 238, token usage: 0.00, #running-req: 2, #queue-req: 0, 
[2025-08-25 15:45:56] INFO:     127.0.0.1:53902 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 15:45:56] INFO:     127.0.0.1:53918 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 15:45:57 TP0] Prefill batch. #new-seq: 2, #new-token: 2000, #cached-token: 238, token usage: 0.00, #running-req: 2, #queue-req: 0, 
[2025-08-25 15:45:57] INFO:     127.0.0.1:53924 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 15:45:57] INFO:     127.0.0.1:53932 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 15:45:57 TP0] Decode batch. #running-req: 2, #token: 2119, token usage: 0.05, gen throughput (token/s): 3.22, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:45:57 TP0] Prefill batch. #new-seq: 2, #new-token: 2000, #cached-token: 238, token usage: 0.05, #running-req: 4, #queue-req: 0, 
[2025-08-25 15:45:57] INFO:     127.0.0.1:53902 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 15:45:57] INFO:     127.0.0.1:53918 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 15:45:58 TP0] Prefill batch. #new-seq: 2, #new-token: 2000, #cached-token: 238, token usage: 0.00, #running-req: 2, #queue-req: 0, 
[2025-08-25 15:45:58] INFO:     127.0.0.1:53924 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 15:45:58] INFO:     127.0.0.1:53932 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 15:45:59 TP0] Prefill batch. #new-seq: 2, #new-token: 2000, #cached-token: 238, token usage: 0.05, #running-req: 4, #queue-req: 0, 
[2025-08-25 15:45:59] INFO:     127.0.0.1:53902 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 15:45:59] INFO:     127.0.0.1:53918 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 15:45:59 TP0] Prefill batch. #new-seq: 2, #new-token: 2164, #cached-token: 92, token usage: 0.00, #running-req: 2, #queue-req: 0, 
[2025-08-25 15:45:59] INFO:     127.0.0.1:53924 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 15:45:59] INFO:     127.0.0.1:53932 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 15:45:59 TP0] Prefill batch. #new-seq: 2, #new-token: 2164, #cached-token: 92, token usage: 0.06, #running-req: 4, #queue-req: 0, 
[2025-08-25 15:46:02 TP0] Decode batch. #running-req: 4, #token: 4272, token usage: 0.11, gen throughput (token/s): 31.08, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:46:04 TP0] Decode batch. #running-req: 4, #token: 4432, token usage: 0.11, gen throughput (token/s): 87.86, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:46:06 TP0] Decode batch. #running-req: 4, #token: 4592, token usage: 0.12, gen throughput (token/s): 87.29, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:46:07] INFO:     127.0.0.1:53902 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:46:07] INFO:     127.0.0.1:53918 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:46:07] INFO:     127.0.0.1:53924 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:46:07] INFO:     127.0.0.1:53932 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:46:07 TP0] Prefill batch. #new-seq: 2, #new-token: 1989, #cached-token: 267, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-08-25 15:46:08 TP0] Decode batch. #running-req: 2, #token: 2142, token usage: 0.05, gen throughput (token/s): 59.57, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:46:10 TP0] Decode batch. #running-req: 2, #token: 2222, token usage: 0.06, gen throughput (token/s): 44.39, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:46:12 TP0] Decode batch. #running-req: 2, #token: 2302, token usage: 0.06, gen throughput (token/s): 44.60, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:46:14 TP0] Decode batch. #running-req: 2, #token: 2382, token usage: 0.06, gen throughput (token/s): 44.22, largest-len: 0, #queue-req: 0, 
[2025-08-25 15:46:15] INFO:     127.0.0.1:53932 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 15:46:15] INFO:     127.0.0.1:53902 - "POST /v1/chat/completions HTTP/1.1" 200 OK
slurmstepd-nwonga100: error: *** JOB 11296 ON nwonga100 CANCELLED AT 2025-08-25T15:52:32 ***
