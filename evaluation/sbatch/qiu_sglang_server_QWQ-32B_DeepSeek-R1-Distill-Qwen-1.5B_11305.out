Mon Aug 25 18:15:49 2025       
+-----------------------------------------------------------------------------------------+
| NVIDIA-SMI 550.54.14              Driver Version: 550.54.14      CUDA Version: 12.4     |
|-----------------------------------------+------------------------+----------------------+
| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |
| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |
|                                         |                        |               MIG M. |
|=========================================+========================+======================|
|   0  NVIDIA A100 80GB PCIe          Off |   00000000:4F:00.0 Off |                    0 |
| N/A   40C    P0             64W /  300W |   66763MiB /  81920MiB |      0%      Default |
|                                         |                        |             Disabled |
+-----------------------------------------+------------------------+----------------------+
|   1  NVIDIA A100 80GB PCIe          Off |   00000000:52:00.0 Off |                    0 |
| N/A   30C    P0             44W /  300W |       0MiB /  81920MiB |      0%      Default |
|                                         |                        |             Disabled |
+-----------------------------------------+------------------------+----------------------+
|   2  NVIDIA A100 80GB PCIe          Off |   00000000:56:00.0 Off |                    0 |
| N/A   27C    P0             63W /  300W |   43627MiB /  81920MiB |      0%      Default |
|                                         |                        |             Disabled |
+-----------------------------------------+------------------------+----------------------+
|   3  NVIDIA A100 80GB PCIe          Off |   00000000:57:00.0 Off |                    0 |
| N/A   28C    P0             44W /  300W |       0MiB /  81920MiB |      0%      Default |
|                                         |                        |             Disabled |
+-----------------------------------------+------------------------+----------------------+
|   4  NVIDIA A100 80GB PCIe          Off |   00000000:D5:00.0 Off |                    0 |
| N/A   29C    P0             42W /  300W |       0MiB /  81920MiB |      0%      Default |
|                                         |                        |             Disabled |
+-----------------------------------------+------------------------+----------------------+
                                                                                         
+-----------------------------------------------------------------------------------------+
| Processes:                                                                              |
|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |
|        ID   ID                                                               Usage      |
|=========================================================================================|
|    0   N/A  N/A   2223691      C   python                                      66754MiB |
|    2   N/A  N/A   2258570      C   /home/shenhui/miniconda3/bin/python         43618MiB |
+-----------------------------------------------------------------------------------------+
/home/xiongjing
Waiting for server on port 40000 to start...
INFO 08-25 18:15:57 __init__.py:190] Automatically detected platform cuda.
INFO 08-25 18:15:57 __init__.py:190] Automatically detected platform cuda.
[2025-08-25 18:16:00] server_args=ServerArgs(model_path='deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B', tokenizer_path='deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B', tokenizer_mode='auto', skip_tokenizer_init=False, load_format='auto', trust_remote_code=False, dtype='auto', kv_cache_dtype='auto', quantization=None, quantization_param_path=None, context_length=None, device='cuda', served_model_name='deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B', chat_template=None, is_embedding=False, revision=None, host='0.0.0.0', port=40001, mem_fraction_static=0.9, max_running_requests=None, max_total_tokens=None, chunked_prefill_size=8192, max_prefill_tokens=16384, schedule_policy='fcfs', schedule_conservativeness=1.0, cpu_offload_gb=0, tp_size=1, stream_interval=1, stream_output=False, random_seed=643246752, constrained_json_whitespace_pattern=None, watchdog_timeout=300, dist_timeout=None, download_dir=None, base_gpu_id=0, gpu_id_step=1, log_level='info', log_level_http=None, log_requests=False, log_requests_level=0, show_time_cost=False, enable_metrics=False, decode_log_interval=40, api_key=None, file_storage_path='sglang_storage', enable_cache_report=False, reasoning_parser=None, dp_size=1, load_balance_method='round_robin', ep_size=1, dist_init_addr=None, nnodes=1, node_rank=0, json_model_override_args='{}', lora_paths=None, max_loras_per_batch=8, lora_backend='triton', attention_backend='flashinfer', sampling_backend='flashinfer', grammar_backend='outlines', speculative_algorithm=None, speculative_draft_model_path=None, speculative_num_steps=5, speculative_eagle_topk=4, speculative_num_draft_tokens=8, speculative_accept_threshold_single=1.0, speculative_accept_threshold_acc=1.0, speculative_token_map=None, enable_double_sparsity=False, ds_channel_config_path=None, ds_heavy_channel_num=32, ds_heavy_token_num=256, ds_heavy_channel_type='qk', ds_sparse_decode_threshold=4096, disable_radix_cache=False, disable_cuda_graph=False, disable_cuda_graph_padding=False, enable_nccl_nvls=False, disable_outlines_disk_cache=False, disable_custom_all_reduce=False, disable_mla=False, disable_overlap_schedule=False, enable_mixed_chunk=False, enable_dp_attention=False, enable_ep_moe=False, enable_torch_compile=False, torch_compile_max_bs=32, cuda_graph_max_bs=160, cuda_graph_bs=None, torchao_config='', enable_nan_detection=False, enable_p2p_check=False, triton_attention_reduce_in_fp32=False, triton_attention_num_kv_splits=8, num_continuous_decode_steps=1, delete_ckpt_after_loading=False, enable_memory_saver=False, allow_auto_truncate=False, enable_custom_logit_processor=False, tool_call_parser=None, enable_hierarchical_cache=False, enable_flashinfer_mla=False, flashinfer_mla_disable_ragged=False, warmups=None, debug_tensor_dump_output_folder=None, debug_tensor_dump_input_file=None, debug_tensor_dump_inject=False)
[2025-08-25 18:16:00] server_args=ServerArgs(model_path='Qwen/QwQ-32B', tokenizer_path='Qwen/QwQ-32B', tokenizer_mode='auto', skip_tokenizer_init=False, load_format='auto', trust_remote_code=False, dtype='auto', kv_cache_dtype='auto', quantization=None, quantization_param_path=None, context_length=None, device='cuda', served_model_name='Qwen/QwQ-32B', chat_template=None, is_embedding=False, revision=None, host='0.0.0.0', port=40000, mem_fraction_static=0.9, max_running_requests=None, max_total_tokens=None, chunked_prefill_size=8192, max_prefill_tokens=16384, schedule_policy='fcfs', schedule_conservativeness=1.0, cpu_offload_gb=0, tp_size=2, stream_interval=1, stream_output=False, random_seed=175441227, constrained_json_whitespace_pattern=None, watchdog_timeout=300, dist_timeout=None, download_dir=None, base_gpu_id=0, gpu_id_step=1, log_level='info', log_level_http=None, log_requests=False, log_requests_level=0, show_time_cost=False, enable_metrics=False, decode_log_interval=40, api_key=None, file_storage_path='sglang_storage', enable_cache_report=False, reasoning_parser=None, dp_size=1, load_balance_method='round_robin', ep_size=1, dist_init_addr=None, nnodes=1, node_rank=0, json_model_override_args='{}', lora_paths=None, max_loras_per_batch=8, lora_backend='triton', attention_backend='flashinfer', sampling_backend='flashinfer', grammar_backend='outlines', speculative_algorithm=None, speculative_draft_model_path=None, speculative_num_steps=5, speculative_eagle_topk=4, speculative_num_draft_tokens=8, speculative_accept_threshold_single=1.0, speculative_accept_threshold_acc=1.0, speculative_token_map=None, enable_double_sparsity=False, ds_channel_config_path=None, ds_heavy_channel_num=32, ds_heavy_token_num=256, ds_heavy_channel_type='qk', ds_sparse_decode_threshold=4096, disable_radix_cache=False, disable_cuda_graph=False, disable_cuda_graph_padding=False, enable_nccl_nvls=False, disable_outlines_disk_cache=False, disable_custom_all_reduce=False, disable_mla=False, disable_overlap_schedule=False, enable_mixed_chunk=False, enable_dp_attention=False, enable_ep_moe=False, enable_torch_compile=False, torch_compile_max_bs=32, cuda_graph_max_bs=160, cuda_graph_bs=None, torchao_config='', enable_nan_detection=False, enable_p2p_check=False, triton_attention_reduce_in_fp32=False, triton_attention_num_kv_splits=8, num_continuous_decode_steps=1, delete_ckpt_after_loading=False, enable_memory_saver=False, allow_auto_truncate=False, enable_custom_logit_processor=False, tool_call_parser=None, enable_hierarchical_cache=False, enable_flashinfer_mla=False, flashinfer_mla_disable_ragged=False, warmups=None, debug_tensor_dump_output_folder=None, debug_tensor_dump_input_file=None, debug_tensor_dump_inject=False)
Waiting for server on port 40000 to start...
Waiting for server on port 40000 to start...
INFO 08-25 18:16:16 __init__.py:190] Automatically detected platform cuda.
INFO 08-25 18:16:16 __init__.py:190] Automatically detected platform cuda.
INFO 08-25 18:16:16 __init__.py:190] Automatically detected platform cuda.
INFO 08-25 18:16:16 __init__.py:190] Automatically detected platform cuda.
INFO 08-25 18:16:17 __init__.py:190] Automatically detected platform cuda.
Waiting for server on port 40000 to start...
[2025-08-25 18:16:25 TP1] Init torch distributed begin.
[2025-08-25 18:16:25 TP0] Init torch distributed begin.
[2025-08-25 18:16:25 TP0] Init torch distributed begin.
[2025-08-25 18:16:25 TP0] Init torch distributed ends. mem usage=0.00 GB
[2025-08-25 18:16:25 TP0] Load weight begin. avail mem=78.73 GB
[2025-08-25 18:16:25 TP0] sglang is using nccl==2.21.5
[2025-08-25 18:16:25 TP1] sglang is using nccl==2.21.5
[2025-08-25 18:16:26 TP0] The following error message 'operation scheduled before its operands' can be ignored.
[2025-08-25 18:16:26 TP1] Init torch distributed ends. mem usage=0.25 GB
[2025-08-25 18:16:26 TP0] Init torch distributed ends. mem usage=0.25 GB
[2025-08-25 18:16:26 TP1] Load weight begin. avail mem=78.48 GB
[2025-08-25 18:16:26 TP0] Load weight begin. avail mem=78.48 GB
[2025-08-25 18:16:26 TP0] Using model weights format ['*.safetensors']
[2025-08-25 18:16:27 TP0] No model.safetensors.index.json found in remote.
Loading safetensors checkpoint shards:   0% Completed | 0/1 [00:00<?, ?it/s]
[2025-08-25 18:16:27 TP1] The following error message 'operation scheduled before its operands' can be ignored.
[2025-08-25 18:16:27 TP0] The following error message 'operation scheduled before its operands' can be ignored.
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:01<00:00,  1.01s/it]
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:01<00:00,  1.01s/it]

[2025-08-25 18:16:28 TP0] Load weight end. type=Qwen2ForCausalLM, dtype=torch.bfloat16, avail mem=75.14 GB, mem usage=3.58 GB.
[2025-08-25 18:16:28 TP0] KV Cache is allocated. #tokens: 2519168, K size: 33.63 GB, V size: 33.63 GB
[2025-08-25 18:16:28 TP0] Memory pool end. avail mem=5.76 GB
[2025-08-25 18:16:28 TP1] Using model weights format ['*.safetensors']
[2025-08-25 18:16:28 TP0] Capture cuda graph begin. This can take up to several minutes. avail mem=5.15 GB
  0%|          | 0/23 [00:00<?, ?it/s][2025-08-25 18:16:28 TP0] Using model weights format ['*.safetensors']
  4%|▍         | 1/23 [00:00<00:21,  1.02it/s]Loading safetensors checkpoint shards:   0% Completed | 0/14 [00:00<?, ?it/s]
  9%|▊         | 2/23 [00:01<00:12,  1.69it/s] 13%|█▎        | 3/23 [00:01<00:10,  1.84it/s]Waiting for server on port 40000 to start...
 17%|█▋        | 4/23 [00:02<00:10,  1.86it/s]Loading safetensors checkpoint shards:   7% Completed | 1/14 [00:01<00:15,  1.23s/it]
 22%|██▏       | 5/23 [00:02<00:09,  2.00it/s] 26%|██▌       | 6/23 [00:03<00:08,  2.00it/s] 30%|███       | 7/23 [00:03<00:08,  1.98it/s]Loading safetensors checkpoint shards:  14% Completed | 2/14 [00:02<00:17,  1.47s/it]
 35%|███▍      | 8/23 [00:04<00:07,  2.01it/s] 39%|███▉      | 9/23 [00:04<00:06,  2.15it/s] 43%|████▎     | 10/23 [00:05<00:05,  2.17it/s] 48%|████▊     | 11/23 [00:05<00:05,  2.27it/s]Loading safetensors checkpoint shards:  21% Completed | 3/14 [00:04<00:16,  1.52s/it]
 52%|█████▏    | 12/23 [00:05<00:04,  2.40it/s] 57%|█████▋    | 13/23 [00:06<00:04,  2.34it/s] 61%|██████    | 14/23 [00:06<00:04,  2.19it/s] 65%|██████▌   | 15/23 [00:07<00:03,  2.27it/s]Loading safetensors checkpoint shards:  29% Completed | 4/14 [00:05<00:15,  1.53s/it]
 70%|██████▉   | 16/23 [00:07<00:03,  2.30it/s] 74%|███████▍  | 17/23 [00:08<00:02,  2.39it/s] 78%|███████▊  | 18/23 [00:08<00:02,  2.46it/s] 83%|████████▎ | 19/23 [00:08<00:01,  2.36it/s]Loading safetensors checkpoint shards:  36% Completed | 5/14 [00:07<00:14,  1.63s/it]
 87%|████████▋ | 20/23 [00:09<00:01,  2.24it/s] 91%|█████████▏| 21/23 [00:09<00:00,  2.36it/s] 96%|█████████▌| 22/23 [00:10<00:00,  2.28it/s]100%|██████████| 23/23 [00:10<00:00,  2.21it/s]100%|██████████| 23/23 [00:10<00:00,  2.15it/s]
[2025-08-25 18:16:39 TP0] Capture cuda graph end. Time elapsed: 10.71 s. avail mem=3.21 GB. mem usage=1.94 GB.
Loading safetensors checkpoint shards:  43% Completed | 6/14 [00:09<00:13,  1.66s/it]
[2025-08-25 18:16:40 TP0] max_total_num_tokens=2519168, chunked_prefill_size=8192, max_prefill_tokens=16384, max_running_requests=4097, context_len=131072
[2025-08-25 18:16:40] INFO:     Started server process [2394118]
[2025-08-25 18:16:40] INFO:     Waiting for application startup.
[2025-08-25 18:16:40] INFO:     Application startup complete.
[2025-08-25 18:16:40] INFO:     Uvicorn running on http://0.0.0.0:40001 (Press CTRL+C to quit)
Waiting for server on port 40000 to start...
Loading safetensors checkpoint shards:  50% Completed | 7/14 [00:11<00:11,  1.64s/it]
[2025-08-25 18:16:41] INFO:     127.0.0.1:36598 - "GET /get_model_info HTTP/1.1" 200 OK
[2025-08-25 18:16:41 TP0] Prefill batch. #new-seq: 1, #new-token: 7, #cached-token: 0, token usage: 0.00, #running-req: 0, #queue-req: 0, 
Loading safetensors checkpoint shards:  57% Completed | 8/14 [00:12<00:10,  1.70s/it]
[2025-08-25 18:16:42] INFO:     127.0.0.1:36614 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 18:16:42] The server is fired up and ready to roll!
Loading safetensors checkpoint shards:  64% Completed | 9/14 [00:14<00:08,  1.74s/it]
Loading safetensors checkpoint shards:  71% Completed | 10/14 [00:16<00:06,  1.72s/it]
Loading safetensors checkpoint shards:  79% Completed | 11/14 [00:17<00:04,  1.45s/it]
Loading safetensors checkpoint shards:  86% Completed | 12/14 [00:18<00:02,  1.49s/it]
Loading safetensors checkpoint shards:  93% Completed | 13/14 [00:20<00:01,  1.62s/it]
Waiting for server on port 40000 to start...
[2025-08-25 18:16:51 TP1] Load weight end. type=Qwen2ForCausalLM, dtype=torch.bfloat16, avail mem=47.75 GB, mem usage=30.72 GB.
Loading safetensors checkpoint shards: 100% Completed | 14/14 [00:22<00:00,  1.52s/it]
Loading safetensors checkpoint shards: 100% Completed | 14/14 [00:22<00:00,  1.58s/it]

[2025-08-25 18:16:52 TP0] Load weight end. type=Qwen2ForCausalLM, dtype=torch.bfloat16, avail mem=47.75 GB, mem usage=30.72 GB.
[2025-08-25 18:16:52 TP0] KV Cache is allocated. #tokens: 326885, K size: 19.95 GB, V size: 19.95 GB
[2025-08-25 18:16:52 TP0] Memory pool end. avail mem=7.13 GB
[2025-08-25 18:16:52 TP1] KV Cache is allocated. #tokens: 326885, K size: 19.95 GB, V size: 19.95 GB
[2025-08-25 18:16:52 TP1] Memory pool end. avail mem=7.13 GB
[2025-08-25 18:16:52 TP0] Capture cuda graph begin. This can take up to several minutes. avail mem=6.51 GB
  0%|          | 0/23 [00:00<?, ?it/s][2025-08-25 18:16:52 TP1] Capture cuda graph begin. This can take up to several minutes. avail mem=6.51 GB
  4%|▍         | 1/23 [00:02<01:01,  2.80s/it]  9%|▊         | 2/23 [00:03<00:34,  1.66s/it] 13%|█▎        | 3/23 [00:04<00:29,  1.47s/it] 17%|█▋        | 4/23 [00:05<00:21,  1.13s/it] 22%|██▏       | 5/23 [00:06<00:16,  1.06it/s] 26%|██▌       | 6/23 [00:06<00:14,  1.21it/s] 30%|███       | 7/23 [00:07<00:12,  1.28it/s] 35%|███▍      | 8/23 [00:08<00:11,  1.34it/s]Waiting for server on port 40000 to start...
 39%|███▉      | 9/23 [00:08<00:09,  1.47it/s] 43%|████▎     | 10/23 [00:09<00:09,  1.42it/s] 48%|████▊     | 11/23 [00:10<00:08,  1.45it/s] 52%|█████▏    | 12/23 [00:10<00:07,  1.45it/s] 57%|█████▋    | 13/23 [00:11<00:06,  1.48it/s] 61%|██████    | 14/23 [00:11<00:05,  1.53it/s] 65%|██████▌   | 15/23 [00:12<00:05,  1.52it/s] 70%|██████▉   | 16/23 [00:13<00:04,  1.56it/s] 74%|███████▍  | 17/23 [00:13<00:04,  1.48it/s] 78%|███████▊  | 18/23 [00:14<00:03,  1.52it/s] 83%|████████▎ | 19/23 [00:15<00:02,  1.61it/s] 87%|████████▋ | 20/23 [00:15<00:01,  1.59it/s] 91%|█████████▏| 21/23 [00:16<00:01,  1.52it/s] 96%|█████████▌| 22/23 [00:17<00:00,  1.52it/s][2025-08-25 18:17:10 TP1] Registering 2967 cuda graph addresses
100%|██████████| 23/23 [00:17<00:00,  1.55it/s]100%|██████████| 23/23 [00:17<00:00,  1.29it/s]
[2025-08-25 18:17:10 TP0] Registering 2967 cuda graph addresses
[2025-08-25 18:17:10 TP0] Capture cuda graph end. Time elapsed: 17.86 s. avail mem=4.09 GB. mem usage=2.42 GB.
[2025-08-25 18:17:10 TP1] Capture cuda graph end. Time elapsed: 17.77 s. avail mem=4.09 GB. mem usage=2.42 GB.
Waiting for server on port 40000 to start...
[2025-08-25 18:17:11 TP0] max_total_num_tokens=326885, chunked_prefill_size=8192, max_prefill_tokens=16384, max_running_requests=4087, context_len=40960
[2025-08-25 18:17:11 TP1] max_total_num_tokens=326885, chunked_prefill_size=8192, max_prefill_tokens=16384, max_running_requests=4087, context_len=40960
[2025-08-25 18:17:11] INFO:     Started server process [2394117]
[2025-08-25 18:17:11] INFO:     Waiting for application startup.
[2025-08-25 18:17:11] INFO:     Application startup complete.
[2025-08-25 18:17:11] INFO:     Uvicorn running on http://0.0.0.0:40000 (Press CTRL+C to quit)
[2025-08-25 18:17:12] INFO:     127.0.0.1:2596 - "GET /get_model_info HTTP/1.1" 200 OK
[2025-08-25 18:17:12 TP0] Prefill batch. #new-seq: 1, #new-token: 6, #cached-token: 0, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-08-25 18:17:17] INFO:     127.0.0.1:2600 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 18:17:17] The server is fired up and ready to roll!
[2025-08-25 18:17:20] INFO:     127.0.0.1:39188 - "GET /get_model_info HTTP/1.1" 200 OK
Server on port 40000 is ready!
[2025-08-25 18:17:21] INFO:     127.0.0.1:38360 - "GET /get_model_info HTTP/1.1" 200 OK
Server on port 40001 is ready!
[2025-08-25 18:18:17 TP0] Prefill batch. #new-seq: 1, #new-token: 82, #cached-token: 1, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-08-25 18:18:17 TP0] Prefill batch. #new-seq: 3, #new-token: 246, #cached-token: 3, token usage: 0.00, #running-req: 1, #queue-req: 0, 
[2025-08-25 18:18:17 TP0] Decode batch. #running-req: 4, #token: 215, token usage: 0.00, gen throughput (token/s): 1.40, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:18:17 TP0] Decode batch. #running-req: 4, #token: 375, token usage: 0.00, gen throughput (token/s): 835.10, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:18:17 TP0] Decode batch. #running-req: 4, #token: 535, token usage: 0.00, gen throughput (token/s): 856.04, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:18:18 TP0] Decode batch. #running-req: 4, #token: 695, token usage: 0.00, gen throughput (token/s): 849.09, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:18:18 TP0] Decode batch. #running-req: 4, #token: 855, token usage: 0.00, gen throughput (token/s): 869.35, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:18:18 TP0] Decode batch. #running-req: 4, #token: 1015, token usage: 0.00, gen throughput (token/s): 848.88, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:18:18 TP0] Decode batch. #running-req: 4, #token: 1175, token usage: 0.00, gen throughput (token/s): 836.01, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:18:18 TP0] Decode batch. #running-req: 4, #token: 1335, token usage: 0.00, gen throughput (token/s): 858.79, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:18:19 TP0] Decode batch. #running-req: 4, #token: 1495, token usage: 0.00, gen throughput (token/s): 836.05, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:18:19 TP0] Decode batch. #running-req: 4, #token: 1655, token usage: 0.00, gen throughput (token/s): 883.92, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:18:19 TP0] Decode batch. #running-req: 4, #token: 1815, token usage: 0.00, gen throughput (token/s): 837.89, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:18:19 TP0] Decode batch. #running-req: 4, #token: 1975, token usage: 0.00, gen throughput (token/s): 840.30, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:18:19] INFO:     127.0.0.1:37638 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 18:18:19] INFO:     127.0.0.1:37640 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 18:18:19] INFO:     127.0.0.1:37642 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 18:18:19] INFO:     127.0.0.1:37654 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 18:18:19 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 82, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-08-25 18:18:19 TP0] Prefill batch. #new-seq: 3, #new-token: 3, #cached-token: 246, token usage: 0.00, #running-req: 1, #queue-req: 0, 
[2025-08-25 18:18:19 TP0] Decode batch. #running-req: 4, #token: 135, token usage: 0.00, gen throughput (token/s): 564.75, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:18:20 TP0] Decode batch. #running-req: 4, #token: 295, token usage: 0.00, gen throughput (token/s): 878.21, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:18:20 TP0] Decode batch. #running-req: 4, #token: 455, token usage: 0.00, gen throughput (token/s): 865.43, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:18:20 TP0] Decode batch. #running-req: 4, #token: 615, token usage: 0.00, gen throughput (token/s): 859.57, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:18:20 TP0] Decode batch. #running-req: 4, #token: 775, token usage: 0.00, gen throughput (token/s): 856.26, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:18:20 TP0] Decode batch. #running-req: 4, #token: 935, token usage: 0.00, gen throughput (token/s): 871.64, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:18:21 TP0] Decode batch. #running-req: 4, #token: 1095, token usage: 0.00, gen throughput (token/s): 845.34, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:18:21 TP0] Decode batch. #running-req: 4, #token: 1255, token usage: 0.00, gen throughput (token/s): 863.49, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:18:21 TP0] Decode batch. #running-req: 4, #token: 1415, token usage: 0.00, gen throughput (token/s): 867.05, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:18:21 TP0] Decode batch. #running-req: 4, #token: 1575, token usage: 0.00, gen throughput (token/s): 856.07, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:18:21 TP0] Decode batch. #running-req: 4, #token: 1735, token usage: 0.00, gen throughput (token/s): 865.65, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:18:21 TP0] Decode batch. #running-req: 4, #token: 1895, token usage: 0.00, gen throughput (token/s): 858.82, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:18:22 TP0] Decode batch. #running-req: 4, #token: 2055, token usage: 0.00, gen throughput (token/s): 859.30, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:18:22] INFO:     127.0.0.1:37638 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 18:18:22] INFO:     127.0.0.1:37640 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 18:18:22] INFO:     127.0.0.1:37642 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 18:18:22] INFO:     127.0.0.1:37654 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 18:18:22 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 82, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-08-25 18:18:22 TP0] Prefill batch. #new-seq: 3, #new-token: 3, #cached-token: 246, token usage: 0.00, #running-req: 1, #queue-req: 0, 
[2025-08-25 18:18:22 TP0] Decode batch. #running-req: 4, #token: 215, token usage: 0.00, gen throughput (token/s): 574.15, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:18:22 TP0] Decode batch. #running-req: 4, #token: 375, token usage: 0.00, gen throughput (token/s): 873.51, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:18:22 TP0] Decode batch. #running-req: 4, #token: 535, token usage: 0.00, gen throughput (token/s): 873.97, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:18:22 TP0] Decode batch. #running-req: 4, #token: 695, token usage: 0.00, gen throughput (token/s): 868.35, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:18:23 TP0] Decode batch. #running-req: 4, #token: 855, token usage: 0.00, gen throughput (token/s): 860.26, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:18:23 TP0] Decode batch. #running-req: 4, #token: 1015, token usage: 0.00, gen throughput (token/s): 841.43, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:18:23 TP0] Decode batch. #running-req: 4, #token: 1175, token usage: 0.00, gen throughput (token/s): 843.02, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:18:23 TP0] Decode batch. #running-req: 4, #token: 1335, token usage: 0.00, gen throughput (token/s): 845.94, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:18:23 TP0] Decode batch. #running-req: 4, #token: 1495, token usage: 0.00, gen throughput (token/s): 835.89, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:18:24 TP0] Decode batch. #running-req: 4, #token: 1655, token usage: 0.00, gen throughput (token/s): 859.77, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:18:24 TP0] Decode batch. #running-req: 4, #token: 1815, token usage: 0.00, gen throughput (token/s): 856.38, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:18:24 TP0] Decode batch. #running-req: 4, #token: 1975, token usage: 0.00, gen throughput (token/s): 840.58, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:18:24] INFO:     127.0.0.1:37638 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 18:18:24] INFO:     127.0.0.1:37640 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 18:18:24] INFO:     127.0.0.1:37642 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 18:18:24] INFO:     127.0.0.1:37654 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 18:18:24 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 82, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-08-25 18:18:24 TP0] Prefill batch. #new-seq: 3, #new-token: 3, #cached-token: 246, token usage: 0.00, #running-req: 1, #queue-req: 0, 
[2025-08-25 18:18:24 TP0] Decode batch. #running-req: 4, #token: 135, token usage: 0.00, gen throughput (token/s): 578.85, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:18:24 TP0] Decode batch. #running-req: 4, #token: 295, token usage: 0.00, gen throughput (token/s): 870.75, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:18:25 TP0] Decode batch. #running-req: 4, #token: 455, token usage: 0.00, gen throughput (token/s): 858.25, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:18:25 TP0] Decode batch. #running-req: 4, #token: 615, token usage: 0.00, gen throughput (token/s): 853.67, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:18:25 TP0] Decode batch. #running-req: 4, #token: 775, token usage: 0.00, gen throughput (token/s): 851.02, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:18:25 TP0] Decode batch. #running-req: 4, #token: 935, token usage: 0.00, gen throughput (token/s): 851.67, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:18:25 TP0] Decode batch. #running-req: 4, #token: 1095, token usage: 0.00, gen throughput (token/s): 862.39, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:18:26 TP0] Decode batch. #running-req: 4, #token: 1255, token usage: 0.00, gen throughput (token/s): 863.58, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:18:26 TP0] Decode batch. #running-req: 4, #token: 1415, token usage: 0.00, gen throughput (token/s): 840.12, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:18:26 TP0] Decode batch. #running-req: 4, #token: 1575, token usage: 0.00, gen throughput (token/s): 862.28, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:18:26 TP0] Decode batch. #running-req: 4, #token: 1735, token usage: 0.00, gen throughput (token/s): 853.07, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:18:26 TP0] Decode batch. #running-req: 4, #token: 1895, token usage: 0.00, gen throughput (token/s): 842.13, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:18:26 TP0] Decode batch. #running-req: 4, #token: 2055, token usage: 0.00, gen throughput (token/s): 870.27, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:18:27] INFO:     127.0.0.1:37638 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 18:18:27] INFO:     127.0.0.1:37640 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 18:18:27] INFO:     127.0.0.1:37642 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 18:18:27] INFO:     127.0.0.1:37654 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 18:18:27 TP0] Prefill batch. #new-seq: 4, #new-token: 2288, #cached-token: 0, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-08-25 18:18:28] INFO:     127.0.0.1:34290 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 18:18:28] INFO:     127.0.0.1:34294 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 18:18:28] INFO:     127.0.0.1:34310 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 18:18:28] INFO:     127.0.0.1:34318 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 18:18:28 TP0] Prefill batch. #new-seq: 1, #new-token: 500, #cached-token: 72, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-08-25 18:18:28 TP0] Prefill batch. #new-seq: 3, #new-token: 1500, #cached-token: 216, token usage: 0.00, #running-req: 1, #queue-req: 0, 
[2025-08-25 18:18:29] INFO:     127.0.0.1:34310 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 18:18:29] INFO:     127.0.0.1:34290 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 18:18:29] INFO:     127.0.0.1:34294 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 18:18:29] INFO:     127.0.0.1:34318 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 18:18:29 TP0] Prefill batch. #new-seq: 1, #new-token: 500, #cached-token: 72, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-08-25 18:18:29] INFO:     127.0.0.1:34310 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 18:18:29 TP0] Prefill batch. #new-seq: 3, #new-token: 1500, #cached-token: 216, token usage: 0.00, #running-req: 1, #queue-req: 0, 
[2025-08-25 18:18:29 TP0] Prefill batch. #new-seq: 1, #new-token: 500, #cached-token: 72, token usage: 0.00, #running-req: 4, #queue-req: 0, 
[2025-08-25 18:18:30] INFO:     127.0.0.1:34290 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 18:18:30] INFO:     127.0.0.1:34294 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 18:18:30] INFO:     127.0.0.1:34318 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 18:18:30 TP0] Prefill batch. #new-seq: 3, #new-token: 1500, #cached-token: 216, token usage: 0.00, #running-req: 1, #queue-req: 0, 
[2025-08-25 18:18:30] INFO:     127.0.0.1:34310 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 18:18:30 TP0] Prefill batch. #new-seq: 1, #new-token: 581, #cached-token: 0, token usage: 0.00, #running-req: 4, #queue-req: 0, 
[2025-08-25 18:18:30] INFO:     127.0.0.1:34290 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 18:18:30] INFO:     127.0.0.1:34294 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 18:18:30] INFO:     127.0.0.1:34318 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 18:18:30 TP0] Prefill batch. #new-seq: 3, #new-token: 1489, #cached-token: 254, token usage: 0.00, #running-req: 1, #queue-req: 0, 
[2025-08-25 18:18:32 TP0] Decode batch. #running-req: 4, #token: 2183, token usage: 0.01, gen throughput (token/s): 1.56, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:18:33 TP0] Decode batch. #running-req: 4, #token: 2343, token usage: 0.01, gen throughput (token/s): 154.22, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:18:34 TP0] Decode batch. #running-req: 4, #token: 2503, token usage: 0.01, gen throughput (token/s): 153.32, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:18:35 TP0] Decode batch. #running-req: 4, #token: 2663, token usage: 0.01, gen throughput (token/s): 153.40, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:18:35] INFO:     127.0.0.1:34310 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 18:18:35] INFO:     127.0.0.1:34290 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 18:18:35] INFO:     127.0.0.1:34294 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 18:18:35] INFO:     127.0.0.1:34318 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 18:18:35 TP0] Prefill batch. #new-seq: 1, #new-token: 492, #cached-token: 89, token usage: 0.00, #running-req: 3, #queue-req: 0, 
[2025-08-25 18:18:36 TP0] Decode batch. #running-req: 1, #token: 619, token usage: 0.00, gen throughput (token/s): 41.21, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:18:37 TP0] Decode batch. #running-req: 1, #token: 659, token usage: 0.00, gen throughput (token/s): 39.01, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:18:38 TP0] Decode batch. #running-req: 1, #token: 699, token usage: 0.00, gen throughput (token/s): 39.10, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:18:39] INFO:     127.0.0.1:34310 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 18:18:39 TP0] Prefill batch. #new-seq: 4, #new-token: 648, #cached-token: 200, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-08-25 18:18:39 TP0] Decode batch. #running-req: 4, #token: 344, token usage: 0.00, gen throughput (token/s): 12.86, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:18:39 TP0] Decode batch. #running-req: 4, #token: 504, token usage: 0.00, gen throughput (token/s): 851.89, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:18:39 TP0] Decode batch. #running-req: 4, #token: 664, token usage: 0.00, gen throughput (token/s): 872.88, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:18:39 TP0] Decode batch. #running-req: 4, #token: 824, token usage: 0.00, gen throughput (token/s): 838.36, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:18:40 TP0] Decode batch. #running-req: 4, #token: 984, token usage: 0.00, gen throughput (token/s): 872.19, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:18:40 TP0] Decode batch. #running-req: 4, #token: 1144, token usage: 0.00, gen throughput (token/s): 842.59, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:18:40 TP0] Decode batch. #running-req: 4, #token: 1304, token usage: 0.00, gen throughput (token/s): 849.86, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:18:40 TP0] Decode batch. #running-req: 4, #token: 1464, token usage: 0.00, gen throughput (token/s): 846.34, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:18:40 TP0] Decode batch. #running-req: 4, #token: 1624, token usage: 0.00, gen throughput (token/s): 845.70, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:18:41 TP0] Decode batch. #running-req: 4, #token: 1784, token usage: 0.00, gen throughput (token/s): 856.62, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:18:41 TP0] Decode batch. #running-req: 4, #token: 1944, token usage: 0.00, gen throughput (token/s): 847.78, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:18:41 TP0] Decode batch. #running-req: 4, #token: 2104, token usage: 0.00, gen throughput (token/s): 931.50, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:18:41] INFO:     127.0.0.1:47284 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 18:18:41] INFO:     127.0.0.1:47298 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 18:18:41] INFO:     127.0.0.1:47300 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 18:18:41] INFO:     127.0.0.1:47306 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 18:18:41 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 211, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-08-25 18:18:41 TP0] Prefill batch. #new-seq: 3, #new-token: 3, #cached-token: 633, token usage: 0.00, #running-req: 1, #queue-req: 0, 
[2025-08-25 18:18:41 TP0] Decode batch. #running-req: 4, #token: 264, token usage: 0.00, gen throughput (token/s): 574.21, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:18:41 TP0] Decode batch. #running-req: 4, #token: 424, token usage: 0.00, gen throughput (token/s): 887.63, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:18:42 TP0] Decode batch. #running-req: 4, #token: 584, token usage: 0.00, gen throughput (token/s): 873.29, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:18:42 TP0] Decode batch. #running-req: 4, #token: 744, token usage: 0.00, gen throughput (token/s): 887.24, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:18:42 TP0] Decode batch. #running-req: 4, #token: 904, token usage: 0.00, gen throughput (token/s): 894.59, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:18:42 TP0] Decode batch. #running-req: 4, #token: 1064, token usage: 0.00, gen throughput (token/s): 888.69, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:18:42 TP0] Decode batch. #running-req: 4, #token: 1224, token usage: 0.00, gen throughput (token/s): 882.39, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:18:43 TP0] Decode batch. #running-req: 4, #token: 1384, token usage: 0.00, gen throughput (token/s): 872.99, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:18:43 TP0] Decode batch. #running-req: 4, #token: 1544, token usage: 0.00, gen throughput (token/s): 874.87, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:18:43 TP0] Decode batch. #running-req: 4, #token: 1704, token usage: 0.00, gen throughput (token/s): 902.11, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:18:43 TP0] Decode batch. #running-req: 4, #token: 1864, token usage: 0.00, gen throughput (token/s): 913.22, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:18:43 TP0] Decode batch. #running-req: 4, #token: 2024, token usage: 0.00, gen throughput (token/s): 885.28, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:18:43 TP0] Decode batch. #running-req: 4, #token: 2184, token usage: 0.00, gen throughput (token/s): 884.09, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:18:43] INFO:     127.0.0.1:47306 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 18:18:43] INFO:     127.0.0.1:47284 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 18:18:43] INFO:     127.0.0.1:47298 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 18:18:43] INFO:     127.0.0.1:47300 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 18:18:43 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 211, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-08-25 18:18:44 TP0] Prefill batch. #new-seq: 3, #new-token: 3, #cached-token: 633, token usage: 0.00, #running-req: 1, #queue-req: 0, 
[2025-08-25 18:18:44 TP0] Decode batch. #running-req: 4, #token: 344, token usage: 0.00, gen throughput (token/s): 572.57, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:18:44 TP0] Decode batch. #running-req: 4, #token: 504, token usage: 0.00, gen throughput (token/s): 873.76, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:18:44 TP0] Decode batch. #running-req: 4, #token: 664, token usage: 0.00, gen throughput (token/s): 870.66, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:18:44 TP0] Decode batch. #running-req: 4, #token: 824, token usage: 0.00, gen throughput (token/s): 873.23, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:18:44 TP0] Decode batch. #running-req: 4, #token: 984, token usage: 0.00, gen throughput (token/s): 873.97, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:18:45 TP0] Decode batch. #running-req: 4, #token: 1144, token usage: 0.00, gen throughput (token/s): 886.70, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:18:45 TP0] Decode batch. #running-req: 4, #token: 1304, token usage: 0.00, gen throughput (token/s): 883.00, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:18:45 TP0] Decode batch. #running-req: 4, #token: 1464, token usage: 0.00, gen throughput (token/s): 881.53, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:18:45 TP0] Decode batch. #running-req: 4, #token: 1624, token usage: 0.00, gen throughput (token/s): 864.08, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:18:45 TP0] Decode batch. #running-req: 4, #token: 1784, token usage: 0.00, gen throughput (token/s): 861.57, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:18:46 TP0] Decode batch. #running-req: 4, #token: 1944, token usage: 0.00, gen throughput (token/s): 867.34, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:18:46 TP0] Decode batch. #running-req: 4, #token: 2104, token usage: 0.00, gen throughput (token/s): 849.98, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:18:46] INFO:     127.0.0.1:47306 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 18:18:46] INFO:     127.0.0.1:47284 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 18:18:46] INFO:     127.0.0.1:47298 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 18:18:46] INFO:     127.0.0.1:47300 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 18:18:46 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 211, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-08-25 18:18:46 TP0] Prefill batch. #new-seq: 3, #new-token: 3, #cached-token: 633, token usage: 0.00, #running-req: 1, #queue-req: 0, 
[2025-08-25 18:18:46 TP0] Decode batch. #running-req: 4, #token: 264, token usage: 0.00, gen throughput (token/s): 573.42, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:18:46 TP0] Decode batch. #running-req: 4, #token: 424, token usage: 0.00, gen throughput (token/s): 865.96, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:18:46 TP0] Decode batch. #running-req: 4, #token: 584, token usage: 0.00, gen throughput (token/s): 885.25, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:18:47 TP0] Decode batch. #running-req: 4, #token: 744, token usage: 0.00, gen throughput (token/s): 849.93, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:18:47 TP0] Decode batch. #running-req: 4, #token: 904, token usage: 0.00, gen throughput (token/s): 873.06, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:18:47 TP0] Decode batch. #running-req: 4, #token: 1064, token usage: 0.00, gen throughput (token/s): 865.55, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:18:47 TP0] Decode batch. #running-req: 4, #token: 1224, token usage: 0.00, gen throughput (token/s): 866.21, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:18:47 TP0] Decode batch. #running-req: 4, #token: 1384, token usage: 0.00, gen throughput (token/s): 877.04, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:18:47 TP0] Decode batch. #running-req: 4, #token: 1544, token usage: 0.00, gen throughput (token/s): 851.36, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:18:48 TP0] Decode batch. #running-req: 4, #token: 1704, token usage: 0.00, gen throughput (token/s): 854.16, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:18:48 TP0] Decode batch. #running-req: 4, #token: 1864, token usage: 0.00, gen throughput (token/s): 877.18, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:18:48 TP0] Decode batch. #running-req: 4, #token: 2024, token usage: 0.00, gen throughput (token/s): 855.77, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:18:48 TP0] Decode batch. #running-req: 4, #token: 2184, token usage: 0.00, gen throughput (token/s): 881.24, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:18:48] INFO:     127.0.0.1:47306 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 18:18:48] INFO:     127.0.0.1:47284 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 18:18:48] INFO:     127.0.0.1:47298 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 18:18:48] INFO:     127.0.0.1:47300 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 18:18:48 TP0] Prefill batch. #new-seq: 4, #new-token: 2636, #cached-token: 168, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-08-25 18:18:49] INFO:     127.0.0.1:26494 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 18:18:49] INFO:     127.0.0.1:26510 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 18:18:49] INFO:     127.0.0.1:26522 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 18:18:49] INFO:     127.0.0.1:26532 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 18:18:49 TP0] Prefill batch. #new-seq: 1, #new-token: 500, #cached-token: 201, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-08-25 18:18:49 TP0] Prefill batch. #new-seq: 3, #new-token: 1500, #cached-token: 603, token usage: 0.00, #running-req: 1, #queue-req: 0, 
[2025-08-25 18:18:50] INFO:     127.0.0.1:26494 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 18:18:50] INFO:     127.0.0.1:26532 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 18:18:50] INFO:     127.0.0.1:26510 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 18:18:50] INFO:     127.0.0.1:26522 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 18:18:50 TP0] Prefill batch. #new-seq: 1, #new-token: 500, #cached-token: 201, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-08-25 18:18:50] INFO:     127.0.0.1:26494 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 18:18:50 TP0] Prefill batch. #new-seq: 3, #new-token: 1500, #cached-token: 603, token usage: 0.00, #running-req: 1, #queue-req: 0, 
[2025-08-25 18:18:50 TP0] Prefill batch. #new-seq: 1, #new-token: 500, #cached-token: 201, token usage: 0.01, #running-req: 4, #queue-req: 0, 
[2025-08-25 18:18:50] INFO:     127.0.0.1:26532 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 18:18:51] INFO:     127.0.0.1:26510 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 18:18:51] INFO:     127.0.0.1:26522 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 18:18:51 TP0] Prefill batch. #new-seq: 3, #new-token: 1500, #cached-token: 603, token usage: 0.00, #running-req: 1, #queue-req: 0, 
[2025-08-25 18:18:51] INFO:     127.0.0.1:26494 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 18:18:51 TP0] Prefill batch. #new-seq: 1, #new-token: 666, #cached-token: 44, token usage: 0.01, #running-req: 4, #queue-req: 0, 
[2025-08-25 18:18:51] INFO:     127.0.0.1:26532 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 18:18:51] INFO:     127.0.0.1:26510 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 18:18:51] INFO:     127.0.0.1:26522 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 18:18:51 TP0] Prefill batch. #new-seq: 3, #new-token: 1498, #cached-token: 632, token usage: 0.00, #running-req: 1, #queue-req: 0, 
[2025-08-25 18:18:52 TP0] Decode batch. #running-req: 4, #token: 2217, token usage: 0.01, gen throughput (token/s): 3.67, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:18:53 TP0] Decode batch. #running-req: 4, #token: 2377, token usage: 0.01, gen throughput (token/s): 153.78, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:18:54 TP0] Decode batch. #running-req: 4, #token: 2537, token usage: 0.01, gen throughput (token/s): 153.00, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:18:55 TP0] Decode batch. #running-req: 4, #token: 2697, token usage: 0.01, gen throughput (token/s): 154.40, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:18:56] INFO:     127.0.0.1:26494 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 18:18:56] INFO:     127.0.0.1:26532 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 18:18:56] INFO:     127.0.0.1:26510 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 18:18:56] INFO:     127.0.0.1:26522 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 18:18:56 TP0] Prefill batch. #new-seq: 1, #new-token: 478, #cached-token: 232, token usage: 0.00, #running-req: 3, #queue-req: 0, 
[2025-08-25 18:18:56 TP0] Decode batch. #running-req: 1, #token: 723, token usage: 0.00, gen throughput (token/s): 102.72, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:18:57 TP0] Decode batch. #running-req: 1, #token: 763, token usage: 0.00, gen throughput (token/s): 38.87, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:18:58 TP0] Decode batch. #running-req: 1, #token: 803, token usage: 0.00, gen throughput (token/s): 38.90, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:18:59 TP0] Decode batch. #running-req: 1, #token: 843, token usage: 0.00, gen throughput (token/s): 39.05, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:19:00] INFO:     127.0.0.1:26494 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 18:19:00 TP0] Prefill batch. #new-seq: 4, #new-token: 468, #cached-token: 200, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-08-25 18:19:00 TP0] Decode batch. #running-req: 4, #token: 299, token usage: 0.00, gen throughput (token/s): 13.76, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:19:00 TP0] Decode batch. #running-req: 4, #token: 459, token usage: 0.00, gen throughput (token/s): 885.63, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:19:00 TP0] Decode batch. #running-req: 4, #token: 619, token usage: 0.00, gen throughput (token/s): 877.03, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:19:00 TP0] Decode batch. #running-req: 4, #token: 779, token usage: 0.00, gen throughput (token/s): 866.67, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:19:01 TP0] Decode batch. #running-req: 4, #token: 939, token usage: 0.00, gen throughput (token/s): 863.93, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:19:01 TP0] Decode batch. #running-req: 4, #token: 1099, token usage: 0.00, gen throughput (token/s): 853.51, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:19:01 TP0] Decode batch. #running-req: 4, #token: 1259, token usage: 0.00, gen throughput (token/s): 836.22, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:19:01 TP0] Decode batch. #running-req: 4, #token: 1419, token usage: 0.00, gen throughput (token/s): 853.99, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:19:01 TP0] Decode batch. #running-req: 4, #token: 1579, token usage: 0.00, gen throughput (token/s): 848.92, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:19:02 TP0] Decode batch. #running-req: 4, #token: 1739, token usage: 0.00, gen throughput (token/s): 869.65, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:19:02 TP0] Decode batch. #running-req: 4, #token: 1899, token usage: 0.00, gen throughput (token/s): 837.37, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:19:02 TP0] Decode batch. #running-req: 4, #token: 2059, token usage: 0.00, gen throughput (token/s): 869.76, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:19:02] INFO:     127.0.0.1:35080 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 18:19:02] INFO:     127.0.0.1:35094 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 18:19:02] INFO:     127.0.0.1:35102 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 18:19:02] INFO:     127.0.0.1:35106 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 18:19:02 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 166, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-08-25 18:19:02 TP0] Prefill batch. #new-seq: 3, #new-token: 3, #cached-token: 498, token usage: 0.00, #running-req: 1, #queue-req: 0, 
[2025-08-25 18:19:02 TP0] Decode batch. #running-req: 4, #token: 219, token usage: 0.00, gen throughput (token/s): 541.35, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:19:02 TP0] Decode batch. #running-req: 4, #token: 379, token usage: 0.00, gen throughput (token/s): 849.42, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:19:03 TP0] Decode batch. #running-req: 4, #token: 539, token usage: 0.00, gen throughput (token/s): 936.21, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:19:03 TP0] Decode batch. #running-req: 4, #token: 699, token usage: 0.00, gen throughput (token/s): 949.63, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:19:03 TP0] Decode batch. #running-req: 4, #token: 859, token usage: 0.00, gen throughput (token/s): 876.51, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:19:03 TP0] Decode batch. #running-req: 4, #token: 1019, token usage: 0.00, gen throughput (token/s): 895.34, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:19:03 TP0] Decode batch. #running-req: 4, #token: 1179, token usage: 0.00, gen throughput (token/s): 942.26, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:19:03 TP0] Decode batch. #running-req: 4, #token: 1339, token usage: 0.00, gen throughput (token/s): 962.62, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:19:04 TP0] Decode batch. #running-req: 4, #token: 1499, token usage: 0.00, gen throughput (token/s): 955.04, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:19:04 TP0] Decode batch. #running-req: 4, #token: 1659, token usage: 0.00, gen throughput (token/s): 910.86, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:19:04 TP0] Decode batch. #running-req: 4, #token: 1819, token usage: 0.00, gen throughput (token/s): 876.78, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:19:04 TP0] Decode batch. #running-req: 4, #token: 1979, token usage: 0.00, gen throughput (token/s): 892.79, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:19:04 TP0] Decode batch. #running-req: 4, #token: 2139, token usage: 0.00, gen throughput (token/s): 884.76, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:19:04] INFO:     127.0.0.1:35106 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 18:19:04] INFO:     127.0.0.1:35080 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 18:19:04] INFO:     127.0.0.1:35094 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 18:19:04] INFO:     127.0.0.1:35102 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 18:19:04 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 166, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-08-25 18:19:04 TP0] Prefill batch. #new-seq: 3, #new-token: 3, #cached-token: 498, token usage: 0.00, #running-req: 1, #queue-req: 0, 
[2025-08-25 18:19:05 TP0] Decode batch. #running-req: 4, #token: 299, token usage: 0.00, gen throughput (token/s): 564.08, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:19:05 TP0] Decode batch. #running-req: 4, #token: 459, token usage: 0.00, gen throughput (token/s): 872.91, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:19:05 TP0] Decode batch. #running-req: 4, #token: 619, token usage: 0.00, gen throughput (token/s): 868.94, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:19:05 TP0] Decode batch. #running-req: 4, #token: 779, token usage: 0.00, gen throughput (token/s): 877.28, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:19:05 TP0] Decode batch. #running-req: 4, #token: 939, token usage: 0.00, gen throughput (token/s): 875.66, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:19:05 TP0] Decode batch. #running-req: 4, #token: 1099, token usage: 0.00, gen throughput (token/s): 868.62, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:19:06 TP0] Decode batch. #running-req: 4, #token: 1259, token usage: 0.00, gen throughput (token/s): 853.34, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:19:06 TP0] Decode batch. #running-req: 4, #token: 1419, token usage: 0.00, gen throughput (token/s): 850.67, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:19:06 TP0] Decode batch. #running-req: 4, #token: 1579, token usage: 0.00, gen throughput (token/s): 856.00, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:19:06 TP0] Decode batch. #running-req: 4, #token: 1739, token usage: 0.00, gen throughput (token/s): 861.12, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:19:06 TP0] Decode batch. #running-req: 4, #token: 1899, token usage: 0.00, gen throughput (token/s): 848.72, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:19:07 TP0] Decode batch. #running-req: 4, #token: 2059, token usage: 0.00, gen throughput (token/s): 846.14, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:19:07] INFO:     127.0.0.1:35106 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 18:19:07] INFO:     127.0.0.1:35080 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 18:19:07] INFO:     127.0.0.1:35094 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 18:19:07] INFO:     127.0.0.1:35102 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 18:19:07 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 166, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-08-25 18:19:07 TP0] Prefill batch. #new-seq: 3, #new-token: 3, #cached-token: 498, token usage: 0.00, #running-req: 1, #queue-req: 0, 
[2025-08-25 18:19:07 TP0] Decode batch. #running-req: 4, #token: 219, token usage: 0.00, gen throughput (token/s): 572.04, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:19:07 TP0] Decode batch. #running-req: 4, #token: 379, token usage: 0.00, gen throughput (token/s): 865.22, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:19:07 TP0] Decode batch. #running-req: 4, #token: 539, token usage: 0.00, gen throughput (token/s): 871.80, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:19:07 TP0] Decode batch. #running-req: 4, #token: 699, token usage: 0.00, gen throughput (token/s): 848.49, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:19:08 TP0] Decode batch. #running-req: 4, #token: 859, token usage: 0.00, gen throughput (token/s): 852.05, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:19:08 TP0] Decode batch. #running-req: 4, #token: 1019, token usage: 0.00, gen throughput (token/s): 842.46, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:19:08 TP0] Decode batch. #running-req: 4, #token: 1179, token usage: 0.00, gen throughput (token/s): 832.26, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:19:08 TP0] Decode batch. #running-req: 4, #token: 1339, token usage: 0.00, gen throughput (token/s): 869.07, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:19:08 TP0] Decode batch. #running-req: 4, #token: 1499, token usage: 0.00, gen throughput (token/s): 844.49, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:19:09 TP0] Decode batch. #running-req: 4, #token: 1659, token usage: 0.00, gen throughput (token/s): 859.14, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:19:09 TP0] Decode batch. #running-req: 4, #token: 1819, token usage: 0.00, gen throughput (token/s): 832.33, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:19:09 TP0] Decode batch. #running-req: 4, #token: 1979, token usage: 0.00, gen throughput (token/s): 844.98, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:19:09 TP0] Decode batch. #running-req: 4, #token: 2139, token usage: 0.00, gen throughput (token/s): 863.61, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:19:09] INFO:     127.0.0.1:35106 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 18:19:09] INFO:     127.0.0.1:35080 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 18:19:09] INFO:     127.0.0.1:35094 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 18:19:09] INFO:     127.0.0.1:35102 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 18:19:09 TP0] Prefill batch. #new-seq: 4, #new-token: 2456, #cached-token: 168, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-08-25 18:19:10] INFO:     127.0.0.1:65004 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 18:19:10] INFO:     127.0.0.1:65008 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 18:19:10] INFO:     127.0.0.1:65018 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 18:19:10] INFO:     127.0.0.1:65034 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 18:19:10 TP0] Prefill batch. #new-seq: 1, #new-token: 500, #cached-token: 156, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-08-25 18:19:10 TP0] Prefill batch. #new-seq: 3, #new-token: 1500, #cached-token: 468, token usage: 0.00, #running-req: 1, #queue-req: 0, 
[2025-08-25 18:19:11] INFO:     127.0.0.1:65034 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 18:19:11] INFO:     127.0.0.1:65004 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 18:19:11] INFO:     127.0.0.1:65008 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 18:19:11] INFO:     127.0.0.1:65018 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 18:19:11 TP0] Prefill batch. #new-seq: 1, #new-token: 500, #cached-token: 156, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-08-25 18:19:11 TP0] Prefill batch. #new-seq: 3, #new-token: 1500, #cached-token: 468, token usage: 0.00, #running-req: 1, #queue-req: 0, 
[2025-08-25 18:19:11] INFO:     127.0.0.1:65034 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 18:19:11] INFO:     127.0.0.1:65004 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 18:19:11] INFO:     127.0.0.1:65008 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 18:19:12] INFO:     127.0.0.1:65018 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 18:19:12 TP0] Prefill batch. #new-seq: 1, #new-token: 500, #cached-token: 156, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-08-25 18:19:12 TP0] Prefill batch. #new-seq: 3, #new-token: 1500, #cached-token: 468, token usage: 0.00, #running-req: 1, #queue-req: 0, 
[2025-08-25 18:19:12] INFO:     127.0.0.1:65034 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 18:19:12 TP0] Prefill batch. #new-seq: 1, #new-token: 621, #cached-token: 44, token usage: 0.00, #running-req: 3, #queue-req: 0, 
[2025-08-25 18:19:12] INFO:     127.0.0.1:65004 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 18:19:12] INFO:     127.0.0.1:65008 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 18:19:12] INFO:     127.0.0.1:65018 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 18:19:12 TP0] Prefill batch. #new-seq: 3, #new-token: 1863, #cached-token: 132, token usage: 0.00, #running-req: 4, #queue-req: 0, 
[2025-08-25 18:19:13 TP0] Decode batch. #running-req: 4, #token: 2230, token usage: 0.01, gen throughput (token/s): 7.29, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:19:14 TP0] Decode batch. #running-req: 4, #token: 2390, token usage: 0.01, gen throughput (token/s): 153.25, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:19:15 TP0] Decode batch. #running-req: 4, #token: 2550, token usage: 0.01, gen throughput (token/s): 154.07, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:19:16 TP0] Decode batch. #running-req: 4, #token: 2710, token usage: 0.01, gen throughput (token/s): 152.89, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:19:17] INFO:     127.0.0.1:65034 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 18:19:17] INFO:     127.0.0.1:65004 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 18:19:17] INFO:     127.0.0.1:65008 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 18:19:17] INFO:     127.0.0.1:65018 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 18:19:17 TP0] Prefill batch. #new-seq: 1, #new-token: 491, #cached-token: 174, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-08-25 18:19:17 TP0] Prefill batch. #new-seq: 1, #new-token: 483, #cached-token: 182, token usage: 0.00, #running-req: 1, #queue-req: 0, 
[2025-08-25 18:19:18 TP0] Decode batch. #running-req: 2, #token: 1219, token usage: 0.00, gen throughput (token/s): 77.16, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:19:19 TP0] Decode batch. #running-req: 2, #token: 1299, token usage: 0.00, gen throughput (token/s): 77.57, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:19:20 TP0] Decode batch. #running-req: 2, #token: 1379, token usage: 0.00, gen throughput (token/s): 77.83, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:19:21 TP0] Decode batch. #running-req: 2, #token: 1459, token usage: 0.00, gen throughput (token/s): 77.74, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:19:21] INFO:     127.0.0.1:65034 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 18:19:21] INFO:     127.0.0.1:65004 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 18:19:21 TP0] Prefill batch. #new-seq: 4, #new-token: 232, #cached-token: 208, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-08-25 18:19:21 TP0] Decode batch. #running-req: 4, #token: 242, token usage: 0.00, gen throughput (token/s): 13.37, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:19:21 TP0] Decode batch. #running-req: 4, #token: 402, token usage: 0.00, gen throughput (token/s): 880.00, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:19:21 TP0] Decode batch. #running-req: 4, #token: 562, token usage: 0.00, gen throughput (token/s): 859.26, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:19:22 TP0] Decode batch. #running-req: 4, #token: 722, token usage: 0.00, gen throughput (token/s): 849.90, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:19:22 TP0] Decode batch. #running-req: 4, #token: 882, token usage: 0.00, gen throughput (token/s): 867.94, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:19:22 TP0] Decode batch. #running-req: 4, #token: 1042, token usage: 0.00, gen throughput (token/s): 854.16, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:19:22 TP0] Decode batch. #running-req: 4, #token: 1202, token usage: 0.00, gen throughput (token/s): 853.35, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:19:22 TP0] Decode batch. #running-req: 4, #token: 1362, token usage: 0.00, gen throughput (token/s): 854.84, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:19:23 TP0] Decode batch. #running-req: 4, #token: 1522, token usage: 0.00, gen throughput (token/s): 839.52, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:19:23 TP0] Decode batch. #running-req: 4, #token: 1682, token usage: 0.00, gen throughput (token/s): 883.40, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:19:23 TP0] Decode batch. #running-req: 4, #token: 1842, token usage: 0.00, gen throughput (token/s): 867.91, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:19:23 TP0] Decode batch. #running-req: 4, #token: 2002, token usage: 0.00, gen throughput (token/s): 854.74, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:19:23] INFO:     127.0.0.1:41062 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 18:19:23] INFO:     127.0.0.1:41076 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 18:19:23] INFO:     127.0.0.1:41090 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 18:19:23] INFO:     127.0.0.1:41092 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 18:19:23 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 109, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-08-25 18:19:23 TP0] Prefill batch. #new-seq: 3, #new-token: 3, #cached-token: 327, token usage: 0.00, #running-req: 1, #queue-req: 0, 
[2025-08-25 18:19:23 TP0] Decode batch. #running-req: 4, #token: 162, token usage: 0.00, gen throughput (token/s): 590.09, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:19:24 TP0] Decode batch. #running-req: 4, #token: 322, token usage: 0.00, gen throughput (token/s): 883.23, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:19:24 TP0] Decode batch. #running-req: 4, #token: 482, token usage: 0.00, gen throughput (token/s): 888.18, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:19:24 TP0] Decode batch. #running-req: 4, #token: 642, token usage: 0.00, gen throughput (token/s): 855.21, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:19:24 TP0] Decode batch. #running-req: 4, #token: 802, token usage: 0.00, gen throughput (token/s): 879.02, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:19:24 TP0] Decode batch. #running-req: 4, #token: 962, token usage: 0.00, gen throughput (token/s): 856.65, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:19:25 TP0] Decode batch. #running-req: 4, #token: 1122, token usage: 0.00, gen throughput (token/s): 890.60, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:19:25 TP0] Decode batch. #running-req: 4, #token: 1282, token usage: 0.00, gen throughput (token/s): 876.05, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:19:25 TP0] Decode batch. #running-req: 4, #token: 1442, token usage: 0.00, gen throughput (token/s): 856.24, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:19:25 TP0] Decode batch. #running-req: 4, #token: 1602, token usage: 0.00, gen throughput (token/s): 877.99, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:19:25 TP0] Decode batch. #running-req: 4, #token: 1762, token usage: 0.00, gen throughput (token/s): 851.85, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:19:25 TP0] Decode batch. #running-req: 4, #token: 1922, token usage: 0.00, gen throughput (token/s): 863.82, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:19:26 TP0] Decode batch. #running-req: 4, #token: 2082, token usage: 0.00, gen throughput (token/s): 876.34, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:19:26] INFO:     127.0.0.1:41092 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 18:19:26] INFO:     127.0.0.1:41062 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 18:19:26] INFO:     127.0.0.1:41076 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 18:19:26] INFO:     127.0.0.1:41090 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 18:19:26 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 109, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-08-25 18:19:26 TP0] Prefill batch. #new-seq: 3, #new-token: 3, #cached-token: 327, token usage: 0.00, #running-req: 1, #queue-req: 0, 
[2025-08-25 18:19:26 TP0] Decode batch. #running-req: 4, #token: 242, token usage: 0.00, gen throughput (token/s): 576.71, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:19:26 TP0] Decode batch. #running-req: 4, #token: 402, token usage: 0.00, gen throughput (token/s): 858.68, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:19:26 TP0] Decode batch. #running-req: 4, #token: 562, token usage: 0.00, gen throughput (token/s): 843.02, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:19:26 TP0] Decode batch. #running-req: 4, #token: 722, token usage: 0.00, gen throughput (token/s): 853.14, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:19:27 TP0] Decode batch. #running-req: 4, #token: 882, token usage: 0.00, gen throughput (token/s): 880.25, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:19:27 TP0] Decode batch. #running-req: 4, #token: 1042, token usage: 0.00, gen throughput (token/s): 858.44, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:19:27 TP0] Decode batch. #running-req: 4, #token: 1202, token usage: 0.00, gen throughput (token/s): 860.57, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:19:27 TP0] Decode batch. #running-req: 4, #token: 1362, token usage: 0.00, gen throughput (token/s): 847.49, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:19:27 TP0] Decode batch. #running-req: 4, #token: 1522, token usage: 0.00, gen throughput (token/s): 880.22, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:19:28 TP0] Decode batch. #running-req: 4, #token: 1682, token usage: 0.00, gen throughput (token/s): 889.87, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:19:28 TP0] Decode batch. #running-req: 4, #token: 1842, token usage: 0.00, gen throughput (token/s): 861.49, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:19:28 TP0] Decode batch. #running-req: 4, #token: 2002, token usage: 0.00, gen throughput (token/s): 855.49, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:19:28] INFO:     127.0.0.1:41092 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 18:19:28] INFO:     127.0.0.1:41062 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 18:19:28] INFO:     127.0.0.1:41076 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 18:19:28] INFO:     127.0.0.1:41090 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 18:19:28 TP0] Prefill batch. #new-seq: 4, #new-token: 4, #cached-token: 436, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-08-25 18:19:28 TP0] Decode batch. #running-req: 4, #token: 162, token usage: 0.00, gen throughput (token/s): 647.46, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:19:28 TP0] Decode batch. #running-req: 4, #token: 322, token usage: 0.00, gen throughput (token/s): 848.16, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:19:29 TP0] Decode batch. #running-req: 4, #token: 482, token usage: 0.00, gen throughput (token/s): 881.18, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:19:29 TP0] Decode batch. #running-req: 4, #token: 642, token usage: 0.00, gen throughput (token/s): 872.12, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:19:29 TP0] Decode batch. #running-req: 4, #token: 802, token usage: 0.00, gen throughput (token/s): 885.80, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:19:29 TP0] Decode batch. #running-req: 4, #token: 962, token usage: 0.00, gen throughput (token/s): 863.34, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:19:29 TP0] Decode batch. #running-req: 4, #token: 1122, token usage: 0.00, gen throughput (token/s): 882.57, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:19:29 TP0] Decode batch. #running-req: 4, #token: 1282, token usage: 0.00, gen throughput (token/s): 859.04, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:19:30 TP0] Decode batch. #running-req: 4, #token: 1442, token usage: 0.00, gen throughput (token/s): 847.42, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:19:30 TP0] Decode batch. #running-req: 4, #token: 1602, token usage: 0.00, gen throughput (token/s): 853.99, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:19:30 TP0] Decode batch. #running-req: 4, #token: 1762, token usage: 0.00, gen throughput (token/s): 855.62, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:19:30 TP0] Decode batch. #running-req: 4, #token: 1922, token usage: 0.00, gen throughput (token/s): 865.06, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:19:30 TP0] Decode batch. #running-req: 4, #token: 2082, token usage: 0.00, gen throughput (token/s): 866.29, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:19:30] INFO:     127.0.0.1:41090 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 18:19:30] INFO:     127.0.0.1:41092 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 18:19:30] INFO:     127.0.0.1:41062 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 18:19:30] INFO:     127.0.0.1:41076 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 18:19:31 TP0] Prefill batch. #new-seq: 4, #new-token: 2220, #cached-token: 176, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-08-25 18:19:31] INFO:     127.0.0.1:27654 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 18:19:31] INFO:     127.0.0.1:27668 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 18:19:31] INFO:     127.0.0.1:27670 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 18:19:31] INFO:     127.0.0.1:27682 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 18:19:31 TP0] Prefill batch. #new-seq: 1, #new-token: 500, #cached-token: 99, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-08-25 18:19:31 TP0] Prefill batch. #new-seq: 3, #new-token: 1500, #cached-token: 297, token usage: 0.00, #running-req: 1, #queue-req: 0, 
[2025-08-25 18:19:31] INFO:     127.0.0.1:27670 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 18:19:31 TP0] Prefill batch. #new-seq: 1, #new-token: 500, #cached-token: 99, token usage: 0.00, #running-req: 4, #queue-req: 0, 
[2025-08-25 18:19:32] INFO:     127.0.0.1:27654 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 18:19:32] INFO:     127.0.0.1:27668 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 18:19:32] INFO:     127.0.0.1:27682 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 18:19:32] INFO:     127.0.0.1:27670 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 18:19:32 TP0] Prefill batch. #new-seq: 3, #new-token: 1500, #cached-token: 297, token usage: 0.00, #running-req: 1, #queue-req: 0, 
[2025-08-25 18:19:33 TP0] Prefill batch. #new-seq: 1, #new-token: 500, #cached-token: 99, token usage: 0.00, #running-req: 4, #queue-req: 0, 
[2025-08-25 18:19:33] INFO:     127.0.0.1:27682 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 18:19:33] INFO:     127.0.0.1:27654 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 18:19:33] INFO:     127.0.0.1:27668 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 18:19:33] INFO:     127.0.0.1:27670 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 18:19:33 TP0] Prefill batch. #new-seq: 3, #new-token: 1500, #cached-token: 297, token usage: 0.00, #running-req: 1, #queue-req: 0, 
[2025-08-25 18:19:33 TP0] Prefill batch. #new-seq: 1, #new-token: 562, #cached-token: 46, token usage: 0.01, #running-req: 4, #queue-req: 0, 
[2025-08-25 18:19:33] INFO:     127.0.0.1:27682 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 18:19:33] INFO:     127.0.0.1:27654 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 18:19:33] INFO:     127.0.0.1:27668 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 18:19:33 TP0] Prefill batch. #new-seq: 3, #new-token: 1391, #cached-token: 433, token usage: 0.00, #running-req: 1, #queue-req: 0, 
[2025-08-25 18:19:35 TP0] Decode batch. #running-req: 4, #token: 2136, token usage: 0.01, gen throughput (token/s): 10.44, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:19:36 TP0] Decode batch. #running-req: 4, #token: 2296, token usage: 0.01, gen throughput (token/s): 152.62, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:19:37 TP0] Decode batch. #running-req: 4, #token: 2456, token usage: 0.01, gen throughput (token/s): 152.02, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:19:38] INFO:     127.0.0.1:27670 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 18:19:38] INFO:     127.0.0.1:27654 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 18:19:38] INFO:     127.0.0.1:27682 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 18:19:38] INFO:     127.0.0.1:27668 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 18:19:38 TP0] Prefill batch. #new-seq: 1, #new-token: 455, #cached-token: 153, token usage: 0.00, #running-req: 3, #queue-req: 0, 
[2025-08-25 18:19:38 TP0] Prefill batch. #new-seq: 1, #new-token: 428, #cached-token: 180, token usage: 0.00, #running-req: 4, #queue-req: 0, 
[2025-08-25 18:19:38 TP0] Decode batch. #running-req: 2, #token: 1074, token usage: 0.00, gen throughput (token/s): 115.45, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:19:39 TP0] Decode batch. #running-req: 2, #token: 1154, token usage: 0.00, gen throughput (token/s): 78.11, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:19:40 TP0] Decode batch. #running-req: 2, #token: 1234, token usage: 0.00, gen throughput (token/s): 77.30, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:19:41 TP0] Decode batch. #running-req: 2, #token: 1314, token usage: 0.00, gen throughput (token/s): 78.42, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:19:42] INFO:     127.0.0.1:27670 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 18:19:42] INFO:     127.0.0.1:27682 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 18:19:42 TP0] Prefill batch. #new-seq: 4, #new-token: 344, #cached-token: 200, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-08-25 18:19:42 TP0] Decode batch. #running-req: 4, #token: 268, token usage: 0.00, gen throughput (token/s): 13.77, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:19:42 TP0] Decode batch. #running-req: 4, #token: 428, token usage: 0.00, gen throughput (token/s): 871.17, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:19:42 TP0] Decode batch. #running-req: 4, #token: 588, token usage: 0.00, gen throughput (token/s): 860.80, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:19:43 TP0] Decode batch. #running-req: 4, #token: 748, token usage: 0.00, gen throughput (token/s): 868.14, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:19:43 TP0] Decode batch. #running-req: 4, #token: 908, token usage: 0.00, gen throughput (token/s): 860.25, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:19:43 TP0] Decode batch. #running-req: 4, #token: 1068, token usage: 0.00, gen throughput (token/s): 870.13, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:19:43 TP0] Decode batch. #running-req: 4, #token: 1228, token usage: 0.00, gen throughput (token/s): 883.80, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:19:43 TP0] Decode batch. #running-req: 4, #token: 1388, token usage: 0.00, gen throughput (token/s): 870.19, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:19:44 TP0] Decode batch. #running-req: 4, #token: 1548, token usage: 0.00, gen throughput (token/s): 878.47, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:19:44 TP0] Decode batch. #running-req: 4, #token: 1708, token usage: 0.00, gen throughput (token/s): 860.20, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:19:44 TP0] Decode batch. #running-req: 4, #token: 1868, token usage: 0.00, gen throughput (token/s): 868.24, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:19:44 TP0] Decode batch. #running-req: 4, #token: 2028, token usage: 0.00, gen throughput (token/s): 842.11, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:19:44] INFO:     127.0.0.1:10150 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 18:19:44] INFO:     127.0.0.1:10166 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 18:19:44] INFO:     127.0.0.1:10174 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 18:19:44] INFO:     127.0.0.1:10176 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 18:19:44 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 135, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-08-25 18:19:44 TP0] Prefill batch. #new-seq: 3, #new-token: 3, #cached-token: 405, token usage: 0.00, #running-req: 1, #queue-req: 0, 
[2025-08-25 18:19:44 TP0] Decode batch. #running-req: 4, #token: 188, token usage: 0.00, gen throughput (token/s): 577.28, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:19:45 TP0] Decode batch. #running-req: 4, #token: 348, token usage: 0.00, gen throughput (token/s): 964.90, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:19:45 TP0] Decode batch. #running-req: 4, #token: 508, token usage: 0.00, gen throughput (token/s): 877.57, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:19:45 TP0] Decode batch. #running-req: 4, #token: 668, token usage: 0.00, gen throughput (token/s): 850.73, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:19:45 TP0] Decode batch. #running-req: 4, #token: 828, token usage: 0.00, gen throughput (token/s): 863.14, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:19:45 TP0] Decode batch. #running-req: 4, #token: 988, token usage: 0.00, gen throughput (token/s): 854.25, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:19:45 TP0] Decode batch. #running-req: 4, #token: 1148, token usage: 0.00, gen throughput (token/s): 851.89, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:19:46 TP0] Decode batch. #running-req: 4, #token: 1308, token usage: 0.00, gen throughput (token/s): 860.41, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:19:46 TP0] Decode batch. #running-req: 4, #token: 1468, token usage: 0.00, gen throughput (token/s): 858.42, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:19:46 TP0] Decode batch. #running-req: 4, #token: 1628, token usage: 0.00, gen throughput (token/s): 852.60, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:19:46 TP0] Decode batch. #running-req: 4, #token: 1788, token usage: 0.00, gen throughput (token/s): 858.18, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:19:46 TP0] Decode batch. #running-req: 4, #token: 1948, token usage: 0.00, gen throughput (token/s): 868.80, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:19:47 TP0] Decode batch. #running-req: 4, #token: 2108, token usage: 0.00, gen throughput (token/s): 938.08, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:19:47] INFO:     127.0.0.1:10176 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 18:19:47] INFO:     127.0.0.1:10150 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 18:19:47] INFO:     127.0.0.1:10166 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 18:19:47] INFO:     127.0.0.1:10174 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 18:19:47 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 135, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-08-25 18:19:47 TP0] Prefill batch. #new-seq: 3, #new-token: 3, #cached-token: 405, token usage: 0.00, #running-req: 1, #queue-req: 0, 
[2025-08-25 18:19:47 TP0] Decode batch. #running-req: 4, #token: 265, token usage: 0.00, gen throughput (token/s): 564.44, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:19:47 TP0] Decode batch. #running-req: 4, #token: 425, token usage: 0.00, gen throughput (token/s): 852.52, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:19:47 TP0] Decode batch. #running-req: 4, #token: 585, token usage: 0.00, gen throughput (token/s): 855.03, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:19:47 TP0] Decode batch. #running-req: 4, #token: 745, token usage: 0.00, gen throughput (token/s): 852.49, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:19:48 TP0] Decode batch. #running-req: 4, #token: 905, token usage: 0.00, gen throughput (token/s): 869.10, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:19:48 TP0] Decode batch. #running-req: 4, #token: 1065, token usage: 0.00, gen throughput (token/s): 851.42, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:19:48 TP0] Decode batch. #running-req: 4, #token: 1225, token usage: 0.00, gen throughput (token/s): 858.84, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:19:48 TP0] Decode batch. #running-req: 4, #token: 1385, token usage: 0.00, gen throughput (token/s): 856.49, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:19:48 TP0] Decode batch. #running-req: 4, #token: 1545, token usage: 0.00, gen throughput (token/s): 853.12, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:19:49 TP0] Decode batch. #running-req: 4, #token: 1705, token usage: 0.00, gen throughput (token/s): 877.86, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:19:49 TP0] Decode batch. #running-req: 4, #token: 1865, token usage: 0.00, gen throughput (token/s): 846.12, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:19:49 TP0] Decode batch. #running-req: 4, #token: 2025, token usage: 0.00, gen throughput (token/s): 846.66, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:19:49] INFO:     127.0.0.1:10176 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 18:19:49] INFO:     127.0.0.1:10150 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 18:19:49] INFO:     127.0.0.1:10166 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 18:19:49] INFO:     127.0.0.1:10174 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 18:19:49 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 135, token usage: 0.00, #running-req: 3, #queue-req: 0, 
[2025-08-25 18:19:49 TP0] Prefill batch. #new-seq: 3, #new-token: 3, #cached-token: 405, token usage: 0.00, #running-req: 4, #queue-req: 0, 
[2025-08-25 18:19:49 TP0] Decode batch. #running-req: 4, #token: 184, token usage: 0.00, gen throughput (token/s): 595.70, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:19:49 TP0] Decode batch. #running-req: 4, #token: 344, token usage: 0.00, gen throughput (token/s): 863.06, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:19:50 TP0] Decode batch. #running-req: 4, #token: 504, token usage: 0.00, gen throughput (token/s): 869.03, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:19:50 TP0] Decode batch. #running-req: 4, #token: 664, token usage: 0.00, gen throughput (token/s): 873.82, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:19:50 TP0] Decode batch. #running-req: 4, #token: 824, token usage: 0.00, gen throughput (token/s): 906.39, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:19:50 TP0] Decode batch. #running-req: 4, #token: 984, token usage: 0.00, gen throughput (token/s): 852.39, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:19:50 TP0] Decode batch. #running-req: 4, #token: 1144, token usage: 0.00, gen throughput (token/s): 857.95, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:19:50 TP0] Decode batch. #running-req: 4, #token: 1304, token usage: 0.00, gen throughput (token/s): 870.18, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:19:51 TP0] Decode batch. #running-req: 4, #token: 1464, token usage: 0.00, gen throughput (token/s): 862.79, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:19:51 TP0] Decode batch. #running-req: 4, #token: 1624, token usage: 0.00, gen throughput (token/s): 887.01, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:19:51 TP0] Decode batch. #running-req: 4, #token: 1784, token usage: 0.00, gen throughput (token/s): 870.81, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:19:51 TP0] Decode batch. #running-req: 4, #token: 1944, token usage: 0.00, gen throughput (token/s): 865.00, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:19:51 TP0] Decode batch. #running-req: 4, #token: 2104, token usage: 0.00, gen throughput (token/s): 866.98, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:19:51] INFO:     127.0.0.1:10176 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 18:19:51] INFO:     127.0.0.1:10166 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 18:19:51] INFO:     127.0.0.1:10150 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 18:19:51] INFO:     127.0.0.1:10174 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 18:19:51 TP0] Prefill batch. #new-seq: 4, #new-token: 2332, #cached-token: 168, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-08-25 18:19:52] INFO:     127.0.0.1:29850 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 18:19:52] INFO:     127.0.0.1:29862 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 18:19:52] INFO:     127.0.0.1:29866 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 18:19:52] INFO:     127.0.0.1:29880 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 18:19:52 TP0] Prefill batch. #new-seq: 1, #new-token: 500, #cached-token: 125, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-08-25 18:19:52 TP0] Prefill batch. #new-seq: 3, #new-token: 1500, #cached-token: 375, token usage: 0.00, #running-req: 1, #queue-req: 0, 
[2025-08-25 18:19:53] INFO:     127.0.0.1:29880 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 18:19:53] INFO:     127.0.0.1:29850 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 18:19:53] INFO:     127.0.0.1:29862 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 18:19:53] INFO:     127.0.0.1:29866 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 18:19:53 TP0] Prefill batch. #new-seq: 1, #new-token: 500, #cached-token: 125, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-08-25 18:19:53 TP0] Prefill batch. #new-seq: 3, #new-token: 1500, #cached-token: 375, token usage: 0.00, #running-req: 1, #queue-req: 0, 
[2025-08-25 18:19:54] INFO:     127.0.0.1:29880 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 18:19:54] INFO:     127.0.0.1:29850 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 18:19:54] INFO:     127.0.0.1:29862 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 18:19:54 TP0] Prefill batch. #new-seq: 1, #new-token: 500, #cached-token: 125, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-08-25 18:19:54] INFO:     127.0.0.1:29866 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 18:19:54] INFO:     127.0.0.1:29880 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 18:19:54 TP0] Prefill batch. #new-seq: 3, #new-token: 1500, #cached-token: 375, token usage: 0.00, #running-req: 1, #queue-req: 0, 
[2025-08-25 18:19:54 TP0] Prefill batch. #new-seq: 1, #new-token: 590, #cached-token: 44, token usage: 0.01, #running-req: 4, #queue-req: 0, 
[2025-08-25 18:19:54] INFO:     127.0.0.1:29850 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 18:19:54] INFO:     127.0.0.1:29862 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 18:19:54] INFO:     127.0.0.1:29866 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 18:19:55 TP0] Prefill batch. #new-seq: 3, #new-token: 1489, #cached-token: 413, token usage: 0.00, #running-req: 1, #queue-req: 0, 
[2025-08-25 18:19:55 TP0] Decode batch. #running-req: 4, #token: 2160, token usage: 0.01, gen throughput (token/s): 7.01, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:19:56 TP0] Decode batch. #running-req: 4, #token: 2320, token usage: 0.01, gen throughput (token/s): 152.12, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:19:57 TP0] Decode batch. #running-req: 4, #token: 2480, token usage: 0.01, gen throughput (token/s): 154.46, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:19:58 TP0] Decode batch. #running-req: 4, #token: 2640, token usage: 0.01, gen throughput (token/s): 153.74, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:19:59] INFO:     127.0.0.1:29880 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 18:19:59] INFO:     127.0.0.1:29850 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 18:19:59] INFO:     127.0.0.1:29862 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 18:19:59] INFO:     127.0.0.1:29866 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 18:19:59 TP0] Prefill batch. #new-seq: 1, #new-token: 496, #cached-token: 138, token usage: 0.00, #running-req: 3, #queue-req: 0, 
[2025-08-25 18:19:59 TP0] Prefill batch. #new-seq: 1, #new-token: 496, #cached-token: 138, token usage: 0.00, #running-req: 4, #queue-req: 0, 
[2025-08-25 18:20:00 TP0] Decode batch. #running-req: 2, #token: 1168, token usage: 0.00, gen throughput (token/s): 92.01, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:20:01 TP0] Decode batch. #running-req: 2, #token: 1248, token usage: 0.00, gen throughput (token/s): 78.46, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:20:02 TP0] Decode batch. #running-req: 2, #token: 1328, token usage: 0.00, gen throughput (token/s): 78.42, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:20:03 TP0] Decode batch. #running-req: 2, #token: 1408, token usage: 0.00, gen throughput (token/s): 78.51, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:20:03] INFO:     127.0.0.1:29880 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 18:20:03] INFO:     127.0.0.1:29862 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 18:20:03 TP0] Prefill batch. #new-seq: 4, #new-token: 340, #cached-token: 200, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-08-25 18:20:03 TP0] Decode batch. #running-req: 4, #token: 263, token usage: 0.00, gen throughput (token/s): 13.54, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:20:03 TP0] Decode batch. #running-req: 4, #token: 423, token usage: 0.00, gen throughput (token/s): 875.40, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:20:04 TP0] Decode batch. #running-req: 4, #token: 583, token usage: 0.00, gen throughput (token/s): 864.69, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:20:04 TP0] Decode batch. #running-req: 4, #token: 743, token usage: 0.00, gen throughput (token/s): 845.12, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:20:04 TP0] Decode batch. #running-req: 4, #token: 903, token usage: 0.00, gen throughput (token/s): 886.36, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:20:04 TP0] Decode batch. #running-req: 4, #token: 1063, token usage: 0.00, gen throughput (token/s): 857.78, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:20:04 TP0] Decode batch. #running-req: 4, #token: 1223, token usage: 0.00, gen throughput (token/s): 869.91, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:20:04 TP0] Decode batch. #running-req: 4, #token: 1383, token usage: 0.00, gen throughput (token/s): 852.84, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:20:05 TP0] Decode batch. #running-req: 4, #token: 1543, token usage: 0.00, gen throughput (token/s): 847.69, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:20:05 TP0] Decode batch. #running-req: 4, #token: 1703, token usage: 0.00, gen throughput (token/s): 872.89, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:20:05 TP0] Decode batch. #running-req: 4, #token: 1863, token usage: 0.00, gen throughput (token/s): 867.11, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:20:05 TP0] Decode batch. #running-req: 4, #token: 2023, token usage: 0.00, gen throughput (token/s): 869.10, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:20:05] INFO:     127.0.0.1:47308 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 18:20:05] INFO:     127.0.0.1:47314 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 18:20:05] INFO:     127.0.0.1:47328 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 18:20:05] INFO:     127.0.0.1:47336 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 18:20:05 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 134, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-08-25 18:20:05 TP0] Prefill batch. #new-seq: 3, #new-token: 3, #cached-token: 402, token usage: 0.00, #running-req: 1, #queue-req: 0, 
[2025-08-25 18:20:05 TP0] Decode batch. #running-req: 4, #token: 183, token usage: 0.00, gen throughput (token/s): 567.42, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:20:06 TP0] Decode batch. #running-req: 4, #token: 343, token usage: 0.00, gen throughput (token/s): 866.42, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:20:06 TP0] Decode batch. #running-req: 4, #token: 503, token usage: 0.00, gen throughput (token/s): 875.52, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:20:06 TP0] Decode batch. #running-req: 4, #token: 663, token usage: 0.00, gen throughput (token/s): 858.72, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:20:06 TP0] Decode batch. #running-req: 4, #token: 823, token usage: 0.00, gen throughput (token/s): 878.91, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:20:06 TP0] Decode batch. #running-req: 4, #token: 983, token usage: 0.00, gen throughput (token/s): 868.08, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:20:07 TP0] Decode batch. #running-req: 4, #token: 1143, token usage: 0.00, gen throughput (token/s): 844.45, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:20:07 TP0] Decode batch. #running-req: 4, #token: 1303, token usage: 0.00, gen throughput (token/s): 863.85, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:20:07 TP0] Decode batch. #running-req: 4, #token: 1463, token usage: 0.00, gen throughput (token/s): 872.01, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:20:07 TP0] Decode batch. #running-req: 4, #token: 1623, token usage: 0.00, gen throughput (token/s): 886.33, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:20:07 TP0] Decode batch. #running-req: 4, #token: 1783, token usage: 0.00, gen throughput (token/s): 853.65, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:20:08 TP0] Decode batch. #running-req: 4, #token: 1943, token usage: 0.00, gen throughput (token/s): 850.21, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:20:08 TP0] Decode batch. #running-req: 4, #token: 2103, token usage: 0.00, gen throughput (token/s): 870.81, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:20:08] INFO:     127.0.0.1:47336 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 18:20:08] INFO:     127.0.0.1:47308 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 18:20:08] INFO:     127.0.0.1:47314 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 18:20:08] INFO:     127.0.0.1:47328 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 18:20:08 TP0] Prefill batch. #new-seq: 2, #new-token: 2, #cached-token: 268, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-08-25 18:20:08 TP0] Prefill batch. #new-seq: 2, #new-token: 2, #cached-token: 268, token usage: 0.00, #running-req: 2, #queue-req: 0, 
[2025-08-25 18:20:08 TP0] Decode batch. #running-req: 4, #token: 263, token usage: 0.00, gen throughput (token/s): 574.67, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:20:08 TP0] Decode batch. #running-req: 4, #token: 423, token usage: 0.00, gen throughput (token/s): 877.61, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:20:08 TP0] Decode batch. #running-req: 4, #token: 583, token usage: 0.00, gen throughput (token/s): 848.46, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:20:09 TP0] Decode batch. #running-req: 4, #token: 743, token usage: 0.00, gen throughput (token/s): 856.80, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:20:09 TP0] Decode batch. #running-req: 4, #token: 903, token usage: 0.00, gen throughput (token/s): 859.27, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:20:09 TP0] Decode batch. #running-req: 4, #token: 1063, token usage: 0.00, gen throughput (token/s): 852.61, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:20:09 TP0] Decode batch. #running-req: 4, #token: 1223, token usage: 0.00, gen throughput (token/s): 844.94, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:20:09 TP0] Decode batch. #running-req: 4, #token: 1383, token usage: 0.00, gen throughput (token/s): 845.41, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:20:09 TP0] Decode batch. #running-req: 4, #token: 1543, token usage: 0.00, gen throughput (token/s): 847.44, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:20:10 TP0] Decode batch. #running-req: 4, #token: 1703, token usage: 0.00, gen throughput (token/s): 876.94, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:20:10 TP0] Decode batch. #running-req: 4, #token: 1863, token usage: 0.00, gen throughput (token/s): 864.48, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:20:10 TP0] Decode batch. #running-req: 4, #token: 2023, token usage: 0.00, gen throughput (token/s): 848.00, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:20:10] INFO:     127.0.0.1:47314 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 18:20:10] INFO:     127.0.0.1:47336 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 18:20:10] INFO:     127.0.0.1:47308 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 18:20:10] INFO:     127.0.0.1:47328 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 18:20:10 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 134, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-08-25 18:20:10 TP0] Prefill batch. #new-seq: 3, #new-token: 3, #cached-token: 402, token usage: 0.00, #running-req: 1, #queue-req: 0, 
[2025-08-25 18:20:10 TP0] Decode batch. #running-req: 4, #token: 183, token usage: 0.00, gen throughput (token/s): 576.87, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:20:11 TP0] Decode batch. #running-req: 4, #token: 343, token usage: 0.00, gen throughput (token/s): 865.96, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:20:11 TP0] Decode batch. #running-req: 4, #token: 503, token usage: 0.00, gen throughput (token/s): 890.44, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:20:11 TP0] Decode batch. #running-req: 4, #token: 663, token usage: 0.00, gen throughput (token/s): 865.07, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:20:11 TP0] Decode batch. #running-req: 4, #token: 823, token usage: 0.00, gen throughput (token/s): 843.96, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:20:11 TP0] Decode batch. #running-req: 4, #token: 983, token usage: 0.00, gen throughput (token/s): 853.35, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:20:11 TP0] Decode batch. #running-req: 4, #token: 1143, token usage: 0.00, gen throughput (token/s): 866.35, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:20:12 TP0] Decode batch. #running-req: 4, #token: 1303, token usage: 0.00, gen throughput (token/s): 871.67, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:20:12 TP0] Decode batch. #running-req: 4, #token: 1463, token usage: 0.00, gen throughput (token/s): 849.75, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:20:12 TP0] Decode batch. #running-req: 4, #token: 1623, token usage: 0.00, gen throughput (token/s): 833.89, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:20:12 TP0] Decode batch. #running-req: 4, #token: 1783, token usage: 0.00, gen throughput (token/s): 834.06, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:20:12 TP0] Decode batch. #running-req: 4, #token: 1943, token usage: 0.00, gen throughput (token/s): 833.43, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:20:13 TP0] Decode batch. #running-req: 4, #token: 2103, token usage: 0.00, gen throughput (token/s): 920.77, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:20:13] INFO:     127.0.0.1:47336 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 18:20:13] INFO:     127.0.0.1:47308 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 18:20:13] INFO:     127.0.0.1:47314 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 18:20:13] INFO:     127.0.0.1:47328 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 18:20:13 TP0] Prefill batch. #new-seq: 4, #new-token: 2328, #cached-token: 168, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-08-25 18:20:13] INFO:     127.0.0.1:62374 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 18:20:13] INFO:     127.0.0.1:62376 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 18:20:13] INFO:     127.0.0.1:62386 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 18:20:13] INFO:     127.0.0.1:62392 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 18:20:13 TP0] Prefill batch. #new-seq: 2, #new-token: 1000, #cached-token: 248, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-08-25 18:20:13 TP0] Prefill batch. #new-seq: 2, #new-token: 1000, #cached-token: 248, token usage: 0.00, #running-req: 2, #queue-req: 0, 
[2025-08-25 18:20:14] INFO:     127.0.0.1:62392 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 18:20:14] INFO:     127.0.0.1:62374 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 18:20:14] INFO:     127.0.0.1:62376 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 18:20:14] INFO:     127.0.0.1:62386 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 18:20:14 TP0] Prefill batch. #new-seq: 1, #new-token: 500, #cached-token: 124, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-08-25 18:20:14] INFO:     127.0.0.1:62374 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 18:20:14 TP0] Prefill batch. #new-seq: 3, #new-token: 1500, #cached-token: 372, token usage: 0.00, #running-req: 1, #queue-req: 0, 
[2025-08-25 18:20:15 TP0] Prefill batch. #new-seq: 1, #new-token: 500, #cached-token: 124, token usage: 0.00, #running-req: 4, #queue-req: 0, 
[2025-08-25 18:20:15] INFO:     127.0.0.1:62392 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 18:20:15] INFO:     127.0.0.1:62376 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 18:20:15] INFO:     127.0.0.1:62386 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 18:20:15] INFO:     127.0.0.1:62374 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 18:20:15 TP0] Prefill batch. #new-seq: 3, #new-token: 1500, #cached-token: 372, token usage: 0.00, #running-req: 1, #queue-req: 0, 
[2025-08-25 18:20:15 TP0] Prefill batch. #new-seq: 1, #new-token: 589, #cached-token: 44, token usage: 0.01, #running-req: 4, #queue-req: 0, 
[2025-08-25 18:20:15] INFO:     127.0.0.1:62392 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 18:20:16] INFO:     127.0.0.1:62376 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 18:20:16] INFO:     127.0.0.1:62386 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 18:20:16 TP0] Prefill batch. #new-seq: 1, #new-token: 498, #cached-token: 135, token usage: 0.00, #running-req: 1, #queue-req: 0, 
[2025-08-25 18:20:16 TP0] Prefill batch. #new-seq: 2, #new-token: 996, #cached-token: 270, token usage: 0.00, #running-req: 2, #queue-req: 0, 
[2025-08-25 18:20:17 TP0] Decode batch. #running-req: 4, #token: 2134, token usage: 0.01, gen throughput (token/s): 4.21, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:20:18 TP0] Decode batch. #running-req: 4, #token: 2294, token usage: 0.01, gen throughput (token/s): 153.85, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:20:19 TP0] Decode batch. #running-req: 4, #token: 2454, token usage: 0.01, gen throughput (token/s): 153.99, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:20:20 TP0] Decode batch. #running-req: 4, #token: 2614, token usage: 0.01, gen throughput (token/s): 153.52, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:20:20] INFO:     127.0.0.1:62374 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 18:20:20 TP0] Prefill batch. #new-seq: 1, #new-token: 496, #cached-token: 137, token usage: 0.01, #running-req: 3, #queue-req: 0, 
[2025-08-25 18:20:21] INFO:     127.0.0.1:62392 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 18:20:21] INFO:     127.0.0.1:62376 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 18:20:21] INFO:     127.0.0.1:62386 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 18:20:21 TP0] Prefill batch. #new-seq: 2, #new-token: 894, #cached-token: 372, token usage: 0.00, #running-req: 1, #queue-req: 0, 
[2025-08-25 18:20:21 TP0] Decode batch. #running-req: 3, #token: 1650, token usage: 0.01, gen throughput (token/s): 101.59, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:20:22 TP0] Decode batch. #running-req: 3, #token: 1770, token usage: 0.01, gen throughput (token/s): 115.21, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:20:23 TP0] Decode batch. #running-req: 3, #token: 1890, token usage: 0.01, gen throughput (token/s): 114.59, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:20:24] INFO:     127.0.0.1:62374 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 18:20:24 TP0] Decode batch. #running-req: 2, #token: 1360, token usage: 0.00, gen throughput (token/s): 112.67, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:20:25] INFO:     127.0.0.1:62376 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 18:20:25] INFO:     127.0.0.1:62392 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 18:20:25 TP0] Prefill batch. #new-seq: 3, #new-token: 438, #cached-token: 153, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-08-25 18:20:25 TP0] Prefill batch. #new-seq: 1, #new-token: 146, #cached-token: 51, token usage: 0.00, #running-req: 3, #queue-req: 0, 
[2025-08-25 18:20:25 TP0] Decode batch. #running-req: 4, #token: 325, token usage: 0.00, gen throughput (token/s): 12.73, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:20:25 TP0] Decode batch. #running-req: 4, #token: 485, token usage: 0.00, gen throughput (token/s): 864.86, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:20:26 TP0] Decode batch. #running-req: 4, #token: 645, token usage: 0.00, gen throughput (token/s): 866.23, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:20:26 TP0] Decode batch. #running-req: 4, #token: 805, token usage: 0.00, gen throughput (token/s): 881.58, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:20:26 TP0] Decode batch. #running-req: 4, #token: 965, token usage: 0.00, gen throughput (token/s): 876.11, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:20:26 TP0] Decode batch. #running-req: 4, #token: 1125, token usage: 0.00, gen throughput (token/s): 872.88, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:20:26 TP0] Decode batch. #running-req: 4, #token: 1285, token usage: 0.00, gen throughput (token/s): 855.04, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:20:26 TP0] Decode batch. #running-req: 4, #token: 1445, token usage: 0.00, gen throughput (token/s): 861.45, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:20:27 TP0] Decode batch. #running-req: 4, #token: 1605, token usage: 0.00, gen throughput (token/s): 852.34, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:20:27 TP0] Decode batch. #running-req: 4, #token: 1765, token usage: 0.00, gen throughput (token/s): 873.11, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:20:27 TP0] Decode batch. #running-req: 4, #token: 1925, token usage: 0.00, gen throughput (token/s): 856.29, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:20:27 TP0] Decode batch. #running-req: 4, #token: 2085, token usage: 0.00, gen throughput (token/s): 860.59, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:20:27] INFO:     127.0.0.1:5400 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 18:20:27] INFO:     127.0.0.1:5402 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 18:20:27] INFO:     127.0.0.1:5408 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 18:20:27] INFO:     127.0.0.1:5416 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 18:20:27 TP0] Prefill batch. #new-seq: 4, #new-token: 4, #cached-token: 784, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-08-25 18:20:27 TP0] Decode batch. #running-req: 4, #token: 245, token usage: 0.00, gen throughput (token/s): 635.74, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:20:28 TP0] Decode batch. #running-req: 4, #token: 405, token usage: 0.00, gen throughput (token/s): 874.35, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:20:28 TP0] Decode batch. #running-req: 4, #token: 565, token usage: 0.00, gen throughput (token/s): 881.79, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:20:28 TP0] Decode batch. #running-req: 4, #token: 725, token usage: 0.00, gen throughput (token/s): 883.08, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:20:28 TP0] Decode batch. #running-req: 4, #token: 885, token usage: 0.00, gen throughput (token/s): 902.26, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:20:28 TP0] Decode batch. #running-req: 4, #token: 1045, token usage: 0.00, gen throughput (token/s): 879.43, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:20:29 TP0] Decode batch. #running-req: 4, #token: 1205, token usage: 0.00, gen throughput (token/s): 880.48, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:20:29 TP0] Decode batch. #running-req: 4, #token: 1365, token usage: 0.00, gen throughput (token/s): 908.08, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:20:29 TP0] Decode batch. #running-req: 4, #token: 1525, token usage: 0.00, gen throughput (token/s): 872.94, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:20:29 TP0] Decode batch. #running-req: 4, #token: 1685, token usage: 0.00, gen throughput (token/s): 875.90, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:20:29 TP0] Decode batch. #running-req: 4, #token: 1845, token usage: 0.00, gen throughput (token/s): 856.71, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:20:29 TP0] Decode batch. #running-req: 4, #token: 2005, token usage: 0.00, gen throughput (token/s): 864.41, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:20:30 TP0] Decode batch. #running-req: 4, #token: 2165, token usage: 0.00, gen throughput (token/s): 879.13, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:20:30] INFO:     127.0.0.1:5400 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 18:20:30] INFO:     127.0.0.1:5416 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 18:20:30] INFO:     127.0.0.1:5402 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 18:20:30] INFO:     127.0.0.1:5408 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 18:20:30 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 196, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-08-25 18:20:30 TP0] Prefill batch. #new-seq: 3, #new-token: 3, #cached-token: 588, token usage: 0.00, #running-req: 1, #queue-req: 0, 
[2025-08-25 18:20:30 TP0] Decode batch. #running-req: 4, #token: 325, token usage: 0.00, gen throughput (token/s): 563.21, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:20:30 TP0] Decode batch. #running-req: 4, #token: 485, token usage: 0.00, gen throughput (token/s): 873.29, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:20:30 TP0] Decode batch. #running-req: 4, #token: 645, token usage: 0.00, gen throughput (token/s): 854.63, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:20:30 TP0] Decode batch. #running-req: 4, #token: 805, token usage: 0.00, gen throughput (token/s): 855.17, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:20:31 TP0] Decode batch. #running-req: 4, #token: 965, token usage: 0.00, gen throughput (token/s): 878.19, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:20:31 TP0] Decode batch. #running-req: 4, #token: 1125, token usage: 0.00, gen throughput (token/s): 851.29, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:20:31 TP0] Decode batch. #running-req: 4, #token: 1285, token usage: 0.00, gen throughput (token/s): 863.62, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:20:31 TP0] Decode batch. #running-req: 4, #token: 1445, token usage: 0.00, gen throughput (token/s): 845.94, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:20:31 TP0] Decode batch. #running-req: 4, #token: 1605, token usage: 0.00, gen throughput (token/s): 846.03, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:20:32 TP0] Decode batch. #running-req: 4, #token: 1765, token usage: 0.00, gen throughput (token/s): 865.91, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:20:32 TP0] Decode batch. #running-req: 4, #token: 1925, token usage: 0.00, gen throughput (token/s): 840.68, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:20:32 TP0] Decode batch. #running-req: 4, #token: 2085, token usage: 0.00, gen throughput (token/s): 839.90, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:20:32] INFO:     127.0.0.1:5416 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 18:20:32] INFO:     127.0.0.1:5400 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 18:20:32] INFO:     127.0.0.1:5402 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 18:20:32] INFO:     127.0.0.1:5408 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 18:20:32 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 196, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-08-25 18:20:32 TP0] Prefill batch. #new-seq: 3, #new-token: 3, #cached-token: 588, token usage: 0.00, #running-req: 1, #queue-req: 0, 
[2025-08-25 18:20:32 TP0] Decode batch. #running-req: 4, #token: 245, token usage: 0.00, gen throughput (token/s): 568.36, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:20:32 TP0] Decode batch. #running-req: 4, #token: 405, token usage: 0.00, gen throughput (token/s): 861.91, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:20:33 TP0] Decode batch. #running-req: 4, #token: 565, token usage: 0.00, gen throughput (token/s): 865.52, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:20:33 TP0] Decode batch. #running-req: 4, #token: 725, token usage: 0.00, gen throughput (token/s): 846.25, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:20:33 TP0] Decode batch. #running-req: 4, #token: 885, token usage: 0.00, gen throughput (token/s): 854.02, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:20:33 TP0] Decode batch. #running-req: 4, #token: 1045, token usage: 0.00, gen throughput (token/s): 835.93, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:20:33 TP0] Decode batch. #running-req: 4, #token: 1205, token usage: 0.00, gen throughput (token/s): 852.11, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:20:34 TP0] Decode batch. #running-req: 4, #token: 1365, token usage: 0.00, gen throughput (token/s): 861.66, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:20:34 TP0] Decode batch. #running-req: 4, #token: 1525, token usage: 0.00, gen throughput (token/s): 858.14, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:20:34 TP0] Decode batch. #running-req: 4, #token: 1685, token usage: 0.00, gen throughput (token/s): 844.54, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:20:34 TP0] Decode batch. #running-req: 4, #token: 1845, token usage: 0.00, gen throughput (token/s): 853.33, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:20:34 TP0] Decode batch. #running-req: 4, #token: 2005, token usage: 0.00, gen throughput (token/s): 869.34, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:20:34 TP0] Decode batch. #running-req: 4, #token: 2165, token usage: 0.00, gen throughput (token/s): 858.41, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:20:35] INFO:     127.0.0.1:5416 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 18:20:35] INFO:     127.0.0.1:5400 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 18:20:35] INFO:     127.0.0.1:5402 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 18:20:35] INFO:     127.0.0.1:5408 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 18:20:35 TP0] Prefill batch. #new-seq: 4, #new-token: 2572, #cached-token: 172, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-08-25 18:20:35] INFO:     127.0.0.1:12510 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 18:20:35] INFO:     127.0.0.1:12518 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 18:20:35] INFO:     127.0.0.1:12532 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 18:20:35] INFO:     127.0.0.1:12544 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 18:20:35 TP0] Prefill batch. #new-seq: 3, #new-token: 1500, #cached-token: 558, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-08-25 18:20:36 TP0] Prefill batch. #new-seq: 1, #new-token: 500, #cached-token: 186, token usage: 0.01, #running-req: 3, #queue-req: 0, 
[2025-08-25 18:20:36] INFO:     127.0.0.1:12544 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 18:20:36] INFO:     127.0.0.1:12510 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 18:20:36] INFO:     127.0.0.1:12518 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 18:20:36 TP0] Prefill batch. #new-seq: 3, #new-token: 1500, #cached-token: 558, token usage: 0.00, #running-req: 1, #queue-req: 0, 
[2025-08-25 18:20:36] INFO:     127.0.0.1:12532 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 18:20:37 TP0] Prefill batch. #new-seq: 1, #new-token: 500, #cached-token: 186, token usage: 0.01, #running-req: 4, #queue-req: 0, 
[2025-08-25 18:20:37] INFO:     127.0.0.1:12544 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 18:20:37] INFO:     127.0.0.1:12510 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 18:20:37] INFO:     127.0.0.1:12518 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 18:20:37 TP0] Prefill batch. #new-seq: 3, #new-token: 1500, #cached-token: 558, token usage: 0.00, #running-req: 1, #queue-req: 0, 
[2025-08-25 18:20:37] INFO:     127.0.0.1:12532 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 18:20:37 TP0] Prefill batch. #new-seq: 1, #new-token: 500, #cached-token: 186, token usage: 0.01, #running-req: 4, #queue-req: 0, 
[2025-08-25 18:20:37] INFO:     127.0.0.1:12544 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 18:20:37] INFO:     127.0.0.1:12510 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 18:20:37] INFO:     127.0.0.1:12518 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 18:20:37] INFO:     127.0.0.1:12532 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 18:20:37 TP0] Prefill batch. #new-seq: 1, #new-token: 650, #cached-token: 45, token usage: 0.00, #running-req: 1, #queue-req: 0, 
[2025-08-25 18:20:38 TP0] Decode batch. #running-req: 1, #token: 712, token usage: 0.00, gen throughput (token/s): 4.60, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:20:39 TP0] Decode batch. #running-req: 1, #token: 752, token usage: 0.00, gen throughput (token/s): 39.05, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:20:40 TP0] Decode batch. #running-req: 1, #token: 792, token usage: 0.00, gen throughput (token/s): 38.97, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:20:41 TP0] Decode batch. #running-req: 1, #token: 832, token usage: 0.00, gen throughput (token/s): 38.92, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:20:42] INFO:     127.0.0.1:12544 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 18:20:42 TP0] Prefill batch. #new-seq: 4, #new-token: 492, #cached-token: 200, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-08-25 18:20:42 TP0] Decode batch. #running-req: 4, #token: 301, token usage: 0.00, gen throughput (token/s): 22.16, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:20:42 TP0] Decode batch. #running-req: 4, #token: 461, token usage: 0.00, gen throughput (token/s): 872.92, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:20:42 TP0] Decode batch. #running-req: 4, #token: 621, token usage: 0.00, gen throughput (token/s): 871.83, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:20:42 TP0] Decode batch. #running-req: 4, #token: 781, token usage: 0.00, gen throughput (token/s): 867.08, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:20:42 TP0] Decode batch. #running-req: 4, #token: 941, token usage: 0.00, gen throughput (token/s): 873.45, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:20:43 TP0] Decode batch. #running-req: 4, #token: 1101, token usage: 0.00, gen throughput (token/s): 843.98, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:20:43 TP0] Decode batch. #running-req: 4, #token: 1261, token usage: 0.00, gen throughput (token/s): 853.51, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:20:43 TP0] Decode batch. #running-req: 4, #token: 1421, token usage: 0.00, gen throughput (token/s): 859.66, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:20:43 TP0] Decode batch. #running-req: 4, #token: 1581, token usage: 0.00, gen throughput (token/s): 878.79, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:20:43 TP0] Decode batch. #running-req: 4, #token: 1741, token usage: 0.00, gen throughput (token/s): 870.70, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:20:44 TP0] Decode batch. #running-req: 4, #token: 1901, token usage: 0.00, gen throughput (token/s): 902.77, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:20:44 TP0] Decode batch. #running-req: 4, #token: 2061, token usage: 0.00, gen throughput (token/s): 931.86, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:20:44] INFO:     127.0.0.1:19226 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 18:20:44] INFO:     127.0.0.1:19232 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 18:20:44] INFO:     127.0.0.1:19246 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 18:20:44] INFO:     127.0.0.1:19252 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 18:20:44 TP0] Prefill batch. #new-seq: 4, #new-token: 4, #cached-token: 688, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-08-25 18:20:44 TP0] Decode batch. #running-req: 4, #token: 221, token usage: 0.00, gen throughput (token/s): 649.56, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:20:44 TP0] Decode batch. #running-req: 4, #token: 381, token usage: 0.00, gen throughput (token/s): 862.76, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:20:44 TP0] Decode batch. #running-req: 4, #token: 541, token usage: 0.00, gen throughput (token/s): 892.27, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:20:44 TP0] Decode batch. #running-req: 4, #token: 701, token usage: 0.00, gen throughput (token/s): 879.08, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:20:45 TP0] Decode batch. #running-req: 4, #token: 861, token usage: 0.00, gen throughput (token/s): 862.52, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:20:45 TP0] Decode batch. #running-req: 4, #token: 1021, token usage: 0.00, gen throughput (token/s): 847.36, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:20:45 TP0] Decode batch. #running-req: 4, #token: 1181, token usage: 0.00, gen throughput (token/s): 845.28, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:20:45 TP0] Decode batch. #running-req: 4, #token: 1341, token usage: 0.00, gen throughput (token/s): 860.12, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:20:45 TP0] Decode batch. #running-req: 4, #token: 1501, token usage: 0.00, gen throughput (token/s): 861.31, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:20:46 TP0] Decode batch. #running-req: 4, #token: 1661, token usage: 0.00, gen throughput (token/s): 857.88, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:20:46 TP0] Decode batch. #running-req: 4, #token: 1821, token usage: 0.00, gen throughput (token/s): 850.40, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:20:46 TP0] Decode batch. #running-req: 4, #token: 1981, token usage: 0.00, gen throughput (token/s): 931.99, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:20:46 TP0] Decode batch. #running-req: 4, #token: 2141, token usage: 0.00, gen throughput (token/s): 895.18, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:20:46] INFO:     127.0.0.1:19232 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 18:20:46] INFO:     127.0.0.1:19252 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 18:20:46] INFO:     127.0.0.1:19226 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 18:20:46] INFO:     127.0.0.1:19246 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 18:20:46 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 172, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-08-25 18:20:46 TP0] Prefill batch. #new-seq: 3, #new-token: 3, #cached-token: 516, token usage: 0.00, #running-req: 1, #queue-req: 0, 
[2025-08-25 18:20:46 TP0] Decode batch. #running-req: 4, #token: 301, token usage: 0.00, gen throughput (token/s): 589.23, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:20:47 TP0] Decode batch. #running-req: 4, #token: 461, token usage: 0.00, gen throughput (token/s): 869.12, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:20:47 TP0] Decode batch. #running-req: 4, #token: 621, token usage: 0.00, gen throughput (token/s): 868.46, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:20:47 TP0] Decode batch. #running-req: 4, #token: 781, token usage: 0.00, gen throughput (token/s): 864.34, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:20:47 TP0] Decode batch. #running-req: 4, #token: 941, token usage: 0.00, gen throughput (token/s): 902.70, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:20:47 TP0] Decode batch. #running-req: 4, #token: 1101, token usage: 0.00, gen throughput (token/s): 847.55, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:20:48 TP0] Decode batch. #running-req: 4, #token: 1261, token usage: 0.00, gen throughput (token/s): 844.99, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:20:48 TP0] Decode batch. #running-req: 4, #token: 1421, token usage: 0.00, gen throughput (token/s): 836.44, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:20:48 TP0] Decode batch. #running-req: 4, #token: 1581, token usage: 0.00, gen throughput (token/s): 843.01, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:20:48 TP0] Decode batch. #running-req: 4, #token: 1741, token usage: 0.00, gen throughput (token/s): 867.63, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:20:48 TP0] Decode batch. #running-req: 4, #token: 1901, token usage: 0.00, gen throughput (token/s): 870.16, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:20:48 TP0] Decode batch. #running-req: 4, #token: 2061, token usage: 0.00, gen throughput (token/s): 831.52, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:20:49] INFO:     127.0.0.1:19252 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 18:20:49] INFO:     127.0.0.1:19226 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 18:20:49] INFO:     127.0.0.1:19232 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 18:20:49] INFO:     127.0.0.1:19246 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 18:20:49 TP0] Prefill batch. #new-seq: 4, #new-token: 4, #cached-token: 688, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-08-25 18:20:49 TP0] Decode batch. #running-req: 4, #token: 221, token usage: 0.00, gen throughput (token/s): 630.09, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:20:49 TP0] Decode batch. #running-req: 4, #token: 381, token usage: 0.00, gen throughput (token/s): 848.95, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:20:49 TP0] Decode batch. #running-req: 4, #token: 541, token usage: 0.00, gen throughput (token/s): 900.34, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:20:49 TP0] Decode batch. #running-req: 4, #token: 701, token usage: 0.00, gen throughput (token/s): 882.28, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:20:49 TP0] Decode batch. #running-req: 4, #token: 861, token usage: 0.00, gen throughput (token/s): 863.96, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:20:50 TP0] Decode batch. #running-req: 4, #token: 1021, token usage: 0.00, gen throughput (token/s): 860.40, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:20:50 TP0] Decode batch. #running-req: 4, #token: 1181, token usage: 0.00, gen throughput (token/s): 867.33, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:20:50 TP0] Decode batch. #running-req: 4, #token: 1341, token usage: 0.00, gen throughput (token/s): 872.38, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:20:50 TP0] Decode batch. #running-req: 4, #token: 1501, token usage: 0.00, gen throughput (token/s): 890.60, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:20:50 TP0] Decode batch. #running-req: 4, #token: 1661, token usage: 0.00, gen throughput (token/s): 880.01, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:20:51 TP0] Decode batch. #running-req: 4, #token: 1821, token usage: 0.00, gen throughput (token/s): 878.55, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:20:51 TP0] Decode batch. #running-req: 4, #token: 1981, token usage: 0.00, gen throughput (token/s): 965.41, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:20:51 TP0] Decode batch. #running-req: 4, #token: 2141, token usage: 0.00, gen throughput (token/s): 862.60, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:20:51] INFO:     127.0.0.1:19232 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 18:20:51] INFO:     127.0.0.1:19252 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 18:20:51] INFO:     127.0.0.1:19226 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 18:20:51] INFO:     127.0.0.1:19246 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 18:20:51 TP0] Prefill batch. #new-seq: 4, #new-token: 2480, #cached-token: 168, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-08-25 18:20:52] INFO:     127.0.0.1:16304 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 18:20:52] INFO:     127.0.0.1:16306 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 18:20:52] INFO:     127.0.0.1:16314 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 18:20:52] INFO:     127.0.0.1:16328 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 18:20:52 TP0] Prefill batch. #new-seq: 1, #new-token: 500, #cached-token: 162, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-08-25 18:20:52 TP0] Prefill batch. #new-seq: 2, #new-token: 1000, #cached-token: 324, token usage: 0.00, #running-req: 1, #queue-req: 0, 
[2025-08-25 18:20:52 TP0] Prefill batch. #new-seq: 1, #new-token: 500, #cached-token: 162, token usage: 0.00, #running-req: 3, #queue-req: 0, 
[2025-08-25 18:20:52] INFO:     127.0.0.1:16304 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 18:20:52] INFO:     127.0.0.1:16328 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 18:20:52] INFO:     127.0.0.1:16306 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 18:20:53 TP0] Prefill batch. #new-seq: 3, #new-token: 1500, #cached-token: 486, token usage: 0.00, #running-req: 1, #queue-req: 0, 
[2025-08-25 18:20:53] INFO:     127.0.0.1:16314 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 18:20:53 TP0] Prefill batch. #new-seq: 1, #new-token: 500, #cached-token: 162, token usage: 0.01, #running-req: 4, #queue-req: 0, 
[2025-08-25 18:20:53] INFO:     127.0.0.1:16304 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 18:20:53] INFO:     127.0.0.1:16306 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 18:20:53] INFO:     127.0.0.1:16328 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 18:20:53 TP0] Prefill batch. #new-seq: 3, #new-token: 1500, #cached-token: 486, token usage: 0.00, #running-req: 1, #queue-req: 0, 
[2025-08-25 18:20:53] INFO:     127.0.0.1:16314 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 18:20:54 TP0] Prefill batch. #new-seq: 1, #new-token: 500, #cached-token: 162, token usage: 0.01, #running-req: 4, #queue-req: 0, 
[2025-08-25 18:20:54] INFO:     127.0.0.1:16304 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 18:20:54] INFO:     127.0.0.1:16328 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 18:20:54] INFO:     127.0.0.1:16306 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 18:20:54 TP0] Prefill batch. #new-seq: 1, #new-token: 627, #cached-token: 44, token usage: 0.00, #running-req: 1, #queue-req: 0, 
[2025-08-25 18:20:54] INFO:     127.0.0.1:16314 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 18:20:55 TP0] Decode batch. #running-req: 1, #token: 694, token usage: 0.00, gen throughput (token/s): 3.11, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:20:56 TP0] Decode batch. #running-req: 1, #token: 734, token usage: 0.00, gen throughput (token/s): 38.94, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:20:57 TP0] Decode batch. #running-req: 1, #token: 774, token usage: 0.00, gen throughput (token/s): 39.01, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:20:58 TP0] Decode batch. #running-req: 1, #token: 814, token usage: 0.00, gen throughput (token/s): 39.04, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:20:58] INFO:     127.0.0.1:16328 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 18:20:58 TP0] Prefill batch. #new-seq: 3, #new-token: 312, #cached-token: 153, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-08-25 18:20:58 TP0] Prefill batch. #new-seq: 1, #new-token: 104, #cached-token: 51, token usage: 0.00, #running-req: 3, #queue-req: 0, 
[2025-08-25 18:20:59 TP0] Decode batch. #running-req: 4, #token: 283, token usage: 0.00, gen throughput (token/s): 21.06, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:20:59 TP0] Decode batch. #running-req: 4, #token: 443, token usage: 0.00, gen throughput (token/s): 869.78, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:20:59 TP0] Decode batch. #running-req: 4, #token: 603, token usage: 0.00, gen throughput (token/s): 866.01, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:20:59 TP0] Decode batch. #running-req: 4, #token: 763, token usage: 0.00, gen throughput (token/s): 838.24, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:20:59 TP0] Decode batch. #running-req: 4, #token: 923, token usage: 0.00, gen throughput (token/s): 867.29, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:20:59 TP0] Decode batch. #running-req: 4, #token: 1083, token usage: 0.00, gen throughput (token/s): 838.79, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:21:00 TP0] Decode batch. #running-req: 4, #token: 1243, token usage: 0.00, gen throughput (token/s): 856.12, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:21:00 TP0] Decode batch. #running-req: 4, #token: 1403, token usage: 0.00, gen throughput (token/s): 850.60, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:21:00 TP0] Decode batch. #running-req: 4, #token: 1563, token usage: 0.00, gen throughput (token/s): 867.50, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:21:00 TP0] Decode batch. #running-req: 4, #token: 1723, token usage: 0.00, gen throughput (token/s): 855.94, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:21:00 TP0] Decode batch. #running-req: 4, #token: 1883, token usage: 0.00, gen throughput (token/s): 850.47, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:21:01 TP0] Decode batch. #running-req: 4, #token: 2043, token usage: 0.00, gen throughput (token/s): 847.43, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:21:01] INFO:     127.0.0.1:64260 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 18:21:01] INFO:     127.0.0.1:64270 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 18:21:01] INFO:     127.0.0.1:64276 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 18:21:01] INFO:     127.0.0.1:64284 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 18:21:01 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 154, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-08-25 18:21:01 TP0] Prefill batch. #new-seq: 3, #new-token: 3, #cached-token: 462, token usage: 0.00, #running-req: 1, #queue-req: 0, 
[2025-08-25 18:21:01 TP0] Decode batch. #running-req: 4, #token: 203, token usage: 0.00, gen throughput (token/s): 578.36, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:21:01 TP0] Decode batch. #running-req: 4, #token: 363, token usage: 0.00, gen throughput (token/s): 859.58, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:21:01 TP0] Decode batch. #running-req: 4, #token: 523, token usage: 0.00, gen throughput (token/s): 862.72, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:21:01 TP0] Decode batch. #running-req: 4, #token: 683, token usage: 0.00, gen throughput (token/s): 857.10, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:21:02 TP0] Decode batch. #running-req: 4, #token: 843, token usage: 0.00, gen throughput (token/s): 865.04, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:21:02 TP0] Decode batch. #running-req: 4, #token: 1003, token usage: 0.00, gen throughput (token/s): 858.38, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:21:02 TP0] Decode batch. #running-req: 4, #token: 1163, token usage: 0.00, gen throughput (token/s): 850.39, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:21:02 TP0] Decode batch. #running-req: 4, #token: 1323, token usage: 0.00, gen throughput (token/s): 887.20, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:21:02 TP0] Decode batch. #running-req: 4, #token: 1483, token usage: 0.00, gen throughput (token/s): 871.53, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:21:03 TP0] Decode batch. #running-req: 4, #token: 1643, token usage: 0.00, gen throughput (token/s): 864.74, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:21:03 TP0] Decode batch. #running-req: 4, #token: 1803, token usage: 0.00, gen throughput (token/s): 848.08, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:21:03 TP0] Decode batch. #running-req: 4, #token: 1963, token usage: 0.00, gen throughput (token/s): 850.10, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:21:03 TP0] Decode batch. #running-req: 4, #token: 2123, token usage: 0.00, gen throughput (token/s): 855.31, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:21:03] INFO:     127.0.0.1:64270 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 18:21:03] INFO:     127.0.0.1:64284 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 18:21:03] INFO:     127.0.0.1:64260 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 18:21:03] INFO:     127.0.0.1:64276 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 18:21:03 TP0] Prefill batch. #new-seq: 4, #new-token: 4, #cached-token: 616, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-08-25 18:21:03 TP0] Decode batch. #running-req: 4, #token: 283, token usage: 0.00, gen throughput (token/s): 644.92, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:21:04 TP0] Decode batch. #running-req: 4, #token: 443, token usage: 0.00, gen throughput (token/s): 843.81, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:21:04 TP0] Decode batch. #running-req: 4, #token: 603, token usage: 0.00, gen throughput (token/s): 831.39, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:21:04 TP0] Decode batch. #running-req: 4, #token: 763, token usage: 0.00, gen throughput (token/s): 837.74, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:21:04 TP0] Decode batch. #running-req: 4, #token: 923, token usage: 0.00, gen throughput (token/s): 859.45, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:21:04 TP0] Decode batch. #running-req: 4, #token: 1083, token usage: 0.00, gen throughput (token/s): 845.43, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:21:04 TP0] Decode batch. #running-req: 4, #token: 1243, token usage: 0.00, gen throughput (token/s): 848.94, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:21:05 TP0] Decode batch. #running-req: 4, #token: 1403, token usage: 0.00, gen throughput (token/s): 835.01, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:21:05 TP0] Decode batch. #running-req: 4, #token: 1563, token usage: 0.00, gen throughput (token/s): 851.71, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:21:05 TP0] Decode batch. #running-req: 4, #token: 1723, token usage: 0.00, gen throughput (token/s): 850.12, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:21:05 TP0] Decode batch. #running-req: 4, #token: 1883, token usage: 0.00, gen throughput (token/s): 847.84, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:21:05 TP0] Decode batch. #running-req: 4, #token: 2043, token usage: 0.00, gen throughput (token/s): 829.49, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:21:06] INFO:     127.0.0.1:64270 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 18:21:06] INFO:     127.0.0.1:64284 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 18:21:06] INFO:     127.0.0.1:64260 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 18:21:06] INFO:     127.0.0.1:64276 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 18:21:06 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 154, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-08-25 18:21:06 TP0] Prefill batch. #new-seq: 3, #new-token: 3, #cached-token: 462, token usage: 0.00, #running-req: 1, #queue-req: 0, 
[2025-08-25 18:21:06 TP0] Decode batch. #running-req: 4, #token: 203, token usage: 0.00, gen throughput (token/s): 577.18, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:21:06 TP0] Decode batch. #running-req: 4, #token: 363, token usage: 0.00, gen throughput (token/s): 935.08, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:21:06 TP0] Decode batch. #running-req: 4, #token: 523, token usage: 0.00, gen throughput (token/s): 867.37, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:21:06 TP0] Decode batch. #running-req: 4, #token: 683, token usage: 0.00, gen throughput (token/s): 885.28, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:21:06 TP0] Decode batch. #running-req: 4, #token: 843, token usage: 0.00, gen throughput (token/s): 876.73, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:21:07 TP0] Decode batch. #running-req: 4, #token: 1003, token usage: 0.00, gen throughput (token/s): 857.43, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:21:07 TP0] Decode batch. #running-req: 4, #token: 1163, token usage: 0.00, gen throughput (token/s): 934.22, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:21:07 TP0] Decode batch. #running-req: 4, #token: 1323, token usage: 0.00, gen throughput (token/s): 872.35, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:21:07 TP0] Decode batch. #running-req: 4, #token: 1483, token usage: 0.00, gen throughput (token/s): 854.95, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:21:07 TP0] Decode batch. #running-req: 4, #token: 1643, token usage: 0.00, gen throughput (token/s): 861.67, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:21:08 TP0] Decode batch. #running-req: 4, #token: 1803, token usage: 0.00, gen throughput (token/s): 854.57, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:21:08 TP0] Decode batch. #running-req: 4, #token: 1963, token usage: 0.00, gen throughput (token/s): 859.75, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:21:08 TP0] Decode batch. #running-req: 4, #token: 2123, token usage: 0.00, gen throughput (token/s): 856.80, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:21:08] INFO:     127.0.0.1:64284 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 18:21:08] INFO:     127.0.0.1:64260 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 18:21:08] INFO:     127.0.0.1:64270 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 18:21:08] INFO:     127.0.0.1:64276 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 18:21:08 TP0] Prefill batch. #new-seq: 4, #new-token: 2404, #cached-token: 172, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-08-25 18:21:09] INFO:     127.0.0.1:54908 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 18:21:09] INFO:     127.0.0.1:54918 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 18:21:09] INFO:     127.0.0.1:54920 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 18:21:09] INFO:     127.0.0.1:54928 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 18:21:09 TP0] Prefill batch. #new-seq: 2, #new-token: 1000, #cached-token: 288, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-08-25 18:21:09] INFO:     127.0.0.1:54928 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 18:21:09] INFO:     127.0.0.1:54908 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 18:21:09 TP0] Prefill batch. #new-seq: 2, #new-token: 1000, #cached-token: 288, token usage: 0.00, #running-req: 2, #queue-req: 0, 
[2025-08-25 18:21:09 TP0] Prefill batch. #new-seq: 2, #new-token: 1000, #cached-token: 288, token usage: 0.00, #running-req: 4, #queue-req: 0, 
[2025-08-25 18:21:10] INFO:     127.0.0.1:54918 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 18:21:10] INFO:     127.0.0.1:54920 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 18:21:10] INFO:     127.0.0.1:54928 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 18:21:10 TP0] Prefill batch. #new-seq: 2, #new-token: 1000, #cached-token: 288, token usage: 0.00, #running-req: 2, #queue-req: 0, 
[2025-08-25 18:21:10] INFO:     127.0.0.1:54908 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 18:21:10 TP0] Prefill batch. #new-seq: 2, #new-token: 1000, #cached-token: 288, token usage: 0.00, #running-req: 4, #queue-req: 0, 
[2025-08-25 18:21:10] INFO:     127.0.0.1:54918 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 18:21:10] INFO:     127.0.0.1:54920 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 18:21:10] INFO:     127.0.0.1:54928 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 18:21:10 TP0] Prefill batch. #new-seq: 2, #new-token: 1000, #cached-token: 288, token usage: 0.00, #running-req: 2, #queue-req: 0, 
[2025-08-25 18:21:11] INFO:     127.0.0.1:54908 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 18:21:11] INFO:     127.0.0.1:54920 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 18:21:11] INFO:     127.0.0.1:54918 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 18:21:11 TP0] Prefill batch. #new-seq: 2, #new-token: 1216, #cached-token: 90, token usage: 0.00, #running-req: 2, #queue-req: 0, 
[2025-08-25 18:21:11 TP0] Prefill batch. #new-seq: 2, #new-token: 1216, #cached-token: 90, token usage: 0.00, #running-req: 4, #queue-req: 0, 
[2025-08-25 18:21:12 TP0] Decode batch. #running-req: 4, #token: 2183, token usage: 0.01, gen throughput (token/s): 9.06, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:21:13 TP0] Decode batch. #running-req: 4, #token: 2343, token usage: 0.01, gen throughput (token/s): 152.38, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:21:14 TP0] Decode batch. #running-req: 4, #token: 2503, token usage: 0.01, gen throughput (token/s): 153.27, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:21:15 TP0] Decode batch. #running-req: 4, #token: 2663, token usage: 0.01, gen throughput (token/s): 153.03, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:21:15] INFO:     127.0.0.1:54928 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 18:21:15] INFO:     127.0.0.1:54908 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 18:21:15] INFO:     127.0.0.1:54918 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 18:21:15] INFO:     127.0.0.1:54920 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 18:21:15 TP0] Prefill batch. #new-seq: 1, #new-token: 496, #cached-token: 157, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-08-25 18:21:17 TP0] Decode batch. #running-req: 1, #token: 691, token usage: 0.00, gen throughput (token/s): 40.90, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:21:18 TP0] Decode batch. #running-req: 1, #token: 731, token usage: 0.00, gen throughput (token/s): 38.86, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:21:19 TP0] Decode batch. #running-req: 1, #token: 771, token usage: 0.00, gen throughput (token/s): 38.63, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:21:19] INFO:     127.0.0.1:54928 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 18:21:19 TP0] Prefill batch. #new-seq: 4, #new-token: 1028, #cached-token: 208, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-08-25 18:21:20 TP0] Decode batch. #running-req: 4, #token: 437, token usage: 0.00, gen throughput (token/s): 13.59, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:21:20 TP0] Decode batch. #running-req: 4, #token: 597, token usage: 0.00, gen throughput (token/s): 869.15, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:21:20 TP0] Decode batch. #running-req: 4, #token: 757, token usage: 0.00, gen throughput (token/s): 878.00, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:21:20 TP0] Decode batch. #running-req: 4, #token: 917, token usage: 0.00, gen throughput (token/s): 858.88, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:21:20 TP0] Decode batch. #running-req: 4, #token: 1077, token usage: 0.00, gen throughput (token/s): 865.27, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:21:21 TP0] Decode batch. #running-req: 4, #token: 1237, token usage: 0.00, gen throughput (token/s): 884.25, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:21:21 TP0] Decode batch. #running-req: 4, #token: 1397, token usage: 0.00, gen throughput (token/s): 960.01, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:21:21 TP0] Decode batch. #running-req: 4, #token: 1557, token usage: 0.00, gen throughput (token/s): 952.96, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:21:21 TP0] Decode batch. #running-req: 4, #token: 1717, token usage: 0.00, gen throughput (token/s): 867.98, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:21:21 TP0] Decode batch. #running-req: 4, #token: 1877, token usage: 0.00, gen throughput (token/s): 877.67, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:21:21 TP0] Decode batch. #running-req: 4, #token: 2037, token usage: 0.00, gen throughput (token/s): 879.36, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:21:22 TP0] Decode batch. #running-req: 4, #token: 2197, token usage: 0.00, gen throughput (token/s): 866.83, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:21:22] INFO:     127.0.0.1:47816 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 18:21:22] INFO:     127.0.0.1:47832 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 18:21:22] INFO:     127.0.0.1:47846 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 18:21:22] INFO:     127.0.0.1:47850 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 18:21:22 TP0] Prefill batch. #new-seq: 2, #new-token: 2, #cached-token: 616, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-08-25 18:21:22 TP0] Prefill batch. #new-seq: 2, #new-token: 2, #cached-token: 616, token usage: 0.00, #running-req: 2, #queue-req: 0, 
[2025-08-25 18:21:22 TP0] Decode batch. #running-req: 4, #token: 357, token usage: 0.00, gen throughput (token/s): 576.37, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:21:22 TP0] Decode batch. #running-req: 4, #token: 517, token usage: 0.00, gen throughput (token/s): 865.80, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:21:22 TP0] Decode batch. #running-req: 4, #token: 677, token usage: 0.00, gen throughput (token/s): 863.62, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:21:22 TP0] Decode batch. #running-req: 4, #token: 837, token usage: 0.00, gen throughput (token/s): 868.94, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:21:23 TP0] Decode batch. #running-req: 4, #token: 997, token usage: 0.00, gen throughput (token/s): 845.49, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:21:23 TP0] Decode batch. #running-req: 4, #token: 1157, token usage: 0.00, gen throughput (token/s): 851.72, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:21:23 TP0] Decode batch. #running-req: 4, #token: 1317, token usage: 0.00, gen throughput (token/s): 859.61, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:21:23 TP0] Decode batch. #running-req: 4, #token: 1477, token usage: 0.00, gen throughput (token/s): 867.56, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:21:23 TP0] Decode batch. #running-req: 4, #token: 1637, token usage: 0.00, gen throughput (token/s): 847.24, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:21:24 TP0] Decode batch. #running-req: 4, #token: 1797, token usage: 0.00, gen throughput (token/s): 855.27, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:21:24 TP0] Decode batch. #running-req: 4, #token: 1957, token usage: 0.00, gen throughput (token/s): 951.11, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:21:24 TP0] Decode batch. #running-req: 4, #token: 2117, token usage: 0.00, gen throughput (token/s): 845.11, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:21:24 TP0] Decode batch. #running-req: 4, #token: 2277, token usage: 0.00, gen throughput (token/s): 881.70, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:21:24] INFO:     127.0.0.1:47850 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 18:21:24] INFO:     127.0.0.1:47816 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 18:21:24] INFO:     127.0.0.1:47832 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 18:21:24] INFO:     127.0.0.1:47846 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 18:21:24 TP0] Prefill batch. #new-seq: 4, #new-token: 4, #cached-token: 1232, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-08-25 18:21:24 TP0] Decode batch. #running-req: 4, #token: 437, token usage: 0.00, gen throughput (token/s): 655.95, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:21:25 TP0] Decode batch. #running-req: 4, #token: 597, token usage: 0.00, gen throughput (token/s): 882.70, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:21:25 TP0] Decode batch. #running-req: 4, #token: 757, token usage: 0.00, gen throughput (token/s): 865.95, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:21:25 TP0] Decode batch. #running-req: 4, #token: 917, token usage: 0.00, gen throughput (token/s): 929.59, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:21:25 TP0] Decode batch. #running-req: 4, #token: 1077, token usage: 0.00, gen throughput (token/s): 857.13, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:21:25 TP0] Decode batch. #running-req: 4, #token: 1237, token usage: 0.00, gen throughput (token/s): 867.21, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:21:25 TP0] Decode batch. #running-req: 4, #token: 1397, token usage: 0.00, gen throughput (token/s): 865.85, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:21:26 TP0] Decode batch. #running-req: 4, #token: 1557, token usage: 0.00, gen throughput (token/s): 848.15, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:21:26 TP0] Decode batch. #running-req: 4, #token: 1717, token usage: 0.00, gen throughput (token/s): 921.37, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:21:26 TP0] Decode batch. #running-req: 4, #token: 1877, token usage: 0.00, gen throughput (token/s): 853.61, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:21:26 TP0] Decode batch. #running-req: 4, #token: 2037, token usage: 0.00, gen throughput (token/s): 869.04, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:21:26 TP0] Decode batch. #running-req: 4, #token: 2197, token usage: 0.00, gen throughput (token/s): 835.35, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:21:27] INFO:     127.0.0.1:47816 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 18:21:27] INFO:     127.0.0.1:47850 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 18:21:27] INFO:     127.0.0.1:47832 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 18:21:27] INFO:     127.0.0.1:47846 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 18:21:27 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 308, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-08-25 18:21:27 TP0] Prefill batch. #new-seq: 3, #new-token: 3, #cached-token: 924, token usage: 0.00, #running-req: 1, #queue-req: 0, 
[2025-08-25 18:21:27 TP0] Decode batch. #running-req: 4, #token: 357, token usage: 0.00, gen throughput (token/s): 580.25, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:21:27 TP0] Decode batch. #running-req: 4, #token: 517, token usage: 0.00, gen throughput (token/s): 847.43, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:21:27 TP0] Decode batch. #running-req: 4, #token: 677, token usage: 0.00, gen throughput (token/s): 948.26, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:21:27 TP0] Decode batch. #running-req: 4, #token: 837, token usage: 0.00, gen throughput (token/s): 883.96, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:21:27 TP0] Decode batch. #running-req: 4, #token: 997, token usage: 0.00, gen throughput (token/s): 852.99, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:21:28 TP0] Decode batch. #running-req: 4, #token: 1157, token usage: 0.00, gen throughput (token/s): 927.44, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:21:28 TP0] Decode batch. #running-req: 4, #token: 1317, token usage: 0.00, gen throughput (token/s): 860.93, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:21:28 TP0] Decode batch. #running-req: 4, #token: 1477, token usage: 0.00, gen throughput (token/s): 872.88, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:21:28 TP0] Decode batch. #running-req: 4, #token: 1637, token usage: 0.00, gen throughput (token/s): 868.11, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:21:28 TP0] Decode batch. #running-req: 4, #token: 1797, token usage: 0.00, gen throughput (token/s): 867.37, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:21:28 TP0] Decode batch. #running-req: 4, #token: 1957, token usage: 0.00, gen throughput (token/s): 872.65, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:21:29 TP0] Decode batch. #running-req: 4, #token: 2117, token usage: 0.00, gen throughput (token/s): 931.16, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:21:29 TP0] Decode batch. #running-req: 4, #token: 2277, token usage: 0.00, gen throughput (token/s): 900.50, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:21:29] INFO:     127.0.0.1:47832 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 18:21:29] INFO:     127.0.0.1:47850 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 18:21:29] INFO:     127.0.0.1:47816 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 18:21:29] INFO:     127.0.0.1:47846 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 18:21:29 TP0] Prefill batch. #new-seq: 4, #new-token: 3016, #cached-token: 176, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-08-25 18:21:30] INFO:     127.0.0.1:64010 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 18:21:30] INFO:     127.0.0.1:64012 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 18:21:30] INFO:     127.0.0.1:64024 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 18:21:30] INFO:     127.0.0.1:64032 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 18:21:30 TP0] Prefill batch. #new-seq: 1, #new-token: 500, #cached-token: 298, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-08-25 18:21:30 TP0] Prefill batch. #new-seq: 3, #new-token: 1500, #cached-token: 894, token usage: 0.00, #running-req: 1, #queue-req: 0, 
[2025-08-25 18:21:31] INFO:     127.0.0.1:64032 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 18:21:31] INFO:     127.0.0.1:64010 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 18:21:31] INFO:     127.0.0.1:64012 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 18:21:31] INFO:     127.0.0.1:64024 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 18:21:31 TP0] Prefill batch. #new-seq: 1, #new-token: 500, #cached-token: 298, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-08-25 18:21:31 TP0] Prefill batch. #new-seq: 2, #new-token: 1000, #cached-token: 596, token usage: 0.00, #running-req: 1, #queue-req: 0, 
[2025-08-25 18:21:31 TP0] Prefill batch. #new-seq: 1, #new-token: 500, #cached-token: 298, token usage: 0.00, #running-req: 3, #queue-req: 0, 
[2025-08-25 18:21:31] INFO:     127.0.0.1:64032 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 18:21:31] INFO:     127.0.0.1:64010 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 18:21:31] INFO:     127.0.0.1:64012 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 18:21:31] INFO:     127.0.0.1:64024 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 18:21:31 TP0] Prefill batch. #new-seq: 3, #new-token: 1500, #cached-token: 894, token usage: 0.00, #running-req: 1, #queue-req: 0, 
[2025-08-25 18:21:32 TP0] Prefill batch. #new-seq: 1, #new-token: 500, #cached-token: 298, token usage: 0.01, #running-req: 4, #queue-req: 0, 
[2025-08-25 18:21:32] INFO:     127.0.0.1:64032 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 18:21:32] INFO:     127.0.0.1:64010 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 18:21:32] INFO:     127.0.0.1:64012 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 18:21:32] INFO:     127.0.0.1:64024 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 18:21:32 TP0] Prefill batch. #new-seq: 3, #new-token: 2283, #cached-token: 138, token usage: 0.00, #running-req: 1, #queue-req: 0, 
[2025-08-25 18:21:33 TP0] Decode batch. #running-req: 3, #token: 1808, token usage: 0.01, gen throughput (token/s): 3.63, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:21:34 TP0] Decode batch. #running-req: 3, #token: 1928, token usage: 0.01, gen throughput (token/s): 115.21, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:21:35 TP0] Decode batch. #running-req: 3, #token: 2048, token usage: 0.01, gen throughput (token/s): 116.24, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:21:36 TP0] Decode batch. #running-req: 3, #token: 2168, token usage: 0.01, gen throughput (token/s): 115.78, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:21:36] INFO:     127.0.0.1:64032 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 18:21:36] INFO:     127.0.0.1:64010 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 18:21:36] INFO:     127.0.0.1:64012 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 18:21:36 TP0] Prefill batch. #new-seq: 1, #new-token: 203, #cached-token: 50, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-08-25 18:21:36 TP0] Prefill batch. #new-seq: 3, #new-token: 609, #cached-token: 150, token usage: 0.00, #running-req: 1, #queue-req: 0, 
[2025-08-25 18:21:37 TP0] Decode batch. #running-req: 4, #token: 381, token usage: 0.00, gen throughput (token/s): 20.36, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:21:37 TP0] Decode batch. #running-req: 4, #token: 541, token usage: 0.00, gen throughput (token/s): 872.37, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:21:37 TP0] Decode batch. #running-req: 4, #token: 701, token usage: 0.00, gen throughput (token/s): 862.54, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:21:37 TP0] Decode batch. #running-req: 4, #token: 861, token usage: 0.00, gen throughput (token/s): 840.50, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:21:37 TP0] Decode batch. #running-req: 4, #token: 1021, token usage: 0.00, gen throughput (token/s): 864.02, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:21:38 TP0] Decode batch. #running-req: 4, #token: 1181, token usage: 0.00, gen throughput (token/s): 869.80, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:21:38 TP0] Decode batch. #running-req: 4, #token: 1341, token usage: 0.00, gen throughput (token/s): 850.66, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:21:38 TP0] Decode batch. #running-req: 4, #token: 1501, token usage: 0.00, gen throughput (token/s): 849.41, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:21:38 TP0] Decode batch. #running-req: 4, #token: 1661, token usage: 0.00, gen throughput (token/s): 861.06, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:21:38 TP0] Decode batch. #running-req: 4, #token: 1821, token usage: 0.00, gen throughput (token/s): 871.67, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:21:39 TP0] Decode batch. #running-req: 4, #token: 1981, token usage: 0.00, gen throughput (token/s): 847.59, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:21:39 TP0] Decode batch. #running-req: 4, #token: 2141, token usage: 0.00, gen throughput (token/s): 880.29, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:21:39] INFO:     127.0.0.1:44440 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 18:21:39] INFO:     127.0.0.1:44462 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 18:21:39] INFO:     127.0.0.1:44456 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 18:21:39] INFO:     127.0.0.1:44466 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 18:21:39 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 252, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-08-25 18:21:39 TP0] Prefill batch. #new-seq: 3, #new-token: 3, #cached-token: 756, token usage: 0.00, #running-req: 1, #queue-req: 0, 
[2025-08-25 18:21:39 TP0] Decode batch. #running-req: 4, #token: 301, token usage: 0.00, gen throughput (token/s): 580.54, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:21:39 TP0] Decode batch. #running-req: 4, #token: 461, token usage: 0.00, gen throughput (token/s): 867.58, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:21:39 TP0] Decode batch. #running-req: 4, #token: 621, token usage: 0.00, gen throughput (token/s): 856.38, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:21:40 TP0] Decode batch. #running-req: 4, #token: 781, token usage: 0.00, gen throughput (token/s): 833.26, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:21:40 TP0] Decode batch. #running-req: 4, #token: 941, token usage: 0.00, gen throughput (token/s): 840.96, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:21:40 TP0] Decode batch. #running-req: 4, #token: 1101, token usage: 0.00, gen throughput (token/s): 840.68, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:21:40 TP0] Decode batch. #running-req: 4, #token: 1261, token usage: 0.00, gen throughput (token/s): 838.45, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:21:40 TP0] Decode batch. #running-req: 4, #token: 1421, token usage: 0.00, gen throughput (token/s): 863.61, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:21:41 TP0] Decode batch. #running-req: 4, #token: 1581, token usage: 0.00, gen throughput (token/s): 840.19, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:21:41 TP0] Decode batch. #running-req: 4, #token: 1741, token usage: 0.00, gen throughput (token/s): 840.27, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:21:41 TP0] Decode batch. #running-req: 4, #token: 1901, token usage: 0.00, gen throughput (token/s): 844.30, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:21:41 TP0] Decode batch. #running-req: 4, #token: 2061, token usage: 0.00, gen throughput (token/s): 892.92, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:21:41 TP0] Decode batch. #running-req: 4, #token: 2221, token usage: 0.00, gen throughput (token/s): 873.07, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:21:41] INFO:     127.0.0.1:44440 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 18:21:41] INFO:     127.0.0.1:44466 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 18:21:41] INFO:     127.0.0.1:44456 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 18:21:41] INFO:     127.0.0.1:44462 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 18:21:41 TP0] Prefill batch. #new-seq: 4, #new-token: 4, #cached-token: 1008, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-08-25 18:21:42 TP0] Decode batch. #running-req: 4, #token: 381, token usage: 0.00, gen throughput (token/s): 643.92, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:21:42 TP0] Decode batch. #running-req: 4, #token: 541, token usage: 0.00, gen throughput (token/s): 857.25, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:21:42 TP0] Decode batch. #running-req: 4, #token: 701, token usage: 0.00, gen throughput (token/s): 850.72, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:21:42 TP0] Decode batch. #running-req: 4, #token: 861, token usage: 0.00, gen throughput (token/s): 843.23, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:21:42 TP0] Decode batch. #running-req: 4, #token: 1021, token usage: 0.00, gen throughput (token/s): 862.44, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:21:42 TP0] Decode batch. #running-req: 4, #token: 1181, token usage: 0.00, gen throughput (token/s): 826.78, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:21:43 TP0] Decode batch. #running-req: 4, #token: 1341, token usage: 0.00, gen throughput (token/s): 860.84, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:21:43 TP0] Decode batch. #running-req: 4, #token: 1501, token usage: 0.00, gen throughput (token/s): 867.37, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:21:43 TP0] Decode batch. #running-req: 4, #token: 1661, token usage: 0.00, gen throughput (token/s): 849.08, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:21:43 TP0] Decode batch. #running-req: 4, #token: 1821, token usage: 0.00, gen throughput (token/s): 876.73, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:21:43 TP0] Decode batch. #running-req: 4, #token: 1981, token usage: 0.00, gen throughput (token/s): 841.82, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:21:44 TP0] Decode batch. #running-req: 4, #token: 2141, token usage: 0.00, gen throughput (token/s): 864.78, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:21:44] INFO:     127.0.0.1:44466 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 18:21:44] INFO:     127.0.0.1:44440 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 18:21:44] INFO:     127.0.0.1:44456 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 18:21:44] INFO:     127.0.0.1:44462 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 18:21:44 TP0] Prefill batch. #new-seq: 4, #new-token: 4, #cached-token: 1008, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-08-25 18:21:44 TP0] Decode batch. #running-req: 4, #token: 301, token usage: 0.00, gen throughput (token/s): 628.90, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:21:44 TP0] Decode batch. #running-req: 4, #token: 461, token usage: 0.00, gen throughput (token/s): 862.26, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:21:44 TP0] Decode batch. #running-req: 4, #token: 621, token usage: 0.00, gen throughput (token/s): 868.75, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:21:44 TP0] Decode batch. #running-req: 4, #token: 781, token usage: 0.00, gen throughput (token/s): 866.71, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:21:45 TP0] Decode batch. #running-req: 4, #token: 941, token usage: 0.00, gen throughput (token/s): 859.92, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:21:45 TP0] Decode batch. #running-req: 4, #token: 1101, token usage: 0.00, gen throughput (token/s): 837.59, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:21:45 TP0] Decode batch. #running-req: 4, #token: 1261, token usage: 0.00, gen throughput (token/s): 861.46, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:21:45 TP0] Decode batch. #running-req: 4, #token: 1421, token usage: 0.00, gen throughput (token/s): 868.68, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:21:45 TP0] Decode batch. #running-req: 4, #token: 1581, token usage: 0.00, gen throughput (token/s): 849.51, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:21:46 TP0] Decode batch. #running-req: 4, #token: 1741, token usage: 0.00, gen throughput (token/s): 839.94, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:21:46 TP0] Decode batch. #running-req: 4, #token: 1901, token usage: 0.00, gen throughput (token/s): 844.91, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:21:46 TP0] Decode batch. #running-req: 4, #token: 2061, token usage: 0.00, gen throughput (token/s): 849.16, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:21:46 TP0] Decode batch. #running-req: 4, #token: 2221, token usage: 0.00, gen throughput (token/s): 879.19, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:21:46] INFO:     127.0.0.1:44466 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 18:21:46] INFO:     127.0.0.1:44440 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 18:21:46] INFO:     127.0.0.1:44456 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 18:21:46] INFO:     127.0.0.1:44462 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 18:21:46 TP0] Prefill batch. #new-seq: 4, #new-token: 2800, #cached-token: 168, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-08-25 18:21:47] INFO:     127.0.0.1:4574 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 18:21:47] INFO:     127.0.0.1:4576 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 18:21:47] INFO:     127.0.0.1:4584 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 18:21:47] INFO:     127.0.0.1:4590 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 18:21:47 TP0] Prefill batch. #new-seq: 3, #new-token: 1500, #cached-token: 726, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-08-25 18:21:48 TP0] Prefill batch. #new-seq: 1, #new-token: 500, #cached-token: 242, token usage: 0.00, #running-req: 3, #queue-req: 0, 
[2025-08-25 18:21:48] INFO:     127.0.0.1:4590 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 18:21:48] INFO:     127.0.0.1:4574 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 18:21:48] INFO:     127.0.0.1:4576 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 18:21:48 TP0] Prefill batch. #new-seq: 3, #new-token: 1500, #cached-token: 726, token usage: 0.00, #running-req: 1, #queue-req: 0, 
[2025-08-25 18:21:48] INFO:     127.0.0.1:4584 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 18:21:48 TP0] Prefill batch. #new-seq: 1, #new-token: 500, #cached-token: 242, token usage: 0.01, #running-req: 4, #queue-req: 0, 
[2025-08-25 18:21:49] INFO:     127.0.0.1:4590 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 18:21:49] INFO:     127.0.0.1:4574 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 18:21:49] INFO:     127.0.0.1:4576 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 18:21:49] INFO:     127.0.0.1:4584 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 18:21:49 TP0] Prefill batch. #new-seq: 1, #new-token: 500, #cached-token: 242, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-08-25 18:21:49 TP0] Prefill batch. #new-seq: 3, #new-token: 1500, #cached-token: 726, token usage: 0.00, #running-req: 1, #queue-req: 0, 
[2025-08-25 18:21:49] INFO:     127.0.0.1:4590 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 18:21:49] INFO:     127.0.0.1:4574 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 18:21:49] INFO:     127.0.0.1:4576 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 18:21:49] INFO:     127.0.0.1:4584 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 18:21:49 TP0] Prefill batch. #new-seq: 1, #new-token: 707, #cached-token: 44, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-08-25 18:21:49 TP0] Prefill batch. #new-seq: 2, #new-token: 994, #cached-token: 508, token usage: 0.00, #running-req: 1, #queue-req: 0, 
[2025-08-25 18:21:50 TP0] Decode batch. #running-req: 3, #token: 1770, token usage: 0.01, gen throughput (token/s): 8.11, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:21:51 TP0] Decode batch. #running-req: 3, #token: 1890, token usage: 0.01, gen throughput (token/s): 114.53, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:21:52 TP0] Decode batch. #running-req: 3, #token: 2010, token usage: 0.01, gen throughput (token/s): 114.30, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:21:53 TP0] Decode batch. #running-req: 3, #token: 2130, token usage: 0.01, gen throughput (token/s): 115.04, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:21:54] INFO:     127.0.0.1:4590 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 18:21:54] INFO:     127.0.0.1:4574 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 18:21:54] INFO:     127.0.0.1:4576 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 18:21:54 TP0] Prefill batch. #new-seq: 4, #new-token: 452, #cached-token: 204, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-08-25 18:21:54 TP0] Decode batch. #running-req: 4, #token: 292, token usage: 0.00, gen throughput (token/s): 20.49, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:21:54 TP0] Decode batch. #running-req: 4, #token: 452, token usage: 0.00, gen throughput (token/s): 845.84, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:21:54 TP0] Decode batch. #running-req: 4, #token: 612, token usage: 0.00, gen throughput (token/s): 834.48, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:21:54 TP0] Decode batch. #running-req: 4, #token: 772, token usage: 0.00, gen throughput (token/s): 838.00, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:21:55 TP0] Decode batch. #running-req: 4, #token: 932, token usage: 0.00, gen throughput (token/s): 860.01, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:21:55 TP0] Decode batch. #running-req: 4, #token: 1092, token usage: 0.00, gen throughput (token/s): 840.22, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:21:55 TP0] Decode batch. #running-req: 4, #token: 1252, token usage: 0.00, gen throughput (token/s): 849.69, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:21:55 TP0] Decode batch. #running-req: 4, #token: 1412, token usage: 0.00, gen throughput (token/s): 861.15, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:21:55 TP0] Decode batch. #running-req: 4, #token: 1572, token usage: 0.00, gen throughput (token/s): 847.69, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:21:56 TP0] Decode batch. #running-req: 4, #token: 1732, token usage: 0.00, gen throughput (token/s): 855.77, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:21:56 TP0] Decode batch. #running-req: 4, #token: 1892, token usage: 0.00, gen throughput (token/s): 852.58, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:21:56 TP0] Decode batch. #running-req: 4, #token: 2052, token usage: 0.00, gen throughput (token/s): 839.84, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:21:56] INFO:     127.0.0.1:26210 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 18:21:56] INFO:     127.0.0.1:26212 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 18:21:56] INFO:     127.0.0.1:26228 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 18:21:56] INFO:     127.0.0.1:26242 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 18:21:56 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 163, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-08-25 18:21:56 TP0] Prefill batch. #new-seq: 3, #new-token: 3, #cached-token: 489, token usage: 0.00, #running-req: 1, #queue-req: 0, 
[2025-08-25 18:21:56 TP0] Decode batch. #running-req: 4, #token: 209, token usage: 0.00, gen throughput (token/s): 556.90, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:21:56 TP0] Decode batch. #running-req: 4, #token: 369, token usage: 0.00, gen throughput (token/s): 861.29, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:21:57 TP0] Decode batch. #running-req: 4, #token: 529, token usage: 0.00, gen throughput (token/s): 900.26, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:21:57 TP0] Decode batch. #running-req: 4, #token: 689, token usage: 0.00, gen throughput (token/s): 850.97, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:21:57 TP0] Decode batch. #running-req: 4, #token: 849, token usage: 0.00, gen throughput (token/s): 857.30, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:21:57 TP0] Decode batch. #running-req: 4, #token: 1009, token usage: 0.00, gen throughput (token/s): 833.03, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:21:57 TP0] Decode batch. #running-req: 4, #token: 1169, token usage: 0.00, gen throughput (token/s): 855.78, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:21:58 TP0] Decode batch. #running-req: 4, #token: 1329, token usage: 0.00, gen throughput (token/s): 868.55, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:21:58 TP0] Decode batch. #running-req: 4, #token: 1489, token usage: 0.00, gen throughput (token/s): 840.88, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:21:58 TP0] Decode batch. #running-req: 4, #token: 1649, token usage: 0.00, gen throughput (token/s): 851.29, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:21:58 TP0] Decode batch. #running-req: 4, #token: 1809, token usage: 0.00, gen throughput (token/s): 864.96, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:21:58 TP0] Decode batch. #running-req: 4, #token: 1969, token usage: 0.00, gen throughput (token/s): 864.81, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:21:58 TP0] Decode batch. #running-req: 4, #token: 2129, token usage: 0.00, gen throughput (token/s): 886.38, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:21:59] INFO:     127.0.0.1:26242 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 18:21:59] INFO:     127.0.0.1:26210 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 18:21:59] INFO:     127.0.0.1:26212 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 18:21:59] INFO:     127.0.0.1:26228 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 18:21:59 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 163, token usage: 0.00, #running-req: 3, #queue-req: 0, 
[2025-08-25 18:21:59 TP0] Prefill batch. #new-seq: 3, #new-token: 3, #cached-token: 489, token usage: 0.00, #running-req: 4, #queue-req: 0, 
[2025-08-25 18:21:59 TP0] Decode batch. #running-req: 4, #token: 288, token usage: 0.00, gen throughput (token/s): 585.02, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:21:59 TP0] Decode batch. #running-req: 4, #token: 448, token usage: 0.00, gen throughput (token/s): 862.91, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:21:59 TP0] Decode batch. #running-req: 4, #token: 608, token usage: 0.00, gen throughput (token/s): 876.88, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:21:59 TP0] Decode batch. #running-req: 4, #token: 768, token usage: 0.00, gen throughput (token/s): 871.73, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:21:59 TP0] Decode batch. #running-req: 4, #token: 928, token usage: 0.00, gen throughput (token/s): 873.78, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:22:00 TP0] Decode batch. #running-req: 4, #token: 1088, token usage: 0.00, gen throughput (token/s): 861.31, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:22:00 TP0] Decode batch. #running-req: 4, #token: 1248, token usage: 0.00, gen throughput (token/s): 852.30, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:22:00 TP0] Decode batch. #running-req: 4, #token: 1408, token usage: 0.00, gen throughput (token/s): 864.90, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:22:00 TP0] Decode batch. #running-req: 4, #token: 1568, token usage: 0.00, gen throughput (token/s): 843.96, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:22:00 TP0] Decode batch. #running-req: 4, #token: 1728, token usage: 0.00, gen throughput (token/s): 870.67, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:22:01 TP0] Decode batch. #running-req: 4, #token: 1888, token usage: 0.00, gen throughput (token/s): 875.95, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:22:01 TP0] Decode batch. #running-req: 4, #token: 2048, token usage: 0.00, gen throughput (token/s): 865.66, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:22:01] INFO:     127.0.0.1:26242 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 18:22:01] INFO:     127.0.0.1:26210 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 18:22:01] INFO:     127.0.0.1:26212 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 18:22:01] INFO:     127.0.0.1:26228 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 18:22:01 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 163, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-08-25 18:22:01 TP0] Prefill batch. #new-seq: 3, #new-token: 3, #cached-token: 489, token usage: 0.00, #running-req: 1, #queue-req: 0, 
[2025-08-25 18:22:01 TP0] Decode batch. #running-req: 4, #token: 208, token usage: 0.00, gen throughput (token/s): 574.77, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:22:01 TP0] Decode batch. #running-req: 4, #token: 368, token usage: 0.00, gen throughput (token/s): 874.36, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:22:01 TP0] Decode batch. #running-req: 4, #token: 528, token usage: 0.00, gen throughput (token/s): 918.04, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:22:02 TP0] Decode batch. #running-req: 4, #token: 688, token usage: 0.00, gen throughput (token/s): 957.52, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:22:02 TP0] Decode batch. #running-req: 4, #token: 848, token usage: 0.00, gen throughput (token/s): 962.92, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:22:02 TP0] Decode batch. #running-req: 4, #token: 1008, token usage: 0.00, gen throughput (token/s): 956.64, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:22:02 TP0] Decode batch. #running-req: 4, #token: 1168, token usage: 0.00, gen throughput (token/s): 967.33, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:22:02 TP0] Decode batch. #running-req: 4, #token: 1328, token usage: 0.00, gen throughput (token/s): 931.64, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:22:02 TP0] Decode batch. #running-req: 4, #token: 1488, token usage: 0.00, gen throughput (token/s): 851.24, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:22:03 TP0] Decode batch. #running-req: 4, #token: 1648, token usage: 0.00, gen throughput (token/s): 860.13, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:22:03 TP0] Decode batch. #running-req: 4, #token: 1808, token usage: 0.00, gen throughput (token/s): 871.10, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:22:03 TP0] Decode batch. #running-req: 4, #token: 1968, token usage: 0.00, gen throughput (token/s): 861.78, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:22:03 TP0] Decode batch. #running-req: 4, #token: 2128, token usage: 0.00, gen throughput (token/s): 859.15, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:22:03] INFO:     127.0.0.1:26242 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 18:22:03] INFO:     127.0.0.1:26210 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 18:22:03] INFO:     127.0.0.1:26212 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 18:22:03] INFO:     127.0.0.1:26228 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 18:22:03 TP0] Prefill batch. #new-seq: 4, #new-token: 2440, #cached-token: 172, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-08-25 18:22:04] INFO:     127.0.0.1:17202 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 18:22:04] INFO:     127.0.0.1:17218 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 18:22:04] INFO:     127.0.0.1:17224 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 18:22:04] INFO:     127.0.0.1:17230 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 18:22:04 TP0] Prefill batch. #new-seq: 2, #new-token: 1000, #cached-token: 306, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-08-25 18:22:04 TP0] Prefill batch. #new-seq: 2, #new-token: 1000, #cached-token: 306, token usage: 0.00, #running-req: 2, #queue-req: 0, 
[2025-08-25 18:22:04] INFO:     127.0.0.1:17230 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 18:22:04] INFO:     127.0.0.1:17202 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 18:22:05 TP0] Prefill batch. #new-seq: 2, #new-token: 1000, #cached-token: 306, token usage: 0.00, #running-req: 2, #queue-req: 0, 
[2025-08-25 18:22:05] INFO:     127.0.0.1:17218 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 18:22:05] INFO:     127.0.0.1:17224 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 18:22:05 TP0] Prefill batch. #new-seq: 2, #new-token: 1000, #cached-token: 306, token usage: 0.00, #running-req: 4, #queue-req: 0, 
[2025-08-25 18:22:05] INFO:     127.0.0.1:17202 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 18:22:05] INFO:     127.0.0.1:17230 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 18:22:05] INFO:     127.0.0.1:17218 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 18:22:05] INFO:     127.0.0.1:17224 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 18:22:05 TP0] Prefill batch. #new-seq: 2, #new-token: 1000, #cached-token: 306, token usage: 0.00, #running-req: 2, #queue-req: 0, 
[2025-08-25 18:22:06 TP0] Prefill batch. #new-seq: 2, #new-token: 1000, #cached-token: 306, token usage: 0.00, #running-req: 2, #queue-req: 0, 
[2025-08-25 18:22:06] INFO:     127.0.0.1:17230 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 18:22:06] INFO:     127.0.0.1:17202 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 18:22:06 TP0] Prefill batch. #new-seq: 2, #new-token: 1234, #cached-token: 90, token usage: 0.00, #running-req: 4, #queue-req: 0, 
[2025-08-25 18:22:06] INFO:     127.0.0.1:17218 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 18:22:06] INFO:     127.0.0.1:17224 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 18:22:06 TP0] Prefill batch. #new-seq: 2, #new-token: 993, #cached-token: 331, token usage: 0.00, #running-req: 2, #queue-req: 0, 
[2025-08-25 18:22:07 TP0] Decode batch. #running-req: 4, #token: 2202, token usage: 0.01, gen throughput (token/s): 9.16, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:22:08 TP0] Decode batch. #running-req: 4, #token: 2362, token usage: 0.01, gen throughput (token/s): 153.84, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:22:09 TP0] Decode batch. #running-req: 4, #token: 2522, token usage: 0.01, gen throughput (token/s): 154.22, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:22:10 TP0] Decode batch. #running-req: 4, #token: 2682, token usage: 0.01, gen throughput (token/s): 154.13, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:22:11] INFO:     127.0.0.1:17230 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 18:22:11] INFO:     127.0.0.1:17202 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 18:22:11] INFO:     127.0.0.1:17218 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 18:22:11] INFO:     127.0.0.1:17224 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 18:22:11 TP0] Prefill batch. #new-seq: 4, #new-token: 332, #cached-token: 200, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-08-25 18:22:11 TP0] Decode batch. #running-req: 4, #token: 257, token usage: 0.00, gen throughput (token/s): 20.90, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:22:11 TP0] Decode batch. #running-req: 4, #token: 417, token usage: 0.00, gen throughput (token/s): 884.86, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:22:11 TP0] Decode batch. #running-req: 4, #token: 577, token usage: 0.00, gen throughput (token/s): 867.85, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:22:11 TP0] Decode batch. #running-req: 4, #token: 737, token usage: 0.00, gen throughput (token/s): 860.56, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:22:12 TP0] Decode batch. #running-req: 4, #token: 897, token usage: 0.00, gen throughput (token/s): 866.31, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:22:12 TP0] Decode batch. #running-req: 4, #token: 1057, token usage: 0.00, gen throughput (token/s): 861.24, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:22:12 TP0] Decode batch. #running-req: 4, #token: 1217, token usage: 0.00, gen throughput (token/s): 857.35, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:22:12 TP0] Decode batch. #running-req: 4, #token: 1377, token usage: 0.00, gen throughput (token/s): 860.94, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:22:12 TP0] Decode batch. #running-req: 4, #token: 1537, token usage: 0.00, gen throughput (token/s): 839.48, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:22:13 TP0] Decode batch. #running-req: 4, #token: 1697, token usage: 0.00, gen throughput (token/s): 879.05, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:22:13 TP0] Decode batch. #running-req: 4, #token: 1857, token usage: 0.00, gen throughput (token/s): 839.45, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:22:13 TP0] Decode batch. #running-req: 4, #token: 2017, token usage: 0.00, gen throughput (token/s): 858.07, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:22:13] INFO:     127.0.0.1:39112 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 18:22:13] INFO:     127.0.0.1:39116 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 18:22:13] INFO:     127.0.0.1:39124 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 18:22:13] INFO:     127.0.0.1:39132 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 18:22:13 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 132, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-08-25 18:22:13 TP0] Prefill batch. #new-seq: 3, #new-token: 3, #cached-token: 396, token usage: 0.00, #running-req: 1, #queue-req: 0, 
[2025-08-25 18:22:13 TP0] Decode batch. #running-req: 4, #token: 177, token usage: 0.00, gen throughput (token/s): 565.53, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:22:13 TP0] Decode batch. #running-req: 4, #token: 337, token usage: 0.00, gen throughput (token/s): 869.38, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:22:14 TP0] Decode batch. #running-req: 4, #token: 497, token usage: 0.00, gen throughput (token/s): 885.25, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:22:14 TP0] Decode batch. #running-req: 4, #token: 657, token usage: 0.00, gen throughput (token/s): 878.07, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:22:14 TP0] Decode batch. #running-req: 4, #token: 817, token usage: 0.00, gen throughput (token/s): 857.86, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:22:14 TP0] Decode batch. #running-req: 4, #token: 977, token usage: 0.00, gen throughput (token/s): 840.53, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:22:14 TP0] Decode batch. #running-req: 4, #token: 1137, token usage: 0.00, gen throughput (token/s): 861.29, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:22:14 TP0] Decode batch. #running-req: 4, #token: 1297, token usage: 0.00, gen throughput (token/s): 878.52, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:22:15 TP0] Decode batch. #running-req: 4, #token: 1457, token usage: 0.00, gen throughput (token/s): 840.23, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:22:15 TP0] Decode batch. #running-req: 4, #token: 1617, token usage: 0.00, gen throughput (token/s): 866.27, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:22:15 TP0] Decode batch. #running-req: 4, #token: 1777, token usage: 0.00, gen throughput (token/s): 851.26, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:22:15 TP0] Decode batch. #running-req: 4, #token: 1937, token usage: 0.00, gen throughput (token/s): 857.70, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:22:15 TP0] Decode batch. #running-req: 4, #token: 2097, token usage: 0.00, gen throughput (token/s): 855.17, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:22:15] INFO:     127.0.0.1:39132 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 18:22:15] INFO:     127.0.0.1:39112 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 18:22:15] INFO:     127.0.0.1:39116 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 18:22:15] INFO:     127.0.0.1:39124 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 18:22:15 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 132, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-08-25 18:22:15 TP0] Prefill batch. #new-seq: 3, #new-token: 3, #cached-token: 396, token usage: 0.00, #running-req: 1, #queue-req: 0, 
[2025-08-25 18:22:16 TP0] Decode batch. #running-req: 4, #token: 257, token usage: 0.00, gen throughput (token/s): 573.34, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:22:16 TP0] Decode batch. #running-req: 4, #token: 417, token usage: 0.00, gen throughput (token/s): 873.38, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:22:16 TP0] Decode batch. #running-req: 4, #token: 577, token usage: 0.00, gen throughput (token/s): 872.10, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:22:16 TP0] Decode batch. #running-req: 4, #token: 737, token usage: 0.00, gen throughput (token/s): 859.05, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:22:16 TP0] Decode batch. #running-req: 4, #token: 897, token usage: 0.00, gen throughput (token/s): 867.17, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:22:17 TP0] Decode batch. #running-req: 4, #token: 1057, token usage: 0.00, gen throughput (token/s): 854.74, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:22:17 TP0] Decode batch. #running-req: 4, #token: 1217, token usage: 0.00, gen throughput (token/s): 854.00, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:22:17 TP0] Decode batch. #running-req: 4, #token: 1377, token usage: 0.00, gen throughput (token/s): 877.12, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:22:17 TP0] Decode batch. #running-req: 4, #token: 1537, token usage: 0.00, gen throughput (token/s): 838.12, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:22:17 TP0] Decode batch. #running-req: 4, #token: 1697, token usage: 0.00, gen throughput (token/s): 883.10, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:22:18 TP0] Decode batch. #running-req: 4, #token: 1857, token usage: 0.00, gen throughput (token/s): 867.27, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:22:18 TP0] Decode batch. #running-req: 4, #token: 2017, token usage: 0.00, gen throughput (token/s): 851.58, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:22:18] INFO:     127.0.0.1:39132 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 18:22:18] INFO:     127.0.0.1:39112 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 18:22:18] INFO:     127.0.0.1:39116 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 18:22:18] INFO:     127.0.0.1:39124 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 18:22:18 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 132, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-08-25 18:22:18 TP0] Prefill batch. #new-seq: 3, #new-token: 3, #cached-token: 396, token usage: 0.00, #running-req: 1, #queue-req: 0, 
[2025-08-25 18:22:18 TP0] Decode batch. #running-req: 4, #token: 177, token usage: 0.00, gen throughput (token/s): 574.72, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:22:18 TP0] Decode batch. #running-req: 4, #token: 337, token usage: 0.00, gen throughput (token/s): 879.72, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:22:18 TP0] Decode batch. #running-req: 4, #token: 497, token usage: 0.00, gen throughput (token/s): 866.99, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:22:19 TP0] Decode batch. #running-req: 4, #token: 657, token usage: 0.00, gen throughput (token/s): 849.26, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:22:19 TP0] Decode batch. #running-req: 4, #token: 817, token usage: 0.00, gen throughput (token/s): 865.36, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:22:19 TP0] Decode batch. #running-req: 4, #token: 977, token usage: 0.00, gen throughput (token/s): 864.38, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:22:19 TP0] Decode batch. #running-req: 4, #token: 1137, token usage: 0.00, gen throughput (token/s): 866.04, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:22:19 TP0] Decode batch. #running-req: 4, #token: 1297, token usage: 0.00, gen throughput (token/s): 868.34, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:22:19 TP0] Decode batch. #running-req: 4, #token: 1457, token usage: 0.00, gen throughput (token/s): 865.64, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:22:20 TP0] Decode batch. #running-req: 4, #token: 1617, token usage: 0.00, gen throughput (token/s): 858.74, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:22:20 TP0] Decode batch. #running-req: 4, #token: 1777, token usage: 0.00, gen throughput (token/s): 850.36, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:22:20 TP0] Decode batch. #running-req: 4, #token: 1937, token usage: 0.00, gen throughput (token/s): 838.10, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:22:20 TP0] Decode batch. #running-req: 4, #token: 2097, token usage: 0.00, gen throughput (token/s): 873.74, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:22:20] INFO:     127.0.0.1:39132 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 18:22:20] INFO:     127.0.0.1:39112 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 18:22:20] INFO:     127.0.0.1:39116 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 18:22:20] INFO:     127.0.0.1:39124 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 18:22:20 TP0] Prefill batch. #new-seq: 4, #new-token: 2320, #cached-token: 168, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-08-25 18:22:21] INFO:     127.0.0.1:62748 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 18:22:21] INFO:     127.0.0.1:62762 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 18:22:21] INFO:     127.0.0.1:62766 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 18:22:21] INFO:     127.0.0.1:62780 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 18:22:21 TP0] Prefill batch. #new-seq: 1, #new-token: 500, #cached-token: 122, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-08-25 18:22:21 TP0] Prefill batch. #new-seq: 1, #new-token: 500, #cached-token: 122, token usage: 0.00, #running-req: 1, #queue-req: 0, 
[2025-08-25 18:22:21 TP0] Prefill batch. #new-seq: 2, #new-token: 1000, #cached-token: 244, token usage: 0.00, #running-req: 2, #queue-req: 0, 
[2025-08-25 18:22:21] INFO:     127.0.0.1:62780 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 18:22:22] INFO:     127.0.0.1:62748 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 18:22:22] INFO:     127.0.0.1:62762 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 18:22:22] INFO:     127.0.0.1:62766 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 18:22:22 TP0] Prefill batch. #new-seq: 2, #new-token: 1000, #cached-token: 244, token usage: 0.00, #running-req: 2, #queue-req: 0, 
[2025-08-25 18:22:22 TP0] Prefill batch. #new-seq: 2, #new-token: 1000, #cached-token: 244, token usage: 0.00, #running-req: 4, #queue-req: 0, 
[2025-08-25 18:22:22] INFO:     127.0.0.1:62780 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 18:22:22] INFO:     127.0.0.1:62748 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 18:22:22] INFO:     127.0.0.1:62762 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 18:22:23] INFO:     127.0.0.1:62766 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 18:22:23 TP0] Prefill batch. #new-seq: 2, #new-token: 1000, #cached-token: 244, token usage: 0.00, #running-req: 2, #queue-req: 0, 
[2025-08-25 18:22:23] INFO:     127.0.0.1:62748 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 18:22:23] INFO:     127.0.0.1:62780 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 18:22:23 TP0] Prefill batch. #new-seq: 2, #new-token: 1000, #cached-token: 244, token usage: 0.00, #running-req: 2, #queue-req: 0, 
[2025-08-25 18:22:23 TP0] Prefill batch. #new-seq: 1, #new-token: 587, #cached-token: 44, token usage: 0.00, #running-req: 4, #queue-req: 0, 
[2025-08-25 18:22:23] INFO:     127.0.0.1:62762 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 18:22:23] INFO:     127.0.0.1:62766 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 18:22:23 TP0] Prefill batch. #new-seq: 1, #new-token: 496, #cached-token: 135, token usage: 0.00, #running-req: 1, #queue-req: 0, 
[2025-08-25 18:22:24 TP0] Decode batch. #running-req: 2, #token: 1164, token usage: 0.00, gen throughput (token/s): 8.34, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:22:25 TP0] Decode batch. #running-req: 2, #token: 1244, token usage: 0.00, gen throughput (token/s): 78.28, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:22:26 TP0] Decode batch. #running-req: 2, #token: 1324, token usage: 0.00, gen throughput (token/s): 78.16, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:22:27 TP0] Decode batch. #running-req: 2, #token: 1404, token usage: 0.00, gen throughput (token/s): 78.06, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:22:27] INFO:     127.0.0.1:62780 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 18:22:27] INFO:     127.0.0.1:62748 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 18:22:27 TP0] Prefill batch. #new-seq: 4, #new-token: 516, #cached-token: 208, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-08-25 18:22:28 TP0] Decode batch. #running-req: 4, #token: 305, token usage: 0.00, gen throughput (token/s): 21.83, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:22:28 TP0] Decode batch. #running-req: 4, #token: 465, token usage: 0.00, gen throughput (token/s): 851.34, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:22:28 TP0] Decode batch. #running-req: 4, #token: 625, token usage: 0.00, gen throughput (token/s): 837.94, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:22:28 TP0] Decode batch. #running-req: 4, #token: 785, token usage: 0.00, gen throughput (token/s): 863.60, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:22:28 TP0] Decode batch. #running-req: 4, #token: 945, token usage: 0.00, gen throughput (token/s): 868.74, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:22:28 TP0] Decode batch. #running-req: 4, #token: 1105, token usage: 0.00, gen throughput (token/s): 846.66, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:22:29 TP0] Decode batch. #running-req: 4, #token: 1265, token usage: 0.00, gen throughput (token/s): 852.94, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:22:29 TP0] Decode batch. #running-req: 4, #token: 1425, token usage: 0.00, gen throughput (token/s): 838.43, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:22:29 TP0] Decode batch. #running-req: 4, #token: 1585, token usage: 0.00, gen throughput (token/s): 877.09, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:22:29 TP0] Decode batch. #running-req: 4, #token: 1745, token usage: 0.00, gen throughput (token/s): 864.26, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:22:29 TP0] Decode batch. #running-req: 4, #token: 1905, token usage: 0.00, gen throughput (token/s): 840.51, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:22:30 TP0] Decode batch. #running-req: 4, #token: 2065, token usage: 0.00, gen throughput (token/s): 862.47, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:22:30] INFO:     127.0.0.1:25010 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 18:22:30] INFO:     127.0.0.1:25012 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 18:22:30] INFO:     127.0.0.1:25024 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 18:22:30] INFO:     127.0.0.1:25040 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 18:22:30 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 180, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-08-25 18:22:30 TP0] Prefill batch. #new-seq: 3, #new-token: 3, #cached-token: 540, token usage: 0.00, #running-req: 1, #queue-req: 0, 
[2025-08-25 18:22:30 TP0] Decode batch. #running-req: 4, #token: 225, token usage: 0.00, gen throughput (token/s): 572.26, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:22:30 TP0] Decode batch. #running-req: 4, #token: 385, token usage: 0.00, gen throughput (token/s): 883.41, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:22:30 TP0] Decode batch. #running-req: 4, #token: 545, token usage: 0.00, gen throughput (token/s): 879.39, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:22:30 TP0] Decode batch. #running-req: 4, #token: 705, token usage: 0.00, gen throughput (token/s): 850.68, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:22:31 TP0] Decode batch. #running-req: 4, #token: 865, token usage: 0.00, gen throughput (token/s): 847.95, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:22:31 TP0] Decode batch. #running-req: 4, #token: 1025, token usage: 0.00, gen throughput (token/s): 850.59, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:22:31 TP0] Decode batch. #running-req: 4, #token: 1185, token usage: 0.00, gen throughput (token/s): 835.20, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:22:31 TP0] Decode batch. #running-req: 4, #token: 1345, token usage: 0.00, gen throughput (token/s): 866.72, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:22:31 TP0] Decode batch. #running-req: 4, #token: 1505, token usage: 0.00, gen throughput (token/s): 877.11, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:22:32 TP0] Decode batch. #running-req: 4, #token: 1665, token usage: 0.00, gen throughput (token/s): 861.90, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:22:32 TP0] Decode batch. #running-req: 4, #token: 1825, token usage: 0.00, gen throughput (token/s): 867.62, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:22:32 TP0] Decode batch. #running-req: 4, #token: 1985, token usage: 0.00, gen throughput (token/s): 860.11, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:22:32 TP0] Decode batch. #running-req: 4, #token: 2145, token usage: 0.00, gen throughput (token/s): 856.48, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:22:32] INFO:     127.0.0.1:25040 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 18:22:32] INFO:     127.0.0.1:25010 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 18:22:32] INFO:     127.0.0.1:25012 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 18:22:32] INFO:     127.0.0.1:25024 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 18:22:32 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 180, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-08-25 18:22:32 TP0] Prefill batch. #new-seq: 3, #new-token: 3, #cached-token: 540, token usage: 0.00, #running-req: 1, #queue-req: 0, 
[2025-08-25 18:22:32 TP0] Decode batch. #running-req: 4, #token: 305, token usage: 0.00, gen throughput (token/s): 577.35, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:22:33 TP0] Decode batch. #running-req: 4, #token: 465, token usage: 0.00, gen throughput (token/s): 861.47, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:22:33 TP0] Decode batch. #running-req: 4, #token: 625, token usage: 0.00, gen throughput (token/s): 863.84, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:22:33 TP0] Decode batch. #running-req: 4, #token: 785, token usage: 0.00, gen throughput (token/s): 862.35, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:22:33 TP0] Decode batch. #running-req: 4, #token: 945, token usage: 0.00, gen throughput (token/s): 856.45, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:22:33 TP0] Decode batch. #running-req: 4, #token: 1105, token usage: 0.00, gen throughput (token/s): 851.49, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:22:34 TP0] Decode batch. #running-req: 4, #token: 1265, token usage: 0.00, gen throughput (token/s): 850.82, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:22:34 TP0] Decode batch. #running-req: 4, #token: 1425, token usage: 0.00, gen throughput (token/s): 873.65, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:22:34 TP0] Decode batch. #running-req: 4, #token: 1585, token usage: 0.00, gen throughput (token/s): 854.32, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:22:34 TP0] Decode batch. #running-req: 4, #token: 1745, token usage: 0.00, gen throughput (token/s): 864.93, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:22:34 TP0] Decode batch. #running-req: 4, #token: 1905, token usage: 0.00, gen throughput (token/s): 865.82, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:22:34 TP0] Decode batch. #running-req: 4, #token: 2065, token usage: 0.00, gen throughput (token/s): 852.99, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:22:35] INFO:     127.0.0.1:25040 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 18:22:35] INFO:     127.0.0.1:25010 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 18:22:35] INFO:     127.0.0.1:25012 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 18:22:35] INFO:     127.0.0.1:25024 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 18:22:35 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 180, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-08-25 18:22:35 TP0] Prefill batch. #new-seq: 3, #new-token: 3, #cached-token: 540, token usage: 0.00, #running-req: 1, #queue-req: 0, 
[2025-08-25 18:22:35 TP0] Decode batch. #running-req: 4, #token: 225, token usage: 0.00, gen throughput (token/s): 563.73, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:22:35 TP0] Decode batch. #running-req: 4, #token: 385, token usage: 0.00, gen throughput (token/s): 849.13, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:22:35 TP0] Decode batch. #running-req: 4, #token: 545, token usage: 0.00, gen throughput (token/s): 860.90, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:22:35 TP0] Decode batch. #running-req: 4, #token: 705, token usage: 0.00, gen throughput (token/s): 868.13, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:22:35 TP0] Decode batch. #running-req: 4, #token: 865, token usage: 0.00, gen throughput (token/s): 859.74, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:22:36 TP0] Decode batch. #running-req: 4, #token: 1025, token usage: 0.00, gen throughput (token/s): 848.08, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:22:36 TP0] Decode batch. #running-req: 4, #token: 1185, token usage: 0.00, gen throughput (token/s): 864.02, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:22:36 TP0] Decode batch. #running-req: 4, #token: 1345, token usage: 0.00, gen throughput (token/s): 866.18, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:22:36 TP0] Decode batch. #running-req: 4, #token: 1505, token usage: 0.00, gen throughput (token/s): 847.26, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:22:36 TP0] Decode batch. #running-req: 4, #token: 1665, token usage: 0.00, gen throughput (token/s): 870.40, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:22:37 TP0] Decode batch. #running-req: 4, #token: 1825, token usage: 0.00, gen throughput (token/s): 840.10, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:22:37 TP0] Decode batch. #running-req: 4, #token: 1985, token usage: 0.00, gen throughput (token/s): 847.39, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:22:37 TP0] Decode batch. #running-req: 4, #token: 2145, token usage: 0.00, gen throughput (token/s): 862.52, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:22:37] INFO:     127.0.0.1:25040 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 18:22:37] INFO:     127.0.0.1:25010 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 18:22:37] INFO:     127.0.0.1:25012 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 18:22:37] INFO:     127.0.0.1:25024 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 18:22:37 TP0] Prefill batch. #new-seq: 4, #new-token: 2504, #cached-token: 176, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-08-25 18:22:38] INFO:     127.0.0.1:6476 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 18:22:38] INFO:     127.0.0.1:6478 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 18:22:38] INFO:     127.0.0.1:6480 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 18:22:38] INFO:     127.0.0.1:6488 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 18:22:39 TP0] Prefill batch. #new-seq: 1, #new-token: 500, #cached-token: 170, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-08-25 18:22:39 TP0] Prefill batch. #new-seq: 3, #new-token: 1500, #cached-token: 510, token usage: 0.00, #running-req: 1, #queue-req: 0, 
[2025-08-25 18:22:39] INFO:     127.0.0.1:6488 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 18:22:39 TP0] Prefill batch. #new-seq: 1, #new-token: 500, #cached-token: 170, token usage: 0.00, #running-req: 3, #queue-req: 0, 
[2025-08-25 18:22:39] INFO:     127.0.0.1:6476 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 18:22:39] INFO:     127.0.0.1:6478 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 18:22:39] INFO:     127.0.0.1:6480 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 18:22:39 TP0] Prefill batch. #new-seq: 3, #new-token: 1500, #cached-token: 510, token usage: 0.00, #running-req: 4, #queue-req: 0, 
[2025-08-25 18:22:40] INFO:     127.0.0.1:6488 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 18:22:40] INFO:     127.0.0.1:6476 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 18:22:40] INFO:     127.0.0.1:6478 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 18:22:40] INFO:     127.0.0.1:6480 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 18:22:40 TP0] Prefill batch. #new-seq: 1, #new-token: 500, #cached-token: 170, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-08-25 18:22:40] INFO:     127.0.0.1:6488 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 18:22:40 TP0] Prefill batch. #new-seq: 3, #new-token: 1500, #cached-token: 510, token usage: 0.00, #running-req: 1, #queue-req: 0, 
[2025-08-25 18:22:40 TP0] Prefill batch. #new-seq: 1, #new-token: 633, #cached-token: 46, token usage: 0.01, #running-req: 4, #queue-req: 0, 
[2025-08-25 18:22:41] INFO:     127.0.0.1:6478 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 18:22:41] INFO:     127.0.0.1:6476 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 18:22:41] INFO:     127.0.0.1:6480 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 18:22:41 TP0] Prefill batch. #new-seq: 3, #new-token: 1490, #cached-token: 547, token usage: 0.00, #running-req: 1, #queue-req: 0, 
[2025-08-25 18:22:42 TP0] Decode batch. #running-req: 4, #token: 2262, token usage: 0.01, gen throughput (token/s): 8.46, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:22:43 TP0] Decode batch. #running-req: 4, #token: 2422, token usage: 0.01, gen throughput (token/s): 153.76, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:22:44 TP0] Decode batch. #running-req: 4, #token: 2582, token usage: 0.01, gen throughput (token/s): 152.21, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:22:45 TP0] Decode batch. #running-req: 4, #token: 2742, token usage: 0.01, gen throughput (token/s): 153.45, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:22:45] INFO:     127.0.0.1:6488 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 18:22:45] INFO:     127.0.0.1:6476 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 18:22:45] INFO:     127.0.0.1:6478 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 18:22:45] INFO:     127.0.0.1:6480 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 18:22:45 TP0] Prefill batch. #new-seq: 1, #new-token: 487, #cached-token: 192, token usage: 0.00, #running-req: 3, #queue-req: 0, 
[2025-08-25 18:22:45 TP0] Prefill batch. #new-seq: 1, #new-token: 479, #cached-token: 200, token usage: 0.00, #running-req: 4, #queue-req: 0, 
[2025-08-25 18:22:46 TP0] Decode batch. #running-req: 2, #token: 1239, token usage: 0.00, gen throughput (token/s): 71.76, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:22:47 TP0] Decode batch. #running-req: 2, #token: 1319, token usage: 0.00, gen throughput (token/s): 78.09, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:22:48 TP0] Decode batch. #running-req: 2, #token: 1399, token usage: 0.00, gen throughput (token/s): 78.08, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:22:49] INFO:     127.0.0.1:6488 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 18:22:49] INFO:     127.0.0.1:6478 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 18:22:49 TP0] Prefill batch. #new-seq: 4, #new-token: 312, #cached-token: 208, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-08-25 18:22:49 TP0] Decode batch. #running-req: 4, #token: 254, token usage: 0.00, gen throughput (token/s): 12.77, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:22:50 TP0] Decode batch. #running-req: 4, #token: 414, token usage: 0.00, gen throughput (token/s): 871.65, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:22:50 TP0] Decode batch. #running-req: 4, #token: 574, token usage: 0.00, gen throughput (token/s): 857.10, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:22:50 TP0] Decode batch. #running-req: 4, #token: 734, token usage: 0.00, gen throughput (token/s): 878.54, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:22:50 TP0] Decode batch. #running-req: 4, #token: 894, token usage: 0.00, gen throughput (token/s): 859.38, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:22:50 TP0] Decode batch. #running-req: 4, #token: 1054, token usage: 0.00, gen throughput (token/s): 844.75, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:22:51 TP0] Decode batch. #running-req: 4, #token: 1214, token usage: 0.00, gen throughput (token/s): 848.79, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:22:51 TP0] Decode batch. #running-req: 4, #token: 1374, token usage: 0.00, gen throughput (token/s): 838.36, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:22:51 TP0] Decode batch. #running-req: 4, #token: 1534, token usage: 0.00, gen throughput (token/s): 857.29, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:22:51 TP0] Decode batch. #running-req: 4, #token: 1694, token usage: 0.00, gen throughput (token/s): 886.16, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:22:51 TP0] Decode batch. #running-req: 4, #token: 1854, token usage: 0.00, gen throughput (token/s): 870.03, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:22:52 TP0] Decode batch. #running-req: 4, #token: 2014, token usage: 0.00, gen throughput (token/s): 865.50, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:22:52] INFO:     127.0.0.1:63070 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 18:22:52] INFO:     127.0.0.1:63076 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 18:22:52] INFO:     127.0.0.1:63092 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 18:22:52] INFO:     127.0.0.1:63106 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 18:22:52 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 129, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-08-25 18:22:52 TP0] Prefill batch. #new-seq: 3, #new-token: 3, #cached-token: 387, token usage: 0.00, #running-req: 1, #queue-req: 0, 
[2025-08-25 18:22:52 TP0] Decode batch. #running-req: 4, #token: 174, token usage: 0.00, gen throughput (token/s): 561.80, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:22:52 TP0] Decode batch. #running-req: 4, #token: 334, token usage: 0.00, gen throughput (token/s): 850.86, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:22:52 TP0] Decode batch. #running-req: 4, #token: 494, token usage: 0.00, gen throughput (token/s): 877.94, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:22:52 TP0] Decode batch. #running-req: 4, #token: 654, token usage: 0.00, gen throughput (token/s): 848.92, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:22:53 TP0] Decode batch. #running-req: 4, #token: 814, token usage: 0.00, gen throughput (token/s): 863.66, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:22:53 TP0] Decode batch. #running-req: 4, #token: 974, token usage: 0.00, gen throughput (token/s): 857.11, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:22:53 TP0] Decode batch. #running-req: 4, #token: 1134, token usage: 0.00, gen throughput (token/s): 873.03, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:22:53 TP0] Decode batch. #running-req: 4, #token: 1294, token usage: 0.00, gen throughput (token/s): 881.90, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:22:53 TP0] Decode batch. #running-req: 4, #token: 1454, token usage: 0.00, gen throughput (token/s): 874.31, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:22:53 TP0] Decode batch. #running-req: 4, #token: 1614, token usage: 0.00, gen throughput (token/s): 878.90, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:22:54 TP0] Decode batch. #running-req: 4, #token: 1774, token usage: 0.00, gen throughput (token/s): 876.47, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:22:54 TP0] Decode batch. #running-req: 4, #token: 1934, token usage: 0.00, gen throughput (token/s): 874.78, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:22:54 TP0] Decode batch. #running-req: 4, #token: 2094, token usage: 0.00, gen throughput (token/s): 894.06, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:22:54] INFO:     127.0.0.1:63106 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 18:22:54] INFO:     127.0.0.1:63070 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 18:22:54] INFO:     127.0.0.1:63076 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 18:22:54] INFO:     127.0.0.1:63092 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 18:22:54 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 129, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-08-25 18:22:54 TP0] Prefill batch. #new-seq: 3, #new-token: 3, #cached-token: 387, token usage: 0.00, #running-req: 1, #queue-req: 0, 
[2025-08-25 18:22:54 TP0] Decode batch. #running-req: 4, #token: 254, token usage: 0.00, gen throughput (token/s): 585.19, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:22:54 TP0] Decode batch. #running-req: 4, #token: 414, token usage: 0.00, gen throughput (token/s): 875.69, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:22:55 TP0] Decode batch. #running-req: 4, #token: 574, token usage: 0.00, gen throughput (token/s): 854.75, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:22:55 TP0] Decode batch. #running-req: 4, #token: 734, token usage: 0.00, gen throughput (token/s): 863.34, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:22:55 TP0] Decode batch. #running-req: 4, #token: 894, token usage: 0.00, gen throughput (token/s): 858.66, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:22:55 TP0] Decode batch. #running-req: 4, #token: 1054, token usage: 0.00, gen throughput (token/s): 864.52, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:22:55 TP0] Decode batch. #running-req: 4, #token: 1214, token usage: 0.00, gen throughput (token/s): 856.56, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:22:56 TP0] Decode batch. #running-req: 4, #token: 1374, token usage: 0.00, gen throughput (token/s): 871.59, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:22:56 TP0] Decode batch. #running-req: 4, #token: 1534, token usage: 0.00, gen throughput (token/s): 852.46, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:22:56 TP0] Decode batch. #running-req: 4, #token: 1694, token usage: 0.00, gen throughput (token/s): 863.50, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:22:56 TP0] Decode batch. #running-req: 4, #token: 1854, token usage: 0.00, gen throughput (token/s): 862.80, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:22:56 TP0] Decode batch. #running-req: 4, #token: 2014, token usage: 0.00, gen throughput (token/s): 853.72, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:22:56] INFO:     127.0.0.1:63106 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 18:22:56] INFO:     127.0.0.1:63070 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 18:22:56] INFO:     127.0.0.1:63076 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 18:22:56] INFO:     127.0.0.1:63092 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 18:22:56 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 129, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-08-25 18:22:57 TP0] Prefill batch. #new-seq: 3, #new-token: 3, #cached-token: 387, token usage: 0.00, #running-req: 1, #queue-req: 0, 
[2025-08-25 18:22:57 TP0] Decode batch. #running-req: 4, #token: 174, token usage: 0.00, gen throughput (token/s): 569.92, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:22:57 TP0] Decode batch. #running-req: 4, #token: 334, token usage: 0.00, gen throughput (token/s): 849.06, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:22:57 TP0] Decode batch. #running-req: 4, #token: 494, token usage: 0.00, gen throughput (token/s): 867.66, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:22:57 TP0] Decode batch. #running-req: 4, #token: 654, token usage: 0.00, gen throughput (token/s): 865.40, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:22:57 TP0] Decode batch. #running-req: 4, #token: 814, token usage: 0.00, gen throughput (token/s): 836.26, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:22:58 TP0] Decode batch. #running-req: 4, #token: 974, token usage: 0.00, gen throughput (token/s): 860.02, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:22:58 TP0] Decode batch. #running-req: 4, #token: 1134, token usage: 0.00, gen throughput (token/s): 866.00, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:22:58 TP0] Decode batch. #running-req: 4, #token: 1294, token usage: 0.00, gen throughput (token/s): 856.55, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:22:58 TP0] Decode batch. #running-req: 4, #token: 1454, token usage: 0.00, gen throughput (token/s): 854.78, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:22:58 TP0] Decode batch. #running-req: 4, #token: 1614, token usage: 0.00, gen throughput (token/s): 849.95, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:22:58 TP0] Decode batch. #running-req: 4, #token: 1774, token usage: 0.00, gen throughput (token/s): 853.21, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:22:59 TP0] Decode batch. #running-req: 4, #token: 1934, token usage: 0.00, gen throughput (token/s): 847.01, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:22:59 TP0] Decode batch. #running-req: 4, #token: 2094, token usage: 0.00, gen throughput (token/s): 879.86, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:22:59] INFO:     127.0.0.1:63106 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 18:22:59] INFO:     127.0.0.1:63070 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 18:22:59] INFO:     127.0.0.1:63076 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 18:22:59] INFO:     127.0.0.1:63092 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 18:22:59 TP0] Prefill batch. #new-seq: 4, #new-token: 2300, #cached-token: 176, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-08-25 18:23:00] INFO:     127.0.0.1:41850 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 18:23:00] INFO:     127.0.0.1:41856 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 18:23:00] INFO:     127.0.0.1:41858 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 18:23:00] INFO:     127.0.0.1:41868 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 18:23:00 TP0] Prefill batch. #new-seq: 4, #new-token: 2000, #cached-token: 476, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-08-25 18:23:00] INFO:     127.0.0.1:41868 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 18:23:00] INFO:     127.0.0.1:41850 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 18:23:00 TP0] Decode batch. #running-req: 0, #token: 0, token usage: 0.00, gen throughput (token/s): 6.97, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:23:00] INFO:     127.0.0.1:41856 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 18:23:00] INFO:     127.0.0.1:41858 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 18:23:01 TP0] Prefill batch. #new-seq: 1, #new-token: 500, #cached-token: 119, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-08-25 18:23:01 TP0] Prefill batch. #new-seq: 3, #new-token: 1500, #cached-token: 357, token usage: 0.00, #running-req: 1, #queue-req: 0, 
[2025-08-25 18:23:01] INFO:     127.0.0.1:41868 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 18:23:01] INFO:     127.0.0.1:41850 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 18:23:01] INFO:     127.0.0.1:41856 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 18:23:01] INFO:     127.0.0.1:41858 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 18:23:01 TP0] Prefill batch. #new-seq: 1, #new-token: 500, #cached-token: 119, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-08-25 18:23:01 TP0] Prefill batch. #new-seq: 3, #new-token: 1500, #cached-token: 357, token usage: 0.00, #running-req: 1, #queue-req: 0, 
[2025-08-25 18:23:02] INFO:     127.0.0.1:41868 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 18:23:02] INFO:     127.0.0.1:41850 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 18:23:02] INFO:     127.0.0.1:41856 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 18:23:02] INFO:     127.0.0.1:41858 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 18:23:02 TP0] Prefill batch. #new-seq: 1, #new-token: 582, #cached-token: 46, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-08-25 18:23:02 TP0] Prefill batch. #new-seq: 3, #new-token: 1478, #cached-token: 406, token usage: 0.00, #running-req: 1, #queue-req: 0, 
[2025-08-25 18:23:04 TP0] Decode batch. #running-req: 4, #token: 2242, token usage: 0.01, gen throughput (token/s): 49.19, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:23:05 TP0] Decode batch. #running-req: 4, #token: 2402, token usage: 0.01, gen throughput (token/s): 151.87, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:23:06 TP0] Decode batch. #running-req: 4, #token: 2562, token usage: 0.01, gen throughput (token/s): 151.02, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:23:06] INFO:     127.0.0.1:41868 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 18:23:06] INFO:     127.0.0.1:41850 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 18:23:06] INFO:     127.0.0.1:41856 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 18:23:06] INFO:     127.0.0.1:41858 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 18:23:06 TP0] Prefill batch. #new-seq: 1, #new-token: 452, #cached-token: 176, token usage: 0.00, #running-req: 3, #queue-req: 0, 
[2025-08-25 18:23:07 TP0] Prefill batch. #new-seq: 1, #new-token: 457, #cached-token: 171, token usage: 0.00, #running-req: 4, #queue-req: 0, 
[2025-08-25 18:23:07 TP0] Decode batch. #running-req: 2, #token: 1137, token usage: 0.00, gen throughput (token/s): 107.27, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:23:08 TP0] Decode batch. #running-req: 2, #token: 1217, token usage: 0.00, gen throughput (token/s): 77.30, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:23:09 TP0] Decode batch. #running-req: 2, #token: 1297, token usage: 0.00, gen throughput (token/s): 77.54, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:23:10 TP0] Decode batch. #running-req: 2, #token: 1377, token usage: 0.00, gen throughput (token/s): 77.42, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:23:11] INFO:     127.0.0.1:41868 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 18:23:11] INFO:     127.0.0.1:41850 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 18:24:40 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 82, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-08-25 18:24:40 TP0] Prefill batch. #new-seq: 3, #new-token: 3, #cached-token: 246, token usage: 0.00, #running-req: 1, #queue-req: 0, 
[2025-08-25 18:24:40 TP0] Decode batch. #running-req: 4, #token: 207, token usage: 0.00, gen throughput (token/s): 1.58, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:24:40 TP0] Decode batch. #running-req: 4, #token: 367, token usage: 0.00, gen throughput (token/s): 878.14, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:24:41 TP0] Decode batch. #running-req: 4, #token: 527, token usage: 0.00, gen throughput (token/s): 860.87, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:24:41 TP0] Decode batch. #running-req: 4, #token: 687, token usage: 0.00, gen throughput (token/s): 863.09, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:24:41 TP0] Decode batch. #running-req: 4, #token: 847, token usage: 0.00, gen throughput (token/s): 863.21, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:24:41 TP0] Decode batch. #running-req: 4, #token: 1007, token usage: 0.00, gen throughput (token/s): 840.12, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:24:41 TP0] Decode batch. #running-req: 4, #token: 1167, token usage: 0.00, gen throughput (token/s): 841.46, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:24:42 TP0] Decode batch. #running-req: 4, #token: 1327, token usage: 0.00, gen throughput (token/s): 849.23, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:24:42 TP0] Decode batch. #running-req: 4, #token: 1487, token usage: 0.00, gen throughput (token/s): 851.62, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:24:42 TP0] Decode batch. #running-req: 4, #token: 1647, token usage: 0.00, gen throughput (token/s): 859.13, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:24:42 TP0] Decode batch. #running-req: 4, #token: 1807, token usage: 0.00, gen throughput (token/s): 843.49, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:24:42 TP0] Decode batch. #running-req: 4, #token: 1967, token usage: 0.00, gen throughput (token/s): 851.75, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:24:42 TP0] Decode batch. #running-req: 4, #token: 2127, token usage: 0.00, gen throughput (token/s): 849.59, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:24:43 TP0] Decode batch. #running-req: 4, #token: 2287, token usage: 0.00, gen throughput (token/s): 873.66, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:24:43 TP0] Decode batch. #running-req: 4, #token: 2447, token usage: 0.00, gen throughput (token/s): 856.59, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:24:43 TP0] Decode batch. #running-req: 4, #token: 2607, token usage: 0.00, gen throughput (token/s): 854.20, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:24:43 TP0] Decode batch. #running-req: 4, #token: 2767, token usage: 0.00, gen throughput (token/s): 871.73, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:24:43] INFO:     127.0.0.1:65194 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 18:24:43] INFO:     127.0.0.1:65202 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 18:24:43] INFO:     127.0.0.1:65218 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 18:24:43] INFO:     127.0.0.1:65220 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 18:24:43 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 82, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-08-25 18:24:43 TP0] Prefill batch. #new-seq: 3, #new-token: 3, #cached-token: 246, token usage: 0.00, #running-req: 1, #queue-req: 0, 
[2025-08-25 18:24:44 TP0] Decode batch. #running-req: 4, #token: 127, token usage: 0.00, gen throughput (token/s): 545.73, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:24:44 TP0] Decode batch. #running-req: 4, #token: 287, token usage: 0.00, gen throughput (token/s): 871.65, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:24:44 TP0] Decode batch. #running-req: 4, #token: 447, token usage: 0.00, gen throughput (token/s): 853.85, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:24:44 TP0] Decode batch. #running-req: 4, #token: 607, token usage: 0.00, gen throughput (token/s): 848.08, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:24:44 TP0] Decode batch. #running-req: 4, #token: 767, token usage: 0.00, gen throughput (token/s): 837.80, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:24:44 TP0] Decode batch. #running-req: 4, #token: 927, token usage: 0.00, gen throughput (token/s): 850.84, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:24:45 TP0] Decode batch. #running-req: 4, #token: 1087, token usage: 0.00, gen throughput (token/s): 849.64, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:24:45 TP0] Decode batch. #running-req: 4, #token: 1247, token usage: 0.00, gen throughput (token/s): 862.11, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:24:45 TP0] Decode batch. #running-req: 4, #token: 1407, token usage: 0.00, gen throughput (token/s): 898.40, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:24:45 TP0] Decode batch. #running-req: 4, #token: 1567, token usage: 0.00, gen throughput (token/s): 901.04, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:24:45 TP0] Decode batch. #running-req: 4, #token: 1727, token usage: 0.00, gen throughput (token/s): 842.04, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:24:46 TP0] Decode batch. #running-req: 4, #token: 1887, token usage: 0.00, gen throughput (token/s): 825.57, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:24:46 TP0] Decode batch. #running-req: 4, #token: 2047, token usage: 0.00, gen throughput (token/s): 859.24, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:24:46 TP0] Decode batch. #running-req: 4, #token: 2207, token usage: 0.00, gen throughput (token/s): 834.21, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:24:46 TP0] Decode batch. #running-req: 4, #token: 2367, token usage: 0.00, gen throughput (token/s): 917.97, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:24:46 TP0] Decode batch. #running-req: 4, #token: 2527, token usage: 0.00, gen throughput (token/s): 935.90, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:24:46 TP0] Decode batch. #running-req: 4, #token: 2687, token usage: 0.00, gen throughput (token/s): 874.04, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:24:47 TP0] Decode batch. #running-req: 4, #token: 2847, token usage: 0.00, gen throughput (token/s): 886.61, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:24:47] INFO:     127.0.0.1:65194 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 18:24:47] INFO:     127.0.0.1:65202 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 18:24:47] INFO:     127.0.0.1:65218 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 18:24:47] INFO:     127.0.0.1:65220 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 18:24:47 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 82, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-08-25 18:24:47 TP0] Prefill batch. #new-seq: 3, #new-token: 3, #cached-token: 246, token usage: 0.00, #running-req: 1, #queue-req: 0, 
[2025-08-25 18:24:47 TP0] Decode batch. #running-req: 4, #token: 207, token usage: 0.00, gen throughput (token/s): 587.45, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:24:47 TP0] Decode batch. #running-req: 4, #token: 367, token usage: 0.00, gen throughput (token/s): 864.32, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:24:47 TP0] Decode batch. #running-req: 4, #token: 527, token usage: 0.00, gen throughput (token/s): 869.69, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:24:47 TP0] Decode batch. #running-req: 4, #token: 687, token usage: 0.00, gen throughput (token/s): 855.89, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:24:48 TP0] Decode batch. #running-req: 4, #token: 847, token usage: 0.00, gen throughput (token/s): 872.90, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:24:48 TP0] Decode batch. #running-req: 4, #token: 1007, token usage: 0.00, gen throughput (token/s): 873.06, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:24:48 TP0] Decode batch. #running-req: 4, #token: 1167, token usage: 0.00, gen throughput (token/s): 864.12, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:24:48 TP0] Decode batch. #running-req: 4, #token: 1327, token usage: 0.00, gen throughput (token/s): 861.68, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:24:48 TP0] Decode batch. #running-req: 4, #token: 1487, token usage: 0.00, gen throughput (token/s): 844.59, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:24:49 TP0] Decode batch. #running-req: 4, #token: 1647, token usage: 0.00, gen throughput (token/s): 869.40, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:24:49 TP0] Decode batch. #running-req: 4, #token: 1807, token usage: 0.00, gen throughput (token/s): 855.13, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:24:49 TP0] Decode batch. #running-req: 4, #token: 1967, token usage: 0.00, gen throughput (token/s): 849.97, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:24:49 TP0] Decode batch. #running-req: 4, #token: 2127, token usage: 0.00, gen throughput (token/s): 840.85, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:24:49 TP0] Decode batch. #running-req: 4, #token: 2287, token usage: 0.00, gen throughput (token/s): 845.34, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:24:50 TP0] Decode batch. #running-req: 4, #token: 2447, token usage: 0.00, gen throughput (token/s): 855.05, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:24:50 TP0] Decode batch. #running-req: 4, #token: 2607, token usage: 0.00, gen throughput (token/s): 859.36, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:24:50 TP0] Decode batch. #running-req: 4, #token: 2767, token usage: 0.00, gen throughput (token/s): 840.90, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:24:50] INFO:     127.0.0.1:65194 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 18:24:50] INFO:     127.0.0.1:65202 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 18:24:50] INFO:     127.0.0.1:65218 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 18:24:50] INFO:     127.0.0.1:65220 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 18:24:50 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 82, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-08-25 18:24:50 TP0] Prefill batch. #new-seq: 3, #new-token: 3, #cached-token: 246, token usage: 0.00, #running-req: 1, #queue-req: 0, 
[2025-08-25 18:24:50 TP0] Decode batch. #running-req: 4, #token: 127, token usage: 0.00, gen throughput (token/s): 593.42, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:24:50 TP0] Decode batch. #running-req: 4, #token: 287, token usage: 0.00, gen throughput (token/s): 882.09, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:24:51 TP0] Decode batch. #running-req: 4, #token: 447, token usage: 0.00, gen throughput (token/s): 880.97, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:24:51 TP0] Decode batch. #running-req: 4, #token: 607, token usage: 0.00, gen throughput (token/s): 867.90, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:24:51 TP0] Decode batch. #running-req: 4, #token: 767, token usage: 0.00, gen throughput (token/s): 847.72, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:24:51 TP0] Decode batch. #running-req: 4, #token: 927, token usage: 0.00, gen throughput (token/s): 862.45, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:24:51 TP0] Decode batch. #running-req: 4, #token: 1087, token usage: 0.00, gen throughput (token/s): 848.72, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:24:51 TP0] Decode batch. #running-req: 4, #token: 1247, token usage: 0.00, gen throughput (token/s): 852.40, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:24:52 TP0] Decode batch. #running-req: 4, #token: 1407, token usage: 0.00, gen throughput (token/s): 840.07, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:24:52 TP0] Decode batch. #running-req: 4, #token: 1567, token usage: 0.00, gen throughput (token/s): 864.60, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:24:52 TP0] Decode batch. #running-req: 4, #token: 1727, token usage: 0.00, gen throughput (token/s): 850.30, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:24:52 TP0] Decode batch. #running-req: 4, #token: 1887, token usage: 0.00, gen throughput (token/s): 856.66, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:24:52 TP0] Decode batch. #running-req: 4, #token: 2047, token usage: 0.00, gen throughput (token/s): 866.38, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:24:53 TP0] Decode batch. #running-req: 4, #token: 2207, token usage: 0.00, gen throughput (token/s): 859.43, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:24:53 TP0] Decode batch. #running-req: 4, #token: 2367, token usage: 0.00, gen throughput (token/s): 851.07, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:24:53 TP0] Decode batch. #running-req: 4, #token: 2527, token usage: 0.00, gen throughput (token/s): 854.65, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:24:53 TP0] Decode batch. #running-req: 4, #token: 2687, token usage: 0.00, gen throughput (token/s): 866.64, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:24:53 TP0] Decode batch. #running-req: 4, #token: 2847, token usage: 0.00, gen throughput (token/s): 850.56, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:24:53] INFO:     127.0.0.1:65194 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 18:24:53] INFO:     127.0.0.1:65202 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 18:24:53] INFO:     127.0.0.1:65218 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 18:24:53] INFO:     127.0.0.1:65220 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 18:24:53 TP0] Prefill batch. #new-seq: 4, #new-token: 2800, #cached-token: 288, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-08-25 18:24:54] INFO:     127.0.0.1:35896 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 18:24:54] INFO:     127.0.0.1:35912 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 18:24:55] INFO:     127.0.0.1:35922 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 18:24:55] INFO:     127.0.0.1:35924 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 18:24:55 TP0] Prefill batch. #new-seq: 2, #new-token: 1400, #cached-token: 144, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-08-25 18:24:55 TP0] Prefill batch. #new-seq: 2, #new-token: 1400, #cached-token: 144, token usage: 0.00, #running-req: 2, #queue-req: 0, 
[2025-08-25 18:24:55] INFO:     127.0.0.1:35912 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 18:24:55] INFO:     127.0.0.1:35896 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 18:24:56] INFO:     127.0.0.1:35922 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 18:24:56] INFO:     127.0.0.1:35924 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 18:24:56 TP0] Prefill batch. #new-seq: 1, #new-token: 700, #cached-token: 72, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-08-25 18:24:56] INFO:     127.0.0.1:35912 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 18:24:56 TP0] Prefill batch. #new-seq: 3, #new-token: 2100, #cached-token: 216, token usage: 0.00, #running-req: 1, #queue-req: 0, 
[2025-08-25 18:24:56 TP0] Prefill batch. #new-seq: 1, #new-token: 700, #cached-token: 72, token usage: 0.01, #running-req: 4, #queue-req: 0, 
[2025-08-25 18:24:56] INFO:     127.0.0.1:35896 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 18:24:56] INFO:     127.0.0.1:35922 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 18:24:56] INFO:     127.0.0.1:35924 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 18:24:57] INFO:     127.0.0.1:35912 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 18:24:57 TP0] Prefill batch. #new-seq: 3, #new-token: 2100, #cached-token: 216, token usage: 0.00, #running-req: 1, #queue-req: 0, 
[2025-08-25 18:24:57 TP0] Prefill batch. #new-seq: 1, #new-token: 640, #cached-token: 141, token usage: 0.01, #running-req: 4, #queue-req: 0, 
[2025-08-25 18:24:57] INFO:     127.0.0.1:35896 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 18:24:57] INFO:     127.0.0.1:35922 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 18:24:57] INFO:     127.0.0.1:35924 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 18:24:58 TP0] Prefill batch. #new-seq: 3, #new-token: 2071, #cached-token: 272, token usage: 0.00, #running-req: 1, #queue-req: 0, 
[2025-08-25 18:24:58 TP0] Decode batch. #running-req: 4, #token: 2907, token usage: 0.01, gen throughput (token/s): 0.87, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:24:59 TP0] Decode batch. #running-req: 4, #token: 3067, token usage: 0.01, gen throughput (token/s): 153.63, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:25:00 TP0] Decode batch. #running-req: 4, #token: 3227, token usage: 0.01, gen throughput (token/s): 152.65, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:25:01 TP0] Decode batch. #running-req: 4, #token: 3387, token usage: 0.01, gen throughput (token/s): 151.90, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:25:02] INFO:     127.0.0.1:35912 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 18:25:02] INFO:     127.0.0.1:35896 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 18:25:02] INFO:     127.0.0.1:35922 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 18:25:02] INFO:     127.0.0.1:35924 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 18:25:02 TP0] Prefill batch. #new-seq: 3, #new-token: 3, #cached-token: 633, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-08-25 18:25:02 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 211, token usage: 0.00, #running-req: 3, #queue-req: 0, 
[2025-08-25 18:25:02 TP0] Decode batch. #running-req: 4, #token: 336, token usage: 0.00, gen throughput (token/s): 17.94, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:25:02 TP0] Decode batch. #running-req: 4, #token: 496, token usage: 0.00, gen throughput (token/s): 861.62, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:25:03 TP0] Decode batch. #running-req: 4, #token: 656, token usage: 0.00, gen throughput (token/s): 847.35, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:25:03 TP0] Decode batch. #running-req: 4, #token: 816, token usage: 0.00, gen throughput (token/s): 895.30, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:25:03 TP0] Decode batch. #running-req: 4, #token: 976, token usage: 0.00, gen throughput (token/s): 891.13, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:25:03 TP0] Decode batch. #running-req: 4, #token: 1136, token usage: 0.00, gen throughput (token/s): 897.13, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:25:03 TP0] Decode batch. #running-req: 4, #token: 1296, token usage: 0.00, gen throughput (token/s): 898.29, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:25:04 TP0] Decode batch. #running-req: 4, #token: 1456, token usage: 0.00, gen throughput (token/s): 883.34, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:25:04 TP0] Decode batch. #running-req: 4, #token: 1616, token usage: 0.00, gen throughput (token/s): 886.76, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:25:04 TP0] Decode batch. #running-req: 4, #token: 1776, token usage: 0.00, gen throughput (token/s): 887.09, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:25:04 TP0] Decode batch. #running-req: 4, #token: 1936, token usage: 0.00, gen throughput (token/s): 895.56, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:25:04 TP0] Decode batch. #running-req: 4, #token: 2096, token usage: 0.00, gen throughput (token/s): 880.65, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:25:04 TP0] Decode batch. #running-req: 4, #token: 2256, token usage: 0.00, gen throughput (token/s): 880.98, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:25:05 TP0] Decode batch. #running-req: 4, #token: 2416, token usage: 0.00, gen throughput (token/s): 872.49, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:25:05 TP0] Decode batch. #running-req: 4, #token: 2576, token usage: 0.00, gen throughput (token/s): 877.19, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:25:05 TP0] Decode batch. #running-req: 4, #token: 2736, token usage: 0.00, gen throughput (token/s): 877.72, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:25:05 TP0] Decode batch. #running-req: 4, #token: 2896, token usage: 0.00, gen throughput (token/s): 876.33, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:25:05] INFO:     127.0.0.1:14716 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 18:25:05] INFO:     127.0.0.1:14720 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 18:25:05] INFO:     127.0.0.1:14722 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 18:25:05] INFO:     127.0.0.1:14726 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 18:25:05 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 211, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-08-25 18:25:05 TP0] Prefill batch. #new-seq: 3, #new-token: 3, #cached-token: 633, token usage: 0.00, #running-req: 1, #queue-req: 0, 
[2025-08-25 18:25:05 TP0] Decode batch. #running-req: 4, #token: 256, token usage: 0.00, gen throughput (token/s): 565.33, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:25:06 TP0] Decode batch. #running-req: 4, #token: 416, token usage: 0.00, gen throughput (token/s): 860.61, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:25:06 TP0] Decode batch. #running-req: 4, #token: 576, token usage: 0.00, gen throughput (token/s): 869.68, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:25:06 TP0] Decode batch. #running-req: 4, #token: 736, token usage: 0.00, gen throughput (token/s): 852.80, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:25:06 TP0] Decode batch. #running-req: 4, #token: 896, token usage: 0.00, gen throughput (token/s): 860.21, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:25:06 TP0] Decode batch. #running-req: 4, #token: 1056, token usage: 0.00, gen throughput (token/s): 863.98, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:25:07 TP0] Decode batch. #running-req: 4, #token: 1216, token usage: 0.00, gen throughput (token/s): 839.93, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:25:07 TP0] Decode batch. #running-req: 4, #token: 1376, token usage: 0.00, gen throughput (token/s): 871.31, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:25:07 TP0] Decode batch. #running-req: 4, #token: 1536, token usage: 0.00, gen throughput (token/s): 848.83, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:25:07 TP0] Decode batch. #running-req: 4, #token: 1696, token usage: 0.00, gen throughput (token/s): 856.51, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:25:07 TP0] Decode batch. #running-req: 4, #token: 1856, token usage: 0.00, gen throughput (token/s): 848.59, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:25:08 TP0] Decode batch. #running-req: 4, #token: 2016, token usage: 0.00, gen throughput (token/s): 834.63, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:25:08 TP0] Decode batch. #running-req: 4, #token: 2176, token usage: 0.00, gen throughput (token/s): 865.23, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:25:08 TP0] Decode batch. #running-req: 4, #token: 2336, token usage: 0.00, gen throughput (token/s): 849.38, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:25:08 TP0] Decode batch. #running-req: 4, #token: 2496, token usage: 0.00, gen throughput (token/s): 839.05, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:25:08 TP0] Decode batch. #running-req: 4, #token: 2656, token usage: 0.00, gen throughput (token/s): 869.15, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:25:08 TP0] Decode batch. #running-req: 4, #token: 2816, token usage: 0.00, gen throughput (token/s): 860.25, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:25:09 TP0] Decode batch. #running-req: 4, #token: 2976, token usage: 0.00, gen throughput (token/s): 874.19, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:25:09] INFO:     127.0.0.1:14726 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 18:25:09] INFO:     127.0.0.1:14716 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 18:25:09] INFO:     127.0.0.1:14720 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 18:25:09] INFO:     127.0.0.1:14722 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 18:25:09 TP0] Prefill batch. #new-seq: 4, #new-token: 4, #cached-token: 844, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-08-25 18:25:09 TP0] Decode batch. #running-req: 4, #token: 336, token usage: 0.00, gen throughput (token/s): 637.29, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:25:09 TP0] Decode batch. #running-req: 4, #token: 496, token usage: 0.00, gen throughput (token/s): 860.81, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:25:09 TP0] Decode batch. #running-req: 4, #token: 656, token usage: 0.00, gen throughput (token/s): 875.07, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:25:09 TP0] Decode batch. #running-req: 4, #token: 816, token usage: 0.00, gen throughput (token/s): 867.79, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:25:10 TP0] Decode batch. #running-req: 4, #token: 976, token usage: 0.00, gen throughput (token/s): 859.92, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:25:10 TP0] Decode batch. #running-req: 4, #token: 1136, token usage: 0.00, gen throughput (token/s): 848.29, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:25:10 TP0] Decode batch. #running-req: 4, #token: 1296, token usage: 0.00, gen throughput (token/s): 862.89, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:25:10 TP0] Decode batch. #running-req: 4, #token: 1456, token usage: 0.00, gen throughput (token/s): 845.95, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:25:10 TP0] Decode batch. #running-req: 4, #token: 1616, token usage: 0.00, gen throughput (token/s): 875.40, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:25:11 TP0] Decode batch. #running-req: 4, #token: 1776, token usage: 0.00, gen throughput (token/s): 871.83, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:25:11 TP0] Decode batch. #running-req: 4, #token: 1936, token usage: 0.00, gen throughput (token/s): 870.91, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:25:11 TP0] Decode batch. #running-req: 4, #token: 2096, token usage: 0.00, gen throughput (token/s): 838.86, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:25:11 TP0] Decode batch. #running-req: 4, #token: 2256, token usage: 0.00, gen throughput (token/s): 857.54, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:25:11 TP0] Decode batch. #running-req: 4, #token: 2416, token usage: 0.00, gen throughput (token/s): 863.94, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:25:11 TP0] Decode batch. #running-req: 4, #token: 2576, token usage: 0.00, gen throughput (token/s): 865.36, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:25:12 TP0] Decode batch. #running-req: 4, #token: 2736, token usage: 0.00, gen throughput (token/s): 891.32, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:25:12 TP0] Decode batch. #running-req: 4, #token: 2896, token usage: 0.00, gen throughput (token/s): 853.73, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:25:12] INFO:     127.0.0.1:14716 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 18:25:12] INFO:     127.0.0.1:14726 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 18:25:12] INFO:     127.0.0.1:14720 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 18:25:12] INFO:     127.0.0.1:14722 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 18:25:12 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 211, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-08-25 18:25:12 TP0] Prefill batch. #new-seq: 3, #new-token: 3, #cached-token: 633, token usage: 0.00, #running-req: 1, #queue-req: 0, 
[2025-08-25 18:25:12 TP0] Decode batch. #running-req: 4, #token: 256, token usage: 0.00, gen throughput (token/s): 565.18, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:25:12 TP0] Decode batch. #running-req: 4, #token: 416, token usage: 0.00, gen throughput (token/s): 861.78, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:25:12 TP0] Decode batch. #running-req: 4, #token: 576, token usage: 0.00, gen throughput (token/s): 890.62, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:25:13 TP0] Decode batch. #running-req: 4, #token: 736, token usage: 0.00, gen throughput (token/s): 860.31, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:25:13 TP0] Decode batch. #running-req: 4, #token: 896, token usage: 0.00, gen throughput (token/s): 855.19, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:25:13 TP0] Decode batch. #running-req: 4, #token: 1056, token usage: 0.00, gen throughput (token/s): 861.85, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:25:13 TP0] Decode batch. #running-req: 4, #token: 1216, token usage: 0.00, gen throughput (token/s): 858.14, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:25:13 TP0] Decode batch. #running-req: 4, #token: 1376, token usage: 0.00, gen throughput (token/s): 861.14, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:25:14 TP0] Decode batch. #running-req: 4, #token: 1536, token usage: 0.00, gen throughput (token/s): 864.91, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:25:14 TP0] Decode batch. #running-req: 4, #token: 1696, token usage: 0.00, gen throughput (token/s): 854.65, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:25:14 TP0] Decode batch. #running-req: 4, #token: 1856, token usage: 0.00, gen throughput (token/s): 878.95, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:25:14 TP0] Decode batch. #running-req: 4, #token: 2016, token usage: 0.00, gen throughput (token/s): 872.34, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:25:14 TP0] Decode batch. #running-req: 4, #token: 2176, token usage: 0.00, gen throughput (token/s): 868.11, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:25:15 TP0] Decode batch. #running-req: 4, #token: 2336, token usage: 0.00, gen throughput (token/s): 861.50, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:25:15 TP0] Decode batch. #running-req: 4, #token: 2496, token usage: 0.00, gen throughput (token/s): 862.45, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:25:15 TP0] Decode batch. #running-req: 4, #token: 2656, token usage: 0.00, gen throughput (token/s): 910.10, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:25:15 TP0] Decode batch. #running-req: 4, #token: 2816, token usage: 0.00, gen throughput (token/s): 870.99, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:25:15 TP0] Decode batch. #running-req: 4, #token: 2976, token usage: 0.00, gen throughput (token/s): 868.56, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:25:15] INFO:     127.0.0.1:14726 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 18:25:15] INFO:     127.0.0.1:14716 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 18:25:15] INFO:     127.0.0.1:14720 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 18:25:15] INFO:     127.0.0.1:14722 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 18:25:15 TP0] Prefill batch. #new-seq: 4, #new-token: 2800, #cached-token: 804, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-08-25 18:25:16] INFO:     127.0.0.1:23522 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 18:25:16] INFO:     127.0.0.1:23528 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 18:25:16] INFO:     127.0.0.1:23540 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 18:25:16] INFO:     127.0.0.1:23552 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 18:25:16 TP0] Prefill batch. #new-seq: 2, #new-token: 1400, #cached-token: 402, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-08-25 18:25:17 TP0] Prefill batch. #new-seq: 2, #new-token: 1400, #cached-token: 402, token usage: 0.00, #running-req: 2, #queue-req: 0, 
[2025-08-25 18:25:17] INFO:     127.0.0.1:23552 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 18:25:17] INFO:     127.0.0.1:23522 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 18:25:17 TP0] Prefill batch. #new-seq: 2, #new-token: 1400, #cached-token: 402, token usage: 0.00, #running-req: 2, #queue-req: 0, 
[2025-08-25 18:25:17] INFO:     127.0.0.1:23528 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 18:25:17] INFO:     127.0.0.1:23540 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 18:25:18 TP0] Prefill batch. #new-seq: 2, #new-token: 1400, #cached-token: 402, token usage: 0.00, #running-req: 4, #queue-req: 0, 
[2025-08-25 18:25:18] INFO:     127.0.0.1:23552 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 18:25:18] INFO:     127.0.0.1:23522 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 18:25:18] INFO:     127.0.0.1:23528 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 18:25:18] INFO:     127.0.0.1:23540 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 18:25:18 TP0] Prefill batch. #new-seq: 1, #new-token: 700, #cached-token: 201, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-08-25 18:25:19] INFO:     127.0.0.1:23552 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 18:25:19 TP0] Prefill batch. #new-seq: 3, #new-token: 2100, #cached-token: 603, token usage: 0.00, #running-req: 1, #queue-req: 0, 
[2025-08-25 18:25:19 TP0] Prefill batch. #new-seq: 1, #new-token: 696, #cached-token: 214, token usage: 0.01, #running-req: 4, #queue-req: 0, 
[2025-08-25 18:25:19] INFO:     127.0.0.1:23522 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 18:25:19] INFO:     127.0.0.1:23528 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 18:25:19] INFO:     127.0.0.1:23540 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 18:25:19 TP0] Prefill batch. #new-seq: 3, #new-token: 2080, #cached-token: 650, token usage: 0.00, #running-req: 1, #queue-req: 0, 
[2025-08-25 18:25:20 TP0] Decode batch. #running-req: 4, #token: 3056, token usage: 0.01, gen throughput (token/s): 7.62, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:25:21 TP0] Decode batch. #running-req: 4, #token: 3216, token usage: 0.01, gen throughput (token/s): 153.19, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:25:22 TP0] Decode batch. #running-req: 4, #token: 3376, token usage: 0.01, gen throughput (token/s): 151.71, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:25:24 TP0] Decode batch. #running-req: 4, #token: 3536, token usage: 0.01, gen throughput (token/s): 149.63, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:25:24] INFO:     127.0.0.1:23552 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 18:25:24] INFO:     127.0.0.1:23522 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 18:25:24] INFO:     127.0.0.1:23528 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 18:25:24] INFO:     127.0.0.1:23540 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 18:25:24 TP0] Prefill batch. #new-seq: 1, #new-token: 670, #cached-token: 240, token usage: 0.00, #running-req: 3, #queue-req: 0, 
[2025-08-25 18:25:24 TP0] Prefill batch. #new-seq: 3, #new-token: 2080, #cached-token: 650, token usage: 0.00, #running-req: 4, #queue-req: 0, 
[2025-08-25 18:25:25 TP0] Decode batch. #running-req: 4, #token: 3093, token usage: 0.01, gen throughput (token/s): 87.77, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:25:26 TP0] Decode batch. #running-req: 4, #token: 3253, token usage: 0.01, gen throughput (token/s): 153.46, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:25:27 TP0] Decode batch. #running-req: 4, #token: 3413, token usage: 0.01, gen throughput (token/s): 151.82, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:25:29 TP0] Decode batch. #running-req: 4, #token: 3573, token usage: 0.01, gen throughput (token/s): 152.12, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:25:29] INFO:     127.0.0.1:23552 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 18:25:29] INFO:     127.0.0.1:23522 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 18:25:29] INFO:     127.0.0.1:23528 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 18:25:29] INFO:     127.0.0.1:23540 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 18:25:29 TP0] Prefill batch. #new-seq: 1, #new-token: 698, #cached-token: 212, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-08-25 18:25:30 TP0] Decode batch. #running-req: 1, #token: 944, token usage: 0.00, gen throughput (token/s): 49.25, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:25:31 TP0] Decode batch. #running-req: 1, #token: 984, token usage: 0.00, gen throughput (token/s): 38.68, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:25:32 TP0] Decode batch. #running-req: 1, #token: 1024, token usage: 0.00, gen throughput (token/s): 38.66, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:25:33] INFO:     127.0.0.1:23552 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 18:25:33 TP0] Prefill batch. #new-seq: 4, #new-token: 4, #cached-token: 664, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-08-25 18:25:33 TP0] Decode batch. #running-req: 4, #token: 291, token usage: 0.00, gen throughput (token/s): 9.04, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:25:33 TP0] Decode batch. #running-req: 4, #token: 451, token usage: 0.00, gen throughput (token/s): 857.37, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:25:33 TP0] Decode batch. #running-req: 4, #token: 611, token usage: 0.00, gen throughput (token/s): 846.18, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:25:34 TP0] Decode batch. #running-req: 4, #token: 771, token usage: 0.00, gen throughput (token/s): 849.15, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:25:34 TP0] Decode batch. #running-req: 4, #token: 931, token usage: 0.00, gen throughput (token/s): 877.36, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:25:34 TP0] Decode batch. #running-req: 4, #token: 1091, token usage: 0.00, gen throughput (token/s): 851.50, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:25:34 TP0] Decode batch. #running-req: 4, #token: 1251, token usage: 0.00, gen throughput (token/s): 866.17, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:25:34 TP0] Decode batch. #running-req: 4, #token: 1411, token usage: 0.00, gen throughput (token/s): 841.07, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:25:34 TP0] Decode batch. #running-req: 4, #token: 1571, token usage: 0.00, gen throughput (token/s): 832.42, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:25:35 TP0] Decode batch. #running-req: 4, #token: 1731, token usage: 0.00, gen throughput (token/s): 853.85, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:25:35 TP0] Decode batch. #running-req: 4, #token: 1891, token usage: 0.00, gen throughput (token/s): 844.16, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:25:35 TP0] Decode batch. #running-req: 4, #token: 2051, token usage: 0.00, gen throughput (token/s): 846.12, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:25:35 TP0] Decode batch. #running-req: 4, #token: 2211, token usage: 0.00, gen throughput (token/s): 830.32, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:25:35 TP0] Decode batch. #running-req: 4, #token: 2371, token usage: 0.00, gen throughput (token/s): 827.70, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:25:36 TP0] Decode batch. #running-req: 4, #token: 2531, token usage: 0.00, gen throughput (token/s): 844.14, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:25:36 TP0] Decode batch. #running-req: 4, #token: 2691, token usage: 0.00, gen throughput (token/s): 833.49, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:25:36 TP0] Decode batch. #running-req: 4, #token: 2851, token usage: 0.00, gen throughput (token/s): 824.53, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:25:36] INFO:     127.0.0.1:51392 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 18:25:36] INFO:     127.0.0.1:51404 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 18:25:36] INFO:     127.0.0.1:51418 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 18:25:36] INFO:     127.0.0.1:51426 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 18:25:36 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 166, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-08-25 18:25:36 TP0] Prefill batch. #new-seq: 3, #new-token: 3, #cached-token: 498, token usage: 0.00, #running-req: 1, #queue-req: 0, 
[2025-08-25 18:25:36 TP0] Decode batch. #running-req: 4, #token: 211, token usage: 0.00, gen throughput (token/s): 565.66, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:25:36 TP0] Decode batch. #running-req: 4, #token: 371, token usage: 0.00, gen throughput (token/s): 939.60, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:25:37 TP0] Decode batch. #running-req: 4, #token: 531, token usage: 0.00, gen throughput (token/s): 868.83, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:25:37 TP0] Decode batch. #running-req: 4, #token: 691, token usage: 0.00, gen throughput (token/s): 847.47, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:25:37 TP0] Decode batch. #running-req: 4, #token: 851, token usage: 0.00, gen throughput (token/s): 846.42, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:25:37 TP0] Decode batch. #running-req: 4, #token: 1011, token usage: 0.00, gen throughput (token/s): 838.23, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:25:37 TP0] Decode batch. #running-req: 4, #token: 1171, token usage: 0.00, gen throughput (token/s): 855.24, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:25:38 TP0] Decode batch. #running-req: 4, #token: 1331, token usage: 0.00, gen throughput (token/s): 850.87, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:25:38 TP0] Decode batch. #running-req: 4, #token: 1491, token usage: 0.00, gen throughput (token/s): 831.77, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:25:38 TP0] Decode batch. #running-req: 4, #token: 1651, token usage: 0.00, gen throughput (token/s): 841.07, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:25:38 TP0] Decode batch. #running-req: 4, #token: 1811, token usage: 0.00, gen throughput (token/s): 830.03, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:25:38 TP0] Decode batch. #running-req: 4, #token: 1971, token usage: 0.00, gen throughput (token/s): 833.30, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:25:39 TP0] Decode batch. #running-req: 4, #token: 2131, token usage: 0.00, gen throughput (token/s): 867.83, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:25:39 TP0] Decode batch. #running-req: 4, #token: 2291, token usage: 0.00, gen throughput (token/s): 852.43, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:25:39 TP0] Decode batch. #running-req: 4, #token: 2451, token usage: 0.00, gen throughput (token/s): 840.53, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:25:39 TP0] Decode batch. #running-req: 4, #token: 2611, token usage: 0.00, gen throughput (token/s): 871.62, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:25:39 TP0] Decode batch. #running-req: 4, #token: 2771, token usage: 0.00, gen throughput (token/s): 838.62, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:25:39 TP0] Decode batch. #running-req: 4, #token: 2931, token usage: 0.00, gen throughput (token/s): 867.32, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:25:39] INFO:     127.0.0.1:51426 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 18:25:39] INFO:     127.0.0.1:51392 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 18:25:39] INFO:     127.0.0.1:51404 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 18:25:39] INFO:     127.0.0.1:51418 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 18:25:40 TP0] Prefill batch. #new-seq: 4, #new-token: 4, #cached-token: 664, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-08-25 18:25:40 TP0] Decode batch. #running-req: 4, #token: 291, token usage: 0.00, gen throughput (token/s): 643.02, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:25:40 TP0] Decode batch. #running-req: 4, #token: 451, token usage: 0.00, gen throughput (token/s): 889.71, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:25:40 TP0] Decode batch. #running-req: 4, #token: 611, token usage: 0.00, gen throughput (token/s): 836.46, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:25:40 TP0] Decode batch. #running-req: 4, #token: 771, token usage: 0.00, gen throughput (token/s): 861.74, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:25:40 TP0] Decode batch. #running-req: 4, #token: 931, token usage: 0.00, gen throughput (token/s): 861.83, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:25:41 TP0] Decode batch. #running-req: 4, #token: 1091, token usage: 0.00, gen throughput (token/s): 851.34, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:25:41 TP0] Decode batch. #running-req: 4, #token: 1251, token usage: 0.00, gen throughput (token/s): 842.02, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:25:41 TP0] Decode batch. #running-req: 4, #token: 1411, token usage: 0.00, gen throughput (token/s): 861.13, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:25:41 TP0] Decode batch. #running-req: 4, #token: 1571, token usage: 0.00, gen throughput (token/s): 875.44, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:25:41 TP0] Decode batch. #running-req: 4, #token: 1731, token usage: 0.00, gen throughput (token/s): 860.09, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:25:42 TP0] Decode batch. #running-req: 4, #token: 1891, token usage: 0.00, gen throughput (token/s): 853.19, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:25:42 TP0] Decode batch. #running-req: 4, #token: 2051, token usage: 0.00, gen throughput (token/s): 852.10, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:25:42 TP0] Decode batch. #running-req: 4, #token: 2211, token usage: 0.00, gen throughput (token/s): 870.76, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:25:42 TP0] Decode batch. #running-req: 4, #token: 2371, token usage: 0.00, gen throughput (token/s): 855.45, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:25:42 TP0] Decode batch. #running-req: 4, #token: 2531, token usage: 0.00, gen throughput (token/s): 877.64, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:25:42 TP0] Decode batch. #running-req: 4, #token: 2691, token usage: 0.00, gen throughput (token/s): 864.58, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:25:43 TP0] Decode batch. #running-req: 4, #token: 2851, token usage: 0.00, gen throughput (token/s): 834.20, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:25:43] INFO:     127.0.0.1:51392 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 18:25:43] INFO:     127.0.0.1:51426 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 18:25:43] INFO:     127.0.0.1:51404 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 18:25:43] INFO:     127.0.0.1:51418 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 18:25:43 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 166, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-08-25 18:25:43 TP0] Prefill batch. #new-seq: 3, #new-token: 3, #cached-token: 498, token usage: 0.00, #running-req: 1, #queue-req: 0, 
[2025-08-25 18:25:43 TP0] Decode batch. #running-req: 4, #token: 211, token usage: 0.00, gen throughput (token/s): 569.17, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:25:43 TP0] Decode batch. #running-req: 4, #token: 371, token usage: 0.00, gen throughput (token/s): 859.15, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:25:43 TP0] Decode batch. #running-req: 4, #token: 531, token usage: 0.00, gen throughput (token/s): 871.86, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:25:44 TP0] Decode batch. #running-req: 4, #token: 691, token usage: 0.00, gen throughput (token/s): 849.22, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:25:44 TP0] Decode batch. #running-req: 4, #token: 851, token usage: 0.00, gen throughput (token/s): 851.28, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:25:44 TP0] Decode batch. #running-req: 4, #token: 1011, token usage: 0.00, gen throughput (token/s): 862.28, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:25:44 TP0] Decode batch. #running-req: 4, #token: 1171, token usage: 0.00, gen throughput (token/s): 868.29, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:25:44 TP0] Decode batch. #running-req: 4, #token: 1331, token usage: 0.00, gen throughput (token/s): 855.41, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:25:44 TP0] Decode batch. #running-req: 4, #token: 1491, token usage: 0.00, gen throughput (token/s): 853.08, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:25:45 TP0] Decode batch. #running-req: 4, #token: 1651, token usage: 0.00, gen throughput (token/s): 844.37, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:25:45 TP0] Decode batch. #running-req: 4, #token: 1811, token usage: 0.00, gen throughput (token/s): 862.65, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:25:45 TP0] Decode batch. #running-req: 4, #token: 1971, token usage: 0.00, gen throughput (token/s): 863.22, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:25:45 TP0] Decode batch. #running-req: 4, #token: 2131, token usage: 0.00, gen throughput (token/s): 910.89, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:25:45 TP0] Decode batch. #running-req: 4, #token: 2291, token usage: 0.00, gen throughput (token/s): 893.07, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:25:46 TP0] Decode batch. #running-req: 4, #token: 2451, token usage: 0.00, gen throughput (token/s): 873.41, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:25:46 TP0] Decode batch. #running-req: 4, #token: 2611, token usage: 0.00, gen throughput (token/s): 874.86, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:25:46 TP0] Decode batch. #running-req: 4, #token: 2771, token usage: 0.00, gen throughput (token/s): 920.57, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:25:46 TP0] Decode batch. #running-req: 4, #token: 2931, token usage: 0.00, gen throughput (token/s): 864.42, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:25:46] INFO:     127.0.0.1:51426 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 18:25:46] INFO:     127.0.0.1:51392 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 18:25:46] INFO:     127.0.0.1:51404 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 18:25:46] INFO:     127.0.0.1:51418 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 18:25:46 TP0] Prefill batch. #new-seq: 4, #new-token: 2800, #cached-token: 624, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-08-25 18:25:47] INFO:     127.0.0.1:35344 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 18:25:47] INFO:     127.0.0.1:35356 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 18:25:47] INFO:     127.0.0.1:35360 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 18:25:47] INFO:     127.0.0.1:35362 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 18:25:48 TP0] Prefill batch. #new-seq: 1, #new-token: 700, #cached-token: 156, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-08-25 18:25:48 TP0] Prefill batch. #new-seq: 2, #new-token: 1400, #cached-token: 312, token usage: 0.00, #running-req: 1, #queue-req: 0, 
[2025-08-25 18:25:48 TP0] Prefill batch. #new-seq: 1, #new-token: 700, #cached-token: 156, token usage: 0.00, #running-req: 3, #queue-req: 0, 
[2025-08-25 18:25:48] INFO:     127.0.0.1:35356 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 18:25:48] INFO:     127.0.0.1:35362 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 18:25:48] INFO:     127.0.0.1:35344 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 18:25:48 TP0] Prefill batch. #new-seq: 3, #new-token: 2100, #cached-token: 468, token usage: 0.00, #running-req: 1, #queue-req: 0, 
[2025-08-25 18:25:48] INFO:     127.0.0.1:35360 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 18:25:49 TP0] Prefill batch. #new-seq: 1, #new-token: 700, #cached-token: 156, token usage: 0.01, #running-req: 4, #queue-req: 0, 
[2025-08-25 18:25:49] INFO:     127.0.0.1:35356 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 18:25:49] INFO:     127.0.0.1:35362 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 18:25:49] INFO:     127.0.0.1:35344 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 18:25:49 TP0] Prefill batch. #new-seq: 3, #new-token: 2100, #cached-token: 468, token usage: 0.00, #running-req: 1, #queue-req: 0, 
[2025-08-25 18:25:49] INFO:     127.0.0.1:35360 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 18:25:50 TP0] Decode batch. #running-req: 1, #token: 2256, token usage: 0.01, gen throughput (token/s): 2.38, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:25:50 TP0] Prefill batch. #new-seq: 1, #new-token: 700, #cached-token: 156, token usage: 0.01, #running-req: 4, #queue-req: 0, 
[2025-08-25 18:25:50] INFO:     127.0.0.1:35362 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 18:25:50] INFO:     127.0.0.1:35344 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 18:25:50] INFO:     127.0.0.1:35356 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 18:25:50 TP0] Prefill batch. #new-seq: 3, #new-token: 2091, #cached-token: 504, token usage: 0.00, #running-req: 1, #queue-req: 0, 
[2025-08-25 18:25:50] INFO:     127.0.0.1:35360 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 18:25:50 TP0] Prefill batch. #new-seq: 1, #new-token: 698, #cached-token: 167, token usage: 0.01, #running-req: 4, #queue-req: 0, 
[2025-08-25 18:25:52 TP0] Decode batch. #running-req: 4, #token: 3114, token usage: 0.01, gen throughput (token/s): 76.69, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:25:53 TP0] Decode batch. #running-req: 4, #token: 3274, token usage: 0.01, gen throughput (token/s): 152.47, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:25:54 TP0] Decode batch. #running-req: 4, #token: 3434, token usage: 0.01, gen throughput (token/s): 153.11, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:25:55] INFO:     127.0.0.1:35362 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 18:25:55] INFO:     127.0.0.1:35344 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 18:25:55] INFO:     127.0.0.1:35356 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 18:25:55] INFO:     127.0.0.1:35360 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 18:25:55 TP0] Prefill batch. #new-seq: 4, #new-token: 4, #cached-token: 436, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-08-25 18:25:55 TP0] Decode batch. #running-req: 4, #token: 234, token usage: 0.00, gen throughput (token/s): 17.88, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:25:55 TP0] Decode batch. #running-req: 4, #token: 394, token usage: 0.00, gen throughput (token/s): 875.00, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:25:55 TP0] Decode batch. #running-req: 4, #token: 554, token usage: 0.00, gen throughput (token/s): 875.70, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:25:56 TP0] Decode batch. #running-req: 4, #token: 714, token usage: 0.00, gen throughput (token/s): 871.95, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:25:56 TP0] Decode batch. #running-req: 4, #token: 874, token usage: 0.00, gen throughput (token/s): 879.46, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:25:56 TP0] Decode batch. #running-req: 4, #token: 1034, token usage: 0.00, gen throughput (token/s): 915.82, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:25:56 TP0] Decode batch. #running-req: 4, #token: 1194, token usage: 0.00, gen throughput (token/s): 874.84, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:25:56 TP0] Decode batch. #running-req: 4, #token: 1354, token usage: 0.00, gen throughput (token/s): 880.98, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:25:56 TP0] Decode batch. #running-req: 4, #token: 1514, token usage: 0.00, gen throughput (token/s): 882.27, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:25:57 TP0] Decode batch. #running-req: 4, #token: 1674, token usage: 0.00, gen throughput (token/s): 857.39, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:25:57 TP0] Decode batch. #running-req: 4, #token: 1834, token usage: 0.00, gen throughput (token/s): 866.48, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:25:57 TP0] Decode batch. #running-req: 4, #token: 1994, token usage: 0.00, gen throughput (token/s): 862.54, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:25:57 TP0] Decode batch. #running-req: 4, #token: 2154, token usage: 0.00, gen throughput (token/s): 872.42, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:25:57 TP0] Decode batch. #running-req: 4, #token: 2314, token usage: 0.00, gen throughput (token/s): 855.01, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:25:58 TP0] Decode batch. #running-req: 4, #token: 2474, token usage: 0.00, gen throughput (token/s): 885.66, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:25:58 TP0] Decode batch. #running-req: 4, #token: 2634, token usage: 0.00, gen throughput (token/s): 868.31, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:25:58 TP0] Decode batch. #running-req: 4, #token: 2794, token usage: 0.00, gen throughput (token/s): 838.40, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:25:58] INFO:     127.0.0.1:49892 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 18:25:58] INFO:     127.0.0.1:49908 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 18:25:58] INFO:     127.0.0.1:49912 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 18:25:58] INFO:     127.0.0.1:49914 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 18:25:58 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 109, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-08-25 18:25:58 TP0] Prefill batch. #new-seq: 3, #new-token: 3, #cached-token: 327, token usage: 0.00, #running-req: 1, #queue-req: 0, 
[2025-08-25 18:25:58 TP0] Decode batch. #running-req: 4, #token: 154, token usage: 0.00, gen throughput (token/s): 573.47, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:25:58 TP0] Decode batch. #running-req: 4, #token: 314, token usage: 0.00, gen throughput (token/s): 900.23, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:25:59 TP0] Decode batch. #running-req: 4, #token: 474, token usage: 0.00, gen throughput (token/s): 867.69, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:25:59 TP0] Decode batch. #running-req: 4, #token: 634, token usage: 0.00, gen throughput (token/s): 855.25, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:25:59 TP0] Decode batch. #running-req: 4, #token: 794, token usage: 0.00, gen throughput (token/s): 842.34, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:25:59 TP0] Decode batch. #running-req: 4, #token: 954, token usage: 0.00, gen throughput (token/s): 872.30, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:25:59 TP0] Decode batch. #running-req: 4, #token: 1114, token usage: 0.00, gen throughput (token/s): 849.47, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:26:00 TP0] Decode batch. #running-req: 4, #token: 1274, token usage: 0.00, gen throughput (token/s): 860.81, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:26:00 TP0] Decode batch. #running-req: 4, #token: 1434, token usage: 0.00, gen throughput (token/s): 854.03, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:26:00 TP0] Decode batch. #running-req: 4, #token: 1594, token usage: 0.00, gen throughput (token/s): 848.20, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:26:00 TP0] Decode batch. #running-req: 4, #token: 1754, token usage: 0.00, gen throughput (token/s): 856.32, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:26:00 TP0] Decode batch. #running-req: 4, #token: 1914, token usage: 0.00, gen throughput (token/s): 854.37, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:26:00 TP0] Decode batch. #running-req: 4, #token: 2074, token usage: 0.00, gen throughput (token/s): 864.32, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:26:01 TP0] Decode batch. #running-req: 4, #token: 2234, token usage: 0.00, gen throughput (token/s): 854.57, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:26:01 TP0] Decode batch. #running-req: 4, #token: 2394, token usage: 0.00, gen throughput (token/s): 846.04, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:26:01 TP0] Decode batch. #running-req: 4, #token: 2554, token usage: 0.00, gen throughput (token/s): 851.27, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:26:01 TP0] Decode batch. #running-req: 4, #token: 2714, token usage: 0.00, gen throughput (token/s): 857.00, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:26:01 TP0] Decode batch. #running-req: 4, #token: 2874, token usage: 0.00, gen throughput (token/s): 857.41, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:26:01] INFO:     127.0.0.1:49914 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 18:26:01] INFO:     127.0.0.1:49892 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 18:26:01] INFO:     127.0.0.1:49908 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 18:26:01] INFO:     127.0.0.1:49912 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 18:26:01 TP0] Prefill batch. #new-seq: 4, #new-token: 4, #cached-token: 436, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-08-25 18:26:02 TP0] Decode batch. #running-req: 4, #token: 234, token usage: 0.00, gen throughput (token/s): 691.37, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:26:02 TP0] Decode batch. #running-req: 4, #token: 394, token usage: 0.00, gen throughput (token/s): 853.26, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:26:02 TP0] Decode batch. #running-req: 4, #token: 554, token usage: 0.00, gen throughput (token/s): 847.94, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:26:02 TP0] Decode batch. #running-req: 4, #token: 714, token usage: 0.00, gen throughput (token/s): 859.54, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:26:02 TP0] Decode batch. #running-req: 4, #token: 874, token usage: 0.00, gen throughput (token/s): 849.06, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:26:03 TP0] Decode batch. #running-req: 4, #token: 1034, token usage: 0.00, gen throughput (token/s): 842.14, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:26:03 TP0] Decode batch. #running-req: 4, #token: 1194, token usage: 0.00, gen throughput (token/s): 851.77, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:26:03 TP0] Decode batch. #running-req: 4, #token: 1354, token usage: 0.00, gen throughput (token/s): 863.25, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:26:03 TP0] Decode batch. #running-req: 4, #token: 1514, token usage: 0.00, gen throughput (token/s): 852.63, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:26:03 TP0] Decode batch. #running-req: 4, #token: 1674, token usage: 0.00, gen throughput (token/s): 860.58, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:26:04 TP0] Decode batch. #running-req: 4, #token: 1834, token usage: 0.00, gen throughput (token/s): 854.96, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:26:04 TP0] Decode batch. #running-req: 4, #token: 1994, token usage: 0.00, gen throughput (token/s): 873.67, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:26:04 TP0] Decode batch. #running-req: 4, #token: 2154, token usage: 0.00, gen throughput (token/s): 841.42, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:26:04 TP0] Decode batch. #running-req: 4, #token: 2314, token usage: 0.00, gen throughput (token/s): 851.13, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:26:04 TP0] Decode batch. #running-req: 4, #token: 2474, token usage: 0.00, gen throughput (token/s): 873.20, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:26:04 TP0] Decode batch. #running-req: 4, #token: 2634, token usage: 0.00, gen throughput (token/s): 856.24, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:26:05 TP0] Decode batch. #running-req: 4, #token: 2794, token usage: 0.00, gen throughput (token/s): 861.31, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:26:05] INFO:     127.0.0.1:49914 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 18:26:05] INFO:     127.0.0.1:49892 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 18:26:05] INFO:     127.0.0.1:49908 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 18:26:05] INFO:     127.0.0.1:49912 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 18:26:05 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 109, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-08-25 18:26:05 TP0] Prefill batch. #new-seq: 3, #new-token: 3, #cached-token: 327, token usage: 0.00, #running-req: 1, #queue-req: 0, 
[2025-08-25 18:26:05 TP0] Decode batch. #running-req: 4, #token: 154, token usage: 0.00, gen throughput (token/s): 574.08, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:26:05 TP0] Decode batch. #running-req: 4, #token: 314, token usage: 0.00, gen throughput (token/s): 884.85, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:26:05 TP0] Decode batch. #running-req: 4, #token: 474, token usage: 0.00, gen throughput (token/s): 867.66, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:26:05 TP0] Decode batch. #running-req: 4, #token: 634, token usage: 0.00, gen throughput (token/s): 855.50, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:26:06 TP0] Decode batch. #running-req: 4, #token: 794, token usage: 0.00, gen throughput (token/s): 858.48, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:26:06 TP0] Decode batch. #running-req: 4, #token: 954, token usage: 0.00, gen throughput (token/s): 851.59, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:26:06 TP0] Decode batch. #running-req: 4, #token: 1114, token usage: 0.00, gen throughput (token/s): 843.08, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:26:06 TP0] Decode batch. #running-req: 4, #token: 1274, token usage: 0.00, gen throughput (token/s): 889.81, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:26:06 TP0] Decode batch. #running-req: 4, #token: 1434, token usage: 0.00, gen throughput (token/s): 847.86, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:26:07 TP0] Decode batch. #running-req: 4, #token: 1594, token usage: 0.00, gen throughput (token/s): 853.10, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:26:07 TP0] Decode batch. #running-req: 4, #token: 1754, token usage: 0.00, gen throughput (token/s): 891.39, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:26:07 TP0] Decode batch. #running-req: 4, #token: 1914, token usage: 0.00, gen throughput (token/s): 869.57, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:26:07 TP0] Decode batch. #running-req: 4, #token: 2074, token usage: 0.00, gen throughput (token/s): 887.49, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:26:07 TP0] Decode batch. #running-req: 4, #token: 2234, token usage: 0.00, gen throughput (token/s): 849.55, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:26:08 TP0] Decode batch. #running-req: 4, #token: 2394, token usage: 0.00, gen throughput (token/s): 865.76, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:26:08 TP0] Decode batch. #running-req: 4, #token: 2554, token usage: 0.00, gen throughput (token/s): 831.99, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:26:08 TP0] Decode batch. #running-req: 4, #token: 2714, token usage: 0.00, gen throughput (token/s): 858.20, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:26:08 TP0] Decode batch. #running-req: 4, #token: 2874, token usage: 0.00, gen throughput (token/s): 880.52, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:26:08] INFO:     127.0.0.1:49914 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 18:26:08] INFO:     127.0.0.1:49892 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 18:26:08] INFO:     127.0.0.1:49908 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 18:26:08] INFO:     127.0.0.1:49912 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 18:26:08 TP0] Prefill batch. #new-seq: 4, #new-token: 2800, #cached-token: 396, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-08-25 18:26:09] INFO:     127.0.0.1:12614 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 18:26:09] INFO:     127.0.0.1:12628 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 18:26:09] INFO:     127.0.0.1:12644 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 18:26:09] INFO:     127.0.0.1:12646 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 18:26:09 TP0] Prefill batch. #new-seq: 1, #new-token: 700, #cached-token: 99, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-08-25 18:26:09 TP0] Prefill batch. #new-seq: 3, #new-token: 2100, #cached-token: 297, token usage: 0.00, #running-req: 1, #queue-req: 0, 
[2025-08-25 18:26:10] INFO:     127.0.0.1:12646 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 18:26:10] INFO:     127.0.0.1:12614 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 18:26:10] INFO:     127.0.0.1:12628 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 18:26:10] INFO:     127.0.0.1:12644 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 18:26:10 TP0] Prefill batch. #new-seq: 1, #new-token: 700, #cached-token: 99, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-08-25 18:26:11 TP0] Prefill batch. #new-seq: 3, #new-token: 2100, #cached-token: 297, token usage: 0.00, #running-req: 1, #queue-req: 0, 
[2025-08-25 18:26:11] INFO:     127.0.0.1:12646 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 18:26:11 TP0] Prefill batch. #new-seq: 1, #new-token: 700, #cached-token: 99, token usage: 0.00, #running-req: 3, #queue-req: 0, 
[2025-08-25 18:26:11] INFO:     127.0.0.1:12614 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 18:26:11] INFO:     127.0.0.1:12628 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 18:26:11] INFO:     127.0.0.1:12644 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 18:26:12 TP0] Prefill batch. #new-seq: 3, #new-token: 2100, #cached-token: 297, token usage: 0.00, #running-req: 4, #queue-req: 0, 
[2025-08-25 18:26:12] INFO:     127.0.0.1:12646 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 18:26:12 TP0] Prefill batch. #new-seq: 1, #new-token: 678, #cached-token: 130, token usage: 0.00, #running-req: 3, #queue-req: 0, 
[2025-08-25 18:26:12] INFO:     127.0.0.1:12614 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 18:26:12] INFO:     127.0.0.1:12628 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 18:26:12] INFO:     127.0.0.1:12644 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 18:26:12 TP0] Prefill batch. #new-seq: 1, #new-token: 700, #cached-token: 108, token usage: 0.00, #running-req: 4, #queue-req: 0, 
[2025-08-25 18:26:13 TP0] Decode batch. #running-req: 2, #token: 1518, token usage: 0.00, gen throughput (token/s): 7.79, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:26:14 TP0] Decode batch. #running-req: 2, #token: 1598, token usage: 0.00, gen throughput (token/s): 78.06, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:26:15 TP0] Decode batch. #running-req: 2, #token: 1678, token usage: 0.01, gen throughput (token/s): 78.17, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:26:16 TP0] Decode batch. #running-req: 2, #token: 1758, token usage: 0.01, gen throughput (token/s): 78.11, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:26:16] INFO:     127.0.0.1:12646 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 18:26:16] INFO:     127.0.0.1:12614 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 18:26:17 TP0] Prefill batch. #new-seq: 4, #new-token: 4, #cached-token: 540, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-08-25 18:26:17 TP0] Decode batch. #running-req: 4, #token: 260, token usage: 0.00, gen throughput (token/s): 18.53, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:26:17 TP0] Decode batch. #running-req: 4, #token: 420, token usage: 0.00, gen throughput (token/s): 866.73, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:26:17 TP0] Decode batch. #running-req: 4, #token: 580, token usage: 0.00, gen throughput (token/s): 857.13, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:26:17 TP0] Decode batch. #running-req: 4, #token: 740, token usage: 0.00, gen throughput (token/s): 883.35, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:26:17 TP0] Decode batch. #running-req: 4, #token: 900, token usage: 0.00, gen throughput (token/s): 870.14, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:26:18 TP0] Decode batch. #running-req: 4, #token: 1060, token usage: 0.00, gen throughput (token/s): 870.27, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:26:18 TP0] Decode batch. #running-req: 4, #token: 1220, token usage: 0.00, gen throughput (token/s): 868.84, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:26:18 TP0] Decode batch. #running-req: 4, #token: 1380, token usage: 0.00, gen throughput (token/s): 851.58, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:26:18 TP0] Decode batch. #running-req: 4, #token: 1540, token usage: 0.00, gen throughput (token/s): 860.52, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:26:18 TP0] Decode batch. #running-req: 4, #token: 1700, token usage: 0.00, gen throughput (token/s): 865.03, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:26:19 TP0] Decode batch. #running-req: 4, #token: 1860, token usage: 0.00, gen throughput (token/s): 858.34, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:26:19 TP0] Decode batch. #running-req: 4, #token: 2020, token usage: 0.00, gen throughput (token/s): 866.06, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:26:19 TP0] Decode batch. #running-req: 4, #token: 2180, token usage: 0.00, gen throughput (token/s): 863.93, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:26:19 TP0] Decode batch. #running-req: 4, #token: 2340, token usage: 0.00, gen throughput (token/s): 872.44, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:26:19 TP0] Decode batch. #running-req: 4, #token: 2500, token usage: 0.00, gen throughput (token/s): 884.29, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:26:19 TP0] Decode batch. #running-req: 4, #token: 2660, token usage: 0.00, gen throughput (token/s): 872.15, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:26:20 TP0] Decode batch. #running-req: 4, #token: 2820, token usage: 0.00, gen throughput (token/s): 871.58, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:26:20] INFO:     127.0.0.1:51282 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 18:26:20] INFO:     127.0.0.1:51298 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 18:26:20] INFO:     127.0.0.1:51310 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 18:26:20] INFO:     127.0.0.1:51318 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 18:26:20 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 135, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-08-25 18:26:20 TP0] Prefill batch. #new-seq: 3, #new-token: 3, #cached-token: 405, token usage: 0.00, #running-req: 1, #queue-req: 0, 
[2025-08-25 18:26:20 TP0] Decode batch. #running-req: 4, #token: 180, token usage: 0.00, gen throughput (token/s): 590.92, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:26:20 TP0] Decode batch. #running-req: 4, #token: 340, token usage: 0.00, gen throughput (token/s): 881.17, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:26:20 TP0] Decode batch. #running-req: 4, #token: 500, token usage: 0.00, gen throughput (token/s): 882.39, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:26:20 TP0] Decode batch. #running-req: 4, #token: 660, token usage: 0.00, gen throughput (token/s): 860.25, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:26:21 TP0] Decode batch. #running-req: 4, #token: 820, token usage: 0.00, gen throughput (token/s): 852.92, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:26:21 TP0] Decode batch. #running-req: 4, #token: 980, token usage: 0.00, gen throughput (token/s): 849.93, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:26:21 TP0] Decode batch. #running-req: 4, #token: 1140, token usage: 0.00, gen throughput (token/s): 879.36, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:26:21 TP0] Decode batch. #running-req: 4, #token: 1300, token usage: 0.00, gen throughput (token/s): 867.93, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:26:21 TP0] Decode batch. #running-req: 4, #token: 1460, token usage: 0.00, gen throughput (token/s): 876.88, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:26:22 TP0] Decode batch. #running-req: 4, #token: 1620, token usage: 0.00, gen throughput (token/s): 862.44, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:26:22 TP0] Decode batch. #running-req: 4, #token: 1780, token usage: 0.00, gen throughput (token/s): 864.64, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:26:22 TP0] Decode batch. #running-req: 4, #token: 1940, token usage: 0.00, gen throughput (token/s): 881.88, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:26:22 TP0] Decode batch. #running-req: 4, #token: 2100, token usage: 0.00, gen throughput (token/s): 861.88, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:26:22 TP0] Decode batch. #running-req: 4, #token: 2260, token usage: 0.00, gen throughput (token/s): 854.63, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:26:23 TP0] Decode batch. #running-req: 4, #token: 2420, token usage: 0.00, gen throughput (token/s): 847.84, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:26:23 TP0] Decode batch. #running-req: 4, #token: 2580, token usage: 0.00, gen throughput (token/s): 854.73, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:26:23 TP0] Decode batch. #running-req: 4, #token: 2740, token usage: 0.00, gen throughput (token/s): 838.89, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:26:23 TP0] Decode batch. #running-req: 4, #token: 2900, token usage: 0.00, gen throughput (token/s): 861.11, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:26:23] INFO:     127.0.0.1:51318 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 18:26:23] INFO:     127.0.0.1:51282 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 18:26:23] INFO:     127.0.0.1:51298 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 18:26:23] INFO:     127.0.0.1:51310 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 18:26:23 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 135, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-08-25 18:26:23 TP0] Prefill batch. #new-seq: 3, #new-token: 3, #cached-token: 405, token usage: 0.00, #running-req: 1, #queue-req: 0, 
[2025-08-25 18:26:23 TP0] Decode batch. #running-req: 4, #token: 260, token usage: 0.00, gen throughput (token/s): 574.97, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:26:24 TP0] Decode batch. #running-req: 4, #token: 420, token usage: 0.00, gen throughput (token/s): 864.74, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:26:24 TP0] Decode batch. #running-req: 4, #token: 580, token usage: 0.00, gen throughput (token/s): 852.81, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:26:24 TP0] Decode batch. #running-req: 4, #token: 740, token usage: 0.00, gen throughput (token/s): 884.18, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:26:24 TP0] Decode batch. #running-req: 4, #token: 900, token usage: 0.00, gen throughput (token/s): 861.78, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:26:24 TP0] Decode batch. #running-req: 4, #token: 1060, token usage: 0.00, gen throughput (token/s): 938.09, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:26:24 TP0] Decode batch. #running-req: 4, #token: 1220, token usage: 0.00, gen throughput (token/s): 918.31, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:26:25 TP0] Decode batch. #running-req: 4, #token: 1380, token usage: 0.00, gen throughput (token/s): 859.15, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:26:25 TP0] Decode batch. #running-req: 4, #token: 1540, token usage: 0.00, gen throughput (token/s): 869.81, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:26:25 TP0] Decode batch. #running-req: 4, #token: 1700, token usage: 0.00, gen throughput (token/s): 886.74, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:26:25 TP0] Decode batch. #running-req: 4, #token: 1860, token usage: 0.00, gen throughput (token/s): 879.09, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:26:25 TP0] Decode batch. #running-req: 4, #token: 2020, token usage: 0.00, gen throughput (token/s): 879.32, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:26:26 TP0] Decode batch. #running-req: 4, #token: 2180, token usage: 0.00, gen throughput (token/s): 874.44, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:26:26 TP0] Decode batch. #running-req: 4, #token: 2340, token usage: 0.00, gen throughput (token/s): 866.95, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:26:26 TP0] Decode batch. #running-req: 4, #token: 2500, token usage: 0.00, gen throughput (token/s): 872.86, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:26:26 TP0] Decode batch. #running-req: 4, #token: 2660, token usage: 0.00, gen throughput (token/s): 867.67, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:26:26 TP0] Decode batch. #running-req: 4, #token: 2820, token usage: 0.00, gen throughput (token/s): 905.25, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:26:26] INFO:     127.0.0.1:51318 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 18:26:26] INFO:     127.0.0.1:51282 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 18:26:26] INFO:     127.0.0.1:51298 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 18:26:26] INFO:     127.0.0.1:51310 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 18:26:26 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 135, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-08-25 18:26:26 TP0] Prefill batch. #new-seq: 3, #new-token: 3, #cached-token: 405, token usage: 0.00, #running-req: 1, #queue-req: 0, 
[2025-08-25 18:26:27 TP0] Decode batch. #running-req: 4, #token: 180, token usage: 0.00, gen throughput (token/s): 584.11, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:26:27 TP0] Decode batch. #running-req: 4, #token: 340, token usage: 0.00, gen throughput (token/s): 866.30, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:26:27 TP0] Decode batch. #running-req: 4, #token: 500, token usage: 0.00, gen throughput (token/s): 894.78, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:26:27 TP0] Decode batch. #running-req: 4, #token: 660, token usage: 0.00, gen throughput (token/s): 890.69, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:26:27 TP0] Decode batch. #running-req: 4, #token: 820, token usage: 0.00, gen throughput (token/s): 877.51, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:26:27 TP0] Decode batch. #running-req: 4, #token: 980, token usage: 0.00, gen throughput (token/s): 874.56, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:26:28 TP0] Decode batch. #running-req: 4, #token: 1140, token usage: 0.00, gen throughput (token/s): 877.39, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:26:28 TP0] Decode batch. #running-req: 4, #token: 1300, token usage: 0.00, gen throughput (token/s): 874.83, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:26:28 TP0] Decode batch. #running-req: 4, #token: 1460, token usage: 0.00, gen throughput (token/s): 843.08, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:26:28 TP0] Decode batch. #running-req: 4, #token: 1620, token usage: 0.00, gen throughput (token/s): 844.34, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:26:28 TP0] Decode batch. #running-req: 4, #token: 1780, token usage: 0.00, gen throughput (token/s): 860.83, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:26:29 TP0] Decode batch. #running-req: 4, #token: 1940, token usage: 0.00, gen throughput (token/s): 833.75, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:26:29 TP0] Decode batch. #running-req: 4, #token: 2100, token usage: 0.00, gen throughput (token/s): 864.85, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:26:29 TP0] Decode batch. #running-req: 4, #token: 2260, token usage: 0.00, gen throughput (token/s): 843.21, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:26:29 TP0] Decode batch. #running-req: 4, #token: 2420, token usage: 0.00, gen throughput (token/s): 858.16, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:26:29 TP0] Decode batch. #running-req: 4, #token: 2580, token usage: 0.00, gen throughput (token/s): 855.70, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:26:30 TP0] Decode batch. #running-req: 4, #token: 2740, token usage: 0.00, gen throughput (token/s): 877.85, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:26:30 TP0] Decode batch. #running-req: 4, #token: 2900, token usage: 0.00, gen throughput (token/s): 871.97, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:26:30] INFO:     127.0.0.1:51318 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 18:26:30] INFO:     127.0.0.1:51282 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 18:26:30] INFO:     127.0.0.1:51298 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 18:26:30] INFO:     127.0.0.1:51310 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 18:26:30 TP0] Prefill batch. #new-seq: 4, #new-token: 2800, #cached-token: 500, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-08-25 18:26:31] INFO:     127.0.0.1:7916 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 18:26:31] INFO:     127.0.0.1:7922 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 18:26:31] INFO:     127.0.0.1:7932 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 18:26:31] INFO:     127.0.0.1:7938 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 18:26:31 TP0] Prefill batch. #new-seq: 2, #new-token: 1400, #cached-token: 250, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-08-25 18:26:31 TP0] Prefill batch. #new-seq: 2, #new-token: 1400, #cached-token: 250, token usage: 0.00, #running-req: 2, #queue-req: 0, 
[2025-08-25 18:26:32] INFO:     127.0.0.1:7916 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 18:26:32] INFO:     127.0.0.1:7938 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 18:26:32] INFO:     127.0.0.1:7922 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 18:26:32] INFO:     127.0.0.1:7932 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 18:26:32 TP0] Prefill batch. #new-seq: 1, #new-token: 700, #cached-token: 125, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-08-25 18:26:32 TP0] Prefill batch. #new-seq: 3, #new-token: 2100, #cached-token: 375, token usage: 0.00, #running-req: 1, #queue-req: 0, 
[2025-08-25 18:26:33] INFO:     127.0.0.1:7938 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 18:26:33] INFO:     127.0.0.1:7916 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 18:26:33] INFO:     127.0.0.1:7922 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 18:26:33] INFO:     127.0.0.1:7932 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 18:26:33 TP0] Prefill batch. #new-seq: 1, #new-token: 700, #cached-token: 125, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-08-25 18:26:33 TP0] Prefill batch. #new-seq: 1, #new-token: 700, #cached-token: 125, token usage: 0.00, #running-req: 1, #queue-req: 0, 
[2025-08-25 18:26:33 TP0] Prefill batch. #new-seq: 2, #new-token: 1400, #cached-token: 250, token usage: 0.00, #running-req: 2, #queue-req: 0, 
[2025-08-25 18:26:33] INFO:     127.0.0.1:7938 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 18:26:33] INFO:     127.0.0.1:7916 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 18:26:34] INFO:     127.0.0.1:7922 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 18:26:34 TP0] Prefill batch. #new-seq: 2, #new-token: 1384, #cached-token: 284, token usage: 0.00, #running-req: 2, #queue-req: 0, 
[2025-08-25 18:26:34] INFO:     127.0.0.1:7932 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 18:26:34 TP0] Prefill batch. #new-seq: 2, #new-token: 1386, #cached-token: 282, token usage: 0.00, #running-req: 2, #queue-req: 0, 
[2025-08-25 18:26:35 TP0] Decode batch. #running-req: 4, #token: 2956, token usage: 0.01, gen throughput (token/s): 5.36, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:26:36 TP0] Decode batch. #running-req: 4, #token: 3116, token usage: 0.01, gen throughput (token/s): 153.87, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:26:37 TP0] Decode batch. #running-req: 4, #token: 3276, token usage: 0.01, gen throughput (token/s): 153.22, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:26:38 TP0] Decode batch. #running-req: 4, #token: 3436, token usage: 0.01, gen throughput (token/s): 151.82, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:26:38] INFO:     127.0.0.1:7938 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 18:26:38] INFO:     127.0.0.1:7916 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 18:26:38] INFO:     127.0.0.1:7922 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 18:26:38] INFO:     127.0.0.1:7932 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 18:26:38 TP0] Prefill batch. #new-seq: 2, #new-token: 1385, #cached-token: 283, token usage: 0.00, #running-req: 2, #queue-req: 0, 
[2025-08-25 18:26:39 TP0] Decode batch. #running-req: 2, #token: 1570, token usage: 0.00, gen throughput (token/s): 86.18, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:26:40 TP0] Decode batch. #running-req: 2, #token: 1650, token usage: 0.01, gen throughput (token/s): 78.44, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:26:41 TP0] Decode batch. #running-req: 2, #token: 1730, token usage: 0.01, gen throughput (token/s): 78.17, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:26:42 TP0] Decode batch. #running-req: 2, #token: 1810, token usage: 0.01, gen throughput (token/s): 79.03, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:26:43] INFO:     127.0.0.1:7938 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 18:26:43] INFO:     127.0.0.1:7916 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 18:26:43 TP0] Prefill batch. #new-seq: 3, #new-token: 3, #cached-token: 402, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-08-25 18:26:43 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 134, token usage: 0.00, #running-req: 3, #queue-req: 0, 
[2025-08-25 18:26:43 TP0] Decode batch. #running-req: 4, #token: 259, token usage: 0.00, gen throughput (token/s): 12.21, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:26:43 TP0] Decode batch. #running-req: 4, #token: 419, token usage: 0.00, gen throughput (token/s): 881.36, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:26:43 TP0] Decode batch. #running-req: 4, #token: 579, token usage: 0.00, gen throughput (token/s): 861.74, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:26:43 TP0] Decode batch. #running-req: 4, #token: 739, token usage: 0.00, gen throughput (token/s): 885.37, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:26:44 TP0] Decode batch. #running-req: 4, #token: 899, token usage: 0.00, gen throughput (token/s): 868.12, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:26:44 TP0] Decode batch. #running-req: 4, #token: 1059, token usage: 0.00, gen throughput (token/s): 853.42, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:26:44 TP0] Decode batch. #running-req: 4, #token: 1219, token usage: 0.00, gen throughput (token/s): 839.51, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:26:44 TP0] Decode batch. #running-req: 4, #token: 1379, token usage: 0.00, gen throughput (token/s): 846.11, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:26:44 TP0] Decode batch. #running-req: 4, #token: 1539, token usage: 0.00, gen throughput (token/s): 861.27, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:26:44 TP0] Decode batch. #running-req: 4, #token: 1699, token usage: 0.00, gen throughput (token/s): 857.92, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:26:45 TP0] Decode batch. #running-req: 4, #token: 1859, token usage: 0.00, gen throughput (token/s): 837.84, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:26:45 TP0] Decode batch. #running-req: 4, #token: 2019, token usage: 0.00, gen throughput (token/s): 850.15, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:26:45 TP0] Decode batch. #running-req: 4, #token: 2179, token usage: 0.00, gen throughput (token/s): 841.76, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:26:45 TP0] Decode batch. #running-req: 4, #token: 2339, token usage: 0.00, gen throughput (token/s): 853.48, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:26:45 TP0] Decode batch. #running-req: 4, #token: 2499, token usage: 0.00, gen throughput (token/s): 873.89, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:26:46 TP0] Decode batch. #running-req: 4, #token: 2659, token usage: 0.00, gen throughput (token/s): 847.68, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:26:46 TP0] Decode batch. #running-req: 4, #token: 2819, token usage: 0.00, gen throughput (token/s): 853.38, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:26:46] INFO:     127.0.0.1:39904 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 18:26:46] INFO:     127.0.0.1:39916 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 18:26:46] INFO:     127.0.0.1:39924 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 18:26:46] INFO:     127.0.0.1:39930 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 18:26:46 TP0] Prefill batch. #new-seq: 4, #new-token: 4, #cached-token: 536, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-08-25 18:26:46 TP0] Decode batch. #running-req: 4, #token: 179, token usage: 0.00, gen throughput (token/s): 641.99, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:26:46 TP0] Decode batch. #running-req: 4, #token: 339, token usage: 0.00, gen throughput (token/s): 875.63, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:26:46 TP0] Decode batch. #running-req: 4, #token: 499, token usage: 0.00, gen throughput (token/s): 882.54, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:26:47 TP0] Decode batch. #running-req: 4, #token: 659, token usage: 0.00, gen throughput (token/s): 868.48, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:26:47 TP0] Decode batch. #running-req: 4, #token: 819, token usage: 0.00, gen throughput (token/s): 865.38, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:26:47 TP0] Decode batch. #running-req: 4, #token: 979, token usage: 0.00, gen throughput (token/s): 869.95, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:26:47 TP0] Decode batch. #running-req: 4, #token: 1139, token usage: 0.00, gen throughput (token/s): 879.90, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:26:47 TP0] Decode batch. #running-req: 4, #token: 1299, token usage: 0.00, gen throughput (token/s): 869.22, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:26:47 TP0] Decode batch. #running-req: 4, #token: 1459, token usage: 0.00, gen throughput (token/s): 847.98, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:26:48 TP0] Decode batch. #running-req: 4, #token: 1619, token usage: 0.00, gen throughput (token/s): 841.15, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:26:48 TP0] Decode batch. #running-req: 4, #token: 1779, token usage: 0.00, gen throughput (token/s): 877.37, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:26:48 TP0] Decode batch. #running-req: 4, #token: 1939, token usage: 0.00, gen throughput (token/s): 844.61, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:26:48 TP0] Decode batch. #running-req: 4, #token: 2099, token usage: 0.00, gen throughput (token/s): 860.60, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:26:48 TP0] Decode batch. #running-req: 4, #token: 2259, token usage: 0.00, gen throughput (token/s): 858.62, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:26:49 TP0] Decode batch. #running-req: 4, #token: 2419, token usage: 0.00, gen throughput (token/s): 855.84, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:26:49 TP0] Decode batch. #running-req: 4, #token: 2579, token usage: 0.00, gen throughput (token/s): 854.61, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:26:49 TP0] Decode batch. #running-req: 4, #token: 2739, token usage: 0.00, gen throughput (token/s): 854.60, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:26:49 TP0] Decode batch. #running-req: 4, #token: 2899, token usage: 0.00, gen throughput (token/s): 868.87, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:26:49] INFO:     127.0.0.1:39904 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 18:26:49] INFO:     127.0.0.1:39930 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 18:26:49] INFO:     127.0.0.1:39916 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 18:26:49] INFO:     127.0.0.1:39924 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 18:26:49 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 134, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-08-25 18:26:49 TP0] Prefill batch. #new-seq: 3, #new-token: 3, #cached-token: 402, token usage: 0.00, #running-req: 1, #queue-req: 0, 
[2025-08-25 18:26:49 TP0] Decode batch. #running-req: 4, #token: 259, token usage: 0.00, gen throughput (token/s): 580.28, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:26:50 TP0] Decode batch. #running-req: 4, #token: 419, token usage: 0.00, gen throughput (token/s): 857.68, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:26:50 TP0] Decode batch. #running-req: 4, #token: 579, token usage: 0.00, gen throughput (token/s): 858.86, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:26:50 TP0] Decode batch. #running-req: 4, #token: 739, token usage: 0.00, gen throughput (token/s): 832.01, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:26:50 TP0] Decode batch. #running-req: 4, #token: 899, token usage: 0.00, gen throughput (token/s): 870.48, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:26:50 TP0] Decode batch. #running-req: 4, #token: 1059, token usage: 0.00, gen throughput (token/s): 859.03, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:26:51 TP0] Decode batch. #running-req: 4, #token: 1219, token usage: 0.00, gen throughput (token/s): 849.61, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:26:51 TP0] Decode batch. #running-req: 4, #token: 1379, token usage: 0.00, gen throughput (token/s): 866.14, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:26:51 TP0] Decode batch. #running-req: 4, #token: 1539, token usage: 0.00, gen throughput (token/s): 868.75, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:26:51 TP0] Decode batch. #running-req: 4, #token: 1699, token usage: 0.00, gen throughput (token/s): 861.76, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:26:51 TP0] Decode batch. #running-req: 4, #token: 1859, token usage: 0.00, gen throughput (token/s): 865.08, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:26:52 TP0] Decode batch. #running-req: 4, #token: 2019, token usage: 0.00, gen throughput (token/s): 851.88, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:26:52 TP0] Decode batch. #running-req: 4, #token: 2179, token usage: 0.00, gen throughput (token/s): 855.56, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:26:52 TP0] Decode batch. #running-req: 4, #token: 2339, token usage: 0.00, gen throughput (token/s): 849.86, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:26:52 TP0] Decode batch. #running-req: 4, #token: 2499, token usage: 0.00, gen throughput (token/s): 871.00, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:26:52 TP0] Decode batch. #running-req: 4, #token: 2659, token usage: 0.00, gen throughput (token/s): 848.20, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:26:52 TP0] Decode batch. #running-req: 4, #token: 2819, token usage: 0.00, gen throughput (token/s): 841.02, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:26:53] INFO:     127.0.0.1:39930 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 18:26:53] INFO:     127.0.0.1:39904 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 18:26:53] INFO:     127.0.0.1:39916 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 18:26:53] INFO:     127.0.0.1:39924 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 18:26:53 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 134, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-08-25 18:26:53 TP0] Prefill batch. #new-seq: 3, #new-token: 3, #cached-token: 402, token usage: 0.00, #running-req: 1, #queue-req: 0, 
[2025-08-25 18:26:53 TP0] Decode batch. #running-req: 4, #token: 179, token usage: 0.00, gen throughput (token/s): 570.88, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:26:53 TP0] Decode batch. #running-req: 4, #token: 339, token usage: 0.00, gen throughput (token/s): 884.09, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:26:53 TP0] Decode batch. #running-req: 4, #token: 499, token usage: 0.00, gen throughput (token/s): 871.76, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:26:53 TP0] Decode batch. #running-req: 4, #token: 659, token usage: 0.00, gen throughput (token/s): 869.37, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:26:53 TP0] Decode batch. #running-req: 4, #token: 819, token usage: 0.00, gen throughput (token/s): 855.15, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:26:54 TP0] Decode batch. #running-req: 4, #token: 979, token usage: 0.00, gen throughput (token/s): 865.53, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:26:54 TP0] Decode batch. #running-req: 4, #token: 1139, token usage: 0.00, gen throughput (token/s): 848.64, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:26:54 TP0] Decode batch. #running-req: 4, #token: 1299, token usage: 0.00, gen throughput (token/s): 870.14, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:26:54 TP0] Decode batch. #running-req: 4, #token: 1459, token usage: 0.00, gen throughput (token/s): 885.83, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:26:54 TP0] Decode batch. #running-req: 4, #token: 1619, token usage: 0.00, gen throughput (token/s): 866.27, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:26:55 TP0] Decode batch. #running-req: 4, #token: 1779, token usage: 0.00, gen throughput (token/s): 844.08, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:26:55 TP0] Decode batch. #running-req: 4, #token: 1939, token usage: 0.00, gen throughput (token/s): 856.03, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:26:55 TP0] Decode batch. #running-req: 4, #token: 2099, token usage: 0.00, gen throughput (token/s): 877.84, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:26:55 TP0] Decode batch. #running-req: 4, #token: 2259, token usage: 0.00, gen throughput (token/s): 852.27, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:26:55 TP0] Decode batch. #running-req: 4, #token: 2419, token usage: 0.00, gen throughput (token/s): 859.48, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:26:55 TP0] Decode batch. #running-req: 4, #token: 2579, token usage: 0.00, gen throughput (token/s): 843.80, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:26:56 TP0] Decode batch. #running-req: 4, #token: 2739, token usage: 0.00, gen throughput (token/s): 852.70, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:26:56 TP0] Decode batch. #running-req: 4, #token: 2899, token usage: 0.00, gen throughput (token/s): 877.13, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:26:56] INFO:     127.0.0.1:39930 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 18:26:56] INFO:     127.0.0.1:39904 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 18:26:56] INFO:     127.0.0.1:39916 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 18:26:56] INFO:     127.0.0.1:39924 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 18:26:56 TP0] Prefill batch. #new-seq: 4, #new-token: 2800, #cached-token: 496, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-08-25 18:26:57] INFO:     127.0.0.1:33462 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 18:26:57] INFO:     127.0.0.1:33470 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 18:26:57] INFO:     127.0.0.1:33474 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 18:26:57] INFO:     127.0.0.1:33484 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 18:26:57 TP0] Prefill batch. #new-seq: 2, #new-token: 1400, #cached-token: 248, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-08-25 18:26:57 TP0] Prefill batch. #new-seq: 2, #new-token: 1400, #cached-token: 248, token usage: 0.00, #running-req: 2, #queue-req: 0, 
[2025-08-25 18:26:58] INFO:     127.0.0.1:33462 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 18:26:58] INFO:     127.0.0.1:33484 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 18:26:58] INFO:     127.0.0.1:33470 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 18:26:58] INFO:     127.0.0.1:33474 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 18:26:58 TP0] Prefill batch. #new-seq: 4, #new-token: 2800, #cached-token: 496, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-08-25 18:26:59] INFO:     127.0.0.1:33484 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 18:26:59] INFO:     127.0.0.1:33462 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 18:26:59] INFO:     127.0.0.1:33474 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 18:26:59] INFO:     127.0.0.1:33470 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 18:26:59 TP0] Prefill batch. #new-seq: 1, #new-token: 700, #cached-token: 124, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-08-25 18:26:59 TP0] Prefill batch. #new-seq: 3, #new-token: 2100, #cached-token: 372, token usage: 0.00, #running-req: 1, #queue-req: 0, 
[2025-08-25 18:27:00] INFO:     127.0.0.1:33462 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 18:27:00 TP0] Prefill batch. #new-seq: 1, #new-token: 692, #cached-token: 141, token usage: 0.00, #running-req: 3, #queue-req: 0, 
[2025-08-25 18:27:00] INFO:     127.0.0.1:33484 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 18:27:00] INFO:     127.0.0.1:33470 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 18:27:00] INFO:     127.0.0.1:33474 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 18:27:00 TP0] Prefill batch. #new-seq: 3, #new-token: 2034, #cached-token: 465, token usage: 0.00, #running-req: 4, #queue-req: 0, 
[2025-08-25 18:27:01 TP0] Decode batch. #running-req: 4, #token: 3027, token usage: 0.01, gen throughput (token/s): 7.12, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:27:02 TP0] Decode batch. #running-req: 4, #token: 3187, token usage: 0.01, gen throughput (token/s): 153.00, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:27:03 TP0] Decode batch. #running-req: 4, #token: 3347, token usage: 0.01, gen throughput (token/s): 151.39, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:27:04 TP0] Decode batch. #running-req: 4, #token: 3507, token usage: 0.01, gen throughput (token/s): 151.53, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:27:05] INFO:     127.0.0.1:33462 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 18:27:05] INFO:     127.0.0.1:33474 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 18:27:05] INFO:     127.0.0.1:33484 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 18:27:05] INFO:     127.0.0.1:33470 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 18:27:05 TP0] Prefill batch. #new-seq: 3, #new-token: 2006, #cached-token: 493, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-08-25 18:27:05 TP0] Prefill batch. #new-seq: 1, #new-token: 639, #cached-token: 194, token usage: 0.01, #running-req: 3, #queue-req: 0, 
[2025-08-25 18:27:06 TP0] Decode batch. #running-req: 4, #token: 3071, token usage: 0.01, gen throughput (token/s): 91.32, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:27:07 TP0] Decode batch. #running-req: 4, #token: 3231, token usage: 0.01, gen throughput (token/s): 152.29, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:27:08 TP0] Decode batch. #running-req: 4, #token: 3391, token usage: 0.01, gen throughput (token/s): 151.16, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:27:09] INFO:     127.0.0.1:33484 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 18:27:09] INFO:     127.0.0.1:33462 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 18:27:09] INFO:     127.0.0.1:33470 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 18:27:09] INFO:     127.0.0.1:33474 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 18:27:09 TP0] Prefill batch. #new-seq: 4, #new-token: 2675, #cached-token: 657, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-08-25 18:27:10 TP0] Decode batch. #running-req: 4, #token: 2889, token usage: 0.01, gen throughput (token/s): 90.65, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:27:11 TP0] Decode batch. #running-req: 4, #token: 3049, token usage: 0.01, gen throughput (token/s): 153.94, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:27:12 TP0] Decode batch. #running-req: 4, #token: 3209, token usage: 0.01, gen throughput (token/s): 151.51, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:27:13 TP0] Decode batch. #running-req: 4, #token: 3369, token usage: 0.01, gen throughput (token/s): 151.22, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:27:14] INFO:     127.0.0.1:33484 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 18:27:14] INFO:     127.0.0.1:33462 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 18:27:14] INFO:     127.0.0.1:33470 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 18:27:14] INFO:     127.0.0.1:33474 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 18:27:14 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 196, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-08-25 18:27:14 TP0] Prefill batch. #new-seq: 3, #new-token: 3, #cached-token: 588, token usage: 0.00, #running-req: 1, #queue-req: 0, 
[2025-08-25 18:27:14 TP0] Decode batch. #running-req: 4, #token: 321, token usage: 0.00, gen throughput (token/s): 8.79, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:27:14 TP0] Decode batch. #running-req: 4, #token: 481, token usage: 0.00, gen throughput (token/s): 877.76, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:27:14 TP0] Decode batch. #running-req: 4, #token: 641, token usage: 0.00, gen throughput (token/s): 876.52, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:27:15 TP0] Decode batch. #running-req: 4, #token: 801, token usage: 0.00, gen throughput (token/s): 856.14, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:27:15 TP0] Decode batch. #running-req: 4, #token: 961, token usage: 0.00, gen throughput (token/s): 885.20, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:27:15 TP0] Decode batch. #running-req: 4, #token: 1121, token usage: 0.00, gen throughput (token/s): 872.47, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:27:15 TP0] Decode batch. #running-req: 4, #token: 1281, token usage: 0.00, gen throughput (token/s): 871.26, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:27:15 TP0] Decode batch. #running-req: 4, #token: 1441, token usage: 0.00, gen throughput (token/s): 875.94, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:27:16 TP0] Decode batch. #running-req: 4, #token: 1601, token usage: 0.00, gen throughput (token/s): 874.19, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:27:16 TP0] Decode batch. #running-req: 4, #token: 1761, token usage: 0.00, gen throughput (token/s): 854.08, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:27:16 TP0] Decode batch. #running-req: 4, #token: 1921, token usage: 0.00, gen throughput (token/s): 850.73, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:27:16 TP0] Decode batch. #running-req: 4, #token: 2081, token usage: 0.00, gen throughput (token/s): 862.30, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:27:16 TP0] Decode batch. #running-req: 4, #token: 2241, token usage: 0.00, gen throughput (token/s): 956.85, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:27:16 TP0] Decode batch. #running-req: 4, #token: 2401, token usage: 0.00, gen throughput (token/s): 878.65, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:27:17 TP0] Decode batch. #running-req: 4, #token: 2561, token usage: 0.00, gen throughput (token/s): 850.30, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:27:17 TP0] Decode batch. #running-req: 4, #token: 2721, token usage: 0.00, gen throughput (token/s): 877.09, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:27:17 TP0] Decode batch. #running-req: 4, #token: 2881, token usage: 0.00, gen throughput (token/s): 862.56, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:27:17] INFO:     127.0.0.1:35146 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 18:27:17] INFO:     127.0.0.1:35168 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 18:27:17] INFO:     127.0.0.1:35152 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 18:27:17] INFO:     127.0.0.1:35178 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 18:27:17 TP0] Prefill batch. #new-seq: 3, #new-token: 3, #cached-token: 588, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-08-25 18:27:17 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 196, token usage: 0.00, #running-req: 3, #queue-req: 0, 
[2025-08-25 18:27:17 TP0] Decode batch. #running-req: 4, #token: 241, token usage: 0.00, gen throughput (token/s): 546.20, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:27:17 TP0] Decode batch. #running-req: 4, #token: 401, token usage: 0.00, gen throughput (token/s): 865.79, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:27:18 TP0] Decode batch. #running-req: 4, #token: 561, token usage: 0.00, gen throughput (token/s): 877.84, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:27:18 TP0] Decode batch. #running-req: 4, #token: 721, token usage: 0.00, gen throughput (token/s): 869.13, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:27:18 TP0] Decode batch. #running-req: 4, #token: 881, token usage: 0.00, gen throughput (token/s): 861.92, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:27:18 TP0] Decode batch. #running-req: 4, #token: 1041, token usage: 0.00, gen throughput (token/s): 868.81, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:27:18 TP0] Decode batch. #running-req: 4, #token: 1201, token usage: 0.00, gen throughput (token/s): 855.53, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:27:19 TP0] Decode batch. #running-req: 4, #token: 1361, token usage: 0.00, gen throughput (token/s): 879.15, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:27:19 TP0] Decode batch. #running-req: 4, #token: 1521, token usage: 0.00, gen throughput (token/s): 901.51, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:27:19 TP0] Decode batch. #running-req: 4, #token: 1681, token usage: 0.00, gen throughput (token/s): 874.92, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:27:19 TP0] Decode batch. #running-req: 4, #token: 1841, token usage: 0.00, gen throughput (token/s): 841.28, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:27:19 TP0] Decode batch. #running-req: 4, #token: 2001, token usage: 0.00, gen throughput (token/s): 864.82, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:27:20 TP0] Decode batch. #running-req: 4, #token: 2161, token usage: 0.00, gen throughput (token/s): 873.85, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:27:20 TP0] Decode batch. #running-req: 4, #token: 2321, token usage: 0.00, gen throughput (token/s): 843.31, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:27:20 TP0] Decode batch. #running-req: 4, #token: 2481, token usage: 0.00, gen throughput (token/s): 841.25, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:27:20 TP0] Decode batch. #running-req: 4, #token: 2641, token usage: 0.00, gen throughput (token/s): 917.39, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:27:20 TP0] Decode batch. #running-req: 4, #token: 2801, token usage: 0.00, gen throughput (token/s): 842.24, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:27:20 TP0] Decode batch. #running-req: 4, #token: 2961, token usage: 0.00, gen throughput (token/s): 861.86, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:27:20] INFO:     127.0.0.1:35146 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 18:27:20] INFO:     127.0.0.1:35178 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 18:27:20] INFO:     127.0.0.1:35152 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 18:27:20] INFO:     127.0.0.1:35168 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 18:27:21 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 196, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-08-25 18:27:21 TP0] Prefill batch. #new-seq: 3, #new-token: 3, #cached-token: 588, token usage: 0.00, #running-req: 1, #queue-req: 0, 
[2025-08-25 18:27:21 TP0] Decode batch. #running-req: 4, #token: 321, token usage: 0.00, gen throughput (token/s): 556.99, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:27:21 TP0] Decode batch. #running-req: 4, #token: 481, token usage: 0.00, gen throughput (token/s): 856.01, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:27:21 TP0] Decode batch. #running-req: 4, #token: 641, token usage: 0.00, gen throughput (token/s): 841.92, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:27:21 TP0] Decode batch. #running-req: 4, #token: 801, token usage: 0.00, gen throughput (token/s): 861.00, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:27:21 TP0] Decode batch. #running-req: 4, #token: 961, token usage: 0.00, gen throughput (token/s): 854.72, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:27:22 TP0] Decode batch. #running-req: 4, #token: 1121, token usage: 0.00, gen throughput (token/s): 859.74, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:27:22 TP0] Decode batch. #running-req: 4, #token: 1281, token usage: 0.00, gen throughput (token/s): 877.52, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:27:22 TP0] Decode batch. #running-req: 4, #token: 1441, token usage: 0.00, gen throughput (token/s): 854.39, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:27:22 TP0] Decode batch. #running-req: 4, #token: 1601, token usage: 0.00, gen throughput (token/s): 871.16, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:27:22 TP0] Decode batch. #running-req: 4, #token: 1761, token usage: 0.00, gen throughput (token/s): 864.28, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:27:23 TP0] Decode batch. #running-req: 4, #token: 1921, token usage: 0.00, gen throughput (token/s): 858.67, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:27:23 TP0] Decode batch. #running-req: 4, #token: 2081, token usage: 0.00, gen throughput (token/s): 848.54, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:27:23 TP0] Decode batch. #running-req: 4, #token: 2241, token usage: 0.00, gen throughput (token/s): 867.10, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:27:23 TP0] Decode batch. #running-req: 4, #token: 2401, token usage: 0.00, gen throughput (token/s): 897.61, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:27:23 TP0] Decode batch. #running-req: 4, #token: 2561, token usage: 0.00, gen throughput (token/s): 894.52, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:27:24 TP0] Decode batch. #running-req: 4, #token: 2721, token usage: 0.00, gen throughput (token/s): 886.63, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:27:24 TP0] Decode batch. #running-req: 4, #token: 2881, token usage: 0.00, gen throughput (token/s): 867.38, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:27:24] INFO:     127.0.0.1:35178 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 18:27:24] INFO:     127.0.0.1:35146 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 18:27:24] INFO:     127.0.0.1:35152 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 18:27:24] INFO:     127.0.0.1:35168 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 18:27:24 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 196, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-08-25 18:27:24 TP0] Prefill batch. #new-seq: 3, #new-token: 3, #cached-token: 588, token usage: 0.00, #running-req: 1, #queue-req: 0, 
[2025-08-25 18:27:24 TP0] Decode batch. #running-req: 4, #token: 241, token usage: 0.00, gen throughput (token/s): 581.47, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:27:24 TP0] Decode batch. #running-req: 4, #token: 401, token usage: 0.00, gen throughput (token/s): 887.61, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:27:24 TP0] Decode batch. #running-req: 4, #token: 561, token usage: 0.00, gen throughput (token/s): 916.75, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:27:25 TP0] Decode batch. #running-req: 4, #token: 721, token usage: 0.00, gen throughput (token/s): 840.64, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:27:25 TP0] Decode batch. #running-req: 4, #token: 881, token usage: 0.00, gen throughput (token/s): 844.19, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:27:25 TP0] Decode batch. #running-req: 4, #token: 1041, token usage: 0.00, gen throughput (token/s): 864.41, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:27:25 TP0] Decode batch. #running-req: 4, #token: 1201, token usage: 0.00, gen throughput (token/s): 864.65, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:27:25 TP0] Decode batch. #running-req: 4, #token: 1361, token usage: 0.00, gen throughput (token/s): 869.96, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:27:25 TP0] Decode batch. #running-req: 4, #token: 1521, token usage: 0.00, gen throughput (token/s): 863.93, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:27:26 TP0] Decode batch. #running-req: 4, #token: 1681, token usage: 0.00, gen throughput (token/s): 881.25, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:27:26 TP0] Decode batch. #running-req: 4, #token: 1841, token usage: 0.00, gen throughput (token/s): 850.20, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:27:26 TP0] Decode batch. #running-req: 4, #token: 2001, token usage: 0.00, gen throughput (token/s): 934.34, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:27:26 TP0] Decode batch. #running-req: 4, #token: 2161, token usage: 0.00, gen throughput (token/s): 870.51, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:27:26 TP0] Decode batch. #running-req: 4, #token: 2321, token usage: 0.00, gen throughput (token/s): 871.50, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:27:27 TP0] Decode batch. #running-req: 4, #token: 2481, token usage: 0.00, gen throughput (token/s): 864.80, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:27:27 TP0] Decode batch. #running-req: 4, #token: 2641, token usage: 0.00, gen throughput (token/s): 959.85, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:27:27 TP0] Decode batch. #running-req: 4, #token: 2801, token usage: 0.00, gen throughput (token/s): 958.64, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:27:27 TP0] Decode batch. #running-req: 4, #token: 2961, token usage: 0.00, gen throughput (token/s): 951.82, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:27:27] INFO:     127.0.0.1:35178 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 18:27:27] INFO:     127.0.0.1:35146 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 18:27:27] INFO:     127.0.0.1:35152 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 18:27:27] INFO:     127.0.0.1:35168 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 18:27:27 TP0] Prefill batch. #new-seq: 4, #new-token: 2800, #cached-token: 744, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-08-25 18:27:28] INFO:     127.0.0.1:11062 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 18:27:28] INFO:     127.0.0.1:11070 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 18:27:28] INFO:     127.0.0.1:11084 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 18:27:28] INFO:     127.0.0.1:11098 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 18:27:28 TP0] Prefill batch. #new-seq: 2, #new-token: 1400, #cached-token: 372, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-08-25 18:27:28 TP0] Prefill batch. #new-seq: 2, #new-token: 1400, #cached-token: 372, token usage: 0.00, #running-req: 2, #queue-req: 0, 
[2025-08-25 18:27:29] INFO:     127.0.0.1:11062 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 18:27:29] INFO:     127.0.0.1:11098 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 18:27:29] INFO:     127.0.0.1:11070 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 18:27:29 TP0] Prefill batch. #new-seq: 2, #new-token: 1400, #cached-token: 372, token usage: 0.00, #running-req: 2, #queue-req: 0, 
[2025-08-25 18:27:29] INFO:     127.0.0.1:11084 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 18:27:29 TP0] Prefill batch. #new-seq: 2, #new-token: 1400, #cached-token: 372, token usage: 0.00, #running-req: 4, #queue-req: 0, 
[2025-08-25 18:27:30] INFO:     127.0.0.1:11098 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 18:27:30] INFO:     127.0.0.1:11062 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 18:27:30 TP0] Prefill batch. #new-seq: 2, #new-token: 1400, #cached-token: 372, token usage: 0.00, #running-req: 2, #queue-req: 0, 
[2025-08-25 18:27:30] INFO:     127.0.0.1:11084 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 18:27:30] INFO:     127.0.0.1:11070 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 18:27:30 TP0] Prefill batch. #new-seq: 2, #new-token: 1400, #cached-token: 372, token usage: 0.00, #running-req: 4, #queue-req: 0, 
[2025-08-25 18:27:30] INFO:     127.0.0.1:11098 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 18:27:30] INFO:     127.0.0.1:11062 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 18:27:31] INFO:     127.0.0.1:11070 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 18:27:31 TP0] Prefill batch. #new-seq: 2, #new-token: 1400, #cached-token: 390, token usage: 0.00, #running-req: 2, #queue-req: 0, 
[2025-08-25 18:27:31] INFO:     127.0.0.1:11084 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 18:27:31 TP0] Prefill batch. #new-seq: 2, #new-token: 1400, #cached-token: 390, token usage: 0.00, #running-req: 4, #queue-req: 0, 
[2025-08-25 18:27:32 TP0] Decode batch. #running-req: 4, #token: 3028, token usage: 0.01, gen throughput (token/s): 8.24, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:27:33 TP0] Decode batch. #running-req: 4, #token: 3188, token usage: 0.01, gen throughput (token/s): 152.08, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:27:34 TP0] Decode batch. #running-req: 4, #token: 3348, token usage: 0.01, gen throughput (token/s): 152.71, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:27:35 TP0] Decode batch. #running-req: 4, #token: 3508, token usage: 0.01, gen throughput (token/s): 153.45, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:27:36] INFO:     127.0.0.1:11098 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 18:27:36] INFO:     127.0.0.1:11062 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 18:27:36] INFO:     127.0.0.1:11070 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 18:27:36] INFO:     127.0.0.1:11084 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 18:27:36 TP0] Prefill batch. #new-seq: 2, #new-token: 1377, #cached-token: 413, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-08-25 18:27:36 TP0] Decode batch. #running-req: 2, #token: 1635, token usage: 0.01, gen throughput (token/s): 82.52, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:27:37 TP0] Decode batch. #running-req: 2, #token: 1715, token usage: 0.01, gen throughput (token/s): 77.57, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:27:39 TP0] Decode batch. #running-req: 2, #token: 1795, token usage: 0.01, gen throughput (token/s): 77.13, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:27:40 TP0] Decode batch. #running-req: 2, #token: 1875, token usage: 0.01, gen throughput (token/s): 76.58, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:27:40] INFO:     127.0.0.1:11098 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 18:27:40] INFO:     127.0.0.1:11062 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 18:27:40 TP0] Prefill batch. #new-seq: 4, #new-token: 4, #cached-token: 688, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-08-25 18:27:40 TP0] Decode batch. #running-req: 4, #token: 297, token usage: 0.00, gen throughput (token/s): 12.35, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:27:40 TP0] Decode batch. #running-req: 4, #token: 457, token usage: 0.00, gen throughput (token/s): 872.57, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:27:40 TP0] Decode batch. #running-req: 4, #token: 617, token usage: 0.00, gen throughput (token/s): 850.44, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:27:41 TP0] Decode batch. #running-req: 4, #token: 777, token usage: 0.00, gen throughput (token/s): 843.86, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:27:41 TP0] Decode batch. #running-req: 4, #token: 937, token usage: 0.00, gen throughput (token/s): 863.70, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:27:41 TP0] Decode batch. #running-req: 4, #token: 1097, token usage: 0.00, gen throughput (token/s): 853.22, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:27:41 TP0] Decode batch. #running-req: 4, #token: 1257, token usage: 0.00, gen throughput (token/s): 861.48, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:27:41 TP0] Decode batch. #running-req: 4, #token: 1417, token usage: 0.00, gen throughput (token/s): 873.32, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:27:41 TP0] Decode batch. #running-req: 4, #token: 1577, token usage: 0.00, gen throughput (token/s): 849.88, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:27:42 TP0] Decode batch. #running-req: 4, #token: 1737, token usage: 0.00, gen throughput (token/s): 862.80, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:27:42 TP0] Decode batch. #running-req: 4, #token: 1897, token usage: 0.00, gen throughput (token/s): 853.77, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:27:42 TP0] Decode batch. #running-req: 4, #token: 2057, token usage: 0.00, gen throughput (token/s): 846.05, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:27:42 TP0] Decode batch. #running-req: 4, #token: 2217, token usage: 0.00, gen throughput (token/s): 853.82, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:27:42 TP0] Decode batch. #running-req: 4, #token: 2377, token usage: 0.00, gen throughput (token/s): 835.85, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:27:43 TP0] Decode batch. #running-req: 4, #token: 2537, token usage: 0.00, gen throughput (token/s): 878.31, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:27:43 TP0] Decode batch. #running-req: 4, #token: 2697, token usage: 0.00, gen throughput (token/s): 852.04, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:27:43 TP0] Decode batch. #running-req: 4, #token: 2857, token usage: 0.00, gen throughput (token/s): 849.12, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:27:43] INFO:     127.0.0.1:9488 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 18:27:43] INFO:     127.0.0.1:9496 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 18:27:43] INFO:     127.0.0.1:9502 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 18:27:43] INFO:     127.0.0.1:9516 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 18:27:43 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 172, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-08-25 18:27:43 TP0] Prefill batch. #new-seq: 3, #new-token: 3, #cached-token: 516, token usage: 0.00, #running-req: 1, #queue-req: 0, 
[2025-08-25 18:27:43 TP0] Decode batch. #running-req: 4, #token: 217, token usage: 0.00, gen throughput (token/s): 571.78, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:27:43 TP0] Decode batch. #running-req: 4, #token: 377, token usage: 0.00, gen throughput (token/s): 857.89, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:27:44 TP0] Decode batch. #running-req: 4, #token: 537, token usage: 0.00, gen throughput (token/s): 873.92, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:27:44 TP0] Decode batch. #running-req: 4, #token: 697, token usage: 0.00, gen throughput (token/s): 865.27, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:27:44 TP0] Decode batch. #running-req: 4, #token: 857, token usage: 0.00, gen throughput (token/s): 851.81, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:27:44 TP0] Decode batch. #running-req: 4, #token: 1017, token usage: 0.00, gen throughput (token/s): 850.56, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:27:44 TP0] Decode batch. #running-req: 4, #token: 1177, token usage: 0.00, gen throughput (token/s): 858.66, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:27:45 TP0] Decode batch. #running-req: 4, #token: 1337, token usage: 0.00, gen throughput (token/s): 883.69, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:27:45 TP0] Decode batch. #running-req: 4, #token: 1497, token usage: 0.00, gen throughput (token/s): 860.25, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:27:45 TP0] Decode batch. #running-req: 4, #token: 1657, token usage: 0.00, gen throughput (token/s): 872.48, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:27:45 TP0] Decode batch. #running-req: 4, #token: 1817, token usage: 0.00, gen throughput (token/s): 877.71, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:27:45 TP0] Decode batch. #running-req: 4, #token: 1977, token usage: 0.00, gen throughput (token/s): 860.28, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:27:45 TP0] Decode batch. #running-req: 4, #token: 2137, token usage: 0.00, gen throughput (token/s): 877.37, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:27:46 TP0] Decode batch. #running-req: 4, #token: 2297, token usage: 0.00, gen throughput (token/s): 863.15, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:27:46 TP0] Decode batch. #running-req: 4, #token: 2457, token usage: 0.00, gen throughput (token/s): 854.96, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:27:46 TP0] Decode batch. #running-req: 4, #token: 2617, token usage: 0.00, gen throughput (token/s): 856.90, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:27:46 TP0] Decode batch. #running-req: 4, #token: 2777, token usage: 0.00, gen throughput (token/s): 855.41, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:27:46 TP0] Decode batch. #running-req: 4, #token: 2937, token usage: 0.00, gen throughput (token/s): 868.75, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:27:46] INFO:     127.0.0.1:9516 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 18:27:46] INFO:     127.0.0.1:9488 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 18:27:46] INFO:     127.0.0.1:9496 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 18:27:46] INFO:     127.0.0.1:9502 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 18:27:46 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 172, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-08-25 18:27:47 TP0] Prefill batch. #new-seq: 3, #new-token: 3, #cached-token: 516, token usage: 0.00, #running-req: 1, #queue-req: 0, 
[2025-08-25 18:27:47 TP0] Decode batch. #running-req: 4, #token: 297, token usage: 0.00, gen throughput (token/s): 563.65, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:27:47 TP0] Decode batch. #running-req: 4, #token: 457, token usage: 0.00, gen throughput (token/s): 860.45, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:27:47 TP0] Decode batch. #running-req: 4, #token: 617, token usage: 0.00, gen throughput (token/s): 880.72, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:27:47 TP0] Decode batch. #running-req: 4, #token: 777, token usage: 0.00, gen throughput (token/s): 878.95, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:27:47 TP0] Decode batch. #running-req: 4, #token: 937, token usage: 0.00, gen throughput (token/s): 861.69, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:27:48 TP0] Decode batch. #running-req: 4, #token: 1097, token usage: 0.00, gen throughput (token/s): 851.91, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:27:48 TP0] Decode batch. #running-req: 4, #token: 1257, token usage: 0.00, gen throughput (token/s): 865.73, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:27:48 TP0] Decode batch. #running-req: 4, #token: 1417, token usage: 0.00, gen throughput (token/s): 850.04, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:27:48 TP0] Decode batch. #running-req: 4, #token: 1577, token usage: 0.00, gen throughput (token/s): 850.19, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:27:48 TP0] Decode batch. #running-req: 4, #token: 1737, token usage: 0.00, gen throughput (token/s): 866.29, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:27:49 TP0] Decode batch. #running-req: 4, #token: 1897, token usage: 0.00, gen throughput (token/s): 861.23, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:27:49 TP0] Decode batch. #running-req: 4, #token: 2057, token usage: 0.00, gen throughput (token/s): 854.38, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:27:49 TP0] Decode batch. #running-req: 4, #token: 2217, token usage: 0.00, gen throughput (token/s): 854.36, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:27:49 TP0] Decode batch. #running-req: 4, #token: 2377, token usage: 0.00, gen throughput (token/s): 856.43, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:27:49 TP0] Decode batch. #running-req: 4, #token: 2537, token usage: 0.00, gen throughput (token/s): 879.88, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:27:49 TP0] Decode batch. #running-req: 4, #token: 2697, token usage: 0.00, gen throughput (token/s): 861.09, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:27:50 TP0] Decode batch. #running-req: 4, #token: 2857, token usage: 0.00, gen throughput (token/s): 866.26, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:27:50] INFO:     127.0.0.1:9516 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 18:27:50] INFO:     127.0.0.1:9488 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 18:27:50] INFO:     127.0.0.1:9496 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 18:27:50] INFO:     127.0.0.1:9502 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 18:27:50 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 172, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-08-25 18:27:50 TP0] Prefill batch. #new-seq: 3, #new-token: 3, #cached-token: 516, token usage: 0.00, #running-req: 1, #queue-req: 0, 
[2025-08-25 18:27:50 TP0] Decode batch. #running-req: 4, #token: 217, token usage: 0.00, gen throughput (token/s): 564.33, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:27:50 TP0] Decode batch. #running-req: 4, #token: 377, token usage: 0.00, gen throughput (token/s): 863.59, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:27:50 TP0] Decode batch. #running-req: 4, #token: 537, token usage: 0.00, gen throughput (token/s): 873.34, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:27:50 TP0] Decode batch. #running-req: 4, #token: 697, token usage: 0.00, gen throughput (token/s): 872.83, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:27:51 TP0] Decode batch. #running-req: 4, #token: 857, token usage: 0.00, gen throughput (token/s): 843.08, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:27:51 TP0] Decode batch. #running-req: 4, #token: 1017, token usage: 0.00, gen throughput (token/s): 858.92, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:27:51 TP0] Decode batch. #running-req: 4, #token: 1177, token usage: 0.00, gen throughput (token/s): 851.39, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:27:51 TP0] Decode batch. #running-req: 4, #token: 1337, token usage: 0.00, gen throughput (token/s): 877.01, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:27:51 TP0] Decode batch. #running-req: 4, #token: 1497, token usage: 0.00, gen throughput (token/s): 849.71, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:27:52 TP0] Decode batch. #running-req: 4, #token: 1657, token usage: 0.00, gen throughput (token/s): 867.94, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:27:52 TP0] Decode batch. #running-req: 4, #token: 1817, token usage: 0.00, gen throughput (token/s): 869.55, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:27:52 TP0] Decode batch. #running-req: 4, #token: 1977, token usage: 0.00, gen throughput (token/s): 848.16, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:27:52 TP0] Decode batch. #running-req: 4, #token: 2137, token usage: 0.00, gen throughput (token/s): 861.24, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:27:52 TP0] Decode batch. #running-req: 4, #token: 2297, token usage: 0.00, gen throughput (token/s): 850.14, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:27:53 TP0] Decode batch. #running-req: 4, #token: 2457, token usage: 0.00, gen throughput (token/s): 833.75, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:27:53 TP0] Decode batch. #running-req: 4, #token: 2617, token usage: 0.00, gen throughput (token/s): 855.98, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:27:53 TP0] Decode batch. #running-req: 4, #token: 2777, token usage: 0.00, gen throughput (token/s): 843.38, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:27:53 TP0] Decode batch. #running-req: 4, #token: 2937, token usage: 0.00, gen throughput (token/s): 862.63, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:27:53] INFO:     127.0.0.1:9516 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 18:27:53] INFO:     127.0.0.1:9488 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 18:27:53] INFO:     127.0.0.1:9496 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 18:27:53] INFO:     127.0.0.1:9502 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 18:27:53 TP0] Prefill batch. #new-seq: 4, #new-token: 2800, #cached-token: 648, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-08-25 18:27:54] INFO:     127.0.0.1:20902 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 18:27:54] INFO:     127.0.0.1:20914 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 18:27:54] INFO:     127.0.0.1:20928 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 18:27:54] INFO:     127.0.0.1:20934 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 18:27:54 TP0] Prefill batch. #new-seq: 1, #new-token: 700, #cached-token: 162, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-08-25 18:27:54 TP0] Prefill batch. #new-seq: 3, #new-token: 2100, #cached-token: 486, token usage: 0.00, #running-req: 1, #queue-req: 0, 
[2025-08-25 18:27:55] INFO:     127.0.0.1:20934 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 18:27:55] INFO:     127.0.0.1:20902 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 18:27:55] INFO:     127.0.0.1:20914 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 18:27:55] INFO:     127.0.0.1:20928 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 18:27:55 TP0] Prefill batch. #new-seq: 1, #new-token: 700, #cached-token: 162, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-08-25 18:27:55 TP0] Prefill batch. #new-seq: 3, #new-token: 2100, #cached-token: 486, token usage: 0.00, #running-req: 1, #queue-req: 0, 
[2025-08-25 18:27:55] INFO:     127.0.0.1:20934 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 18:27:55 TP0] Prefill batch. #new-seq: 1, #new-token: 700, #cached-token: 162, token usage: 0.01, #running-req: 4, #queue-req: 0, 
[2025-08-25 18:27:56] INFO:     127.0.0.1:20928 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 18:27:56] INFO:     127.0.0.1:20902 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 18:27:56] INFO:     127.0.0.1:20914 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 18:27:56] INFO:     127.0.0.1:20934 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 18:27:56 TP0] Prefill batch. #new-seq: 3, #new-token: 2100, #cached-token: 486, token usage: 0.00, #running-req: 1, #queue-req: 0, 
[2025-08-25 18:27:57 TP0] Prefill batch. #new-seq: 1, #new-token: 693, #cached-token: 178, token usage: 0.01, #running-req: 4, #queue-req: 0, 
[2025-08-25 18:27:58] INFO:     127.0.0.1:20928 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 18:27:58] INFO:     127.0.0.1:20902 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 18:27:58] INFO:     127.0.0.1:20914 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 18:27:58 TP0] Prefill batch. #new-seq: 2, #new-token: 1396, #cached-token: 346, token usage: 0.00, #running-req: 1, #queue-req: 0, 
[2025-08-25 18:27:58 TP0] Decode batch. #running-req: 3, #token: 2307, token usage: 0.01, gen throughput (token/s): 3.41, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:27:59 TP0] Decode batch. #running-req: 3, #token: 2427, token usage: 0.01, gen throughput (token/s): 115.28, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:28:00 TP0] Decode batch. #running-req: 3, #token: 2547, token usage: 0.01, gen throughput (token/s): 115.53, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:28:01 TP0] Decode batch. #running-req: 3, #token: 2667, token usage: 0.01, gen throughput (token/s): 115.40, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:28:02] INFO:     127.0.0.1:20934 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 18:28:02] INFO:     127.0.0.1:20902 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 18:28:02] INFO:     127.0.0.1:20914 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 18:28:02 TP0] Prefill batch. #new-seq: 4, #new-token: 4, #cached-token: 616, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-08-25 18:28:02 TP0] Decode batch. #running-req: 4, #token: 279, token usage: 0.00, gen throughput (token/s): 17.38, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:28:03 TP0] Decode batch. #running-req: 4, #token: 439, token usage: 0.00, gen throughput (token/s): 851.00, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:28:03 TP0] Decode batch. #running-req: 4, #token: 599, token usage: 0.00, gen throughput (token/s): 841.20, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:28:03 TP0] Decode batch. #running-req: 4, #token: 759, token usage: 0.00, gen throughput (token/s): 853.53, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:28:03 TP0] Decode batch. #running-req: 4, #token: 919, token usage: 0.00, gen throughput (token/s): 855.80, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:28:03 TP0] Decode batch. #running-req: 4, #token: 1079, token usage: 0.00, gen throughput (token/s): 860.92, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:28:03 TP0] Decode batch. #running-req: 4, #token: 1239, token usage: 0.00, gen throughput (token/s): 856.81, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:28:04 TP0] Decode batch. #running-req: 4, #token: 1399, token usage: 0.00, gen throughput (token/s): 853.61, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:28:04 TP0] Decode batch. #running-req: 4, #token: 1559, token usage: 0.00, gen throughput (token/s): 864.02, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:28:04 TP0] Decode batch. #running-req: 4, #token: 1719, token usage: 0.00, gen throughput (token/s): 863.84, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:28:04 TP0] Decode batch. #running-req: 4, #token: 1879, token usage: 0.00, gen throughput (token/s): 852.35, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:28:04 TP0] Decode batch. #running-req: 4, #token: 2039, token usage: 0.00, gen throughput (token/s): 861.52, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:28:05 TP0] Decode batch. #running-req: 4, #token: 2199, token usage: 0.00, gen throughput (token/s): 862.30, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:28:05 TP0] Decode batch. #running-req: 4, #token: 2359, token usage: 0.00, gen throughput (token/s): 851.34, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:28:05 TP0] Decode batch. #running-req: 4, #token: 2519, token usage: 0.00, gen throughput (token/s): 869.82, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:28:05 TP0] Decode batch. #running-req: 4, #token: 2679, token usage: 0.00, gen throughput (token/s): 839.75, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:28:05 TP0] Decode batch. #running-req: 4, #token: 2839, token usage: 0.00, gen throughput (token/s): 838.65, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:28:05] INFO:     127.0.0.1:5266 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 18:28:05] INFO:     127.0.0.1:5274 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 18:28:05] INFO:     127.0.0.1:5278 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 18:28:05] INFO:     127.0.0.1:5290 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 18:28:05 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 154, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-08-25 18:28:05 TP0] Prefill batch. #new-seq: 3, #new-token: 3, #cached-token: 462, token usage: 0.00, #running-req: 1, #queue-req: 0, 
[2025-08-25 18:28:06 TP0] Decode batch. #running-req: 4, #token: 199, token usage: 0.00, gen throughput (token/s): 562.88, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:28:06 TP0] Decode batch. #running-req: 4, #token: 359, token usage: 0.00, gen throughput (token/s): 878.60, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:28:06 TP0] Decode batch. #running-req: 4, #token: 519, token usage: 0.00, gen throughput (token/s): 871.07, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:28:06 TP0] Decode batch. #running-req: 4, #token: 679, token usage: 0.00, gen throughput (token/s): 852.66, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:28:06 TP0] Decode batch. #running-req: 4, #token: 839, token usage: 0.00, gen throughput (token/s): 862.62, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:28:07 TP0] Decode batch. #running-req: 4, #token: 999, token usage: 0.00, gen throughput (token/s): 870.72, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:28:07 TP0] Decode batch. #running-req: 4, #token: 1159, token usage: 0.00, gen throughput (token/s): 858.66, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:28:07 TP0] Decode batch. #running-req: 4, #token: 1319, token usage: 0.00, gen throughput (token/s): 863.67, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:28:07 TP0] Decode batch. #running-req: 4, #token: 1479, token usage: 0.00, gen throughput (token/s): 837.97, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:28:07 TP0] Decode batch. #running-req: 4, #token: 1639, token usage: 0.00, gen throughput (token/s): 858.62, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:28:07 TP0] Decode batch. #running-req: 4, #token: 1799, token usage: 0.00, gen throughput (token/s): 857.55, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:28:08 TP0] Decode batch. #running-req: 4, #token: 1959, token usage: 0.00, gen throughput (token/s): 849.03, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:28:08 TP0] Decode batch. #running-req: 4, #token: 2119, token usage: 0.00, gen throughput (token/s): 853.51, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:28:08 TP0] Decode batch. #running-req: 4, #token: 2279, token usage: 0.00, gen throughput (token/s): 848.64, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:28:08 TP0] Decode batch. #running-req: 4, #token: 2439, token usage: 0.00, gen throughput (token/s): 839.66, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:28:08 TP0] Decode batch. #running-req: 4, #token: 2599, token usage: 0.00, gen throughput (token/s): 834.40, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:28:09 TP0] Decode batch. #running-req: 4, #token: 2759, token usage: 0.00, gen throughput (token/s): 844.74, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:28:09 TP0] Decode batch. #running-req: 4, #token: 2919, token usage: 0.00, gen throughput (token/s): 882.75, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:28:09] INFO:     127.0.0.1:5290 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 18:28:09] INFO:     127.0.0.1:5266 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 18:28:09] INFO:     127.0.0.1:5274 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 18:28:09] INFO:     127.0.0.1:5278 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 18:28:09 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 154, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-08-25 18:28:09 TP0] Prefill batch. #new-seq: 3, #new-token: 3, #cached-token: 462, token usage: 0.00, #running-req: 1, #queue-req: 0, 
[2025-08-25 18:28:09 TP0] Decode batch. #running-req: 4, #token: 279, token usage: 0.00, gen throughput (token/s): 564.53, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:28:09 TP0] Decode batch. #running-req: 4, #token: 439, token usage: 0.00, gen throughput (token/s): 858.71, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:28:09 TP0] Decode batch. #running-req: 4, #token: 599, token usage: 0.00, gen throughput (token/s): 869.21, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:28:10 TP0] Decode batch. #running-req: 4, #token: 759, token usage: 0.00, gen throughput (token/s): 839.38, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:28:10 TP0] Decode batch. #running-req: 4, #token: 919, token usage: 0.00, gen throughput (token/s): 881.90, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:28:10 TP0] Decode batch. #running-req: 4, #token: 1079, token usage: 0.00, gen throughput (token/s): 854.82, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:28:10 TP0] Decode batch. #running-req: 4, #token: 1239, token usage: 0.00, gen throughput (token/s): 869.27, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:28:10 TP0] Decode batch. #running-req: 4, #token: 1399, token usage: 0.00, gen throughput (token/s): 877.84, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:28:11 TP0] Decode batch. #running-req: 4, #token: 1559, token usage: 0.00, gen throughput (token/s): 890.88, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:28:11 TP0] Decode batch. #running-req: 4, #token: 1719, token usage: 0.00, gen throughput (token/s): 913.59, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:28:11 TP0] Decode batch. #running-req: 4, #token: 1879, token usage: 0.00, gen throughput (token/s): 888.73, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:28:11 TP0] Decode batch. #running-req: 4, #token: 2039, token usage: 0.00, gen throughput (token/s): 896.01, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:28:11 TP0] Decode batch. #running-req: 4, #token: 2199, token usage: 0.00, gen throughput (token/s): 894.92, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:28:11 TP0] Decode batch. #running-req: 4, #token: 2359, token usage: 0.00, gen throughput (token/s): 892.49, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:28:12 TP0] Decode batch. #running-req: 4, #token: 2519, token usage: 0.00, gen throughput (token/s): 881.39, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:28:12 TP0] Decode batch. #running-req: 4, #token: 2679, token usage: 0.00, gen throughput (token/s): 879.92, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:28:12 TP0] Decode batch. #running-req: 4, #token: 2839, token usage: 0.00, gen throughput (token/s): 860.41, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:28:12] INFO:     127.0.0.1:5290 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 18:28:12] INFO:     127.0.0.1:5266 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 18:28:12] INFO:     127.0.0.1:5274 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 18:28:12] INFO:     127.0.0.1:5278 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 18:28:12 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 154, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-08-25 18:28:12 TP0] Prefill batch. #new-seq: 3, #new-token: 3, #cached-token: 462, token usage: 0.00, #running-req: 1, #queue-req: 0, 
[2025-08-25 18:28:12 TP0] Decode batch. #running-req: 4, #token: 199, token usage: 0.00, gen throughput (token/s): 582.91, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:28:12 TP0] Decode batch. #running-req: 4, #token: 359, token usage: 0.00, gen throughput (token/s): 913.69, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:28:13 TP0] Decode batch. #running-req: 4, #token: 519, token usage: 0.00, gen throughput (token/s): 884.30, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:28:13 TP0] Decode batch. #running-req: 4, #token: 679, token usage: 0.00, gen throughput (token/s): 883.90, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:28:13 TP0] Decode batch. #running-req: 4, #token: 839, token usage: 0.00, gen throughput (token/s): 855.33, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:28:13 TP0] Decode batch. #running-req: 4, #token: 999, token usage: 0.00, gen throughput (token/s): 852.94, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:28:13 TP0] Decode batch. #running-req: 4, #token: 1159, token usage: 0.00, gen throughput (token/s): 877.12, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:28:14 TP0] Decode batch. #running-req: 4, #token: 1319, token usage: 0.00, gen throughput (token/s): 859.05, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:28:14 TP0] Decode batch. #running-req: 4, #token: 1479, token usage: 0.00, gen throughput (token/s): 838.50, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:28:14 TP0] Decode batch. #running-req: 4, #token: 1639, token usage: 0.00, gen throughput (token/s): 861.06, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:28:14 TP0] Decode batch. #running-req: 4, #token: 1799, token usage: 0.00, gen throughput (token/s): 842.29, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:28:14 TP0] Decode batch. #running-req: 4, #token: 1959, token usage: 0.00, gen throughput (token/s): 844.36, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:28:14 TP0] Decode batch. #running-req: 4, #token: 2119, token usage: 0.00, gen throughput (token/s): 869.94, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:28:15 TP0] Decode batch. #running-req: 4, #token: 2279, token usage: 0.00, gen throughput (token/s): 844.84, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:28:15 TP0] Decode batch. #running-req: 4, #token: 2439, token usage: 0.00, gen throughput (token/s): 852.57, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:28:15 TP0] Decode batch. #running-req: 4, #token: 2599, token usage: 0.00, gen throughput (token/s): 862.26, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:28:15 TP0] Decode batch. #running-req: 4, #token: 2759, token usage: 0.00, gen throughput (token/s): 865.09, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:28:15 TP0] Decode batch. #running-req: 4, #token: 2919, token usage: 0.00, gen throughput (token/s): 903.15, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:28:15] INFO:     127.0.0.1:5290 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 18:28:15] INFO:     127.0.0.1:5266 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 18:28:15] INFO:     127.0.0.1:5274 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 18:28:15] INFO:     127.0.0.1:5278 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 18:28:15 TP0] Prefill batch. #new-seq: 4, #new-token: 2800, #cached-token: 576, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-08-25 18:28:17] INFO:     127.0.0.1:15332 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 18:28:17] INFO:     127.0.0.1:15346 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 18:28:17] INFO:     127.0.0.1:15360 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 18:28:17] INFO:     127.0.0.1:15370 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 18:28:17 TP0] Prefill batch. #new-seq: 4, #new-token: 2800, #cached-token: 576, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-08-25 18:28:18] INFO:     127.0.0.1:15370 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 18:28:18] INFO:     127.0.0.1:15332 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 18:28:18] INFO:     127.0.0.1:15346 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 18:28:18] INFO:     127.0.0.1:15360 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 18:28:18 TP0] Prefill batch. #new-seq: 1, #new-token: 700, #cached-token: 144, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-08-25 18:28:18 TP0] Prefill batch. #new-seq: 3, #new-token: 2100, #cached-token: 432, token usage: 0.00, #running-req: 1, #queue-req: 0, 
[2025-08-25 18:28:18] INFO:     127.0.0.1:15370 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 18:28:19] INFO:     127.0.0.1:15332 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 18:28:19] INFO:     127.0.0.1:15346 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 18:28:19 TP0] Prefill batch. #new-seq: 1, #new-token: 700, #cached-token: 144, token usage: 0.00, #running-req: 3, #queue-req: 0, 
[2025-08-25 18:28:19] INFO:     127.0.0.1:15360 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 18:28:19] INFO:     127.0.0.1:15370 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 18:28:19 TP0] Prefill batch. #new-seq: 3, #new-token: 2100, #cached-token: 432, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-08-25 18:28:20] INFO:     127.0.0.1:15332 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 18:28:20 TP0] Prefill batch. #new-seq: 1, #new-token: 687, #cached-token: 166, token usage: 0.00, #running-req: 3, #queue-req: 0, 
[2025-08-25 18:28:20] INFO:     127.0.0.1:15346 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 18:28:20] INFO:     127.0.0.1:15360 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 18:28:20 TP0] Prefill batch. #new-seq: 3, #new-token: 2078, #cached-token: 481, token usage: 0.00, #running-req: 1, #queue-req: 0, 
[2025-08-25 18:28:21 TP0] Decode batch. #running-req: 4, #token: 2977, token usage: 0.01, gen throughput (token/s): 5.46, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:28:22 TP0] Decode batch. #running-req: 4, #token: 3137, token usage: 0.01, gen throughput (token/s): 152.60, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:28:23 TP0] Decode batch. #running-req: 4, #token: 3297, token usage: 0.01, gen throughput (token/s): 153.55, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:28:24 TP0] Decode batch. #running-req: 4, #token: 3457, token usage: 0.01, gen throughput (token/s): 153.87, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:28:24] INFO:     127.0.0.1:15370 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 18:28:24] INFO:     127.0.0.1:15332 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 18:28:24] INFO:     127.0.0.1:15346 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 18:28:24] INFO:     127.0.0.1:15360 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 18:28:24 TP0] Prefill batch. #new-seq: 1, #new-token: 680, #cached-token: 173, token usage: 0.00, #running-req: 3, #queue-req: 0, 
[2025-08-25 18:28:25 TP0] Prefill batch. #new-seq: 3, #new-token: 2041, #cached-token: 518, token usage: 0.00, #running-req: 4, #queue-req: 0, 
[2025-08-25 18:28:26 TP0] Decode batch. #running-req: 4, #token: 3019, token usage: 0.01, gen throughput (token/s): 89.64, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:28:27 TP0] Decode batch. #running-req: 4, #token: 3179, token usage: 0.01, gen throughput (token/s): 153.13, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:28:28 TP0] Decode batch. #running-req: 4, #token: 3339, token usage: 0.01, gen throughput (token/s): 153.34, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:28:29 TP0] Decode batch. #running-req: 4, #token: 3499, token usage: 0.01, gen throughput (token/s): 154.00, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:28:29] INFO:     127.0.0.1:15370 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 18:28:29] INFO:     127.0.0.1:15332 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 18:28:29] INFO:     127.0.0.1:15346 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 18:28:29] INFO:     127.0.0.1:15360 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 18:28:29 TP0] Prefill batch. #new-seq: 1, #new-token: 664, #cached-token: 189, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-08-25 18:28:30 TP0] Decode batch. #running-req: 1, #token: 883, token usage: 0.00, gen throughput (token/s): 58.97, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:28:31 TP0] Decode batch. #running-req: 1, #token: 923, token usage: 0.00, gen throughput (token/s): 38.55, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:28:32 TP0] Decode batch. #running-req: 1, #token: 963, token usage: 0.00, gen throughput (token/s): 38.69, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:28:33] INFO:     127.0.0.1:15370 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 18:28:33 TP0] Decode batch. #running-req: 1, #token: 1, token usage: 0.00, gen throughput (token/s): 38.64, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:28:33 TP0] Prefill batch. #new-seq: 2, #new-token: 2, #cached-token: 616, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-08-25 18:28:33 TP0] Prefill batch. #new-seq: 2, #new-token: 2, #cached-token: 616, token usage: 0.00, #running-req: 2, #queue-req: 0, 
[2025-08-25 18:28:33 TP0] Decode batch. #running-req: 4, #token: 433, token usage: 0.00, gen throughput (token/s): 8.92, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:28:34 TP0] Decode batch. #running-req: 4, #token: 593, token usage: 0.00, gen throughput (token/s): 867.01, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:28:34 TP0] Decode batch. #running-req: 4, #token: 753, token usage: 0.00, gen throughput (token/s): 854.28, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:28:34 TP0] Decode batch. #running-req: 4, #token: 913, token usage: 0.00, gen throughput (token/s): 867.68, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:28:34 TP0] Decode batch. #running-req: 4, #token: 1073, token usage: 0.00, gen throughput (token/s): 852.48, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:28:34 TP0] Decode batch. #running-req: 4, #token: 1233, token usage: 0.00, gen throughput (token/s): 866.79, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:28:34 TP0] Decode batch. #running-req: 4, #token: 1393, token usage: 0.00, gen throughput (token/s): 864.28, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:28:35 TP0] Decode batch. #running-req: 4, #token: 1553, token usage: 0.00, gen throughput (token/s): 876.08, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:28:35 TP0] Decode batch. #running-req: 4, #token: 1713, token usage: 0.00, gen throughput (token/s): 864.70, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:28:35 TP0] Decode batch. #running-req: 4, #token: 1873, token usage: 0.00, gen throughput (token/s): 872.49, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:28:35 TP0] Decode batch. #running-req: 4, #token: 2033, token usage: 0.00, gen throughput (token/s): 869.49, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:28:35 TP0] Decode batch. #running-req: 4, #token: 2193, token usage: 0.00, gen throughput (token/s): 866.44, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:28:36 TP0] Decode batch. #running-req: 4, #token: 2353, token usage: 0.00, gen throughput (token/s): 863.80, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:28:36 TP0] Decode batch. #running-req: 4, #token: 2513, token usage: 0.00, gen throughput (token/s): 866.05, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:28:36 TP0] Decode batch. #running-req: 4, #token: 2673, token usage: 0.00, gen throughput (token/s): 856.66, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:28:36 TP0] Decode batch. #running-req: 4, #token: 2833, token usage: 0.00, gen throughput (token/s): 872.12, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:28:36 TP0] Decode batch. #running-req: 4, #token: 2993, token usage: 0.00, gen throughput (token/s): 910.40, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:28:36] INFO:     127.0.0.1:43110 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 18:28:36] INFO:     127.0.0.1:43114 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 18:28:36] INFO:     127.0.0.1:43122 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 18:28:36] INFO:     127.0.0.1:43130 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 18:28:36 TP0] Prefill batch. #new-seq: 2, #new-token: 2, #cached-token: 616, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-08-25 18:28:36 TP0] Prefill batch. #new-seq: 2, #new-token: 2, #cached-token: 616, token usage: 0.00, #running-req: 2, #queue-req: 0, 
[2025-08-25 18:28:37 TP0] Decode batch. #running-req: 4, #token: 353, token usage: 0.00, gen throughput (token/s): 570.37, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:28:37 TP0] Decode batch. #running-req: 4, #token: 513, token usage: 0.00, gen throughput (token/s): 870.66, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:28:37 TP0] Decode batch. #running-req: 4, #token: 673, token usage: 0.00, gen throughput (token/s): 897.42, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:28:37 TP0] Decode batch. #running-req: 4, #token: 833, token usage: 0.00, gen throughput (token/s): 870.95, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:28:37 TP0] Decode batch. #running-req: 4, #token: 993, token usage: 0.00, gen throughput (token/s): 861.47, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:28:37 TP0] Decode batch. #running-req: 4, #token: 1153, token usage: 0.00, gen throughput (token/s): 854.37, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:28:38 TP0] Decode batch. #running-req: 4, #token: 1313, token usage: 0.00, gen throughput (token/s): 853.70, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:28:38 TP0] Decode batch. #running-req: 4, #token: 1473, token usage: 0.00, gen throughput (token/s): 882.34, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:28:38 TP0] Decode batch. #running-req: 4, #token: 1633, token usage: 0.00, gen throughput (token/s): 861.71, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:28:38 TP0] Decode batch. #running-req: 4, #token: 1793, token usage: 0.00, gen throughput (token/s): 860.13, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:28:38 TP0] Decode batch. #running-req: 4, #token: 1953, token usage: 0.00, gen throughput (token/s): 853.86, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:28:39 TP0] Decode batch. #running-req: 4, #token: 2113, token usage: 0.00, gen throughput (token/s): 842.67, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:28:39 TP0] Decode batch. #running-req: 4, #token: 2273, token usage: 0.00, gen throughput (token/s): 856.60, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:28:39 TP0] Decode batch. #running-req: 4, #token: 2433, token usage: 0.00, gen throughput (token/s): 864.87, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:28:39 TP0] Decode batch. #running-req: 4, #token: 2593, token usage: 0.00, gen throughput (token/s): 866.26, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:28:39 TP0] Decode batch. #running-req: 4, #token: 2753, token usage: 0.00, gen throughput (token/s): 855.37, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:28:40 TP0] Decode batch. #running-req: 4, #token: 2913, token usage: 0.00, gen throughput (token/s): 856.00, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:28:40 TP0] Decode batch. #running-req: 4, #token: 3073, token usage: 0.00, gen throughput (token/s): 860.52, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:28:40] INFO:     127.0.0.1:43130 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 18:28:40] INFO:     127.0.0.1:43110 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 18:28:40] INFO:     127.0.0.1:43114 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 18:28:40] INFO:     127.0.0.1:43122 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 18:28:40 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 308, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-08-25 18:28:40 TP0] Prefill batch. #new-seq: 3, #new-token: 3, #cached-token: 924, token usage: 0.00, #running-req: 1, #queue-req: 0, 
[2025-08-25 18:28:40 TP0] Decode batch. #running-req: 4, #token: 433, token usage: 0.00, gen throughput (token/s): 570.16, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:28:40 TP0] Decode batch. #running-req: 4, #token: 593, token usage: 0.00, gen throughput (token/s): 870.63, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:28:40 TP0] Decode batch. #running-req: 4, #token: 753, token usage: 0.00, gen throughput (token/s): 841.85, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:28:41 TP0] Decode batch. #running-req: 4, #token: 913, token usage: 0.00, gen throughput (token/s): 865.37, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:28:41 TP0] Decode batch. #running-req: 4, #token: 1073, token usage: 0.00, gen throughput (token/s): 852.95, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:28:41 TP0] Decode batch. #running-req: 4, #token: 1233, token usage: 0.00, gen throughput (token/s): 851.73, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:28:41 TP0] Decode batch. #running-req: 4, #token: 1393, token usage: 0.00, gen throughput (token/s): 852.52, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:28:41 TP0] Decode batch. #running-req: 4, #token: 1553, token usage: 0.00, gen throughput (token/s): 841.60, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:28:42 TP0] Decode batch. #running-req: 4, #token: 1713, token usage: 0.00, gen throughput (token/s): 868.25, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:28:42 TP0] Decode batch. #running-req: 4, #token: 1873, token usage: 0.00, gen throughput (token/s): 867.02, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:28:42 TP0] Decode batch. #running-req: 4, #token: 2033, token usage: 0.00, gen throughput (token/s): 848.44, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:28:42 TP0] Decode batch. #running-req: 4, #token: 2193, token usage: 0.00, gen throughput (token/s): 855.33, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:28:42 TP0] Decode batch. #running-req: 4, #token: 2353, token usage: 0.00, gen throughput (token/s): 864.81, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:28:42 TP0] Decode batch. #running-req: 4, #token: 2513, token usage: 0.00, gen throughput (token/s): 833.89, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:28:43 TP0] Decode batch. #running-req: 4, #token: 2673, token usage: 0.00, gen throughput (token/s): 862.27, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:28:43 TP0] Decode batch. #running-req: 4, #token: 2833, token usage: 0.00, gen throughput (token/s): 839.72, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:28:43 TP0] Decode batch. #running-req: 4, #token: 2993, token usage: 0.00, gen throughput (token/s): 846.46, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:28:43] INFO:     127.0.0.1:43130 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 18:28:43] INFO:     127.0.0.1:43110 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 18:28:43] INFO:     127.0.0.1:43114 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 18:28:43] INFO:     127.0.0.1:43122 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 18:28:43 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 308, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-08-25 18:28:43 TP0] Prefill batch. #new-seq: 3, #new-token: 3, #cached-token: 924, token usage: 0.00, #running-req: 1, #queue-req: 0, 
[2025-08-25 18:28:43 TP0] Decode batch. #running-req: 4, #token: 353, token usage: 0.00, gen throughput (token/s): 565.17, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:28:43 TP0] Decode batch. #running-req: 4, #token: 513, token usage: 0.00, gen throughput (token/s): 888.68, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:28:44 TP0] Decode batch. #running-req: 4, #token: 673, token usage: 0.00, gen throughput (token/s): 867.00, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:28:44 TP0] Decode batch. #running-req: 4, #token: 833, token usage: 0.00, gen throughput (token/s): 858.14, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:28:44 TP0] Decode batch. #running-req: 4, #token: 993, token usage: 0.00, gen throughput (token/s): 858.90, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:28:44 TP0] Decode batch. #running-req: 4, #token: 1153, token usage: 0.00, gen throughput (token/s): 874.50, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:28:44 TP0] Decode batch. #running-req: 4, #token: 1313, token usage: 0.00, gen throughput (token/s): 877.57, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:28:45 TP0] Decode batch. #running-req: 4, #token: 1473, token usage: 0.00, gen throughput (token/s): 880.38, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:28:45 TP0] Decode batch. #running-req: 4, #token: 1633, token usage: 0.00, gen throughput (token/s): 855.54, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:28:45 TP0] Decode batch. #running-req: 4, #token: 1793, token usage: 0.00, gen throughput (token/s): 853.93, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:28:45 TP0] Decode batch. #running-req: 4, #token: 1953, token usage: 0.00, gen throughput (token/s): 862.92, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:28:45 TP0] Decode batch. #running-req: 4, #token: 2113, token usage: 0.00, gen throughput (token/s): 864.30, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:28:45 TP0] Decode batch. #running-req: 4, #token: 2273, token usage: 0.00, gen throughput (token/s): 865.26, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:28:46 TP0] Decode batch. #running-req: 4, #token: 2433, token usage: 0.00, gen throughput (token/s): 844.98, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:28:46 TP0] Decode batch. #running-req: 4, #token: 2593, token usage: 0.00, gen throughput (token/s): 850.27, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:28:46 TP0] Decode batch. #running-req: 4, #token: 2753, token usage: 0.00, gen throughput (token/s): 854.19, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:28:46 TP0] Decode batch. #running-req: 4, #token: 2913, token usage: 0.00, gen throughput (token/s): 875.91, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:28:46 TP0] Decode batch. #running-req: 4, #token: 3073, token usage: 0.00, gen throughput (token/s): 855.83, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:28:46] INFO:     127.0.0.1:43130 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 18:28:46] INFO:     127.0.0.1:43110 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 18:28:46] INFO:     127.0.0.1:43114 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 18:28:46] INFO:     127.0.0.1:43122 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 18:28:47 TP0] Prefill batch. #new-seq: 4, #new-token: 2800, #cached-token: 1192, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-08-25 18:28:47] INFO:     127.0.0.1:23390 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 18:28:47] INFO:     127.0.0.1:23402 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 18:28:47] INFO:     127.0.0.1:23412 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 18:28:47] INFO:     127.0.0.1:23428 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 18:28:47 TP0] Prefill batch. #new-seq: 1, #new-token: 700, #cached-token: 298, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-08-25 18:28:48 TP0] Prefill batch. #new-seq: 3, #new-token: 2100, #cached-token: 894, token usage: 0.00, #running-req: 1, #queue-req: 0, 
[2025-08-25 18:28:48] INFO:     127.0.0.1:23428 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 18:28:48] INFO:     127.0.0.1:23390 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 18:28:48] INFO:     127.0.0.1:23402 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 18:28:49] INFO:     127.0.0.1:23412 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 18:28:49 TP0] Prefill batch. #new-seq: 1, #new-token: 700, #cached-token: 298, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-08-25 18:28:49 TP0] Prefill batch. #new-seq: 3, #new-token: 2100, #cached-token: 894, token usage: 0.00, #running-req: 1, #queue-req: 0, 
[2025-08-25 18:28:49] INFO:     127.0.0.1:23428 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 18:28:49 TP0] Prefill batch. #new-seq: 1, #new-token: 700, #cached-token: 298, token usage: 0.01, #running-req: 4, #queue-req: 0, 
[2025-08-25 18:28:50] INFO:     127.0.0.1:23390 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 18:28:50] INFO:     127.0.0.1:23402 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 18:28:50] INFO:     127.0.0.1:23412 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 18:28:50] INFO:     127.0.0.1:23428 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 18:28:50 TP0] Prefill batch. #new-seq: 1, #new-token: 700, #cached-token: 298, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-08-25 18:28:50 TP0] Prefill batch. #new-seq: 2, #new-token: 1400, #cached-token: 596, token usage: 0.00, #running-req: 1, #queue-req: 0, 
[2025-08-25 18:28:50 TP0] Prefill batch. #new-seq: 1, #new-token: 698, #cached-token: 309, token usage: 0.01, #running-req: 3, #queue-req: 0, 
[2025-08-25 18:28:50] INFO:     127.0.0.1:23390 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 18:28:50] INFO:     127.0.0.1:23402 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 18:28:50] INFO:     127.0.0.1:23412 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 18:28:51 TP0] Prefill batch. #new-seq: 3, #new-token: 2056, #cached-token: 965, token usage: 0.00, #running-req: 1, #queue-req: 0, 
[2025-08-25 18:28:52 TP0] Decode batch. #running-req: 4, #token: 3214, token usage: 0.01, gen throughput (token/s): 7.74, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:28:53 TP0] Decode batch. #running-req: 4, #token: 3374, token usage: 0.01, gen throughput (token/s): 152.32, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:28:54 TP0] Decode batch. #running-req: 4, #token: 3534, token usage: 0.01, gen throughput (token/s): 151.90, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:28:55] INFO:     127.0.0.1:23428 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 18:28:55] INFO:     127.0.0.1:23390 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 18:28:55] INFO:     127.0.0.1:23412 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 18:28:55] INFO:     127.0.0.1:23402 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 18:28:55 TP0] Prefill batch. #new-seq: 1, #new-token: 696, #cached-token: 311, token usage: 0.00, #running-req: 3, #queue-req: 0, 
[2025-08-25 18:28:55 TP0] Prefill batch. #new-seq: 1, #new-token: 648, #cached-token: 359, token usage: 0.00, #running-req: 4, #queue-req: 0, 
[2025-08-25 18:28:56 TP0] Decode batch. #running-req: 2, #token: 1713, token usage: 0.01, gen throughput (token/s): 103.85, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:28:57 TP0] Decode batch. #running-req: 2, #token: 1793, token usage: 0.01, gen throughput (token/s): 77.45, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:28:58 TP0] Decode batch. #running-req: 2, #token: 1873, token usage: 0.01, gen throughput (token/s): 76.98, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:28:59 TP0] Decode batch. #running-req: 2, #token: 1953, token usage: 0.01, gen throughput (token/s): 77.65, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:28:59] INFO:     127.0.0.1:23428 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 18:28:59] INFO:     127.0.0.1:23390 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 18:28:59 TP0] Prefill batch. #new-seq: 4, #new-token: 4, #cached-token: 1008, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-08-25 18:29:00 TP0] Decode batch. #running-req: 4, #token: 377, token usage: 0.00, gen throughput (token/s): 12.14, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:29:00 TP0] Decode batch. #running-req: 4, #token: 537, token usage: 0.00, gen throughput (token/s): 862.26, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:29:00 TP0] Decode batch. #running-req: 4, #token: 697, token usage: 0.00, gen throughput (token/s): 869.74, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:29:00 TP0] Decode batch. #running-req: 4, #token: 857, token usage: 0.00, gen throughput (token/s): 843.56, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:29:00 TP0] Decode batch. #running-req: 4, #token: 1017, token usage: 0.00, gen throughput (token/s): 873.14, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:29:01 TP0] Decode batch. #running-req: 4, #token: 1177, token usage: 0.00, gen throughput (token/s): 859.36, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:29:01 TP0] Decode batch. #running-req: 4, #token: 1337, token usage: 0.00, gen throughput (token/s): 858.18, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:29:01 TP0] Decode batch. #running-req: 4, #token: 1497, token usage: 0.00, gen throughput (token/s): 851.11, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:29:01 TP0] Decode batch. #running-req: 4, #token: 1657, token usage: 0.00, gen throughput (token/s): 855.84, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:29:01 TP0] Decode batch. #running-req: 4, #token: 1817, token usage: 0.00, gen throughput (token/s): 874.79, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:29:01 TP0] Decode batch. #running-req: 4, #token: 1977, token usage: 0.00, gen throughput (token/s): 840.78, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:29:02 TP0] Decode batch. #running-req: 4, #token: 2137, token usage: 0.00, gen throughput (token/s): 855.33, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:29:02 TP0] Decode batch. #running-req: 4, #token: 2297, token usage: 0.00, gen throughput (token/s): 847.30, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:29:02 TP0] Decode batch. #running-req: 4, #token: 2457, token usage: 0.00, gen throughput (token/s): 856.07, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:29:02 TP0] Decode batch. #running-req: 4, #token: 2617, token usage: 0.00, gen throughput (token/s): 877.57, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:29:02 TP0] Decode batch. #running-req: 4, #token: 2777, token usage: 0.00, gen throughput (token/s): 865.33, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:29:03 TP0] Decode batch. #running-req: 4, #token: 2937, token usage: 0.00, gen throughput (token/s): 855.11, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:29:03] INFO:     127.0.0.1:15928 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 18:29:03] INFO:     127.0.0.1:15930 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 18:29:03] INFO:     127.0.0.1:15936 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 18:29:03] INFO:     127.0.0.1:15948 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 18:29:03 TP0] Prefill batch. #new-seq: 4, #new-token: 4, #cached-token: 1008, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-08-25 18:29:03 TP0] Decode batch. #running-req: 4, #token: 297, token usage: 0.00, gen throughput (token/s): 625.36, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:29:03 TP0] Decode batch. #running-req: 4, #token: 457, token usage: 0.00, gen throughput (token/s): 879.04, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:29:03 TP0] Decode batch. #running-req: 4, #token: 617, token usage: 0.00, gen throughput (token/s): 876.95, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:29:03 TP0] Decode batch. #running-req: 4, #token: 777, token usage: 0.00, gen throughput (token/s): 859.12, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:29:04 TP0] Decode batch. #running-req: 4, #token: 937, token usage: 0.00, gen throughput (token/s): 878.63, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:29:04 TP0] Decode batch. #running-req: 4, #token: 1097, token usage: 0.00, gen throughput (token/s): 875.44, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:29:04 TP0] Decode batch. #running-req: 4, #token: 1257, token usage: 0.00, gen throughput (token/s): 860.12, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:29:04 TP0] Decode batch. #running-req: 4, #token: 1417, token usage: 0.00, gen throughput (token/s): 879.37, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:29:04 TP0] Decode batch. #running-req: 4, #token: 1577, token usage: 0.00, gen throughput (token/s): 863.07, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:29:05 TP0] Decode batch. #running-req: 4, #token: 1737, token usage: 0.00, gen throughput (token/s): 849.48, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:29:05 TP0] Decode batch. #running-req: 4, #token: 1897, token usage: 0.00, gen throughput (token/s): 874.04, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:29:05 TP0] Decode batch. #running-req: 4, #token: 2057, token usage: 0.00, gen throughput (token/s): 848.01, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:29:05 TP0] Decode batch. #running-req: 4, #token: 2217, token usage: 0.00, gen throughput (token/s): 876.14, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:29:05 TP0] Decode batch. #running-req: 4, #token: 2377, token usage: 0.00, gen throughput (token/s): 879.31, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:29:05 TP0] Decode batch. #running-req: 4, #token: 2537, token usage: 0.00, gen throughput (token/s): 857.38, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:29:06 TP0] Decode batch. #running-req: 4, #token: 2697, token usage: 0.00, gen throughput (token/s): 865.85, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:29:06 TP0] Decode batch. #running-req: 4, #token: 2857, token usage: 0.00, gen throughput (token/s): 863.28, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:29:06 TP0] Decode batch. #running-req: 4, #token: 3017, token usage: 0.00, gen throughput (token/s): 861.30, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:29:06] INFO:     127.0.0.1:15948 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 18:29:06] INFO:     127.0.0.1:15928 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 18:29:06] INFO:     127.0.0.1:15930 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 18:29:06] INFO:     127.0.0.1:15936 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 18:29:06 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 252, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-08-25 18:29:06 TP0] Prefill batch. #new-seq: 3, #new-token: 3, #cached-token: 756, token usage: 0.00, #running-req: 1, #queue-req: 0, 
[2025-08-25 18:29:06 TP0] Decode batch. #running-req: 4, #token: 377, token usage: 0.00, gen throughput (token/s): 565.88, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:29:06 TP0] Decode batch. #running-req: 4, #token: 537, token usage: 0.00, gen throughput (token/s): 860.68, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:29:07 TP0] Decode batch. #running-req: 4, #token: 697, token usage: 0.00, gen throughput (token/s): 873.32, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:29:07 TP0] Decode batch. #running-req: 4, #token: 857, token usage: 0.00, gen throughput (token/s): 875.89, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:29:07 TP0] Decode batch. #running-req: 4, #token: 1017, token usage: 0.00, gen throughput (token/s): 865.19, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:29:07 TP0] Decode batch. #running-req: 4, #token: 1177, token usage: 0.00, gen throughput (token/s): 907.81, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:29:07 TP0] Decode batch. #running-req: 4, #token: 1337, token usage: 0.00, gen throughput (token/s): 963.21, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:29:08 TP0] Decode batch. #running-req: 4, #token: 1497, token usage: 0.00, gen throughput (token/s): 955.83, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:29:08 TP0] Decode batch. #running-req: 4, #token: 1657, token usage: 0.00, gen throughput (token/s): 958.93, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:29:08 TP0] Decode batch. #running-req: 4, #token: 1817, token usage: 0.00, gen throughput (token/s): 859.23, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:29:08 TP0] Decode batch. #running-req: 4, #token: 1977, token usage: 0.00, gen throughput (token/s): 868.66, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:29:08 TP0] Decode batch. #running-req: 4, #token: 2137, token usage: 0.00, gen throughput (token/s): 859.38, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:29:08 TP0] Decode batch. #running-req: 4, #token: 2297, token usage: 0.00, gen throughput (token/s): 860.06, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:29:09 TP0] Decode batch. #running-req: 4, #token: 2457, token usage: 0.00, gen throughput (token/s): 861.86, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:29:09 TP0] Decode batch. #running-req: 4, #token: 2617, token usage: 0.00, gen throughput (token/s): 865.35, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:29:09 TP0] Decode batch. #running-req: 4, #token: 2777, token usage: 0.00, gen throughput (token/s): 855.96, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:29:09 TP0] Decode batch. #running-req: 4, #token: 2937, token usage: 0.00, gen throughput (token/s): 846.20, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:29:09] INFO:     127.0.0.1:15948 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 18:29:09] INFO:     127.0.0.1:15928 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 18:29:09] INFO:     127.0.0.1:15930 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 18:29:09] INFO:     127.0.0.1:15936 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 18:29:09 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 252, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-08-25 18:29:09 TP0] Prefill batch. #new-seq: 3, #new-token: 3, #cached-token: 756, token usage: 0.00, #running-req: 1, #queue-req: 0, 
[2025-08-25 18:29:09 TP0] Decode batch. #running-req: 4, #token: 297, token usage: 0.00, gen throughput (token/s): 562.89, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:29:10 TP0] Decode batch. #running-req: 4, #token: 457, token usage: 0.00, gen throughput (token/s): 860.16, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:29:10 TP0] Decode batch. #running-req: 4, #token: 617, token usage: 0.00, gen throughput (token/s): 860.79, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:29:10 TP0] Decode batch. #running-req: 4, #token: 777, token usage: 0.00, gen throughput (token/s): 849.58, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:29:10 TP0] Decode batch. #running-req: 4, #token: 937, token usage: 0.00, gen throughput (token/s): 849.11, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:29:10 TP0] Decode batch. #running-req: 4, #token: 1097, token usage: 0.00, gen throughput (token/s): 850.26, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:29:11 TP0] Decode batch. #running-req: 4, #token: 1257, token usage: 0.00, gen throughput (token/s): 850.08, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:29:11 TP0] Decode batch. #running-req: 4, #token: 1417, token usage: 0.00, gen throughput (token/s): 849.86, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:29:11 TP0] Decode batch. #running-req: 4, #token: 1577, token usage: 0.00, gen throughput (token/s): 836.60, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:29:11 TP0] Decode batch. #running-req: 4, #token: 1737, token usage: 0.00, gen throughput (token/s): 838.83, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:29:11 TP0] Decode batch. #running-req: 4, #token: 1897, token usage: 0.00, gen throughput (token/s): 875.94, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:29:12 TP0] Decode batch. #running-req: 4, #token: 2057, token usage: 0.00, gen throughput (token/s): 957.67, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:29:12 TP0] Decode batch. #running-req: 4, #token: 2217, token usage: 0.00, gen throughput (token/s): 884.18, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:29:12 TP0] Decode batch. #running-req: 4, #token: 2377, token usage: 0.00, gen throughput (token/s): 888.97, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:29:12 TP0] Decode batch. #running-req: 4, #token: 2537, token usage: 0.00, gen throughput (token/s): 860.38, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:29:12 TP0] Decode batch. #running-req: 4, #token: 2697, token usage: 0.00, gen throughput (token/s): 875.92, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:29:12 TP0] Decode batch. #running-req: 4, #token: 2857, token usage: 0.00, gen throughput (token/s): 876.85, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:29:13 TP0] Decode batch. #running-req: 4, #token: 3017, token usage: 0.00, gen throughput (token/s): 894.13, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:29:13] INFO:     127.0.0.1:15948 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 18:29:13] INFO:     127.0.0.1:15928 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 18:29:13] INFO:     127.0.0.1:15930 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 18:29:13] INFO:     127.0.0.1:15936 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 18:29:13 TP0] Prefill batch. #new-seq: 4, #new-token: 2800, #cached-token: 968, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-08-25 18:29:14] INFO:     127.0.0.1:51958 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 18:29:14] INFO:     127.0.0.1:51964 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 18:29:14] INFO:     127.0.0.1:51968 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 18:29:14] INFO:     127.0.0.1:51978 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 18:29:14 TP0] Prefill batch. #new-seq: 1, #new-token: 700, #cached-token: 242, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-08-25 18:29:14 TP0] Prefill batch. #new-seq: 3, #new-token: 2100, #cached-token: 726, token usage: 0.00, #running-req: 1, #queue-req: 0, 
[2025-08-25 18:29:14] INFO:     127.0.0.1:51978 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 18:29:15] INFO:     127.0.0.1:51958 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 18:29:15] INFO:     127.0.0.1:51964 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 18:29:15 TP0] Prefill batch. #new-seq: 1, #new-token: 700, #cached-token: 242, token usage: 0.00, #running-req: 3, #queue-req: 0, 
[2025-08-25 18:29:15] INFO:     127.0.0.1:51968 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 18:29:15 TP0] Prefill batch. #new-seq: 3, #new-token: 2100, #cached-token: 726, token usage: 0.00, #running-req: 4, #queue-req: 0, 
[2025-08-25 18:29:15] INFO:     127.0.0.1:51978 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 18:29:16] INFO:     127.0.0.1:51958 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 18:29:16 TP0] Prefill batch. #new-seq: 1, #new-token: 700, #cached-token: 242, token usage: 0.00, #running-req: 3, #queue-req: 0, 
[2025-08-25 18:29:16] INFO:     127.0.0.1:51964 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 18:29:16] INFO:     127.0.0.1:51968 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 18:29:16 TP0] Prefill batch. #new-seq: 3, #new-token: 2100, #cached-token: 726, token usage: 0.00, #running-req: 4, #queue-req: 0, 
[2025-08-25 18:29:16] INFO:     127.0.0.1:51978 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 18:29:16] INFO:     127.0.0.1:51958 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 18:29:16] INFO:     127.0.0.1:51964 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 18:29:16] INFO:     127.0.0.1:51968 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 18:29:16 TP0] Prefill batch. #new-seq: 1, #new-token: 682, #cached-token: 269, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-08-25 18:29:17 TP0] Prefill batch. #new-seq: 3, #new-token: 2083, #cached-token: 770, token usage: 0.00, #running-req: 1, #queue-req: 0, 
[2025-08-25 18:29:18 TP0] Decode batch. #running-req: 4, #token: 3075, token usage: 0.01, gen throughput (token/s): 5.44, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:29:19 TP0] Decode batch. #running-req: 4, #token: 3235, token usage: 0.01, gen throughput (token/s): 151.57, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:29:20 TP0] Decode batch. #running-req: 4, #token: 3395, token usage: 0.01, gen throughput (token/s): 152.11, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:29:21 TP0] Decode batch. #running-req: 4, #token: 3555, token usage: 0.01, gen throughput (token/s): 151.75, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:29:21] INFO:     127.0.0.1:51978 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 18:29:21] INFO:     127.0.0.1:51968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 18:29:21] INFO:     127.0.0.1:51958 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 18:29:21] INFO:     127.0.0.1:51964 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 18:29:21 TP0] Prefill batch. #new-seq: 1, #new-token: 696, #cached-token: 255, token usage: 0.00, #running-req: 3, #queue-req: 0, 
[2025-08-25 18:29:21 TP0] Prefill batch. #new-seq: 2, #new-token: 1383, #cached-token: 519, token usage: 0.00, #running-req: 4, #queue-req: 0, 
[2025-08-25 18:29:22 TP0] Decode batch. #running-req: 3, #token: 2405, token usage: 0.01, gen throughput (token/s): 85.94, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:29:23 TP0] Decode batch. #running-req: 3, #token: 2525, token usage: 0.01, gen throughput (token/s): 114.73, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:29:24 TP0] Decode batch. #running-req: 3, #token: 2645, token usage: 0.01, gen throughput (token/s): 114.86, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:29:25 TP0] Decode batch. #running-req: 3, #token: 2765, token usage: 0.01, gen throughput (token/s): 114.27, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:29:26] INFO:     127.0.0.1:51978 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 18:29:26] INFO:     127.0.0.1:51958 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 18:29:26] INFO:     127.0.0.1:51964 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 18:29:26 TP0] Prefill batch. #new-seq: 4, #new-token: 4, #cached-token: 652, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-08-25 18:29:26 TP0] Decode batch. #running-req: 4, #token: 288, token usage: 0.00, gen throughput (token/s): 12.01, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:29:26 TP0] Decode batch. #running-req: 4, #token: 448, token usage: 0.00, gen throughput (token/s): 875.45, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:29:26 TP0] Decode batch. #running-req: 4, #token: 608, token usage: 0.00, gen throughput (token/s): 873.87, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:29:26 TP0] Decode batch. #running-req: 4, #token: 768, token usage: 0.00, gen throughput (token/s): 831.64, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:29:27 TP0] Decode batch. #running-req: 4, #token: 928, token usage: 0.00, gen throughput (token/s): 883.73, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:29:27 TP0] Decode batch. #running-req: 4, #token: 1088, token usage: 0.00, gen throughput (token/s): 863.51, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:29:27 TP0] Decode batch. #running-req: 4, #token: 1248, token usage: 0.00, gen throughput (token/s): 866.95, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:29:27 TP0] Decode batch. #running-req: 4, #token: 1408, token usage: 0.00, gen throughput (token/s): 874.17, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:29:27 TP0] Decode batch. #running-req: 4, #token: 1568, token usage: 0.00, gen throughput (token/s): 865.52, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:29:28 TP0] Decode batch. #running-req: 4, #token: 1728, token usage: 0.00, gen throughput (token/s): 859.61, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:29:28 TP0] Decode batch. #running-req: 4, #token: 1888, token usage: 0.00, gen throughput (token/s): 855.03, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:29:28 TP0] Decode batch. #running-req: 4, #token: 2048, token usage: 0.00, gen throughput (token/s): 863.71, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:29:28 TP0] Decode batch. #running-req: 4, #token: 2208, token usage: 0.00, gen throughput (token/s): 843.92, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:29:28 TP0] Decode batch. #running-req: 4, #token: 2368, token usage: 0.00, gen throughput (token/s): 853.83, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:29:29 TP0] Decode batch. #running-req: 4, #token: 2528, token usage: 0.00, gen throughput (token/s): 858.69, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:29:29 TP0] Decode batch. #running-req: 4, #token: 2688, token usage: 0.00, gen throughput (token/s): 837.03, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:29:29 TP0] Decode batch. #running-req: 4, #token: 2848, token usage: 0.00, gen throughput (token/s): 845.23, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:29:29] INFO:     127.0.0.1:31668 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 18:29:29] INFO:     127.0.0.1:31674 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 18:29:29] INFO:     127.0.0.1:31676 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 18:29:29] INFO:     127.0.0.1:31678 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 18:29:29 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 163, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-08-25 18:29:29 TP0] Prefill batch. #new-seq: 3, #new-token: 3, #cached-token: 489, token usage: 0.00, #running-req: 1, #queue-req: 0, 
[2025-08-25 18:29:29 TP0] Decode batch. #running-req: 4, #token: 205, token usage: 0.00, gen throughput (token/s): 554.05, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:29:29 TP0] Decode batch. #running-req: 4, #token: 365, token usage: 0.00, gen throughput (token/s): 857.38, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:29:30 TP0] Decode batch. #running-req: 4, #token: 525, token usage: 0.00, gen throughput (token/s): 886.58, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:29:30 TP0] Decode batch. #running-req: 4, #token: 685, token usage: 0.00, gen throughput (token/s): 854.65, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:29:30 TP0] Decode batch. #running-req: 4, #token: 845, token usage: 0.00, gen throughput (token/s): 856.25, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:29:30 TP0] Decode batch. #running-req: 4, #token: 1005, token usage: 0.00, gen throughput (token/s): 861.05, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:29:30 TP0] Decode batch. #running-req: 4, #token: 1165, token usage: 0.00, gen throughput (token/s): 844.15, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:29:30 TP0] Decode batch. #running-req: 4, #token: 1325, token usage: 0.00, gen throughput (token/s): 895.44, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:29:31 TP0] Decode batch. #running-req: 4, #token: 1485, token usage: 0.00, gen throughput (token/s): 846.63, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:29:31 TP0] Decode batch. #running-req: 4, #token: 1645, token usage: 0.00, gen throughput (token/s): 853.06, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:29:31 TP0] Decode batch. #running-req: 4, #token: 1805, token usage: 0.00, gen throughput (token/s): 849.75, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:29:31 TP0] Decode batch. #running-req: 4, #token: 1965, token usage: 0.00, gen throughput (token/s): 854.96, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:29:31 TP0] Decode batch. #running-req: 4, #token: 2125, token usage: 0.00, gen throughput (token/s): 876.96, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:29:32 TP0] Decode batch. #running-req: 4, #token: 2285, token usage: 0.00, gen throughput (token/s): 851.33, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:29:32 TP0] Decode batch. #running-req: 4, #token: 2445, token usage: 0.00, gen throughput (token/s): 845.03, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:29:32 TP0] Decode batch. #running-req: 4, #token: 2605, token usage: 0.00, gen throughput (token/s): 833.83, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:29:32 TP0] Decode batch. #running-req: 4, #token: 2765, token usage: 0.00, gen throughput (token/s): 835.47, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:29:32 TP0] Decode batch. #running-req: 4, #token: 2925, token usage: 0.00, gen throughput (token/s): 865.87, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:29:32] INFO:     127.0.0.1:31678 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 18:29:32] INFO:     127.0.0.1:31668 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 18:29:32] INFO:     127.0.0.1:31674 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 18:29:32] INFO:     127.0.0.1:31676 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 18:29:32 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 163, token usage: 0.00, #running-req: 3, #queue-req: 0, 
[2025-08-25 18:29:32 TP0] Prefill batch. #new-seq: 3, #new-token: 3, #cached-token: 489, token usage: 0.00, #running-req: 4, #queue-req: 0, 
[2025-08-25 18:29:33 TP0] Decode batch. #running-req: 4, #token: 284, token usage: 0.00, gen throughput (token/s): 599.57, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:29:33 TP0] Decode batch. #running-req: 4, #token: 444, token usage: 0.00, gen throughput (token/s): 915.21, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:29:33 TP0] Decode batch. #running-req: 4, #token: 604, token usage: 0.00, gen throughput (token/s): 839.07, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:29:33 TP0] Decode batch. #running-req: 4, #token: 764, token usage: 0.00, gen throughput (token/s): 834.56, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:29:33 TP0] Decode batch. #running-req: 4, #token: 924, token usage: 0.00, gen throughput (token/s): 876.56, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:29:34 TP0] Decode batch. #running-req: 4, #token: 1084, token usage: 0.00, gen throughput (token/s): 832.21, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:29:34 TP0] Decode batch. #running-req: 4, #token: 1244, token usage: 0.00, gen throughput (token/s): 843.17, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:29:34 TP0] Decode batch. #running-req: 4, #token: 1404, token usage: 0.00, gen throughput (token/s): 836.41, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:29:34 TP0] Decode batch. #running-req: 4, #token: 1564, token usage: 0.00, gen throughput (token/s): 836.34, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:29:34 TP0] Decode batch. #running-req: 4, #token: 1724, token usage: 0.00, gen throughput (token/s): 867.37, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:29:34 TP0] Decode batch. #running-req: 4, #token: 1884, token usage: 0.00, gen throughput (token/s): 850.04, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:29:35 TP0] Decode batch. #running-req: 4, #token: 2044, token usage: 0.00, gen throughput (token/s): 843.90, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:29:35 TP0] Decode batch. #running-req: 4, #token: 2204, token usage: 0.00, gen throughput (token/s): 835.86, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:29:35 TP0] Decode batch. #running-req: 4, #token: 2364, token usage: 0.00, gen throughput (token/s): 827.57, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:29:35 TP0] Decode batch. #running-req: 4, #token: 2524, token usage: 0.00, gen throughput (token/s): 883.74, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:29:35 TP0] Decode batch. #running-req: 4, #token: 2684, token usage: 0.00, gen throughput (token/s): 833.37, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:29:36 TP0] Decode batch. #running-req: 4, #token: 2844, token usage: 0.00, gen throughput (token/s): 830.82, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:29:36] INFO:     127.0.0.1:31678 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 18:29:36] INFO:     127.0.0.1:31668 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 18:29:36] INFO:     127.0.0.1:31674 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 18:29:36] INFO:     127.0.0.1:31676 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 18:29:36 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 163, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-08-25 18:29:36 TP0] Prefill batch. #new-seq: 3, #new-token: 3, #cached-token: 489, token usage: 0.00, #running-req: 1, #queue-req: 0, 
[2025-08-25 18:29:36 TP0] Decode batch. #running-req: 4, #token: 204, token usage: 0.00, gen throughput (token/s): 566.77, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:29:36 TP0] Decode batch. #running-req: 4, #token: 364, token usage: 0.00, gen throughput (token/s): 839.14, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:29:36 TP0] Decode batch. #running-req: 4, #token: 524, token usage: 0.00, gen throughput (token/s): 866.84, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:29:36 TP0] Decode batch. #running-req: 4, #token: 684, token usage: 0.00, gen throughput (token/s): 896.15, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:29:37 TP0] Decode batch. #running-req: 4, #token: 844, token usage: 0.00, gen throughput (token/s): 906.48, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:29:37 TP0] Decode batch. #running-req: 4, #token: 1004, token usage: 0.00, gen throughput (token/s): 891.57, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:29:37 TP0] Decode batch. #running-req: 4, #token: 1164, token usage: 0.00, gen throughput (token/s): 874.92, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:29:37 TP0] Decode batch. #running-req: 4, #token: 1324, token usage: 0.00, gen throughput (token/s): 914.34, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:29:37 TP0] Decode batch. #running-req: 4, #token: 1484, token usage: 0.00, gen throughput (token/s): 888.95, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:29:38 TP0] Decode batch. #running-req: 4, #token: 1644, token usage: 0.00, gen throughput (token/s): 851.43, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:29:38 TP0] Decode batch. #running-req: 4, #token: 1804, token usage: 0.00, gen throughput (token/s): 871.28, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:29:38 TP0] Decode batch. #running-req: 4, #token: 1964, token usage: 0.00, gen throughput (token/s): 849.93, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:29:38 TP0] Decode batch. #running-req: 4, #token: 2124, token usage: 0.00, gen throughput (token/s): 874.97, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:29:38 TP0] Decode batch. #running-req: 4, #token: 2284, token usage: 0.00, gen throughput (token/s): 845.47, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:29:38 TP0] Decode batch. #running-req: 4, #token: 2444, token usage: 0.00, gen throughput (token/s): 860.00, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:29:39 TP0] Decode batch. #running-req: 4, #token: 2604, token usage: 0.00, gen throughput (token/s): 868.90, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:29:39 TP0] Decode batch. #running-req: 4, #token: 2764, token usage: 0.00, gen throughput (token/s): 841.34, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:29:39 TP0] Decode batch. #running-req: 4, #token: 2924, token usage: 0.00, gen throughput (token/s): 885.69, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:29:39] INFO:     127.0.0.1:31678 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 18:29:39] INFO:     127.0.0.1:31668 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 18:29:39] INFO:     127.0.0.1:31674 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 18:29:39] INFO:     127.0.0.1:31676 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 18:29:39 TP0] Prefill batch. #new-seq: 4, #new-token: 2800, #cached-token: 612, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-08-25 18:29:40] INFO:     127.0.0.1:62722 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 18:29:40] INFO:     127.0.0.1:62734 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 18:29:40] INFO:     127.0.0.1:62744 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 18:29:40] INFO:     127.0.0.1:62746 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 18:29:40 TP0] Prefill batch. #new-seq: 1, #new-token: 700, #cached-token: 153, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-08-25 18:29:40 TP0] Prefill batch. #new-seq: 2, #new-token: 1400, #cached-token: 306, token usage: 0.00, #running-req: 1, #queue-req: 0, 
[2025-08-25 18:29:41 TP0] Prefill batch. #new-seq: 1, #new-token: 700, #cached-token: 153, token usage: 0.00, #running-req: 3, #queue-req: 0, 
[2025-08-25 18:29:41] INFO:     127.0.0.1:62722 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 18:29:41] INFO:     127.0.0.1:62746 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 18:29:41] INFO:     127.0.0.1:62734 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 18:29:41 TP0] Prefill batch. #new-seq: 3, #new-token: 2100, #cached-token: 459, token usage: 0.00, #running-req: 1, #queue-req: 0, 
[2025-08-25 18:29:41] INFO:     127.0.0.1:62744 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 18:29:42 TP0] Prefill batch. #new-seq: 1, #new-token: 700, #cached-token: 153, token usage: 0.01, #running-req: 4, #queue-req: 0, 
[2025-08-25 18:29:42] INFO:     127.0.0.1:62722 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 18:29:42] INFO:     127.0.0.1:62746 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 18:29:42] INFO:     127.0.0.1:62734 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 18:29:42] INFO:     127.0.0.1:62744 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 18:29:42 TP0] Prefill batch. #new-seq: 3, #new-token: 2100, #cached-token: 459, token usage: 0.00, #running-req: 1, #queue-req: 0, 
[2025-08-25 18:29:43 TP0] Prefill batch. #new-seq: 1, #new-token: 700, #cached-token: 153, token usage: 0.01, #running-req: 4, #queue-req: 0, 
[2025-08-25 18:29:43] INFO:     127.0.0.1:62746 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 18:29:43] INFO:     127.0.0.1:62722 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 18:29:43] INFO:     127.0.0.1:62734 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 18:29:43] INFO:     127.0.0.1:62744 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 18:29:43 TP0] Prefill batch. #new-seq: 1, #new-token: 692, #cached-token: 170, token usage: 0.00, #running-req: 1, #queue-req: 0, 
[2025-08-25 18:29:44 TP0] Decode batch. #running-req: 1, #token: 888, token usage: 0.00, gen throughput (token/s): 3.55, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:29:45 TP0] Decode batch. #running-req: 1, #token: 928, token usage: 0.00, gen throughput (token/s): 38.39, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:29:46 TP0] Decode batch. #running-req: 1, #token: 968, token usage: 0.00, gen throughput (token/s): 38.88, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:29:47 TP0] Decode batch. #running-req: 1, #token: 1008, token usage: 0.00, gen throughput (token/s): 38.68, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:29:47] INFO:     127.0.0.1:62746 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 18:29:47 TP0] Prefill batch. #new-seq: 4, #new-token: 4, #cached-token: 528, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-08-25 18:29:47 TP0] Decode batch. #running-req: 4, #token: 253, token usage: 0.00, gen throughput (token/s): 19.76, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:29:47 TP0] Decode batch. #running-req: 4, #token: 413, token usage: 0.00, gen throughput (token/s): 865.56, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:29:48 TP0] Decode batch. #running-req: 4, #token: 573, token usage: 0.00, gen throughput (token/s): 851.33, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:29:48 TP0] Decode batch. #running-req: 4, #token: 733, token usage: 0.00, gen throughput (token/s): 845.34, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:29:48 TP0] Decode batch. #running-req: 4, #token: 893, token usage: 0.00, gen throughput (token/s): 873.56, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:29:48 TP0] Decode batch. #running-req: 4, #token: 1053, token usage: 0.00, gen throughput (token/s): 834.97, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:29:48 TP0] Decode batch. #running-req: 4, #token: 1213, token usage: 0.00, gen throughput (token/s): 835.73, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:29:48 TP0] Decode batch. #running-req: 4, #token: 1373, token usage: 0.00, gen throughput (token/s): 845.59, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:29:49 TP0] Decode batch. #running-req: 4, #token: 1533, token usage: 0.00, gen throughput (token/s): 841.78, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:29:49 TP0] Decode batch. #running-req: 4, #token: 1693, token usage: 0.00, gen throughput (token/s): 867.24, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:29:49 TP0] Decode batch. #running-req: 4, #token: 1853, token usage: 0.00, gen throughput (token/s): 852.47, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:29:49 TP0] Decode batch. #running-req: 4, #token: 2013, token usage: 0.00, gen throughput (token/s): 838.74, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:29:49 TP0] Decode batch. #running-req: 4, #token: 2173, token usage: 0.00, gen throughput (token/s): 856.70, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:29:50 TP0] Decode batch. #running-req: 4, #token: 2333, token usage: 0.00, gen throughput (token/s): 830.16, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:29:50 TP0] Decode batch. #running-req: 4, #token: 2493, token usage: 0.00, gen throughput (token/s): 870.85, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:29:50 TP0] Decode batch. #running-req: 4, #token: 2653, token usage: 0.00, gen throughput (token/s): 844.72, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:29:50 TP0] Decode batch. #running-req: 4, #token: 2813, token usage: 0.00, gen throughput (token/s): 851.92, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:29:50] INFO:     127.0.0.1:7742 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 18:29:50] INFO:     127.0.0.1:7754 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 18:29:50] INFO:     127.0.0.1:7756 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 18:29:50] INFO:     127.0.0.1:7766 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 18:29:50 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 132, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-08-25 18:29:50 TP0] Prefill batch. #new-seq: 3, #new-token: 3, #cached-token: 396, token usage: 0.00, #running-req: 1, #queue-req: 0, 
[2025-08-25 18:29:50 TP0] Decode batch. #running-req: 4, #token: 173, token usage: 0.00, gen throughput (token/s): 561.75, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:29:51 TP0] Decode batch. #running-req: 4, #token: 333, token usage: 0.00, gen throughput (token/s): 859.91, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:29:51 TP0] Decode batch. #running-req: 4, #token: 493, token usage: 0.00, gen throughput (token/s): 895.31, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:29:51 TP0] Decode batch. #running-req: 4, #token: 653, token usage: 0.00, gen throughput (token/s): 861.19, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:29:51 TP0] Decode batch. #running-req: 4, #token: 813, token usage: 0.00, gen throughput (token/s): 841.85, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:29:51 TP0] Decode batch. #running-req: 4, #token: 973, token usage: 0.00, gen throughput (token/s): 852.68, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:29:52 TP0] Decode batch. #running-req: 4, #token: 1133, token usage: 0.00, gen throughput (token/s): 854.38, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:29:52 TP0] Decode batch. #running-req: 4, #token: 1293, token usage: 0.00, gen throughput (token/s): 870.54, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:29:52 TP0] Decode batch. #running-req: 4, #token: 1453, token usage: 0.00, gen throughput (token/s): 832.52, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:29:52 TP0] Decode batch. #running-req: 4, #token: 1613, token usage: 0.00, gen throughput (token/s): 855.89, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:29:52 TP0] Decode batch. #running-req: 4, #token: 1773, token usage: 0.00, gen throughput (token/s): 849.71, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:29:52 TP0] Decode batch. #running-req: 4, #token: 1933, token usage: 0.00, gen throughput (token/s): 840.78, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:29:53 TP0] Decode batch. #running-req: 4, #token: 2093, token usage: 0.00, gen throughput (token/s): 871.97, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:29:53 TP0] Decode batch. #running-req: 4, #token: 2253, token usage: 0.00, gen throughput (token/s): 855.91, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:29:53 TP0] Decode batch. #running-req: 4, #token: 2413, token usage: 0.00, gen throughput (token/s): 845.74, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:29:53 TP0] Decode batch. #running-req: 4, #token: 2573, token usage: 0.00, gen throughput (token/s): 843.32, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:29:53 TP0] Decode batch. #running-req: 4, #token: 2733, token usage: 0.00, gen throughput (token/s): 842.54, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:29:54 TP0] Decode batch. #running-req: 4, #token: 2893, token usage: 0.00, gen throughput (token/s): 880.58, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:29:54] INFO:     127.0.0.1:7766 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 18:29:54] INFO:     127.0.0.1:7742 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 18:29:54] INFO:     127.0.0.1:7754 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 18:29:54] INFO:     127.0.0.1:7756 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 18:29:54 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 132, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-08-25 18:29:54 TP0] Prefill batch. #new-seq: 3, #new-token: 3, #cached-token: 396, token usage: 0.00, #running-req: 1, #queue-req: 0, 
[2025-08-25 18:29:54 TP0] Decode batch. #running-req: 4, #token: 253, token usage: 0.00, gen throughput (token/s): 577.80, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:29:54 TP0] Decode batch. #running-req: 4, #token: 413, token usage: 0.00, gen throughput (token/s): 881.94, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:29:54 TP0] Decode batch. #running-req: 4, #token: 573, token usage: 0.00, gen throughput (token/s): 859.95, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:29:54 TP0] Decode batch. #running-req: 4, #token: 733, token usage: 0.00, gen throughput (token/s): 854.02, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:29:55 TP0] Decode batch. #running-req: 4, #token: 893, token usage: 0.00, gen throughput (token/s): 873.13, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:29:55 TP0] Decode batch. #running-req: 4, #token: 1053, token usage: 0.00, gen throughput (token/s): 838.15, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:29:55 TP0] Decode batch. #running-req: 4, #token: 1213, token usage: 0.00, gen throughput (token/s): 864.71, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:29:55 TP0] Decode batch. #running-req: 4, #token: 1373, token usage: 0.00, gen throughput (token/s): 844.72, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:29:55 TP0] Decode batch. #running-req: 4, #token: 1533, token usage: 0.00, gen throughput (token/s): 851.82, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:29:56 TP0] Decode batch. #running-req: 4, #token: 1693, token usage: 0.00, gen throughput (token/s): 879.40, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:29:56 TP0] Decode batch. #running-req: 4, #token: 1853, token usage: 0.00, gen throughput (token/s): 854.60, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:29:56 TP0] Decode batch. #running-req: 4, #token: 2013, token usage: 0.00, gen throughput (token/s): 842.37, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:29:56 TP0] Decode batch. #running-req: 4, #token: 2173, token usage: 0.00, gen throughput (token/s): 858.41, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:29:56 TP0] Decode batch. #running-req: 4, #token: 2333, token usage: 0.00, gen throughput (token/s): 842.60, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:29:56 TP0] Decode batch. #running-req: 4, #token: 2493, token usage: 0.00, gen throughput (token/s): 858.28, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:29:57 TP0] Decode batch. #running-req: 4, #token: 2653, token usage: 0.00, gen throughput (token/s): 847.34, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:29:57 TP0] Decode batch. #running-req: 4, #token: 2813, token usage: 0.00, gen throughput (token/s): 845.69, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:29:57] INFO:     127.0.0.1:7766 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 18:29:57] INFO:     127.0.0.1:7742 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 18:29:57] INFO:     127.0.0.1:7754 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 18:29:57] INFO:     127.0.0.1:7756 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 18:29:57 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 132, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-08-25 18:29:57 TP0] Prefill batch. #new-seq: 3, #new-token: 3, #cached-token: 396, token usage: 0.00, #running-req: 1, #queue-req: 0, 
[2025-08-25 18:29:57 TP0] Decode batch. #running-req: 4, #token: 173, token usage: 0.00, gen throughput (token/s): 569.71, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:29:57 TP0] Decode batch. #running-req: 4, #token: 333, token usage: 0.00, gen throughput (token/s): 854.00, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:29:58 TP0] Decode batch. #running-req: 4, #token: 493, token usage: 0.00, gen throughput (token/s): 868.37, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:29:58 TP0] Decode batch. #running-req: 4, #token: 653, token usage: 0.00, gen throughput (token/s): 858.45, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:29:58 TP0] Decode batch. #running-req: 4, #token: 813, token usage: 0.00, gen throughput (token/s): 836.42, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:29:58 TP0] Decode batch. #running-req: 4, #token: 973, token usage: 0.00, gen throughput (token/s): 850.80, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:29:58 TP0] Decode batch. #running-req: 4, #token: 1133, token usage: 0.00, gen throughput (token/s): 840.19, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:29:58 TP0] Decode batch. #running-req: 4, #token: 1293, token usage: 0.00, gen throughput (token/s): 860.06, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:29:59 TP0] Decode batch. #running-req: 4, #token: 1453, token usage: 0.00, gen throughput (token/s): 843.51, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:29:59 TP0] Decode batch. #running-req: 4, #token: 1613, token usage: 0.00, gen throughput (token/s): 870.70, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:29:59 TP0] Decode batch. #running-req: 4, #token: 1773, token usage: 0.00, gen throughput (token/s): 842.86, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:29:59 TP0] Decode batch. #running-req: 4, #token: 1933, token usage: 0.00, gen throughput (token/s): 847.48, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:29:59 TP0] Decode batch. #running-req: 4, #token: 2093, token usage: 0.00, gen throughput (token/s): 889.83, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:30:00 TP0] Decode batch. #running-req: 4, #token: 2253, token usage: 0.00, gen throughput (token/s): 826.06, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:30:00 TP0] Decode batch. #running-req: 4, #token: 2413, token usage: 0.00, gen throughput (token/s): 838.75, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:30:00 TP0] Decode batch. #running-req: 4, #token: 2573, token usage: 0.00, gen throughput (token/s): 864.25, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:30:00 TP0] Decode batch. #running-req: 4, #token: 2733, token usage: 0.00, gen throughput (token/s): 878.37, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:30:00 TP0] Decode batch. #running-req: 4, #token: 2893, token usage: 0.00, gen throughput (token/s): 865.95, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:30:00] INFO:     127.0.0.1:7766 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 18:30:00] INFO:     127.0.0.1:7742 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 18:30:00] INFO:     127.0.0.1:7754 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 18:30:00] INFO:     127.0.0.1:7756 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 18:30:00 TP0] Prefill batch. #new-seq: 4, #new-token: 2800, #cached-token: 488, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-08-25 18:30:01] INFO:     127.0.0.1:27892 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 18:30:01] INFO:     127.0.0.1:27904 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 18:30:01] INFO:     127.0.0.1:27916 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 18:30:01] INFO:     127.0.0.1:27928 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 18:30:02 TP0] Prefill batch. #new-seq: 1, #new-token: 700, #cached-token: 122, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-08-25 18:30:02 TP0] Prefill batch. #new-seq: 3, #new-token: 2100, #cached-token: 366, token usage: 0.00, #running-req: 1, #queue-req: 0, 
[2025-08-25 18:30:02] INFO:     127.0.0.1:27928 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 18:30:02 TP0] Prefill batch. #new-seq: 1, #new-token: 700, #cached-token: 122, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-08-25 18:30:02] INFO:     127.0.0.1:27892 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 18:30:02] INFO:     127.0.0.1:27904 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 18:30:02] INFO:     127.0.0.1:27916 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 18:30:03 TP0] Prefill batch. #new-seq: 3, #new-token: 2100, #cached-token: 366, token usage: 0.00, #running-req: 1, #queue-req: 0, 
[2025-08-25 18:30:03] INFO:     127.0.0.1:27928 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 18:30:03 TP0] Prefill batch. #new-seq: 1, #new-token: 700, #cached-token: 122, token usage: 0.01, #running-req: 4, #queue-req: 0, 
[2025-08-25 18:30:04] INFO:     127.0.0.1:27892 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 18:30:04] INFO:     127.0.0.1:27904 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 18:30:04] INFO:     127.0.0.1:27916 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 18:30:04] INFO:     127.0.0.1:27928 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 18:30:04 TP0] Prefill batch. #new-seq: 1, #new-token: 700, #cached-token: 122, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-08-25 18:30:04 TP0] Prefill batch. #new-seq: 3, #new-token: 2098, #cached-token: 377, token usage: 0.00, #running-req: 1, #queue-req: 0, 
[2025-08-25 18:30:05] INFO:     127.0.0.1:27916 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 18:30:05 TP0] Prefill batch. #new-seq: 1, #new-token: 696, #cached-token: 135, token usage: 0.00, #running-req: 3, #queue-req: 0, 
[2025-08-25 18:30:05] INFO:     127.0.0.1:27892 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 18:30:05] INFO:     127.0.0.1:27904 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 18:30:05 TP0] Prefill batch. #new-seq: 2, #new-token: 1387, #cached-token: 275, token usage: 0.00, #running-req: 4, #queue-req: 0, 
[2025-08-25 18:30:07 TP0] Decode batch. #running-req: 4, #token: 3044, token usage: 0.01, gen throughput (token/s): 6.95, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:30:08 TP0] Decode batch. #running-req: 4, #token: 3204, token usage: 0.01, gen throughput (token/s): 153.29, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:30:09 TP0] Decode batch. #running-req: 4, #token: 3364, token usage: 0.01, gen throughput (token/s): 151.27, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:30:10] INFO:     127.0.0.1:27928 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 18:30:10] INFO:     127.0.0.1:27916 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 18:30:10] INFO:     127.0.0.1:27904 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 18:30:10] INFO:     127.0.0.1:27892 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 18:30:10 TP0] Prefill batch. #new-seq: 1, #new-token: 683, #cached-token: 148, token usage: 0.00, #running-req: 3, #queue-req: 0, 
[2025-08-25 18:30:10 TP0] Decode batch. #running-req: 3, #token: 831, token usage: 0.00, gen throughput (token/s): 137.01, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:30:10 TP0] Prefill batch. #new-seq: 3, #new-token: 2041, #cached-token: 452, token usage: 0.00, #running-req: 4, #queue-req: 0, 
[2025-08-25 18:30:11 TP0] Decode batch. #running-req: 4, #token: 3061, token usage: 0.01, gen throughput (token/s): 96.18, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:30:13 TP0] Decode batch. #running-req: 4, #token: 3221, token usage: 0.01, gen throughput (token/s): 152.87, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:30:14 TP0] Decode batch. #running-req: 4, #token: 3381, token usage: 0.01, gen throughput (token/s): 152.23, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:30:14] INFO:     127.0.0.1:27928 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 18:30:14] INFO:     127.0.0.1:27892 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 18:30:14] INFO:     127.0.0.1:27904 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 18:30:14] INFO:     127.0.0.1:27916 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 18:30:14 TP0] Prefill batch. #new-seq: 4, #new-token: 4, #cached-token: 720, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-08-25 18:30:15 TP0] Decode batch. #running-req: 4, #token: 301, token usage: 0.00, gen throughput (token/s): 11.26, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:30:15 TP0] Decode batch. #running-req: 4, #token: 461, token usage: 0.00, gen throughput (token/s): 876.71, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:30:15 TP0] Decode batch. #running-req: 4, #token: 621, token usage: 0.00, gen throughput (token/s): 881.28, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:30:15 TP0] Decode batch. #running-req: 4, #token: 781, token usage: 0.00, gen throughput (token/s): 874.71, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:30:15 TP0] Decode batch. #running-req: 4, #token: 941, token usage: 0.00, gen throughput (token/s): 872.61, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:30:15 TP0] Decode batch. #running-req: 4, #token: 1101, token usage: 0.00, gen throughput (token/s): 877.73, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:30:16 TP0] Decode batch. #running-req: 4, #token: 1261, token usage: 0.00, gen throughput (token/s): 840.83, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:30:16 TP0] Decode batch. #running-req: 4, #token: 1421, token usage: 0.00, gen throughput (token/s): 859.84, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:30:16 TP0] Decode batch. #running-req: 4, #token: 1581, token usage: 0.00, gen throughput (token/s): 867.55, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:30:16 TP0] Decode batch. #running-req: 4, #token: 1741, token usage: 0.00, gen throughput (token/s): 878.69, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:30:16 TP0] Decode batch. #running-req: 4, #token: 1901, token usage: 0.00, gen throughput (token/s): 857.76, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:30:17 TP0] Decode batch. #running-req: 4, #token: 2061, token usage: 0.00, gen throughput (token/s): 858.16, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:30:17 TP0] Decode batch. #running-req: 4, #token: 2221, token usage: 0.00, gen throughput (token/s): 854.22, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:30:17 TP0] Decode batch. #running-req: 4, #token: 2381, token usage: 0.00, gen throughput (token/s): 852.91, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:30:17 TP0] Decode batch. #running-req: 4, #token: 2541, token usage: 0.00, gen throughput (token/s): 874.89, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:30:17 TP0] Decode batch. #running-req: 4, #token: 2701, token usage: 0.00, gen throughput (token/s): 845.17, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:30:18 TP0] Decode batch. #running-req: 4, #token: 2861, token usage: 0.00, gen throughput (token/s): 863.71, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:30:18] INFO:     127.0.0.1:24040 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 18:30:18] INFO:     127.0.0.1:24052 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 18:30:18] INFO:     127.0.0.1:24064 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 18:30:18] INFO:     127.0.0.1:24074 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 18:30:18 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 180, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-08-25 18:30:18 TP0] Prefill batch. #new-seq: 3, #new-token: 3, #cached-token: 540, token usage: 0.00, #running-req: 1, #queue-req: 0, 
[2025-08-25 18:30:18 TP0] Decode batch. #running-req: 4, #token: 221, token usage: 0.00, gen throughput (token/s): 576.23, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:30:18 TP0] Decode batch. #running-req: 4, #token: 381, token usage: 0.00, gen throughput (token/s): 962.24, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:30:18 TP0] Decode batch. #running-req: 4, #token: 541, token usage: 0.00, gen throughput (token/s): 959.13, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:30:18 TP0] Decode batch. #running-req: 4, #token: 701, token usage: 0.00, gen throughput (token/s): 951.79, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:30:18 TP0] Decode batch. #running-req: 4, #token: 861, token usage: 0.00, gen throughput (token/s): 958.00, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:30:19 TP0] Decode batch. #running-req: 4, #token: 1021, token usage: 0.00, gen throughput (token/s): 910.97, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:30:19 TP0] Decode batch. #running-req: 4, #token: 1181, token usage: 0.00, gen throughput (token/s): 848.87, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:30:19 TP0] Decode batch. #running-req: 4, #token: 1341, token usage: 0.00, gen throughput (token/s): 879.44, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:30:19 TP0] Decode batch. #running-req: 4, #token: 1501, token usage: 0.00, gen throughput (token/s): 857.43, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:30:19 TP0] Decode batch. #running-req: 4, #token: 1661, token usage: 0.00, gen throughput (token/s): 847.84, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:30:20 TP0] Decode batch. #running-req: 4, #token: 1821, token usage: 0.00, gen throughput (token/s): 858.89, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:30:20 TP0] Decode batch. #running-req: 4, #token: 1981, token usage: 0.00, gen throughput (token/s): 859.14, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:30:20 TP0] Decode batch. #running-req: 4, #token: 2141, token usage: 0.00, gen throughput (token/s): 876.50, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:30:20 TP0] Decode batch. #running-req: 4, #token: 2301, token usage: 0.00, gen throughput (token/s): 858.30, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:30:20 TP0] Decode batch. #running-req: 4, #token: 2461, token usage: 0.00, gen throughput (token/s): 847.95, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:30:20 TP0] Decode batch. #running-req: 4, #token: 2621, token usage: 0.00, gen throughput (token/s): 847.29, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:30:21 TP0] Decode batch. #running-req: 4, #token: 2781, token usage: 0.00, gen throughput (token/s): 848.38, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:30:21 TP0] Decode batch. #running-req: 4, #token: 2941, token usage: 0.00, gen throughput (token/s): 888.57, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:30:21] INFO:     127.0.0.1:24074 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 18:30:21] INFO:     127.0.0.1:24040 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 18:30:21] INFO:     127.0.0.1:24052 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 18:30:21] INFO:     127.0.0.1:24064 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 18:30:21 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 180, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-08-25 18:30:21 TP0] Prefill batch. #new-seq: 3, #new-token: 3, #cached-token: 540, token usage: 0.00, #running-req: 1, #queue-req: 0, 
[2025-08-25 18:30:21 TP0] Decode batch. #running-req: 4, #token: 301, token usage: 0.00, gen throughput (token/s): 570.98, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:30:21 TP0] Decode batch. #running-req: 4, #token: 461, token usage: 0.00, gen throughput (token/s): 887.81, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:30:22 TP0] Decode batch. #running-req: 4, #token: 621, token usage: 0.00, gen throughput (token/s): 832.36, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:30:22 TP0] Decode batch. #running-req: 4, #token: 781, token usage: 0.00, gen throughput (token/s): 840.51, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:30:22 TP0] Decode batch. #running-req: 4, #token: 941, token usage: 0.00, gen throughput (token/s): 895.92, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:30:22 TP0] Decode batch. #running-req: 4, #token: 1101, token usage: 0.00, gen throughput (token/s): 842.02, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:30:22 TP0] Decode batch. #running-req: 4, #token: 1261, token usage: 0.00, gen throughput (token/s): 863.10, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:30:22 TP0] Decode batch. #running-req: 4, #token: 1421, token usage: 0.00, gen throughput (token/s): 850.06, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:30:23 TP0] Decode batch. #running-req: 4, #token: 1581, token usage: 0.00, gen throughput (token/s): 846.51, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:30:23 TP0] Decode batch. #running-req: 4, #token: 1741, token usage: 0.00, gen throughput (token/s): 875.85, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:30:23 TP0] Decode batch. #running-req: 4, #token: 1901, token usage: 0.00, gen throughput (token/s): 869.84, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:30:23 TP0] Decode batch. #running-req: 4, #token: 2061, token usage: 0.00, gen throughput (token/s): 873.95, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:30:23 TP0] Decode batch. #running-req: 4, #token: 2221, token usage: 0.00, gen throughput (token/s): 865.90, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:30:24 TP0] Decode batch. #running-req: 4, #token: 2381, token usage: 0.00, gen throughput (token/s): 879.36, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:30:24 TP0] Decode batch. #running-req: 4, #token: 2541, token usage: 0.00, gen throughput (token/s): 843.10, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:30:24 TP0] Decode batch. #running-req: 4, #token: 2701, token usage: 0.00, gen throughput (token/s): 850.25, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:30:24 TP0] Decode batch. #running-req: 4, #token: 2861, token usage: 0.00, gen throughput (token/s): 859.89, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:30:24] INFO:     127.0.0.1:24074 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 18:30:24] INFO:     127.0.0.1:24040 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 18:30:24] INFO:     127.0.0.1:24052 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 18:30:24] INFO:     127.0.0.1:24064 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 18:30:24 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 180, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-08-25 18:30:24 TP0] Prefill batch. #new-seq: 3, #new-token: 3, #cached-token: 540, token usage: 0.00, #running-req: 1, #queue-req: 0, 
[2025-08-25 18:30:24 TP0] Decode batch. #running-req: 4, #token: 221, token usage: 0.00, gen throughput (token/s): 560.16, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:30:25 TP0] Decode batch. #running-req: 4, #token: 381, token usage: 0.00, gen throughput (token/s): 851.41, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:30:25 TP0] Decode batch. #running-req: 4, #token: 541, token usage: 0.00, gen throughput (token/s): 874.12, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:30:25 TP0] Decode batch. #running-req: 4, #token: 701, token usage: 0.00, gen throughput (token/s): 834.81, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:30:25 TP0] Decode batch. #running-req: 4, #token: 861, token usage: 0.00, gen throughput (token/s): 856.67, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:30:25 TP0] Decode batch. #running-req: 4, #token: 1021, token usage: 0.00, gen throughput (token/s): 847.29, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:30:26 TP0] Decode batch. #running-req: 4, #token: 1181, token usage: 0.00, gen throughput (token/s): 832.26, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:30:26 TP0] Decode batch. #running-req: 4, #token: 1341, token usage: 0.00, gen throughput (token/s): 895.20, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:30:26 TP0] Decode batch. #running-req: 4, #token: 1501, token usage: 0.00, gen throughput (token/s): 851.76, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:30:26 TP0] Decode batch. #running-req: 4, #token: 1661, token usage: 0.00, gen throughput (token/s): 861.11, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:30:26 TP0] Decode batch. #running-req: 4, #token: 1821, token usage: 0.00, gen throughput (token/s): 859.37, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:30:26 TP0] Decode batch. #running-req: 4, #token: 1981, token usage: 0.00, gen throughput (token/s): 878.64, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:30:27 TP0] Decode batch. #running-req: 4, #token: 2141, token usage: 0.00, gen throughput (token/s): 883.98, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:30:27 TP0] Decode batch. #running-req: 4, #token: 2301, token usage: 0.00, gen throughput (token/s): 846.28, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:30:27 TP0] Decode batch. #running-req: 4, #token: 2461, token usage: 0.00, gen throughput (token/s): 835.37, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:30:27 TP0] Decode batch. #running-req: 4, #token: 2621, token usage: 0.00, gen throughput (token/s): 859.16, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:30:27 TP0] Decode batch. #running-req: 4, #token: 2781, token usage: 0.00, gen throughput (token/s): 842.92, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:30:28 TP0] Decode batch. #running-req: 4, #token: 2941, token usage: 0.00, gen throughput (token/s): 934.22, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:30:28] INFO:     127.0.0.1:24074 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 18:30:28] INFO:     127.0.0.1:24040 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 18:30:28] INFO:     127.0.0.1:24052 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 18:30:28] INFO:     127.0.0.1:24064 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 18:30:28 TP0] Prefill batch. #new-seq: 4, #new-token: 2800, #cached-token: 680, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-08-25 18:30:28] INFO:     127.0.0.1:54418 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 18:30:29] INFO:     127.0.0.1:54426 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 18:30:29] INFO:     127.0.0.1:54428 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 18:30:29] INFO:     127.0.0.1:54436 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 18:30:29 TP0] Prefill batch. #new-seq: 1, #new-token: 700, #cached-token: 170, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-08-25 18:30:29 TP0] Prefill batch. #new-seq: 3, #new-token: 2100, #cached-token: 510, token usage: 0.00, #running-req: 1, #queue-req: 0, 
[2025-08-25 18:30:30] INFO:     127.0.0.1:54436 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 18:30:30] INFO:     127.0.0.1:54418 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 18:30:30] INFO:     127.0.0.1:54426 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 18:30:30] INFO:     127.0.0.1:54428 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 18:30:30 TP0] Prefill batch. #new-seq: 1, #new-token: 700, #cached-token: 170, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-08-25 18:30:30 TP0] Prefill batch. #new-seq: 3, #new-token: 2100, #cached-token: 510, token usage: 0.00, #running-req: 1, #queue-req: 0, 
[2025-08-25 18:30:31] INFO:     127.0.0.1:54436 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 18:30:31] INFO:     127.0.0.1:54428 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 18:30:31] INFO:     127.0.0.1:54418 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 18:30:31] INFO:     127.0.0.1:54426 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 18:30:31 TP0] Prefill batch. #new-seq: 1, #new-token: 700, #cached-token: 170, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-08-25 18:30:31 TP0] Prefill batch. #new-seq: 3, #new-token: 2100, #cached-token: 510, token usage: 0.00, #running-req: 1, #queue-req: 0, 
[2025-08-25 18:30:31] INFO:     127.0.0.1:54436 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 18:30:32] INFO:     127.0.0.1:54418 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 18:30:32 TP0] Prefill batch. #new-seq: 1, #new-token: 685, #cached-token: 194, token usage: 0.00, #running-req: 3, #queue-req: 0, 
[2025-08-25 18:30:32] INFO:     127.0.0.1:54426 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 18:30:32] INFO:     127.0.0.1:54428 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 18:30:32 TP0] Prefill batch. #new-seq: 2, #new-token: 1358, #cached-token: 400, token usage: 0.00, #running-req: 4, #queue-req: 0, 
[2025-08-25 18:30:32 TP0] Decode batch. #running-req: 3, #token: 2278, token usage: 0.01, gen throughput (token/s): 7.93, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:30:33 TP0] Decode batch. #running-req: 3, #token: 2398, token usage: 0.01, gen throughput (token/s): 115.85, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:30:34 TP0] Decode batch. #running-req: 3, #token: 2518, token usage: 0.01, gen throughput (token/s): 116.40, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:30:35 TP0] Decode batch. #running-req: 3, #token: 2638, token usage: 0.01, gen throughput (token/s): 114.85, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:30:36] INFO:     127.0.0.1:54436 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 18:30:36] INFO:     127.0.0.1:54418 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 18:30:36] INFO:     127.0.0.1:54426 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 18:30:36 TP0] Prefill batch. #new-seq: 4, #new-token: 4, #cached-token: 516, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-08-25 18:30:36 TP0] Decode batch. #running-req: 4, #token: 250, token usage: 0.00, gen throughput (token/s): 18.28, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:30:37 TP0] Decode batch. #running-req: 4, #token: 410, token usage: 0.00, gen throughput (token/s): 853.95, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:30:37 TP0] Decode batch. #running-req: 4, #token: 570, token usage: 0.00, gen throughput (token/s): 832.82, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:30:37 TP0] Decode batch. #running-req: 4, #token: 730, token usage: 0.00, gen throughput (token/s): 854.36, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:30:37 TP0] Decode batch. #running-req: 4, #token: 890, token usage: 0.00, gen throughput (token/s): 881.49, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:30:37 TP0] Decode batch. #running-req: 4, #token: 1050, token usage: 0.00, gen throughput (token/s): 846.98, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:30:37 TP0] Decode batch. #running-req: 4, #token: 1210, token usage: 0.00, gen throughput (token/s): 854.37, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:30:38 TP0] Decode batch. #running-req: 4, #token: 1370, token usage: 0.00, gen throughput (token/s): 858.07, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:30:38 TP0] Decode batch. #running-req: 4, #token: 1530, token usage: 0.00, gen throughput (token/s): 848.98, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:30:38 TP0] Decode batch. #running-req: 4, #token: 1690, token usage: 0.00, gen throughput (token/s): 874.87, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:30:38 TP0] Decode batch. #running-req: 4, #token: 1850, token usage: 0.00, gen throughput (token/s): 843.11, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:30:38 TP0] Decode batch. #running-req: 4, #token: 2010, token usage: 0.00, gen throughput (token/s): 864.44, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:30:39 TP0] Decode batch. #running-req: 4, #token: 2170, token usage: 0.00, gen throughput (token/s): 840.59, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:30:39 TP0] Decode batch. #running-req: 4, #token: 2330, token usage: 0.00, gen throughput (token/s): 854.77, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:30:39 TP0] Decode batch. #running-req: 4, #token: 2490, token usage: 0.00, gen throughput (token/s): 878.58, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:30:39 TP0] Decode batch. #running-req: 4, #token: 2650, token usage: 0.00, gen throughput (token/s): 843.93, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:30:39 TP0] Decode batch. #running-req: 4, #token: 2810, token usage: 0.00, gen throughput (token/s): 835.56, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:30:39] INFO:     127.0.0.1:37680 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 18:30:39] INFO:     127.0.0.1:37686 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 18:30:39] INFO:     127.0.0.1:37702 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 18:30:39] INFO:     127.0.0.1:37704 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 18:30:39 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 129, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-08-25 18:30:40 TP0] Prefill batch. #new-seq: 3, #new-token: 3, #cached-token: 387, token usage: 0.00, #running-req: 1, #queue-req: 0, 
[2025-08-25 18:30:40 TP0] Decode batch. #running-req: 4, #token: 170, token usage: 0.00, gen throughput (token/s): 577.91, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:30:40 TP0] Decode batch. #running-req: 4, #token: 330, token usage: 0.00, gen throughput (token/s): 856.63, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:30:40 TP0] Decode batch. #running-req: 4, #token: 490, token usage: 0.00, gen throughput (token/s): 874.51, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:30:40 TP0] Decode batch. #running-req: 4, #token: 650, token usage: 0.00, gen throughput (token/s): 860.13, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:30:40 TP0] Decode batch. #running-req: 4, #token: 810, token usage: 0.00, gen throughput (token/s): 867.49, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:30:41 TP0] Decode batch. #running-req: 4, #token: 970, token usage: 0.00, gen throughput (token/s): 868.81, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:30:41 TP0] Decode batch. #running-req: 4, #token: 1130, token usage: 0.00, gen throughput (token/s): 872.86, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:30:41 TP0] Decode batch. #running-req: 4, #token: 1290, token usage: 0.00, gen throughput (token/s): 882.79, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:30:41 TP0] Decode batch. #running-req: 4, #token: 1450, token usage: 0.00, gen throughput (token/s): 871.15, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:30:41 TP0] Decode batch. #running-req: 4, #token: 1610, token usage: 0.00, gen throughput (token/s): 858.78, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:30:41 TP0] Decode batch. #running-req: 4, #token: 1770, token usage: 0.00, gen throughput (token/s): 850.92, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:30:42 TP0] Decode batch. #running-req: 4, #token: 1930, token usage: 0.00, gen throughput (token/s): 845.06, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:30:42 TP0] Decode batch. #running-req: 4, #token: 2090, token usage: 0.00, gen throughput (token/s): 897.47, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:30:42 TP0] Decode batch. #running-req: 4, #token: 2250, token usage: 0.00, gen throughput (token/s): 871.87, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:30:42 TP0] Decode batch. #running-req: 4, #token: 2410, token usage: 0.00, gen throughput (token/s): 857.45, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:30:42 TP0] Decode batch. #running-req: 4, #token: 2570, token usage: 0.00, gen throughput (token/s): 852.84, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:30:43 TP0] Decode batch. #running-req: 4, #token: 2730, token usage: 0.00, gen throughput (token/s): 852.08, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:30:43 TP0] Decode batch. #running-req: 4, #token: 2890, token usage: 0.00, gen throughput (token/s): 881.84, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:30:43] INFO:     127.0.0.1:37704 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 18:30:43] INFO:     127.0.0.1:37680 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 18:30:43] INFO:     127.0.0.1:37686 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 18:30:43] INFO:     127.0.0.1:37702 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 18:30:43 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 129, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-08-25 18:30:43 TP0] Prefill batch. #new-seq: 3, #new-token: 3, #cached-token: 387, token usage: 0.00, #running-req: 1, #queue-req: 0, 
[2025-08-25 18:30:43 TP0] Decode batch. #running-req: 4, #token: 250, token usage: 0.00, gen throughput (token/s): 581.83, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:30:43 TP0] Decode batch. #running-req: 4, #token: 410, token usage: 0.00, gen throughput (token/s): 854.50, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:30:43 TP0] Decode batch. #running-req: 4, #token: 570, token usage: 0.00, gen throughput (token/s): 854.40, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:30:44 TP0] Decode batch. #running-req: 4, #token: 730, token usage: 0.00, gen throughput (token/s): 858.32, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:30:44 TP0] Decode batch. #running-req: 4, #token: 890, token usage: 0.00, gen throughput (token/s): 860.63, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:30:44 TP0] Decode batch. #running-req: 4, #token: 1050, token usage: 0.00, gen throughput (token/s): 838.39, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:30:44 TP0] Decode batch. #running-req: 4, #token: 1210, token usage: 0.00, gen throughput (token/s): 846.34, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:30:44 TP0] Decode batch. #running-req: 4, #token: 1370, token usage: 0.00, gen throughput (token/s): 959.96, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:30:44 TP0] Decode batch. #running-req: 4, #token: 1530, token usage: 0.00, gen throughput (token/s): 959.02, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:30:45 TP0] Decode batch. #running-req: 4, #token: 1690, token usage: 0.00, gen throughput (token/s): 862.40, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:30:45 TP0] Decode batch. #running-req: 4, #token: 1850, token usage: 0.00, gen throughput (token/s): 829.22, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:30:45 TP0] Decode batch. #running-req: 4, #token: 2010, token usage: 0.00, gen throughput (token/s): 839.33, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:30:45 TP0] Decode batch. #running-req: 4, #token: 2170, token usage: 0.00, gen throughput (token/s): 836.98, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:30:45 TP0] Decode batch. #running-req: 4, #token: 2330, token usage: 0.00, gen throughput (token/s): 840.10, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:30:46 TP0] Decode batch. #running-req: 4, #token: 2490, token usage: 0.00, gen throughput (token/s): 872.10, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:30:46 TP0] Decode batch. #running-req: 4, #token: 2650, token usage: 0.00, gen throughput (token/s): 857.34, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:30:46 TP0] Decode batch. #running-req: 4, #token: 2810, token usage: 0.00, gen throughput (token/s): 868.03, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:30:46] INFO:     127.0.0.1:37704 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 18:30:46] INFO:     127.0.0.1:37680 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 18:30:46] INFO:     127.0.0.1:37686 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 18:30:46] INFO:     127.0.0.1:37702 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 18:30:46 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 129, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-08-25 18:30:46 TP0] Prefill batch. #new-seq: 3, #new-token: 3, #cached-token: 387, token usage: 0.00, #running-req: 1, #queue-req: 0, 
[2025-08-25 18:30:46 TP0] Decode batch. #running-req: 4, #token: 170, token usage: 0.00, gen throughput (token/s): 571.40, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:30:46 TP0] Decode batch. #running-req: 4, #token: 330, token usage: 0.00, gen throughput (token/s): 894.49, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:30:47 TP0] Decode batch. #running-req: 4, #token: 490, token usage: 0.00, gen throughput (token/s): 965.15, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:30:47 TP0] Decode batch. #running-req: 4, #token: 650, token usage: 0.00, gen throughput (token/s): 874.07, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:30:47 TP0] Decode batch. #running-req: 4, #token: 810, token usage: 0.00, gen throughput (token/s): 851.12, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:30:47 TP0] Decode batch. #running-req: 4, #token: 970, token usage: 0.00, gen throughput (token/s): 841.49, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:30:47 TP0] Decode batch. #running-req: 4, #token: 1130, token usage: 0.00, gen throughput (token/s): 831.13, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:30:48 TP0] Decode batch. #running-req: 4, #token: 1290, token usage: 0.00, gen throughput (token/s): 845.07, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:30:48 TP0] Decode batch. #running-req: 4, #token: 1450, token usage: 0.00, gen throughput (token/s): 832.20, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:30:48 TP0] Decode batch. #running-req: 4, #token: 1610, token usage: 0.00, gen throughput (token/s): 834.68, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:30:48 TP0] Decode batch. #running-req: 4, #token: 1770, token usage: 0.00, gen throughput (token/s): 834.87, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:30:48 TP0] Decode batch. #running-req: 4, #token: 1930, token usage: 0.00, gen throughput (token/s): 849.07, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:30:48 TP0] Decode batch. #running-req: 4, #token: 2090, token usage: 0.00, gen throughput (token/s): 865.21, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:30:49 TP0] Decode batch. #running-req: 4, #token: 2250, token usage: 0.00, gen throughput (token/s): 834.36, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:30:49 TP0] Decode batch. #running-req: 4, #token: 2410, token usage: 0.00, gen throughput (token/s): 842.91, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:30:49 TP0] Decode batch. #running-req: 4, #token: 2570, token usage: 0.00, gen throughput (token/s): 840.98, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:30:49 TP0] Decode batch. #running-req: 4, #token: 2730, token usage: 0.00, gen throughput (token/s): 844.06, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:30:49 TP0] Decode batch. #running-req: 4, #token: 2890, token usage: 0.00, gen throughput (token/s): 859.17, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:30:49] INFO:     127.0.0.1:37704 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 18:30:49] INFO:     127.0.0.1:37680 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 18:30:49] INFO:     127.0.0.1:37686 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 18:30:49] INFO:     127.0.0.1:37702 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 18:30:50 TP0] Prefill batch. #new-seq: 4, #new-token: 2800, #cached-token: 476, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-08-25 18:30:50] INFO:     127.0.0.1:31424 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 18:30:50] INFO:     127.0.0.1:31440 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 18:30:50] INFO:     127.0.0.1:31454 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 18:30:51] INFO:     127.0.0.1:31460 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 18:30:51 TP0] Prefill batch. #new-seq: 1, #new-token: 700, #cached-token: 119, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-08-25 18:30:51 TP0] Prefill batch. #new-seq: 3, #new-token: 2100, #cached-token: 357, token usage: 0.00, #running-req: 1, #queue-req: 0, 
[2025-08-25 18:30:51] INFO:     127.0.0.1:31460 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 18:30:51] INFO:     127.0.0.1:31424 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 18:30:52] INFO:     127.0.0.1:31440 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 18:30:52] INFO:     127.0.0.1:31454 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 18:30:52 TP0] Prefill batch. #new-seq: 1, #new-token: 700, #cached-token: 119, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-08-25 18:30:52 TP0] Prefill batch. #new-seq: 3, #new-token: 2100, #cached-token: 357, token usage: 0.00, #running-req: 1, #queue-req: 0, 
[2025-08-25 18:30:52] INFO:     127.0.0.1:31460 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 18:30:52 TP0] Prefill batch. #new-seq: 1, #new-token: 700, #cached-token: 119, token usage: 0.00, #running-req: 3, #queue-req: 0, 
[2025-08-25 18:30:52] INFO:     127.0.0.1:31424 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 18:30:53] INFO:     127.0.0.1:31440 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 18:30:53] INFO:     127.0.0.1:31454 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 18:30:53 TP0] Prefill batch. #new-seq: 3, #new-token: 2100, #cached-token: 357, token usage: 0.00, #running-req: 4, #queue-req: 0, 
[2025-08-25 18:30:53] INFO:     127.0.0.1:31460 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 18:30:53] INFO:     127.0.0.1:31424 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 18:30:53] INFO:     127.0.0.1:31440 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 18:30:54] INFO:     127.0.0.1:31454 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 18:30:54 TP0] Prefill batch. #new-seq: 1, #new-token: 696, #cached-token: 132, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-08-25 18:30:54 TP0] Prefill batch. #new-seq: 3, #new-token: 2027, #cached-token: 457, token usage: 0.00, #running-req: 1, #queue-req: 0, 
[2025-08-25 18:30:55 TP0] Decode batch. #running-req: 4, #token: 2956, token usage: 0.01, gen throughput (token/s): 6.62, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:30:56 TP0] Decode batch. #running-req: 4, #token: 3116, token usage: 0.01, gen throughput (token/s): 152.11, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:30:57 TP0] Decode batch. #running-req: 4, #token: 3276, token usage: 0.01, gen throughput (token/s): 152.22, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:30:58 TP0] Decode batch. #running-req: 4, #token: 3436, token usage: 0.01, gen throughput (token/s): 150.71, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:30:58] INFO:     127.0.0.1:31460 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 18:30:58 TP0] Prefill batch. #new-seq: 1, #new-token: 694, #cached-token: 134, token usage: 0.00, #running-req: 3, #queue-req: 0, 
[2025-08-25 18:30:58] INFO:     127.0.0.1:31424 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 18:30:58] INFO:     127.0.0.1:31440 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 18:30:58] INFO:     127.0.0.1:31454 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 18:30:58 TP0] Prefill batch. #new-seq: 1, #new-token: 696, #cached-token: 132, token usage: 0.00, #running-req: 4, #queue-req: 0, 
[2025-08-25 18:30:59 TP0] Decode batch. #running-req: 2, #token: 1564, token usage: 0.00, gen throughput (token/s): 84.86, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:31:00 TP0] Decode batch. #running-req: 2, #token: 1644, token usage: 0.01, gen throughput (token/s): 77.99, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:31:01 TP0] Decode batch. #running-req: 2, #token: 1724, token usage: 0.01, gen throughput (token/s): 77.34, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:31:02 TP0] Decode batch. #running-req: 2, #token: 1804, token usage: 0.01, gen throughput (token/s): 77.91, largest-len: 0, #queue-req: 0, 
[2025-08-25 18:31:02] INFO:     127.0.0.1:31460 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 18:31:02] INFO:     127.0.0.1:31424 - "POST /v1/chat/completions HTTP/1.1" 200 OK
slurmstepd-nwonga100: error: *** JOB 11305 ON nwonga100 CANCELLED AT 2025-08-25T19:34:21 ***
