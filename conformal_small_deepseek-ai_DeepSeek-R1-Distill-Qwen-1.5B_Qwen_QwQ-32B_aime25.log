INFO 08-25 17:25:06 __init__.py:190] Automatically detected platform cuda.
[2025-08-25 17:25:15] server_args=ServerArgs(model_path='deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B', tokenizer_path='deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B', tokenizer_mode='auto', skip_tokenizer_init=False, load_format='auto', trust_remote_code=False, dtype='auto', kv_cache_dtype='auto', quantization=None, quantization_param_path=None, context_length=None, device='cuda', served_model_name='deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B', chat_template=None, is_embedding=False, revision=None, host='0.0.0.0', port=40001, mem_fraction_static=0.9, max_running_requests=None, max_total_tokens=None, chunked_prefill_size=8192, max_prefill_tokens=16384, schedule_policy='fcfs', schedule_conservativeness=1.0, cpu_offload_gb=0, tp_size=1, stream_interval=1, stream_output=False, random_seed=986718681, constrained_json_whitespace_pattern=None, watchdog_timeout=300, dist_timeout=None, download_dir=None, base_gpu_id=0, gpu_id_step=1, log_level='info', log_level_http=None, log_requests=False, log_requests_level=0, show_time_cost=False, enable_metrics=False, decode_log_interval=40, api_key=None, file_storage_path='sglang_storage', enable_cache_report=False, reasoning_parser=None, dp_size=1, load_balance_method='round_robin', ep_size=1, dist_init_addr=None, nnodes=1, node_rank=0, json_model_override_args='{}', lora_paths=None, max_loras_per_batch=8, lora_backend='triton', attention_backend='flashinfer', sampling_backend='flashinfer', grammar_backend='outlines', speculative_algorithm=None, speculative_draft_model_path=None, speculative_num_steps=5, speculative_eagle_topk=4, speculative_num_draft_tokens=8, speculative_accept_threshold_single=1.0, speculative_accept_threshold_acc=1.0, speculative_token_map=None, enable_double_sparsity=False, ds_channel_config_path=None, ds_heavy_channel_num=32, ds_heavy_token_num=256, ds_heavy_channel_type='qk', ds_sparse_decode_threshold=4096, disable_radix_cache=False, disable_cuda_graph=False, disable_cuda_graph_padding=False, enable_nccl_nvls=False, disable_outlines_disk_cache=False, disable_custom_all_reduce=False, disable_mla=False, disable_overlap_schedule=False, enable_mixed_chunk=False, enable_dp_attention=False, enable_ep_moe=False, enable_torch_compile=False, torch_compile_max_bs=32, cuda_graph_max_bs=160, cuda_graph_bs=None, torchao_config='', enable_nan_detection=False, enable_p2p_check=False, triton_attention_reduce_in_fp32=False, triton_attention_num_kv_splits=8, num_continuous_decode_steps=1, delete_ckpt_after_loading=False, enable_memory_saver=False, allow_auto_truncate=False, enable_custom_logit_processor=False, tool_call_parser=None, enable_hierarchical_cache=False, enable_flashinfer_mla=False, flashinfer_mla_disable_ragged=False, warmups=None, debug_tensor_dump_output_folder=None, debug_tensor_dump_input_file=None, debug_tensor_dump_inject=False)
INFO 08-25 17:25:31 __init__.py:190] Automatically detected platform cuda.
INFO 08-25 17:25:31 __init__.py:190] Automatically detected platform cuda.
[2025-08-25 17:25:53 TP0] Init torch distributed begin.
[2025-08-25 17:25:53 TP0] Init torch distributed ends. mem usage=0.00 GB
[2025-08-25 17:25:53 TP0] Load weight begin. avail mem=78.73 GB
[2025-08-25 17:25:53 TP0] The following error message 'operation scheduled before its operands' can be ignored.
[2025-08-25 17:25:54 TP0] Using model weights format ['*.safetensors']
[2025-08-25 17:25:54 TP0] No model.safetensors.index.json found in remote.
Loading safetensors checkpoint shards:   0% Completed | 0/1 [00:00<?, ?it/s]
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:00<00:00,  1.57it/s]
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:00<00:00,  1.57it/s]

[2025-08-25 17:25:55 TP0] Load weight end. type=Qwen2ForCausalLM, dtype=torch.bfloat16, avail mem=75.14 GB, mem usage=3.58 GB.
[2025-08-25 17:25:55 TP0] KV Cache is allocated. #tokens: 2519168, K size: 33.63 GB, V size: 33.63 GB
[2025-08-25 17:25:55 TP0] Memory pool end. avail mem=5.76 GB
[2025-08-25 17:25:55 TP0] Capture cuda graph begin. This can take up to several minutes. avail mem=5.15 GB
  0%|          | 0/23 [00:00<?, ?it/s]  4%|▍         | 1/23 [00:01<00:30,  1.41s/it]  9%|▊         | 2/23 [00:01<00:15,  1.40it/s] 13%|█▎        | 3/23 [00:01<00:09,  2.02it/s] 17%|█▋        | 4/23 [00:02<00:07,  2.53it/s] 22%|██▏       | 5/23 [00:02<00:06,  2.98it/s] 26%|██▌       | 6/23 [00:02<00:05,  3.28it/s] 30%|███       | 7/23 [00:02<00:04,  3.61it/s] 35%|███▍      | 8/23 [00:03<00:03,  3.82it/s] 39%|███▉      | 9/23 [00:03<00:03,  3.97it/s] 43%|████▎     | 10/23 [00:03<00:03,  4.07it/s] 48%|████▊     | 11/23 [00:03<00:02,  4.20it/s] 52%|█████▏    | 12/23 [00:03<00:02,  4.33it/s] 57%|█████▋    | 13/23 [00:04<00:02,  4.43it/s] 61%|██████    | 14/23 [00:04<00:02,  4.48it/s] 65%|██████▌   | 15/23 [00:04<00:01,  4.44it/s] 70%|██████▉   | 16/23 [00:04<00:01,  4.42it/s] 74%|███████▍  | 17/23 [00:05<00:01,  4.40it/s] 78%|███████▊  | 18/23 [00:05<00:01,  4.39it/s] 83%|████████▎ | 19/23 [00:05<00:00,  4.37it/s] 87%|████████▋ | 20/23 [00:05<00:00,  4.42it/s] 91%|█████████▏| 21/23 [00:05<00:00,  4.41it/s] 96%|█████████▌| 22/23 [00:06<00:00,  4.40it/s]100%|██████████| 23/23 [00:06<00:00,  4.38it/s]100%|██████████| 23/23 [00:06<00:00,  3.58it/s]
[2025-08-25 17:26:02 TP0] Capture cuda graph end. Time elapsed: 6.42 s. avail mem=3.21 GB. mem usage=1.94 GB.
[2025-08-25 17:26:02 TP0] max_total_num_tokens=2519168, chunked_prefill_size=8192, max_prefill_tokens=16384, max_running_requests=4097, context_len=131072
[2025-08-25 17:26:03] INFO:     Started server process [2367434]
[2025-08-25 17:26:03] INFO:     Waiting for application startup.
[2025-08-25 17:26:03] INFO:     Application startup complete.
[2025-08-25 17:26:03] INFO:     Uvicorn running on http://0.0.0.0:40001 (Press CTRL+C to quit)
[2025-08-25 17:26:04] INFO:     127.0.0.1:1414 - "GET /get_model_info HTTP/1.1" 200 OK
[2025-08-25 17:26:04 TP0] Prefill batch. #new-seq: 1, #new-token: 7, #cached-token: 0, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-08-25 17:26:04] INFO:     127.0.0.1:1418 - "POST /generate HTTP/1.1" 200 OK
[2025-08-25 17:26:04] The server is fired up and ready to roll!
[2025-08-25 17:27:21 TP0] Prefill batch. #new-seq: 1, #new-token: 82, #cached-token: 1, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-08-25 17:27:21 TP0] Prefill batch. #new-seq: 2, #new-token: 164, #cached-token: 2, token usage: 0.00, #running-req: 1, #queue-req: 0, 
[2025-08-25 17:27:21 TP0] Prefill batch. #new-seq: 10, #new-token: 10, #cached-token: 820, token usage: 0.00, #running-req: 3, #queue-req: 0, 
[2025-08-25 17:27:21 TP0] Prefill batch. #new-seq: 2, #new-token: 2, #cached-token: 164, token usage: 0.00, #running-req: 13, #queue-req: 0, 
[2025-08-25 17:27:21 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 82, token usage: 0.00, #running-req: 15, #queue-req: 0, 
[2025-08-25 17:27:22 TP0] Decode batch. #running-req: 16, #token: 611, token usage: 0.00, gen throughput (token/s): 6.57, largest-len: 0, #queue-req: 0, 
[2025-08-25 17:27:22 TP0] Decode batch. #running-req: 16, #token: 1251, token usage: 0.00, gen throughput (token/s): 3102.48, largest-len: 0, #queue-req: 0, 
[2025-08-25 17:27:22 TP0] Decode batch. #running-req: 16, #token: 1891, token usage: 0.00, gen throughput (token/s): 2938.83, largest-len: 0, #queue-req: 0, 
[2025-08-25 17:27:22 TP0] Decode batch. #running-req: 16, #token: 2531, token usage: 0.00, gen throughput (token/s): 2948.40, largest-len: 0, #queue-req: 0, 
[2025-08-25 17:27:22 TP0] Decode batch. #running-req: 16, #token: 3171, token usage: 0.00, gen throughput (token/s): 3157.88, largest-len: 0, #queue-req: 0, 
[2025-08-25 17:27:23 TP0] Decode batch. #running-req: 16, #token: 3811, token usage: 0.00, gen throughput (token/s): 2907.84, largest-len: 0, #queue-req: 0, 
[2025-08-25 17:27:23 TP0] Decode batch. #running-req: 16, #token: 4451, token usage: 0.00, gen throughput (token/s): 2879.21, largest-len: 0, #queue-req: 0, 
[2025-08-25 17:27:23 TP0] Decode batch. #running-req: 16, #token: 5091, token usage: 0.00, gen throughput (token/s): 2944.72, largest-len: 0, #queue-req: 0, 
[2025-08-25 17:27:23 TP0] Decode batch. #running-req: 16, #token: 5731, token usage: 0.00, gen throughput (token/s): 2900.00, largest-len: 0, #queue-req: 0, 
[2025-08-25 17:27:23 TP0] Decode batch. #running-req: 16, #token: 6371, token usage: 0.00, gen throughput (token/s): 3125.59, largest-len: 0, #queue-req: 0, 
[2025-08-25 17:27:24 TP0] Decode batch. #running-req: 16, #token: 7011, token usage: 0.00, gen throughput (token/s): 2947.57, largest-len: 0, #queue-req: 0, 
[2025-08-25 17:27:24 TP0] Decode batch. #running-req: 16, #token: 7651, token usage: 0.00, gen throughput (token/s): 2933.78, largest-len: 0, #queue-req: 0, 
[2025-08-25 17:27:24] INFO:     127.0.0.1:32284 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 17:27:24] INFO:     127.0.0.1:32294 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 17:27:24] INFO:     127.0.0.1:32308 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 17:27:24] INFO:     127.0.0.1:32314 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 17:27:24] INFO:     127.0.0.1:32320 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 17:27:24] INFO:     127.0.0.1:32332 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 17:27:24] INFO:     127.0.0.1:32346 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 17:27:24] INFO:     127.0.0.1:32348 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 17:27:24] INFO:     127.0.0.1:32364 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 17:27:24] INFO:     127.0.0.1:32374 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 17:27:24] INFO:     127.0.0.1:32380 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 17:27:24] INFO:     127.0.0.1:32384 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 17:27:24] INFO:     127.0.0.1:32386 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 17:27:24] INFO:     127.0.0.1:32402 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 17:27:24] INFO:     127.0.0.1:32412 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 17:27:24] INFO:     127.0.0.1:32428 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 17:27:25 TP0] Prefill batch. #new-seq: 1, #new-token: 162, #cached-token: 50, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-08-25 17:27:25 TP0] Decode batch. #running-req: 1, #token: 225, token usage: 0.00, gen throughput (token/s): 623.99, largest-len: 0, #queue-req: 0, 
[2025-08-25 17:27:25 TP0] Decode batch. #running-req: 1, #token: 265, token usage: 0.00, gen throughput (token/s): 202.12, largest-len: 0, #queue-req: 0, 
[2025-08-25 17:27:25 TP0] Decode batch. #running-req: 1, #token: 305, token usage: 0.00, gen throughput (token/s): 213.20, largest-len: 0, #queue-req: 0, 
[2025-08-25 17:27:25 TP0] Decode batch. #running-req: 1, #token: 345, token usage: 0.00, gen throughput (token/s): 202.53, largest-len: 0, #queue-req: 0, 
[2025-08-25 17:27:25 TP0] Decode batch. #running-req: 1, #token: 385, token usage: 0.00, gen throughput (token/s): 199.97, largest-len: 0, #queue-req: 0, 
[2025-08-25 17:27:26 TP0] Decode batch. #running-req: 1, #token: 425, token usage: 0.00, gen throughput (token/s): 196.79, largest-len: 0, #queue-req: 0, 
[2025-08-25 17:27:26 TP0] Decode batch. #running-req: 1, #token: 465, token usage: 0.00, gen throughput (token/s): 201.68, largest-len: 0, #queue-req: 0, 
[2025-08-25 17:27:26 TP0] Decode batch. #running-req: 1, #token: 505, token usage: 0.00, gen throughput (token/s): 194.84, largest-len: 0, #queue-req: 0, 
[2025-08-25 17:27:26 TP0] Decode batch. #running-req: 1, #token: 545, token usage: 0.00, gen throughput (token/s): 194.84, largest-len: 0, #queue-req: 0, 
[2025-08-25 17:27:26 TP0] Decode batch. #running-req: 1, #token: 585, token usage: 0.00, gen throughput (token/s): 190.11, largest-len: 0, #queue-req: 0, 
[2025-08-25 17:27:27 TP0] Decode batch. #running-req: 1, #token: 625, token usage: 0.00, gen throughput (token/s): 188.36, largest-len: 0, #queue-req: 0, 
[2025-08-25 17:27:27 TP0] Decode batch. #running-req: 1, #token: 665, token usage: 0.00, gen throughput (token/s): 201.73, largest-len: 0, #queue-req: 0, 
[2025-08-25 17:27:27 TP0] Decode batch. #running-req: 1, #token: 705, token usage: 0.00, gen throughput (token/s): 195.54, largest-len: 0, #queue-req: 0, 
[2025-08-25 17:27:27] INFO:     127.0.0.1:32284 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 17:27:28 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 211, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-08-25 17:27:28 TP0] Prefill batch. #new-seq: 14, #new-token: 14, #cached-token: 2954, token usage: 0.00, #running-req: 1, #queue-req: 0, 
[2025-08-25 17:27:28 TP0] Prefill batch. #new-seq: 1, #new-token: 117, #cached-token: 50, token usage: 0.00, #running-req: 15, #queue-req: 0, 
[2025-08-25 17:27:28 TP0] Decode batch. #running-req: 16, #token: 823, token usage: 0.00, gen throughput (token/s): 505.75, largest-len: 0, #queue-req: 0, 
[2025-08-25 17:27:28 TP0] Decode batch. #running-req: 16, #token: 1463, token usage: 0.00, gen throughput (token/s): 3195.94, largest-len: 0, #queue-req: 0, 
[2025-08-25 17:27:28 TP0] Decode batch. #running-req: 16, #token: 2103, token usage: 0.00, gen throughput (token/s): 2955.65, largest-len: 0, #queue-req: 0, 
[2025-08-25 17:27:29 TP0] Decode batch. #running-req: 16, #token: 2743, token usage: 0.00, gen throughput (token/s): 3010.23, largest-len: 0, #queue-req: 0, 
[2025-08-25 17:27:29 TP0] Decode batch. #running-req: 16, #token: 3383, token usage: 0.00, gen throughput (token/s): 3122.84, largest-len: 0, #queue-req: 0, 
[2025-08-25 17:27:29 TP0] Decode batch. #running-req: 16, #token: 4023, token usage: 0.00, gen throughput (token/s): 2877.94, largest-len: 0, #queue-req: 0, 
[2025-08-25 17:27:29 TP0] Decode batch. #running-req: 16, #token: 4663, token usage: 0.00, gen throughput (token/s): 3040.02, largest-len: 0, #queue-req: 0, 
[2025-08-25 17:27:30 TP0] Decode batch. #running-req: 16, #token: 5303, token usage: 0.00, gen throughput (token/s): 2977.58, largest-len: 0, #queue-req: 0, 
[2025-08-25 17:27:30 TP0] Decode batch. #running-req: 16, #token: 5943, token usage: 0.00, gen throughput (token/s): 3000.99, largest-len: 0, #queue-req: 0, 
[2025-08-25 17:27:30 TP0] Decode batch. #running-req: 16, #token: 6583, token usage: 0.00, gen throughput (token/s): 3135.39, largest-len: 0, #queue-req: 0, 
[2025-08-25 17:27:30 TP0] Decode batch. #running-req: 16, #token: 7223, token usage: 0.00, gen throughput (token/s): 2919.41, largest-len: 0, #queue-req: 0, 
[2025-08-25 17:27:30 TP0] Decode batch. #running-req: 16, #token: 7863, token usage: 0.00, gen throughput (token/s): 2994.33, largest-len: 0, #queue-req: 0, 
[2025-08-25 17:27:31] INFO:     127.0.0.1:32308 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 17:27:31] INFO:     127.0.0.1:32320 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 17:27:31] INFO:     127.0.0.1:32332 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 17:27:31] INFO:     127.0.0.1:32346 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 17:27:31] INFO:     127.0.0.1:32284 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 17:27:31] INFO:     127.0.0.1:32294 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 17:27:31] INFO:     127.0.0.1:32314 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 17:27:31] INFO:     127.0.0.1:32348 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 17:27:31] INFO:     127.0.0.1:32364 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 17:27:31] INFO:     127.0.0.1:32374 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 17:27:31] INFO:     127.0.0.1:32380 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 17:27:31] INFO:     127.0.0.1:32384 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 17:27:31] INFO:     127.0.0.1:32386 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 17:27:31] INFO:     127.0.0.1:32402 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 17:27:31] INFO:     127.0.0.1:32412 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 17:27:31 TP0] Decode batch. #running-req: 1, #token: 660, token usage: 0.00, gen throughput (token/s): 1987.79, largest-len: 0, #queue-req: 0, 
[2025-08-25 17:27:31] INFO:     127.0.0.1:32428 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 17:27:31 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 166, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-08-25 17:27:31 TP0] Decode batch. #running-req: 1, #token: 200, token usage: 0.00, gen throughput (token/s): 99.92, largest-len: 0, #queue-req: 0, 
[2025-08-25 17:27:31 TP0] Decode batch. #running-req: 1, #token: 240, token usage: 0.00, gen throughput (token/s): 200.43, largest-len: 0, #queue-req: 0, 
[2025-08-25 17:27:31 TP0] Decode batch. #running-req: 1, #token: 280, token usage: 0.00, gen throughput (token/s): 206.15, largest-len: 0, #queue-req: 0, 
[2025-08-25 17:27:32 TP0] Decode batch. #running-req: 1, #token: 320, token usage: 0.00, gen throughput (token/s): 191.76, largest-len: 0, #queue-req: 0, 
[2025-08-25 17:27:32 TP0] Decode batch. #running-req: 1, #token: 360, token usage: 0.00, gen throughput (token/s): 201.80, largest-len: 0, #queue-req: 0, 
[2025-08-25 17:27:32 TP0] Decode batch. #running-req: 1, #token: 400, token usage: 0.00, gen throughput (token/s): 195.67, largest-len: 0, #queue-req: 0, 
[2025-08-25 17:27:32 TP0] Decode batch. #running-req: 1, #token: 440, token usage: 0.00, gen throughput (token/s): 206.60, largest-len: 0, #queue-req: 0, 
[2025-08-25 17:27:32 TP0] Decode batch. #running-req: 1, #token: 480, token usage: 0.00, gen throughput (token/s): 192.10, largest-len: 0, #queue-req: 0, 
[2025-08-25 17:27:33 TP0] Decode batch. #running-req: 1, #token: 520, token usage: 0.00, gen throughput (token/s): 189.58, largest-len: 0, #queue-req: 0, 
[2025-08-25 17:27:33 TP0] Decode batch. #running-req: 1, #token: 560, token usage: 0.00, gen throughput (token/s): 197.51, largest-len: 0, #queue-req: 0, 
[2025-08-25 17:27:33 TP0] Decode batch. #running-req: 1, #token: 600, token usage: 0.00, gen throughput (token/s): 195.47, largest-len: 0, #queue-req: 0, 
[2025-08-25 17:27:33 TP0] Decode batch. #running-req: 1, #token: 640, token usage: 0.00, gen throughput (token/s): 186.40, largest-len: 0, #queue-req: 0, 
[2025-08-25 17:27:33] INFO:     127.0.0.1:32284 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 17:27:34 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 166, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-08-25 17:27:34 TP0] Prefill batch. #new-seq: 14, #new-token: 71, #cached-token: 2210, token usage: 0.00, #running-req: 1, #queue-req: 0, 
[2025-08-25 17:27:34 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 109, token usage: 0.00, #running-req: 15, #queue-req: 0, 
[2025-08-25 17:27:34 TP0] Decode batch. #running-req: 16, #token: 413, token usage: 0.00, gen throughput (token/s): 205.25, largest-len: 0, #queue-req: 0, 
[2025-08-25 17:27:34 TP0] Decode batch. #running-req: 16, #token: 1053, token usage: 0.00, gen throughput (token/s): 3207.86, largest-len: 0, #queue-req: 0, 
[2025-08-25 17:27:35 TP0] Decode batch. #running-req: 16, #token: 1693, token usage: 0.00, gen throughput (token/s): 3237.68, largest-len: 0, #queue-req: 0, 
[2025-08-25 17:27:35 TP0] Decode batch. #running-req: 16, #token: 2333, token usage: 0.00, gen throughput (token/s): 2970.42, largest-len: 0, #queue-req: 0, 
[2025-08-25 17:27:35 TP0] Decode batch. #running-req: 16, #token: 2973, token usage: 0.00, gen throughput (token/s): 2966.20, largest-len: 0, #queue-req: 0, 
[2025-08-25 17:27:35 TP0] Decode batch. #running-req: 16, #token: 3613, token usage: 0.00, gen throughput (token/s): 3033.78, largest-len: 0, #queue-req: 0, 
[2025-08-25 17:27:35 TP0] Decode batch. #running-req: 16, #token: 4253, token usage: 0.00, gen throughput (token/s): 2931.07, largest-len: 0, #queue-req: 0, 
[2025-08-25 17:27:36 TP0] Decode batch. #running-req: 16, #token: 4893, token usage: 0.00, gen throughput (token/s): 3147.95, largest-len: 0, #queue-req: 0, 
[2025-08-25 17:27:36 TP0] Decode batch. #running-req: 16, #token: 5533, token usage: 0.00, gen throughput (token/s): 2873.34, largest-len: 0, #queue-req: 0, 
[2025-08-25 17:27:36 TP0] Decode batch. #running-req: 16, #token: 6173, token usage: 0.00, gen throughput (token/s): 3004.99, largest-len: 0, #queue-req: 0, 
[2025-08-25 17:27:36 TP0] Decode batch. #running-req: 16, #token: 6813, token usage: 0.00, gen throughput (token/s): 2979.27, largest-len: 0, #queue-req: 0, 
[2025-08-25 17:27:37 TP0] Decode batch. #running-req: 16, #token: 7453, token usage: 0.00, gen throughput (token/s): 2895.69, largest-len: 0, #queue-req: 0, 
[2025-08-25 17:27:37 TP0] Decode batch. #running-req: 16, #token: 8093, token usage: 0.00, gen throughput (token/s): 3226.31, largest-len: 0, #queue-req: 0, 
[2025-08-25 17:27:37] INFO:     127.0.0.1:32284 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 17:27:37] INFO:     127.0.0.1:32294 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 17:27:37] INFO:     127.0.0.1:32308 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 17:27:37] INFO:     127.0.0.1:32314 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 17:27:37] INFO:     127.0.0.1:32320 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 17:27:37] INFO:     127.0.0.1:32332 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 17:27:37] INFO:     127.0.0.1:32346 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 17:27:37] INFO:     127.0.0.1:32364 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 17:27:37] INFO:     127.0.0.1:32348 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 17:27:37] INFO:     127.0.0.1:32374 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 17:27:37] INFO:     127.0.0.1:32380 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 17:27:37] INFO:     127.0.0.1:32384 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 17:27:37] INFO:     127.0.0.1:32386 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 17:27:37] INFO:     127.0.0.1:32402 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 17:27:37] INFO:     127.0.0.1:32412 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 17:27:37] INFO:     127.0.0.1:32428 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 17:27:37 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 109, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-08-25 17:27:37 TP0] Decode batch. #running-req: 1, #token: 135, token usage: 0.00, gen throughput (token/s): 347.30, largest-len: 0, #queue-req: 0, 
[2025-08-25 17:27:37 TP0] Decode batch. #running-req: 1, #token: 175, token usage: 0.00, gen throughput (token/s): 188.47, largest-len: 0, #queue-req: 0, 
[2025-08-25 17:27:38 TP0] Decode batch. #running-req: 1, #token: 215, token usage: 0.00, gen throughput (token/s): 200.16, largest-len: 0, #queue-req: 0, 
[2025-08-25 17:27:38 TP0] Decode batch. #running-req: 1, #token: 255, token usage: 0.00, gen throughput (token/s): 192.37, largest-len: 0, #queue-req: 0, 
[2025-08-25 17:27:38 TP0] Decode batch. #running-req: 1, #token: 295, token usage: 0.00, gen throughput (token/s): 195.11, largest-len: 0, #queue-req: 0, 
[2025-08-25 17:27:38 TP0] Decode batch. #running-req: 1, #token: 335, token usage: 0.00, gen throughput (token/s): 194.84, largest-len: 0, #queue-req: 0, 
[2025-08-25 17:27:38 TP0] Decode batch. #running-req: 1, #token: 375, token usage: 0.00, gen throughput (token/s): 195.82, largest-len: 0, #queue-req: 0, 
[2025-08-25 17:27:39 TP0] Decode batch. #running-req: 1, #token: 415, token usage: 0.00, gen throughput (token/s): 200.00, largest-len: 0, #queue-req: 0, 
[2025-08-25 17:27:39 TP0] Decode batch. #running-req: 1, #token: 455, token usage: 0.00, gen throughput (token/s): 190.76, largest-len: 0, #queue-req: 0, 
[2025-08-25 17:27:39 TP0] Decode batch. #running-req: 1, #token: 495, token usage: 0.00, gen throughput (token/s): 196.31, largest-len: 0, #queue-req: 0, 
[2025-08-25 17:27:39 TP0] Decode batch. #running-req: 1, #token: 535, token usage: 0.00, gen throughput (token/s): 194.99, largest-len: 0, #queue-req: 0, 
[2025-08-25 17:27:40 TP0] Decode batch. #running-req: 1, #token: 575, token usage: 0.00, gen throughput (token/s): 195.71, largest-len: 0, #queue-req: 0, 
[2025-08-25 17:27:40] INFO:     127.0.0.1:32284 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 17:27:40 TP0] Prefill batch. #new-seq: 10, #new-token: 95, #cached-token: 1031, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-08-25 17:27:40 TP0] Prefill batch. #new-seq: 5, #new-token: 90, #cached-token: 486, token usage: 0.00, #running-req: 10, #queue-req: 0, 
[2025-08-25 17:27:40 TP0] Decode batch. #running-req: 15, #token: 271, token usage: 0.00, gen throughput (token/s): 97.54, largest-len: 0, #queue-req: 0, 
[2025-08-25 17:27:41 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 135, token usage: 0.00, #running-req: 15, #queue-req: 0, 
[2025-08-25 17:27:41 TP0] Decode batch. #running-req: 16, #token: 895, token usage: 0.00, gen throughput (token/s): 2548.95, largest-len: 0, #queue-req: 0, 
[2025-08-25 17:27:41 TP0] Decode batch. #running-req: 16, #token: 1535, token usage: 0.00, gen throughput (token/s): 3154.69, largest-len: 0, #queue-req: 0, 
[2025-08-25 17:27:41 TP0] Decode batch. #running-req: 16, #token: 2175, token usage: 0.00, gen throughput (token/s): 2983.40, largest-len: 0, #queue-req: 0, 
[2025-08-25 17:27:41 TP0] Decode batch. #running-req: 16, #token: 2815, token usage: 0.00, gen throughput (token/s): 2934.76, largest-len: 0, #queue-req: 0, 
[2025-08-25 17:27:42 TP0] Decode batch. #running-req: 16, #token: 3455, token usage: 0.00, gen throughput (token/s): 2972.99, largest-len: 0, #queue-req: 0, 
[2025-08-25 17:27:42 TP0] Decode batch. #running-req: 16, #token: 4095, token usage: 0.00, gen throughput (token/s): 3229.62, largest-len: 0, #queue-req: 0, 
[2025-08-25 17:27:42 TP0] Decode batch. #running-req: 16, #token: 4735, token usage: 0.00, gen throughput (token/s): 2911.91, largest-len: 0, #queue-req: 0, 
[2025-08-25 17:27:42 TP0] Decode batch. #running-req: 16, #token: 5375, token usage: 0.00, gen throughput (token/s): 2876.34, largest-len: 0, #queue-req: 0, 
[2025-08-25 17:27:42 TP0] Decode batch. #running-req: 16, #token: 6015, token usage: 0.00, gen throughput (token/s): 2851.82, largest-len: 0, #queue-req: 0, 
[2025-08-25 17:27:43 TP0] Decode batch. #running-req: 16, #token: 6655, token usage: 0.00, gen throughput (token/s): 2872.15, largest-len: 0, #queue-req: 0, 
[2025-08-25 17:27:43 TP0] Decode batch. #running-req: 16, #token: 7295, token usage: 0.00, gen throughput (token/s): 3085.91, largest-len: 0, #queue-req: 0, 
[2025-08-25 17:27:43 TP0] Decode batch. #running-req: 16, #token: 7935, token usage: 0.00, gen throughput (token/s): 2867.69, largest-len: 0, #queue-req: 0, 
[2025-08-25 17:27:43] INFO:     127.0.0.1:32294 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 17:27:43] INFO:     127.0.0.1:32308 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 17:27:43] INFO:     127.0.0.1:32314 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 17:27:43] INFO:     127.0.0.1:32320 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 17:27:43] INFO:     127.0.0.1:32332 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 17:27:43] INFO:     127.0.0.1:32346 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 17:27:43] INFO:     127.0.0.1:32348 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 17:27:43] INFO:     127.0.0.1:32364 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 17:27:43] INFO:     127.0.0.1:32374 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 17:27:43] INFO:     127.0.0.1:32380 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 17:27:43] INFO:     127.0.0.1:32384 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 17:27:43] INFO:     127.0.0.1:32386 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 17:27:43] INFO:     127.0.0.1:32402 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 17:27:43] INFO:     127.0.0.1:32284 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 17:27:43] INFO:     127.0.0.1:32412 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 17:27:43] INFO:     127.0.0.1:32428 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 17:27:44 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 135, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-08-25 17:27:44 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 135, token usage: 0.00, #running-req: 1, #queue-req: 0, 
[2025-08-25 17:27:44 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 135, token usage: 0.00, #running-req: 2, #queue-req: 0, 
[2025-08-25 17:27:44 TP0] Decode batch. #running-req: 3, #token: 148, token usage: 0.00, gen throughput (token/s): 307.46, largest-len: 0, #queue-req: 0, 
[2025-08-25 17:27:44 TP0] Decode batch. #running-req: 3, #token: 268, token usage: 0.00, gen throughput (token/s): 577.10, largest-len: 0, #queue-req: 0, 
[2025-08-25 17:27:44 TP0] Decode batch. #running-req: 3, #token: 388, token usage: 0.00, gen throughput (token/s): 583.15, largest-len: 0, #queue-req: 0, 
[2025-08-25 17:27:45 TP0] Decode batch. #running-req: 3, #token: 508, token usage: 0.00, gen throughput (token/s): 602.12, largest-len: 0, #queue-req: 0, 
[2025-08-25 17:27:45 TP0] Decode batch. #running-req: 3, #token: 628, token usage: 0.00, gen throughput (token/s): 600.50, largest-len: 0, #queue-req: 0, 
[2025-08-25 17:27:45 TP0] Decode batch. #running-req: 3, #token: 748, token usage: 0.00, gen throughput (token/s): 590.30, largest-len: 0, #queue-req: 0, 
[2025-08-25 17:27:45 TP0] Decode batch. #running-req: 3, #token: 868, token usage: 0.00, gen throughput (token/s): 592.32, largest-len: 0, #queue-req: 0, 
[2025-08-25 17:27:45 TP0] Decode batch. #running-req: 3, #token: 988, token usage: 0.00, gen throughput (token/s): 586.73, largest-len: 0, #queue-req: 0, 
[2025-08-25 17:27:46 TP0] Decode batch. #running-req: 3, #token: 1108, token usage: 0.00, gen throughput (token/s): 602.80, largest-len: 0, #queue-req: 0, 
[2025-08-25 17:27:46 TP0] Decode batch. #running-req: 3, #token: 1228, token usage: 0.00, gen throughput (token/s): 594.52, largest-len: 0, #queue-req: 0, 
[2025-08-25 17:27:46 TP0] Decode batch. #running-req: 3, #token: 1348, token usage: 0.00, gen throughput (token/s): 585.65, largest-len: 0, #queue-req: 0, 
[2025-08-25 17:27:46 TP0] Decode batch. #running-req: 3, #token: 1468, token usage: 0.00, gen throughput (token/s): 595.12, largest-len: 0, #queue-req: 0, 
[2025-08-25 17:27:46 TP0] Decode batch. #running-req: 3, #token: 1588, token usage: 0.00, gen throughput (token/s): 597.86, largest-len: 0, #queue-req: 0, 
[2025-08-25 17:27:47] INFO:     127.0.0.1:32284 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 17:27:47] INFO:     127.0.0.1:32294 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 17:27:47] INFO:     127.0.0.1:32308 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 17:27:47 TP0] Prefill batch. #new-seq: 2, #new-token: 2, #cached-token: 270, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-08-25 17:27:47 TP0] Prefill batch. #new-seq: 11, #new-token: 263, #cached-token: 1230, token usage: 0.00, #running-req: 2, #queue-req: 0, 
[2025-08-25 17:27:47 TP0] Decode batch. #running-req: 13, #token: 522, token usage: 0.00, gen throughput (token/s): 667.55, largest-len: 0, #queue-req: 0, 
[2025-08-25 17:27:47 TP0] Decode batch. #running-req: 13, #token: 1042, token usage: 0.00, gen throughput (token/s): 2326.76, largest-len: 0, #queue-req: 0, 
[2025-08-25 17:27:47 TP0] Prefill batch. #new-seq: 3, #new-token: 3, #cached-token: 402, token usage: 0.00, #running-req: 13, #queue-req: 0, 
[2025-08-25 17:27:47 TP0] Decode batch. #running-req: 16, #token: 1595, token usage: 0.00, gen throughput (token/s): 1991.75, largest-len: 0, #queue-req: 0, 
[2025-08-25 17:27:48 TP0] Decode batch. #running-req: 16, #token: 2235, token usage: 0.00, gen throughput (token/s): 3190.96, largest-len: 0, #queue-req: 0, 
[2025-08-25 17:27:48 TP0] Decode batch. #running-req: 16, #token: 2875, token usage: 0.00, gen throughput (token/s): 2865.62, largest-len: 0, #queue-req: 0, 
[2025-08-25 17:27:48 TP0] Decode batch. #running-req: 16, #token: 3515, token usage: 0.00, gen throughput (token/s): 2906.52, largest-len: 0, #queue-req: 0, 
[2025-08-25 17:27:48 TP0] Decode batch. #running-req: 16, #token: 4155, token usage: 0.00, gen throughput (token/s): 2897.45, largest-len: 0, #queue-req: 0, 
[2025-08-25 17:27:49 TP0] Decode batch. #running-req: 16, #token: 4795, token usage: 0.00, gen throughput (token/s): 3041.32, largest-len: 0, #queue-req: 0, 
[2025-08-25 17:27:49 TP0] Decode batch. #running-req: 16, #token: 5435, token usage: 0.00, gen throughput (token/s): 3182.66, largest-len: 0, #queue-req: 0, 
[2025-08-25 17:27:49 TP0] Decode batch. #running-req: 16, #token: 6075, token usage: 0.00, gen throughput (token/s): 3160.52, largest-len: 0, #queue-req: 0, 
[2025-08-25 17:27:49 TP0] Decode batch. #running-req: 16, #token: 6715, token usage: 0.00, gen throughput (token/s): 2923.55, largest-len: 0, #queue-req: 0, 
[2025-08-25 17:27:49 TP0] Decode batch. #running-req: 16, #token: 7355, token usage: 0.00, gen throughput (token/s): 2889.35, largest-len: 0, #queue-req: 0, 
[2025-08-25 17:27:50] INFO:     127.0.0.1:32284 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 17:27:50] INFO:     127.0.0.1:32308 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 17:27:50] INFO:     127.0.0.1:32320 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 17:27:50] INFO:     127.0.0.1:32332 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 17:27:50] INFO:     127.0.0.1:32346 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 17:27:50] INFO:     127.0.0.1:32294 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 17:27:50] INFO:     127.0.0.1:32348 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 17:27:50] INFO:     127.0.0.1:32364 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 17:27:50] INFO:     127.0.0.1:32374 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 17:27:50] INFO:     127.0.0.1:32380 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 17:27:50] INFO:     127.0.0.1:32384 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 17:27:50] INFO:     127.0.0.1:32314 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 17:27:50] INFO:     127.0.0.1:32386 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 17:27:50 TP0] Decode batch. #running-req: 3, #token: 1368, token usage: 0.00, gen throughput (token/s): 2422.17, largest-len: 0, #queue-req: 0, 
[2025-08-25 17:27:50 TP0] Decode batch. #running-req: 3, #token: 1488, token usage: 0.00, gen throughput (token/s): 587.52, largest-len: 0, #queue-req: 0, 
[2025-08-25 17:27:50 TP0] Prefill batch. #new-seq: 2, #new-token: 2, #cached-token: 268, token usage: 0.00, #running-req: 3, #queue-req: 0, 
[2025-08-25 17:27:50 TP0] Decode batch. #running-req: 5, #token: 1614, token usage: 0.00, gen throughput (token/s): 504.96, largest-len: 0, #queue-req: 0, 
[2025-08-25 17:27:50] INFO:     127.0.0.1:32402 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 17:27:50] INFO:     127.0.0.1:32428 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 17:27:50] INFO:     127.0.0.1:32412 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 17:27:50 TP0] Decode batch. #running-req: 2, #token: 221, token usage: 0.00, gen throughput (token/s): 438.34, largest-len: 0, #queue-req: 0, 
[2025-08-25 17:27:51 TP0] Decode batch. #running-req: 2, #token: 301, token usage: 0.00, gen throughput (token/s): 366.93, largest-len: 0, #queue-req: 0, 
[2025-08-25 17:27:51 TP0] Decode batch. #running-req: 2, #token: 381, token usage: 0.00, gen throughput (token/s): 432.90, largest-len: 0, #queue-req: 0, 
[2025-08-25 17:27:51 TP0] Decode batch. #running-req: 2, #token: 461, token usage: 0.00, gen throughput (token/s): 365.79, largest-len: 0, #queue-req: 0, 
[2025-08-25 17:27:51 TP0] Decode batch. #running-req: 2, #token: 541, token usage: 0.00, gen throughput (token/s): 434.13, largest-len: 0, #queue-req: 0, 
[2025-08-25 17:27:51 TP0] Decode batch. #running-req: 2, #token: 621, token usage: 0.00, gen throughput (token/s): 435.90, largest-len: 0, #queue-req: 0, 
[2025-08-25 17:27:52 TP0] Decode batch. #running-req: 2, #token: 701, token usage: 0.00, gen throughput (token/s): 432.15, largest-len: 0, #queue-req: 0, 
[2025-08-25 17:27:52 TP0] Decode batch. #running-req: 2, #token: 781, token usage: 0.00, gen throughput (token/s): 334.52, largest-len: 0, #queue-req: 0, 
[2025-08-25 17:27:52 TP0] Decode batch. #running-req: 2, #token: 861, token usage: 0.00, gen throughput (token/s): 413.38, largest-len: 0, #queue-req: 0, 
[2025-08-25 17:27:52 TP0] Decode batch. #running-req: 2, #token: 941, token usage: 0.00, gen throughput (token/s): 384.61, largest-len: 0, #queue-req: 0, 
[2025-08-25 17:27:52 TP0] Decode batch. #running-req: 2, #token: 1021, token usage: 0.00, gen throughput (token/s): 433.88, largest-len: 0, #queue-req: 0, 
[2025-08-25 17:27:52 TP0] Prefill batch. #new-seq: 11, #new-token: 446, #cached-token: 1225, token usage: 0.00, #running-req: 2, #queue-req: 0, 
[2025-08-25 17:27:53 TP0] Decode batch. #running-req: 13, #token: 1567, token usage: 0.00, gen throughput (token/s): 1211.21, largest-len: 0, #queue-req: 0, 
[2025-08-25 17:27:53] INFO:     127.0.0.1:32284 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 17:27:53] INFO:     127.0.0.1:32294 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 17:27:53 TP0] Decode batch. #running-req: 11, #token: 1041, token usage: 0.00, gen throughput (token/s): 2045.58, largest-len: 0, #queue-req: 0, 
[2025-08-25 17:27:53 TP0] Prefill batch. #new-seq: 3, #new-token: 3, #cached-token: 588, token usage: 0.00, #running-req: 11, #queue-req: 0, 
[2025-08-25 17:27:53 TP0] Decode batch. #running-req: 14, #token: 1517, token usage: 0.00, gen throughput (token/s): 1595.12, largest-len: 0, #queue-req: 0, 
[2025-08-25 17:27:53 TP0] Decode batch. #running-req: 14, #token: 2077, token usage: 0.00, gen throughput (token/s): 2522.37, largest-len: 0, #queue-req: 0, 
[2025-08-25 17:27:53 TP0] Prefill batch. #new-seq: 2, #new-token: 2, #cached-token: 392, token usage: 0.00, #running-req: 14, #queue-req: 0, 
[2025-08-25 17:27:54 TP0] Decode batch. #running-req: 16, #token: 2699, token usage: 0.00, gen throughput (token/s): 2239.79, largest-len: 0, #queue-req: 0, 
[2025-08-25 17:27:54 TP0] Decode batch. #running-req: 16, #token: 3339, token usage: 0.00, gen throughput (token/s): 2899.21, largest-len: 0, #queue-req: 0, 
[2025-08-25 17:27:54 TP0] Decode batch. #running-req: 16, #token: 3979, token usage: 0.00, gen throughput (token/s): 2839.41, largest-len: 0, #queue-req: 0, 
[2025-08-25 17:27:54 TP0] Decode batch. #running-req: 16, #token: 4619, token usage: 0.00, gen throughput (token/s): 2823.37, largest-len: 0, #queue-req: 0, 
[2025-08-25 17:27:55 TP0] Decode batch. #running-req: 16, #token: 5259, token usage: 0.00, gen throughput (token/s): 3011.21, largest-len: 0, #queue-req: 0, 
[2025-08-25 17:27:55 TP0] Decode batch. #running-req: 16, #token: 5899, token usage: 0.00, gen throughput (token/s): 2869.76, largest-len: 0, #queue-req: 0, 
[2025-08-25 17:27:55 TP0] Decode batch. #running-req: 16, #token: 6539, token usage: 0.00, gen throughput (token/s): 2882.34, largest-len: 0, #queue-req: 0, 
[2025-08-25 17:27:55 TP0] Decode batch. #running-req: 16, #token: 7179, token usage: 0.00, gen throughput (token/s): 2881.44, largest-len: 0, #queue-req: 0, 
[2025-08-25 17:27:55] INFO:     127.0.0.1:32314 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 17:27:55] INFO:     127.0.0.1:32320 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 17:27:55] INFO:     127.0.0.1:32332 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 17:27:55] INFO:     127.0.0.1:32346 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 17:27:55] INFO:     127.0.0.1:32348 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 17:27:55] INFO:     127.0.0.1:32364 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 17:27:55] INFO:     127.0.0.1:32374 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 17:27:55] INFO:     127.0.0.1:32380 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 17:27:55] INFO:     127.0.0.1:32308 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 17:27:55] INFO:     127.0.0.1:32384 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 17:27:55] INFO:     127.0.0.1:32386 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 17:27:55 TP0] Decode batch. #running-req: 5, #token: 2135, token usage: 0.00, gen throughput (token/s): 2687.49, largest-len: 0, #queue-req: 0, 
[2025-08-25 17:27:56 TP0] Decode batch. #running-req: 5, #token: 2335, token usage: 0.00, gen throughput (token/s): 851.15, largest-len: 0, #queue-req: 0, 
[2025-08-25 17:27:56 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 196, token usage: 0.00, #running-req: 5, #queue-req: 0, 
[2025-08-25 17:27:56 TP0] Decode batch. #running-req: 6, #token: 2569, token usage: 0.00, gen throughput (token/s): 849.92, largest-len: 0, #queue-req: 0, 
[2025-08-25 17:27:56] INFO:     127.0.0.1:32402 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 17:27:56] INFO:     127.0.0.1:32294 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 17:27:56] INFO:     127.0.0.1:32284 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 17:27:56 TP0] Decode batch. #running-req: 3, #token: 1213, token usage: 0.00, gen throughput (token/s): 698.94, largest-len: 0, #queue-req: 0, 
[2025-08-25 17:27:56] INFO:     127.0.0.1:32428 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 17:27:56] INFO:     127.0.0.1:32412 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 17:27:56 TP0] Decode batch. #running-req: 1, #token: 311, token usage: 0.00, gen throughput (token/s): 407.44, largest-len: 0, #queue-req: 0, 
[2025-08-25 17:27:57 TP0] Decode batch. #running-req: 1, #token: 351, token usage: 0.00, gen throughput (token/s): 179.28, largest-len: 0, #queue-req: 0, 
[2025-08-25 17:27:57 TP0] Decode batch. #running-req: 1, #token: 391, token usage: 0.00, gen throughput (token/s): 207.41, largest-len: 0, #queue-req: 0, 
[2025-08-25 17:27:57 TP0] Decode batch. #running-req: 1, #token: 431, token usage: 0.00, gen throughput (token/s): 165.69, largest-len: 0, #queue-req: 0, 
[2025-08-25 17:27:57 TP0] Decode batch. #running-req: 1, #token: 471, token usage: 0.00, gen throughput (token/s): 186.22, largest-len: 0, #queue-req: 0, 
[2025-08-25 17:27:57 TP0] Decode batch. #running-req: 1, #token: 511, token usage: 0.00, gen throughput (token/s): 191.39, largest-len: 0, #queue-req: 0, 
[2025-08-25 17:27:58 TP0] Decode batch. #running-req: 1, #token: 551, token usage: 0.00, gen throughput (token/s): 189.57, largest-len: 0, #queue-req: 0, 
[2025-08-25 17:27:58 TP0] Decode batch. #running-req: 1, #token: 591, token usage: 0.00, gen throughput (token/s): 191.85, largest-len: 0, #queue-req: 0, 
[2025-08-25 17:27:58 TP0] Prefill batch. #new-seq: 10, #new-token: 376, #cached-token: 1522, token usage: 0.00, #running-req: 1, #queue-req: 0, 
[2025-08-25 17:27:58 TP0] Decode batch. #running-req: 11, #token: 944, token usage: 0.00, gen throughput (token/s): 663.29, largest-len: 0, #queue-req: 0, 
[2025-08-25 17:27:58 TP0] Decode batch. #running-req: 11, #token: 1384, token usage: 0.00, gen throughput (token/s): 2101.78, largest-len: 0, #queue-req: 0, 
[2025-08-25 17:27:59] INFO:     127.0.0.1:32308 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 17:27:59 TP0] Decode batch. #running-req: 10, #token: 1310, token usage: 0.00, gen throughput (token/s): 1952.45, largest-len: 0, #queue-req: 0, 
[2025-08-25 17:27:59 TP0] Decode batch. #running-req: 10, #token: 1710, token usage: 0.00, gen throughput (token/s): 1777.61, largest-len: 0, #queue-req: 0, 
[2025-08-25 17:27:59 TP0] Decode batch. #running-req: 10, #token: 2110, token usage: 0.00, gen throughput (token/s): 1651.98, largest-len: 0, #queue-req: 0, 
[2025-08-25 17:27:59 TP0] Prefill batch. #new-seq: 2, #new-token: 2, #cached-token: 344, token usage: 0.00, #running-req: 10, #queue-req: 0, 
[2025-08-25 17:27:59 TP0] Prefill batch. #new-seq: 3, #new-token: 3, #cached-token: 516, token usage: 0.00, #running-req: 12, #queue-req: 0, 
[2025-08-25 17:27:59 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 172, token usage: 0.00, #running-req: 15, #queue-req: 0, 
[2025-08-25 17:28:00 TP0] Decode batch. #running-req: 16, #token: 2719, token usage: 0.00, gen throughput (token/s): 1541.66, largest-len: 0, #queue-req: 0, 
[2025-08-25 17:28:00 TP0] Decode batch. #running-req: 16, #token: 3359, token usage: 0.00, gen throughput (token/s): 3124.07, largest-len: 0, #queue-req: 0, 
[2025-08-25 17:28:00 TP0] Decode batch. #running-req: 16, #token: 3999, token usage: 0.00, gen throughput (token/s): 3107.51, largest-len: 0, #queue-req: 0, 
[2025-08-25 17:28:00 TP0] Decode batch. #running-req: 16, #token: 4639, token usage: 0.00, gen throughput (token/s): 3196.57, largest-len: 0, #queue-req: 0, 
[2025-08-25 17:28:00 TP0] Decode batch. #running-req: 16, #token: 5279, token usage: 0.00, gen throughput (token/s): 3003.71, largest-len: 0, #queue-req: 0, 
[2025-08-25 17:28:01 TP0] Decode batch. #running-req: 16, #token: 5919, token usage: 0.00, gen throughput (token/s): 2898.44, largest-len: 0, #queue-req: 0, 
[2025-08-25 17:28:01 TP0] Decode batch. #running-req: 16, #token: 6559, token usage: 0.00, gen throughput (token/s): 3120.98, largest-len: 0, #queue-req: 0, 
[2025-08-25 17:28:01 TP0] Decode batch. #running-req: 16, #token: 7199, token usage: 0.00, gen throughput (token/s): 3175.63, largest-len: 0, #queue-req: 0, 
[2025-08-25 17:28:01] INFO:     127.0.0.1:32294 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 17:28:01] INFO:     127.0.0.1:32314 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 17:28:01] INFO:     127.0.0.1:32320 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 17:28:01] INFO:     127.0.0.1:32332 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 17:28:01] INFO:     127.0.0.1:32346 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 17:28:01] INFO:     127.0.0.1:32348 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 17:28:01] INFO:     127.0.0.1:32364 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 17:28:01] INFO:     127.0.0.1:32374 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 17:28:01] INFO:     127.0.0.1:32380 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 17:28:01] INFO:     127.0.0.1:32284 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 17:28:01 TP0] Decode batch. #running-req: 6, #token: 2302, token usage: 0.00, gen throughput (token/s): 1258.91, largest-len: 0, #queue-req: 0, 
[2025-08-25 17:28:01 TP0] Decode batch. #running-req: 6, #token: 2542, token usage: 0.00, gen throughput (token/s): 1166.48, largest-len: 0, #queue-req: 0, 
[2025-08-25 17:28:02 TP0] Decode batch. #running-req: 6, #token: 2782, token usage: 0.00, gen throughput (token/s): 1156.33, largest-len: 0, #queue-req: 0, 
[2025-08-25 17:28:02 TP0] Decode batch. #running-req: 6, #token: 3022, token usage: 0.00, gen throughput (token/s): 1111.11, largest-len: 0, #queue-req: 0, 
[2025-08-25 17:28:02 TP0] Prefill batch. #new-seq: 4, #new-token: 4, #cached-token: 688, token usage: 0.00, #running-req: 6, #queue-req: 0, 
[2025-08-25 17:28:02] INFO:     127.0.0.1:32308 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 17:28:02] INFO:     127.0.0.1:32384 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 17:28:02] INFO:     127.0.0.1:32386 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 17:28:02] INFO:     127.0.0.1:32402 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 17:28:02] INFO:     127.0.0.1:32412 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 17:28:02 TP0] Decode batch. #running-req: 5, #token: 808, token usage: 0.00, gen throughput (token/s): 999.81, largest-len: 0, #queue-req: 0, 
[2025-08-25 17:28:02] INFO:     127.0.0.1:32428 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 17:28:02 TP0] Decode batch. #running-req: 4, #token: 469, token usage: 0.00, gen throughput (token/s): 862.57, largest-len: 0, #queue-req: 0, 
[2025-08-25 17:28:03 TP0] Decode batch. #running-req: 4, #token: 629, token usage: 0.00, gen throughput (token/s): 756.69, largest-len: 0, #queue-req: 0, 
[2025-08-25 17:28:03 TP0] Decode batch. #running-req: 4, #token: 789, token usage: 0.00, gen throughput (token/s): 777.70, largest-len: 0, #queue-req: 0, 
[2025-08-25 17:28:03 TP0] Decode batch. #running-req: 4, #token: 949, token usage: 0.00, gen throughput (token/s): 769.74, largest-len: 0, #queue-req: 0, 
[2025-08-25 17:28:03 TP0] Decode batch. #running-req: 4, #token: 1109, token usage: 0.00, gen throughput (token/s): 692.72, largest-len: 0, #queue-req: 0, 
[2025-08-25 17:28:03 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 172, token usage: 0.00, #running-req: 4, #queue-req: 0, 
[2025-08-25 17:28:03 TP0] Prefill batch. #new-seq: 5, #new-token: 314, #cached-token: 497, token usage: 0.00, #running-req: 5, #queue-req: 0, 
[2025-08-25 17:28:04 TP0] Decode batch. #running-req: 10, #token: 1578, token usage: 0.00, gen throughput (token/s): 995.85, largest-len: 0, #queue-req: 0, 
[2025-08-25 17:28:04 TP0] Decode batch. #running-req: 10, #token: 1978, token usage: 0.00, gen throughput (token/s): 1659.22, largest-len: 0, #queue-req: 0, 
[2025-08-25 17:28:04 TP0] Decode batch. #running-req: 10, #token: 2378, token usage: 0.00, gen throughput (token/s): 1825.97, largest-len: 0, #queue-req: 0, 
[2025-08-25 17:28:04 TP0] Decode batch. #running-req: 10, #token: 2778, token usage: 0.00, gen throughput (token/s): 1933.76, largest-len: 0, #queue-req: 0, 
[2025-08-25 17:28:04 TP0] Decode batch. #running-req: 10, #token: 3178, token usage: 0.00, gen throughput (token/s): 1737.34, largest-len: 0, #queue-req: 0, 
[2025-08-25 17:28:05 TP0] Prefill batch. #new-seq: 2, #new-token: 2, #cached-token: 308, token usage: 0.00, #running-req: 10, #queue-req: 0, 
[2025-08-25 17:28:05 TP0] Prefill batch. #new-seq: 4, #new-token: 4, #cached-token: 616, token usage: 0.00, #running-req: 12, #queue-req: 0, 
[2025-08-25 17:28:05 TP0] Decode batch. #running-req: 16, #token: 3598, token usage: 0.00, gen throughput (token/s): 1385.34, largest-len: 0, #queue-req: 0, 
[2025-08-25 17:28:05] INFO:     127.0.0.1:32284 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 17:28:05] INFO:     127.0.0.1:32294 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 17:28:05] INFO:     127.0.0.1:32314 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 17:28:05] INFO:     127.0.0.1:32320 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 17:28:05 TP0] Decode batch. #running-req: 12, #token: 2182, token usage: 0.00, gen throughput (token/s): 2848.58, largest-len: 0, #queue-req: 0, 
[2025-08-25 17:28:05 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 154, token usage: 0.00, #running-req: 12, #queue-req: 0, 
[2025-08-25 17:28:05 TP0] Decode batch. #running-req: 13, #token: 2669, token usage: 0.00, gen throughput (token/s): 1828.68, largest-len: 0, #queue-req: 0, 
[2025-08-25 17:28:05 TP0] Decode batch. #running-req: 13, #token: 3189, token usage: 0.00, gen throughput (token/s): 2261.80, largest-len: 0, #queue-req: 0, 
[2025-08-25 17:28:06 TP0] Decode batch. #running-req: 13, #token: 3709, token usage: 0.00, gen throughput (token/s): 2403.19, largest-len: 0, #queue-req: 0, 
[2025-08-25 17:28:06 TP0] Prefill batch. #new-seq: 3, #new-token: 3, #cached-token: 462, token usage: 0.00, #running-req: 13, #queue-req: 0, 
[2025-08-25 17:28:06 TP0] Decode batch. #running-req: 16, #token: 4286, token usage: 0.00, gen throughput (token/s): 1981.67, largest-len: 0, #queue-req: 0, 
[2025-08-25 17:28:06 TP0] Decode batch. #running-req: 16, #token: 4926, token usage: 0.00, gen throughput (token/s): 3014.85, largest-len: 0, #queue-req: 0, 
[2025-08-25 17:28:06] INFO:     127.0.0.1:32308 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 17:28:06] INFO:     127.0.0.1:32332 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 17:28:06] INFO:     127.0.0.1:32346 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 17:28:06] INFO:     127.0.0.1:32348 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 17:28:06] INFO:     127.0.0.1:32364 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 17:28:06] INFO:     127.0.0.1:32374 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 17:28:06 TP0] Decode batch. #running-req: 10, #token: 2359, token usage: 0.00, gen throughput (token/s): 2515.05, largest-len: 0, #queue-req: 0, 
[2025-08-25 17:28:07 TP0] Decode batch. #running-req: 10, #token: 2759, token usage: 0.00, gen throughput (token/s): 1881.30, largest-len: 0, #queue-req: 0, 
[2025-08-25 17:28:07 TP0] Decode batch. #running-req: 10, #token: 3159, token usage: 0.00, gen throughput (token/s): 1847.60, largest-len: 0, #queue-req: 0, 
[2025-08-25 17:28:07 TP0] Prefill batch. #new-seq: 3, #new-token: 3, #cached-token: 462, token usage: 0.00, #running-req: 10, #queue-req: 0, 
[2025-08-25 17:28:07 TP0] Decode batch. #running-req: 13, #token: 3574, token usage: 0.00, gen throughput (token/s): 1607.20, largest-len: 0, #queue-req: 0, 
[2025-08-25 17:28:07 TP0] Decode batch. #running-req: 13, #token: 4094, token usage: 0.00, gen throughput (token/s): 2310.34, largest-len: 0, #queue-req: 0, 
[2025-08-25 17:28:07 TP0] Decode batch. #running-req: 13, #token: 4614, token usage: 0.00, gen throughput (token/s): 2384.23, largest-len: 0, #queue-req: 0, 
[2025-08-25 17:28:08] INFO:     127.0.0.1:32402 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 17:28:08] INFO:     127.0.0.1:32386 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 17:28:08] INFO:     127.0.0.1:32412 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 17:28:08] INFO:     127.0.0.1:32428 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 17:28:08] INFO:     127.0.0.1:32384 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 17:28:08] INFO:     127.0.0.1:32380 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 17:28:08 TP0] Prefill batch. #new-seq: 3, #new-token: 771, #cached-token: 156, token usage: 0.00, #running-req: 7, #queue-req: 0, 
[2025-08-25 17:28:08 TP0] Decode batch. #running-req: 10, #token: 2294, token usage: 0.00, gen throughput (token/s): 1276.61, largest-len: 0, #queue-req: 0, 
[2025-08-25 17:28:08 TP0] Decode batch. #running-req: 10, #token: 2694, token usage: 0.00, gen throughput (token/s): 1824.19, largest-len: 0, #queue-req: 0, 
[2025-08-25 17:28:08] INFO:     127.0.0.1:32284 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 17:28:08 TP0] Decode batch. #running-req: 9, #token: 2567, token usage: 0.00, gen throughput (token/s): 1738.89, largest-len: 0, #queue-req: 0, 
[2025-08-25 17:28:08 TP0] Decode batch. #running-req: 9, #token: 2927, token usage: 0.00, gen throughput (token/s): 1659.83, largest-len: 0, #queue-req: 0, 
[2025-08-25 17:28:09 TP0] Decode batch. #running-req: 9, #token: 3287, token usage: 0.00, gen throughput (token/s): 1472.41, largest-len: 0, #queue-req: 0, 
[2025-08-25 17:28:09] INFO:     127.0.0.1:32320 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 17:28:09] INFO:     127.0.0.1:32314 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 17:28:09] INFO:     127.0.0.1:32294 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 17:28:09 TP0] Decode batch. #running-req: 6, #token: 2030, token usage: 0.00, gen throughput (token/s): 1086.58, largest-len: 0, #queue-req: 0, 
[2025-08-25 17:28:09 TP0] Prefill batch. #new-seq: 6, #new-token: 6, #cached-token: 1848, token usage: 0.00, #running-req: 6, #queue-req: 0, 
[2025-08-25 17:28:09 TP0] Decode batch. #running-req: 12, #token: 2468, token usage: 0.00, gen throughput (token/s): 1338.56, largest-len: 0, #queue-req: 0, 
[2025-08-25 17:28:09 TP0] Decode batch. #running-req: 12, #token: 2948, token usage: 0.00, gen throughput (token/s): 2151.80, largest-len: 0, #queue-req: 0, 
[2025-08-25 17:28:10 TP0] Decode batch. #running-req: 12, #token: 3428, token usage: 0.00, gen throughput (token/s): 2279.42, largest-len: 0, #queue-req: 0, 
[2025-08-25 17:28:10 TP0] Prefill batch. #new-seq: 4, #new-token: 4, #cached-token: 1232, token usage: 0.00, #running-req: 12, #queue-req: 0, 
[2025-08-25 17:28:10 TP0] Decode batch. #running-req: 16, #token: 3956, token usage: 0.00, gen throughput (token/s): 1683.51, largest-len: 0, #queue-req: 0, 
[2025-08-25 17:28:10] INFO:     127.0.0.1:32308 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 17:28:10] INFO:     127.0.0.1:32332 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 17:28:10] INFO:     127.0.0.1:32346 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 17:28:10 TP0] Decode batch. #running-req: 13, #token: 2917, token usage: 0.00, gen throughput (token/s): 2264.40, largest-len: 0, #queue-req: 0, 
[2025-08-25 17:28:10 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 308, token usage: 0.00, #running-req: 13, #queue-req: 0, 
[2025-08-25 17:28:11 TP0] Decode batch. #running-req: 14, #token: 3465, token usage: 0.00, gen throughput (token/s): 1875.73, largest-len: 0, #queue-req: 0, 
[2025-08-25 17:28:11 TP0] Decode batch. #running-req: 14, #token: 4025, token usage: 0.00, gen throughput (token/s): 2634.48, largest-len: 0, #queue-req: 0, 
[2025-08-25 17:28:11] INFO:     127.0.0.1:32348 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 17:28:11] INFO:     127.0.0.1:32364 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 17:28:11] INFO:     127.0.0.1:32374 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 17:28:11 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 308, token usage: 0.00, #running-req: 14, #queue-req: 0, 
[2025-08-25 17:28:11 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 308, token usage: 0.00, #running-req: 15, #queue-req: 0, 
[2025-08-25 17:28:11 TP0] Decode batch. #running-req: 13, #token: 3051, token usage: 0.00, gen throughput (token/s): 1784.65, largest-len: 0, #queue-req: 0, 
[2025-08-25 17:28:11 TP0] Decode batch. #running-req: 13, #token: 3571, token usage: 0.00, gen throughput (token/s): 2434.12, largest-len: 0, #queue-req: 0, 
[2025-08-25 17:28:11 TP0] Decode batch. #running-req: 13, #token: 4091, token usage: 0.00, gen throughput (token/s): 2483.81, largest-len: 0, #queue-req: 0, 
[2025-08-25 17:28:12 TP0] Prefill batch. #new-seq: 3, #new-token: 609, #cached-token: 150, token usage: 0.00, #running-req: 13, #queue-req: 0, 
[2025-08-25 17:28:12 TP0] Decode batch. #running-req: 16, #token: 4907, token usage: 0.00, gen throughput (token/s): 2200.75, largest-len: 0, #queue-req: 0, 
[2025-08-25 17:28:12 TP0] Decode batch. #running-req: 16, #token: 5547, token usage: 0.00, gen throughput (token/s): 2959.00, largest-len: 0, #queue-req: 0, 
[2025-08-25 17:28:12] INFO:     127.0.0.1:32284 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 17:28:12] INFO:     127.0.0.1:32294 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 17:28:12] INFO:     127.0.0.1:32314 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 17:28:12] INFO:     127.0.0.1:32320 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 17:28:12] INFO:     127.0.0.1:32380 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 17:28:12] INFO:     127.0.0.1:32384 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 17:28:12 TP0] Decode batch. #running-req: 10, #token: 3109, token usage: 0.00, gen throughput (token/s): 2467.49, largest-len: 0, #queue-req: 0, 
[2025-08-25 17:28:12 TP0] Decode batch. #running-req: 10, #token: 3509, token usage: 0.00, gen throughput (token/s): 1930.02, largest-len: 0, #queue-req: 0, 
[2025-08-25 17:28:13 TP0] Decode batch. #running-req: 10, #token: 3909, token usage: 0.00, gen throughput (token/s): 1770.86, largest-len: 0, #queue-req: 0, 
[2025-08-25 17:28:13 TP0] Decode batch. #running-req: 10, #token: 4309, token usage: 0.00, gen throughput (token/s): 1782.11, largest-len: 0, #queue-req: 0, 
[2025-08-25 17:28:13] INFO:     127.0.0.1:32428 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 17:28:13] INFO:     127.0.0.1:32386 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 17:28:13] INFO:     127.0.0.1:32412 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 17:28:13] INFO:     127.0.0.1:32402 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 17:28:13 TP0] Decode batch. #running-req: 6, #token: 2581, token usage: 0.00, gen throughput (token/s): 1205.88, largest-len: 0, #queue-req: 0, 
[2025-08-25 17:28:13] INFO:     127.0.0.1:32308 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 17:28:13 TP0] Decode batch. #running-req: 5, #token: 2313, token usage: 0.00, gen throughput (token/s): 951.21, largest-len: 0, #queue-req: 0, 
[2025-08-25 17:28:13 TP0] Prefill batch. #new-seq: 6, #new-token: 6, #cached-token: 1512, token usage: 0.00, #running-req: 5, #queue-req: 0, 
[2025-08-25 17:28:14 TP0] Decode batch. #running-req: 11, #token: 2615, token usage: 0.00, gen throughput (token/s): 1047.26, largest-len: 0, #queue-req: 0, 
[2025-08-25 17:28:14] INFO:     127.0.0.1:32332 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 17:28:14] INFO:     127.0.0.1:32346 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 17:28:14 TP0] Decode batch. #running-req: 9, #token: 1768, token usage: 0.00, gen throughput (token/s): 1886.98, largest-len: 0, #queue-req: 0, 
[2025-08-25 17:28:14 TP0] Decode batch. #running-req: 9, #token: 2128, token usage: 0.00, gen throughput (token/s): 1678.13, largest-len: 0, #queue-req: 0, 
[2025-08-25 17:28:14 TP0] Decode batch. #running-req: 9, #token: 2488, token usage: 0.00, gen throughput (token/s): 1599.70, largest-len: 0, #queue-req: 0, 
[2025-08-25 17:28:14] INFO:     127.0.0.1:32374 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 17:28:14] INFO:     127.0.0.1:32348 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 17:28:14] INFO:     127.0.0.1:32364 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 17:28:15 TP0] Decode batch. #running-req: 6, #token: 1315, token usage: 0.00, gen throughput (token/s): 1399.35, largest-len: 0, #queue-req: 0, 
[2025-08-25 17:28:15 TP0] Prefill batch. #new-seq: 5, #new-token: 5, #cached-token: 1260, token usage: 0.00, #running-req: 6, #queue-req: 0, 
[2025-08-25 17:28:15 TP0] Decode batch. #running-req: 11, #token: 1730, token usage: 0.00, gen throughput (token/s): 1382.21, largest-len: 0, #queue-req: 0, 
[2025-08-25 17:28:15 TP0] Decode batch. #running-req: 11, #token: 2170, token usage: 0.00, gen throughput (token/s): 2085.05, largest-len: 0, #queue-req: 0, 
[2025-08-25 17:28:15 TP0] Decode batch. #running-req: 11, #token: 2610, token usage: 0.00, gen throughput (token/s): 1998.11, largest-len: 0, #queue-req: 0, 
[2025-08-25 17:28:15 TP0] Decode batch. #running-req: 11, #token: 3050, token usage: 0.00, gen throughput (token/s): 1950.41, largest-len: 0, #queue-req: 0, 
[2025-08-25 17:28:16 TP0] Decode batch. #running-req: 11, #token: 3490, token usage: 0.00, gen throughput (token/s): 1988.08, largest-len: 0, #queue-req: 0, 
[2025-08-25 17:28:16 TP0] Prefill batch. #new-seq: 3, #new-token: 227, #cached-token: 354, token usage: 0.00, #running-req: 11, #queue-req: 0, 
[2025-08-25 17:28:16 TP0] Prefill batch. #new-seq: 2, #new-token: 114, #cached-token: 303, token usage: 0.00, #running-req: 14, #queue-req: 0, 
[2025-08-25 17:28:16 TP0] Decode batch. #running-req: 16, #token: 4219, token usage: 0.00, gen throughput (token/s): 2165.13, largest-len: 0, #queue-req: 0, 
[2025-08-25 17:28:16 TP0] Decode batch. #running-req: 16, #token: 4859, token usage: 0.00, gen throughput (token/s): 3172.44, largest-len: 0, #queue-req: 0, 
[2025-08-25 17:28:16 TP0] Decode batch. #running-req: 16, #token: 5499, token usage: 0.00, gen throughput (token/s): 3107.31, largest-len: 0, #queue-req: 0, 
[2025-08-25 17:28:16] INFO:     127.0.0.1:32308 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 17:28:16] INFO:     127.0.0.1:32314 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 17:28:16] INFO:     127.0.0.1:32284 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 17:28:16] INFO:     127.0.0.1:32294 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 17:28:16] INFO:     127.0.0.1:32320 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 17:28:16] INFO:     127.0.0.1:32380 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 17:28:17 TP0] Decode batch. #running-req: 10, #token: 2917, token usage: 0.00, gen throughput (token/s): 2014.40, largest-len: 0, #queue-req: 0, 
[2025-08-25 17:28:17 TP0] Decode batch. #running-req: 10, #token: 3317, token usage: 0.00, gen throughput (token/s): 2028.47, largest-len: 0, #queue-req: 0, 
[2025-08-25 17:28:17 TP0] Decode batch. #running-req: 10, #token: 3717, token usage: 0.00, gen throughput (token/s): 1789.58, largest-len: 0, #queue-req: 0, 
[2025-08-25 17:28:17 TP0] Decode batch. #running-req: 10, #token: 4117, token usage: 0.00, gen throughput (token/s): 1886.80, largest-len: 0, #queue-req: 0, 
[2025-08-25 17:28:17] INFO:     127.0.0.1:32348 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 17:28:17] INFO:     127.0.0.1:32346 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 17:28:17] INFO:     127.0.0.1:32364 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 17:28:17] INFO:     127.0.0.1:32374 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 17:28:17] INFO:     127.0.0.1:32332 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 17:28:17 TP0] Decode batch. #running-req: 5, #token: 1942, token usage: 0.00, gen throughput (token/s): 1406.82, largest-len: 0, #queue-req: 0, 
[2025-08-25 17:28:18 TP0] Decode batch. #running-req: 5, #token: 2142, token usage: 0.00, gen throughput (token/s): 937.76, largest-len: 0, #queue-req: 0, 
[2025-08-25 17:28:18 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 163, token usage: 0.00, #running-req: 5, #queue-req: 0, 
[2025-08-25 17:28:18 TP0] Prefill batch. #new-seq: 5, #new-token: 5, #cached-token: 815, token usage: 0.00, #running-req: 6, #queue-req: 0, 
[2025-08-25 17:28:18 TP0] Decode batch. #running-req: 11, #token: 2564, token usage: 0.00, gen throughput (token/s): 1254.19, largest-len: 0, #queue-req: 0, 
[2025-08-25 17:28:18 TP0] Decode batch. #running-req: 11, #token: 3004, token usage: 0.00, gen throughput (token/s): 1982.52, largest-len: 0, #queue-req: 0, 
[2025-08-25 17:28:18 TP0] Decode batch. #running-req: 11, #token: 3444, token usage: 0.00, gen throughput (token/s): 1907.45, largest-len: 0, #queue-req: 0, 
[2025-08-25 17:28:19] INFO:     127.0.0.1:32402 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 17:28:19] INFO:     127.0.0.1:32412 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 17:28:19] INFO:     127.0.0.1:32386 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 17:28:19] INFO:     127.0.0.1:32428 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 17:28:19] INFO:     127.0.0.1:32384 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 17:28:19 TP0] Decode batch. #running-req: 6, #token: 1106, token usage: 0.00, gen throughput (token/s): 1552.01, largest-len: 0, #queue-req: 0, 
[2025-08-25 17:28:19 TP0] Prefill batch. #new-seq: 3, #new-token: 3, #cached-token: 489, token usage: 0.00, #running-req: 6, #queue-req: 0, 
[2025-08-25 17:28:19 TP0] Prefill batch. #new-seq: 2, #new-token: 2, #cached-token: 326, token usage: 0.00, #running-req: 9, #queue-req: 0, 
[2025-08-25 17:28:19 TP0] Decode batch. #running-req: 11, #token: 1466, token usage: 0.00, gen throughput (token/s): 1199.09, largest-len: 0, #queue-req: 0, 
[2025-08-25 17:28:19 TP0] Decode batch. #running-req: 11, #token: 1906, token usage: 0.00, gen throughput (token/s): 1839.17, largest-len: 0, #queue-req: 0, 
[2025-08-25 17:28:19 TP0] Decode batch. #running-req: 11, #token: 2346, token usage: 0.00, gen throughput (token/s): 1956.39, largest-len: 0, #queue-req: 0, 
[2025-08-25 17:28:20 TP0] Decode batch. #running-req: 11, #token: 2786, token usage: 0.00, gen throughput (token/s): 1977.98, largest-len: 0, #queue-req: 0, 
[2025-08-25 17:28:20 TP0] Prefill batch. #new-seq: 5, #new-token: 251, #cached-token: 476, token usage: 0.00, #running-req: 11, #queue-req: 0, 
[2025-08-25 17:28:20 TP0] Decode batch. #running-req: 16, #token: 3344, token usage: 0.00, gen throughput (token/s): 1729.49, largest-len: 0, #queue-req: 0, 
[2025-08-25 17:28:20 TP0] Decode batch. #running-req: 16, #token: 3984, token usage: 0.00, gen throughput (token/s): 2816.52, largest-len: 0, #queue-req: 0, 
[2025-08-25 17:28:20 TP0] Decode batch. #running-req: 16, #token: 4624, token usage: 0.00, gen throughput (token/s): 2726.06, largest-len: 0, #queue-req: 0, 
[2025-08-25 17:28:21 TP0] Decode batch. #running-req: 16, #token: 5264, token usage: 0.00, gen throughput (token/s): 2552.51, largest-len: 0, #queue-req: 0, 
[2025-08-25 17:28:21] INFO:     127.0.0.1:32284 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 17:28:21] INFO:     127.0.0.1:32294 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 17:28:21] INFO:     127.0.0.1:32320 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 17:28:21] INFO:     127.0.0.1:32314 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 17:28:21] INFO:     127.0.0.1:32308 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 17:28:21] INFO:     127.0.0.1:32332 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 17:28:21 TP0] Decode batch. #running-req: 10, #token: 2802, token usage: 0.00, gen throughput (token/s): 2482.62, largest-len: 0, #queue-req: 0, 
[2025-08-25 17:28:21 TP0] Decode batch. #running-req: 10, #token: 3202, token usage: 0.00, gen throughput (token/s): 1954.29, largest-len: 0, #queue-req: 0, 
[2025-08-25 17:28:21 TP0] Decode batch. #running-req: 10, #token: 3602, token usage: 0.00, gen throughput (token/s): 1751.08, largest-len: 0, #queue-req: 0, 
[2025-08-25 17:28:22 TP0] Decode batch. #running-req: 10, #token: 4002, token usage: 0.00, gen throughput (token/s): 1744.88, largest-len: 0, #queue-req: 0, 
[2025-08-25 17:28:22] INFO:     127.0.0.1:32348 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 17:28:22] INFO:     127.0.0.1:32364 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 17:28:22] INFO:     127.0.0.1:32346 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 17:28:22] INFO:     127.0.0.1:32374 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 17:28:22] INFO:     127.0.0.1:32380 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 17:28:22 TP0] Decode batch. #running-req: 5, #token: 1882, token usage: 0.00, gen throughput (token/s): 1583.93, largest-len: 0, #queue-req: 0, 
[2025-08-25 17:28:22 TP0] Prefill batch. #new-seq: 4, #new-token: 4, #cached-token: 528, token usage: 0.00, #running-req: 5, #queue-req: 0, 
[2025-08-25 17:28:22 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 132, token usage: 0.00, #running-req: 9, #queue-req: 0, 
[2025-08-25 17:28:22 TP0] Decode batch. #running-req: 10, #token: 2167, token usage: 0.00, gen throughput (token/s): 844.30, largest-len: 0, #queue-req: 0, 
[2025-08-25 17:28:22 TP0] Decode batch. #running-req: 10, #token: 2567, token usage: 0.00, gen throughput (token/s): 1513.20, largest-len: 0, #queue-req: 0, 
[2025-08-25 17:28:23 TP0] Decode batch. #running-req: 10, #token: 2967, token usage: 0.00, gen throughput (token/s): 1754.15, largest-len: 0, #queue-req: 0, 
[2025-08-25 17:28:23 TP0] Decode batch. #running-req: 10, #token: 3367, token usage: 0.00, gen throughput (token/s): 1703.97, largest-len: 0, #queue-req: 0, 
[2025-08-25 17:28:23] INFO:     127.0.0.1:32384 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 17:28:23] INFO:     127.0.0.1:32386 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 17:28:23] INFO:     127.0.0.1:32402 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 17:28:23] INFO:     127.0.0.1:32412 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 17:28:23] INFO:     127.0.0.1:32428 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 17:28:23 TP0] Decode batch. #running-req: 5, #token: 1018, token usage: 0.00, gen throughput (token/s): 1139.37, largest-len: 0, #queue-req: 0, 
[2025-08-25 17:28:23 TP0] Prefill batch. #new-seq: 6, #new-token: 6, #cached-token: 792, token usage: 0.00, #running-req: 5, #queue-req: 0, 
[2025-08-25 17:28:23 TP0] Decode batch. #running-req: 11, #token: 1302, token usage: 0.00, gen throughput (token/s): 900.06, largest-len: 0, #queue-req: 0, 
[2025-08-25 17:28:24 TP0] Decode batch. #running-req: 11, #token: 1742, token usage: 0.00, gen throughput (token/s): 1844.17, largest-len: 0, #queue-req: 0, 
[2025-08-25 17:28:24 TP0] Decode batch. #running-req: 11, #token: 2182, token usage: 0.00, gen throughput (token/s): 1901.20, largest-len: 0, #queue-req: 0, 
[2025-08-25 17:28:24 TP0] Decode batch. #running-req: 11, #token: 2622, token usage: 0.00, gen throughput (token/s): 1975.74, largest-len: 0, #queue-req: 0, 
[2025-08-25 17:28:24 TP0] Decode batch. #running-req: 11, #token: 3062, token usage: 0.00, gen throughput (token/s): 2058.41, largest-len: 0, #queue-req: 0, 
[2025-08-25 17:28:24 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 132, token usage: 0.00, #running-req: 11, #queue-req: 0, 
[2025-08-25 17:28:24 TP0] Prefill batch. #new-seq: 4, #new-token: 388, #cached-token: 288, token usage: 0.00, #running-req: 12, #queue-req: 0, 
[2025-08-25 17:28:25 TP0] Decode batch. #running-req: 16, #token: 3748, token usage: 0.00, gen throughput (token/s): 1755.96, largest-len: 0, #queue-req: 0, 
[2025-08-25 17:28:25 TP0] Decode batch. #running-req: 16, #token: 4388, token usage: 0.00, gen throughput (token/s): 2964.17, largest-len: 0, #queue-req: 0, 
[2025-08-25 17:28:25 TP0] Decode batch. #running-req: 16, #token: 5028, token usage: 0.00, gen throughput (token/s): 3146.08, largest-len: 0, #queue-req: 0, 
[2025-08-25 17:28:25] INFO:     127.0.0.1:32284 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 17:28:25] INFO:     127.0.0.1:32294 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 17:28:25] INFO:     127.0.0.1:32308 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 17:28:25] INFO:     127.0.0.1:32314 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 17:28:25] INFO:     127.0.0.1:32320 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 17:28:25 TP0] Decode batch. #running-req: 11, #token: 2983, token usage: 0.00, gen throughput (token/s): 2120.25, largest-len: 0, #queue-req: 0, 
[2025-08-25 17:28:25 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 180, token usage: 0.00, #running-req: 11, #queue-req: 0, 
[2025-08-25 17:28:25 TP0] Decode batch. #running-req: 12, #token: 3456, token usage: 0.00, gen throughput (token/s): 1929.19, largest-len: 0, #queue-req: 0, 
[2025-08-25 17:28:26 TP0] Decode batch. #running-req: 12, #token: 3936, token usage: 0.00, gen throughput (token/s): 2092.44, largest-len: 0, #queue-req: 0, 
[2025-08-25 17:28:26 TP0] Decode batch. #running-req: 12, #token: 4416, token usage: 0.00, gen throughput (token/s): 2129.63, largest-len: 0, #queue-req: 0, 
[2025-08-25 17:28:26 TP0] Decode batch. #running-req: 12, #token: 4896, token usage: 0.00, gen throughput (token/s): 2159.73, largest-len: 0, #queue-req: 0, 
[2025-08-25 17:28:26] INFO:     127.0.0.1:32346 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 17:28:26] INFO:     127.0.0.1:32364 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 17:28:26] INFO:     127.0.0.1:32332 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 17:28:26] INFO:     127.0.0.1:32380 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 17:28:26] INFO:     127.0.0.1:32348 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 17:28:26] INFO:     127.0.0.1:32374 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 17:28:26 TP0] Prefill batch. #new-seq: 4, #new-token: 4, #cached-token: 720, token usage: 0.00, #running-req: 6, #queue-req: 0, 
[2025-08-25 17:28:26 TP0] Decode batch. #running-req: 10, #token: 2304, token usage: 0.00, gen throughput (token/s): 1315.62, largest-len: 0, #queue-req: 0, 
[2025-08-25 17:28:27 TP0] Decode batch. #running-req: 10, #token: 2704, token usage: 0.00, gen throughput (token/s): 1750.03, largest-len: 0, #queue-req: 0, 
[2025-08-25 17:28:27 TP0] Decode batch. #running-req: 10, #token: 3104, token usage: 0.00, gen throughput (token/s): 1775.48, largest-len: 0, #queue-req: 0, 
[2025-08-25 17:28:27 TP0] Decode batch. #running-req: 10, #token: 3504, token usage: 0.00, gen throughput (token/s): 1768.48, largest-len: 0, #queue-req: 0, 
[2025-08-25 17:28:27] INFO:     127.0.0.1:32384 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 17:28:27] INFO:     127.0.0.1:32386 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 17:28:27] INFO:     127.0.0.1:32402 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 17:28:27] INFO:     127.0.0.1:32428 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 17:28:27] INFO:     127.0.0.1:32412 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 17:28:27 TP0] Decode batch. #running-req: 5, #token: 1306, token usage: 0.00, gen throughput (token/s): 1503.02, largest-len: 0, #queue-req: 0, 
[2025-08-25 17:28:28 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 180, token usage: 0.00, #running-req: 5, #queue-req: 0, 
[2025-08-25 17:28:28 TP0] Decode batch. #running-req: 5, #token: 1502, token usage: 0.00, gen throughput (token/s): 898.16, largest-len: 0, #queue-req: 0, 
[2025-08-25 17:28:28 TP0] Prefill batch. #new-seq: 5, #new-token: 5, #cached-token: 900, token usage: 0.00, #running-req: 6, #queue-req: 0, 
[2025-08-25 17:28:28 TP0] Decode batch. #running-req: 11, #token: 1952, token usage: 0.00, gen throughput (token/s): 1730.77, largest-len: 0, #queue-req: 0, 
[2025-08-25 17:28:28 TP0] Decode batch. #running-req: 11, #token: 2392, token usage: 0.00, gen throughput (token/s): 1916.65, largest-len: 0, #queue-req: 0, 
[2025-08-25 17:28:28] INFO:     127.0.0.1:32284 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 17:28:28 TP0] Decode batch. #running-req: 10, #token: 2319, token usage: 0.00, gen throughput (token/s): 1796.27, largest-len: 0, #queue-req: 0, 
[2025-08-25 17:28:29 TP0] Decode batch. #running-req: 10, #token: 2719, token usage: 0.00, gen throughput (token/s): 1649.53, largest-len: 0, #queue-req: 0, 
[2025-08-25 17:28:29 TP0] Prefill batch. #new-seq: 2, #new-token: 156, #cached-token: 104, token usage: 0.00, #running-req: 10, #queue-req: 0, 
[2025-08-25 17:28:29 TP0] Prefill batch. #new-seq: 3, #new-token: 80, #cached-token: 412, token usage: 0.00, #running-req: 12, #queue-req: 0, 
[2025-08-25 17:28:29 TP0] Decode batch. #running-req: 15, #token: 3252, token usage: 0.00, gen throughput (token/s): 1232.75, largest-len: 0, #queue-req: 0, 
[2025-08-25 17:28:29 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 129, token usage: 0.00, #running-req: 15, #queue-req: 0, 
[2025-08-25 17:28:29 TP0] Decode batch. #running-req: 16, #token: 3887, token usage: 0.00, gen throughput (token/s): 2449.26, largest-len: 0, #queue-req: 0, 
[2025-08-25 17:28:29] INFO:     127.0.0.1:32294 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 17:28:29] INFO:     127.0.0.1:32308 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 17:28:29] INFO:     127.0.0.1:32314 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 17:28:29] INFO:     127.0.0.1:32320 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 17:28:29 TP0] Decode batch. #running-req: 12, #token: 2475, token usage: 0.00, gen throughput (token/s): 2581.16, largest-len: 0, #queue-req: 0, 
[2025-08-25 17:28:30 TP0] Decode batch. #running-req: 12, #token: 2955, token usage: 0.00, gen throughput (token/s): 2065.72, largest-len: 0, #queue-req: 0, 
[2025-08-25 17:28:30 TP0] Prefill batch. #new-seq: 2, #new-token: 2, #cached-token: 258, token usage: 0.00, #running-req: 12, #queue-req: 0, 
[2025-08-25 17:28:30 TP0] Decode batch. #running-req: 14, #token: 3469, token usage: 0.00, gen throughput (token/s): 1951.10, largest-len: 0, #queue-req: 0, 
[2025-08-25 17:28:30 TP0] Decode batch. #running-req: 14, #token: 4029, token usage: 0.00, gen throughput (token/s): 2543.40, largest-len: 0, #queue-req: 0, 
[2025-08-25 17:28:30 TP0] Prefill batch. #new-seq: 2, #new-token: 2, #cached-token: 258, token usage: 0.00, #running-req: 14, #queue-req: 0, 
[2025-08-25 17:28:30 TP0] Decode batch. #running-req: 16, #token: 4639, token usage: 0.00, gen throughput (token/s): 2367.11, largest-len: 0, #queue-req: 0, 
[2025-08-25 17:28:31 TP0] Decode batch. #running-req: 16, #token: 5279, token usage: 0.00, gen throughput (token/s): 2925.51, largest-len: 0, #queue-req: 0, 
[2025-08-25 17:28:31] INFO:     127.0.0.1:32332 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 17:28:31] INFO:     127.0.0.1:32346 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 17:28:31] INFO:     127.0.0.1:32348 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 17:28:31] INFO:     127.0.0.1:32364 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 17:28:31] INFO:     127.0.0.1:32374 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 17:28:31] INFO:     127.0.0.1:32380 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 17:28:31 TP0] Decode batch. #running-req: 10, #token: 2793, token usage: 0.00, gen throughput (token/s): 2218.36, largest-len: 0, #queue-req: 0, 
[2025-08-25 17:28:31 TP0] Decode batch. #running-req: 10, #token: 3193, token usage: 0.00, gen throughput (token/s): 1650.85, largest-len: 0, #queue-req: 0, 
[2025-08-25 17:28:31 TP0] Decode batch. #running-req: 10, #token: 3593, token usage: 0.00, gen throughput (token/s): 1847.87, largest-len: 0, #queue-req: 0, 
[2025-08-25 17:28:32 TP0] Decode batch. #running-req: 10, #token: 3993, token usage: 0.00, gen throughput (token/s): 1763.52, largest-len: 0, #queue-req: 0, 
[2025-08-25 17:28:32 TP0] Decode batch. #running-req: 10, #token: 4393, token usage: 0.00, gen throughput (token/s): 1827.76, largest-len: 0, #queue-req: 0, 
[2025-08-25 17:28:32] INFO:     127.0.0.1:32384 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 17:28:32] INFO:     127.0.0.1:32386 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 17:28:32] INFO:     127.0.0.1:32402 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 17:28:32] INFO:     127.0.0.1:32412 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 17:28:32] INFO:     127.0.0.1:32284 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 17:28:32] INFO:     127.0.0.1:32428 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 17:28:32 TP0] Decode batch. #running-req: 4, #token: 1494, token usage: 0.00, gen throughput (token/s): 1026.32, largest-len: 0, #queue-req: 0, 
[2025-08-25 17:28:32 TP0] Prefill batch. #new-seq: 6, #new-token: 6, #cached-token: 774, token usage: 0.00, #running-req: 4, #queue-req: 0, 
[2025-08-25 17:28:32 TP0] Decode batch. #running-req: 10, #token: 1828, token usage: 0.00, gen throughput (token/s): 1032.92, largest-len: 0, #queue-req: 0, 
[2025-08-25 17:28:33 TP0] Decode batch. #running-req: 10, #token: 2228, token usage: 0.00, gen throughput (token/s): 1850.09, largest-len: 0, #queue-req: 0, 
[2025-08-25 17:28:33 TP0] Decode batch. #running-req: 10, #token: 2628, token usage: 0.00, gen throughput (token/s): 1927.71, largest-len: 0, #queue-req: 0, 
[2025-08-25 17:28:33] INFO:     127.0.0.1:32308 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 17:28:33] INFO:     127.0.0.1:32294 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 17:28:33 TP0] Decode batch. #running-req: 8, #token: 1954, token usage: 0.00, gen throughput (token/s): 1523.09, largest-len: 0, #queue-req: 0, 
[2025-08-25 17:28:33] INFO:     127.0.0.1:32314 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 17:28:33] INFO:     127.0.0.1:32320 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 17:28:33 TP0] Decode batch. #running-req: 6, #token: 1264, token usage: 0.00, gen throughput (token/s): 1461.39, largest-len: 0, #queue-req: 0, 
[2025-08-25 17:28:33 TP0] Decode batch. #running-req: 6, #token: 1504, token usage: 0.00, gen throughput (token/s): 994.12, largest-len: 0, #queue-req: 0, 
[2025-08-25 17:28:34 TP0] Prefill batch. #new-seq: 2, #new-token: 2, #cached-token: 258, token usage: 0.00, #running-req: 6, #queue-req: 0, 
[2025-08-25 17:28:34 TP0] Decode batch. #running-req: 8, #token: 1786, token usage: 0.00, gen throughput (token/s): 974.27, largest-len: 0, #queue-req: 0, 
[2025-08-25 17:28:34 TP0] Decode batch. #running-req: 8, #token: 2106, token usage: 0.00, gen throughput (token/s): 1587.80, largest-len: 0, #queue-req: 0, 
[2025-08-25 17:28:34 TP0] Decode batch. #running-req: 8, #token: 2426, token usage: 0.00, gen throughput (token/s): 1569.67, largest-len: 0, #queue-req: 0, 
[2025-08-25 17:28:34 TP0] Decode batch. #running-req: 8, #token: 2746, token usage: 0.00, gen throughput (token/s): 1523.42, largest-len: 0, #queue-req: 0, 
[2025-08-25 17:28:35 TP0] Decode batch. #running-req: 8, #token: 3066, token usage: 0.00, gen throughput (token/s): 1535.51, largest-len: 0, #queue-req: 0, 
[2025-08-25 17:28:35 TP0] Decode batch. #running-req: 8, #token: 3386, token usage: 0.00, gen throughput (token/s): 1596.63, largest-len: 0, #queue-req: 0, 
[2025-08-25 17:28:35] INFO:     127.0.0.1:32346 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 17:28:35] INFO:     127.0.0.1:32348 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 17:28:35] INFO:     127.0.0.1:32364 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 17:28:35] INFO:     127.0.0.1:32374 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 17:28:35] INFO:     127.0.0.1:32332 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 17:28:35] INFO:     127.0.0.1:32284 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 17:28:35 TP0] Decode batch. #running-req: 2, #token: 652, token usage: 0.00, gen throughput (token/s): 1284.30, largest-len: 0, #queue-req: 0, 
[2025-08-25 17:28:35 TP0] Decode batch. #running-req: 2, #token: 732, token usage: 0.00, gen throughput (token/s): 399.86, largest-len: 0, #queue-req: 0, 
[2025-08-25 17:28:35 TP0] Decode batch. #running-req: 2, #token: 812, token usage: 0.00, gen throughput (token/s): 406.70, largest-len: 0, #queue-req: 0, 
[2025-08-25 17:28:36 TP0] Decode batch. #running-req: 2, #token: 892, token usage: 0.00, gen throughput (token/s): 406.98, largest-len: 0, #queue-req: 0, 
[2025-08-25 17:28:36 TP0] Decode batch. #running-req: 2, #token: 972, token usage: 0.00, gen throughput (token/s): 388.98, largest-len: 0, #queue-req: 0, 
[2025-08-25 17:28:36 TP0] Decode batch. #running-req: 2, #token: 1052, token usage: 0.00, gen throughput (token/s): 398.78, largest-len: 0, #queue-req: 0, 
[2025-08-25 17:28:36] INFO:     127.0.0.1:32308 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 17:28:36] INFO:     127.0.0.1:32294 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[2025-08-25 17:28:36 TP0] Decode batch. #running-req: 0, #token: 0, token usage: 0.00, gen throughput (token/s): 391.08, largest-len: 0, #queue-req: 0, 
[2025-08-25 17:28:39] SIGTERM received. signum=None frame=None. Draining requests and shutting down...
[2025-08-25 17:28:44] Gracefully exiting... remaining number of requests 0
